Directory structure:
└── ax-llm-ax/
    ├── README.md
    ├── CHANGELOG.md
    ├── cspell.json
    ├── eslint.config.js
    ├── LICENSE
    ├── OPTIMIZE.md
    ├── package.json
    ├── SECURITY.md
    ├── tsconfig.json
    ├── typedoc.json
    ├── .editorconfig
    ├── .node-version
    ├── .prettierrc
    ├── .release-it.json
    ├── scripts/
    │   ├── README.md
    │   ├── clean.js
    │   ├── customFrontmatter.mjs
    │   ├── generateIndex.ts
    │   ├── initPackage.js
    │   └── postbuild.js
    ├── src/
    │   ├── ai-sdk-provider/
    │   │   ├── README.md
    │   │   ├── index.test.ts
    │   │   ├── index.ts
    │   │   ├── package.json
    │   │   ├── provider.ts
    │   │   ├── tsconfig.json
    │   │   ├── tsup.config.ts
    │   │   ├── util.ts
    │   │   ├── .prettierignore
    │   │   └── .release-it.json
    │   ├── ax/
    │   │   ├── index.test-d.ts
    │   │   ├── index.ts
    │   │   ├── package.json
    │   │   ├── tsconfig.json
    │   │   ├── tsup.config.ts
    │   │   ├── typedoc.json
    │   │   ├── .prettierignore
    │   │   ├── .release-it.json
    │   │   ├── ai/
    │   │   │   ├── balance.test.ts
    │   │   │   ├── balance.ts
    │   │   │   ├── base.test.ts
    │   │   │   ├── base.ts
    │   │   │   ├── debug.ts
    │   │   │   ├── logger.test.ts
    │   │   │   ├── multiservice.test.ts
    │   │   │   ├── multiservice.ts
    │   │   │   ├── types.ts
    │   │   │   ├── util.ts
    │   │   │   ├── wrap.ts
    │   │   │   ├── anthropic/
    │   │   │   │   ├── api.ts
    │   │   │   │   ├── info.ts
    │   │   │   │   └── types.ts
    │   │   │   ├── azure-openai/
    │   │   │   │   └── api.ts
    │   │   │   ├── cohere/
    │   │   │   │   ├── api.ts
    │   │   │   │   ├── info.ts
    │   │   │   │   └── types.ts
    │   │   │   ├── deepseek/
    │   │   │   │   ├── api.ts
    │   │   │   │   ├── info.ts
    │   │   │   │   └── types.ts
    │   │   │   ├── google-gemini/
    │   │   │   │   ├── api.ts
    │   │   │   │   ├── info.ts
    │   │   │   │   └── types.ts
    │   │   │   ├── google-vertex/
    │   │   │   │   └── auth.ts
    │   │   │   ├── groq/
    │   │   │   │   ├── api.ts
    │   │   │   │   ├── info.ts
    │   │   │   │   └── types.ts
    │   │   │   ├── huggingface/
    │   │   │   │   ├── api.ts
    │   │   │   │   ├── info.ts
    │   │   │   │   └── types.ts
    │   │   │   ├── mistral/
    │   │   │   │   ├── api.ts
    │   │   │   │   ├── info.ts
    │   │   │   │   └── types.ts
    │   │   │   ├── mock/
    │   │   │   │   └── api.ts
    │   │   │   ├── ollama/
    │   │   │   │   └── api.ts
    │   │   │   ├── openai/
    │   │   │   │   ├── api.ts
    │   │   │   │   ├── chat_types.ts
    │   │   │   │   ├── info.ts
    │   │   │   │   ├── responses_api.ts
    │   │   │   │   ├── responses_api_base.ts
    │   │   │   │   └── responses_types.ts
    │   │   │   ├── reka/
    │   │   │   │   ├── api.ts
    │   │   │   │   ├── info.ts
    │   │   │   │   └── types.ts
    │   │   │   ├── together/
    │   │   │   │   ├── api.ts
    │   │   │   │   └── info.ts
    │   │   │   └── x-grok/
    │   │   │       ├── api.ts
    │   │   │       ├── info.ts
    │   │   │       └── types.ts
    │   │   ├── db/
    │   │   │   ├── base.ts
    │   │   │   ├── cloudflare.ts
    │   │   │   ├── memory.ts
    │   │   │   ├── pinecone.ts
    │   │   │   ├── types.ts
    │   │   │   ├── weaviate.ts
    │   │   │   └── wrap.ts
    │   │   ├── docs/
    │   │   │   ├── manager.ts
    │   │   │   ├── reranker.ts
    │   │   │   ├── rewriter.ts
    │   │   │   └── tika.ts
    │   │   ├── dsp/
    │   │   │   ├── asserts.ts
    │   │   │   ├── classifier.ts
    │   │   │   ├── datetime.test.ts
    │   │   │   ├── datetime.ts
    │   │   │   ├── eval.ts
    │   │   │   ├── evaluate.ts
    │   │   │   ├── extract.test.ts
    │   │   │   ├── extract.ts
    │   │   │   ├── fieldProcessor.test.ts
    │   │   │   ├── fieldProcessor.ts
    │   │   │   ├── functions.ts
    │   │   │   ├── generate.test.ts
    │   │   │   ├── generate.ts
    │   │   │   ├── globals.ts
    │   │   │   ├── jsonschema.ts
    │   │   │   ├── loader.ts
    │   │   │   ├── modelinfo.test.ts
    │   │   │   ├── modelinfo.ts
    │   │   │   ├── optimizer.test.ts
    │   │   │   ├── optimizer.ts
    │   │   │   ├── parser.test.ts
    │   │   │   ├── parser.ts
    │   │   │   ├── program.ts
    │   │   │   ├── prompt.test.ts
    │   │   │   ├── prompt.ts
    │   │   │   ├── registry.ts
    │   │   │   ├── sig.test.ts
    │   │   │   ├── sig.ts
    │   │   │   ├── stopwords.ts
    │   │   │   ├── strutil.ts
    │   │   │   ├── template.test.ts
    │   │   │   ├── template.ts
    │   │   │   ├── types.ts
    │   │   │   ├── util.test.ts
    │   │   │   ├── util.ts
    │   │   │   ├── validate.ts
    │   │   │   └── optimizers/
    │   │   │       ├── bootstrapFewshot.ts
    │   │   │       └── miproV2.ts
    │   │   ├── funcs/
    │   │   │   ├── code.ts
    │   │   │   ├── docker.ts
    │   │   │   └── embed.ts
    │   │   ├── mcp/
    │   │   │   ├── client.test.ts
    │   │   │   ├── client.ts
    │   │   │   ├── httpTransport.ts
    │   │   │   ├── stdioTransport.ts
    │   │   │   ├── transport.ts
    │   │   │   └── types.ts
    │   │   ├── mem/
    │   │   │   ├── memory.test.ts
    │   │   │   ├── memory.ts
    │   │   │   └── types.ts
    │   │   ├── prompts/
    │   │   │   ├── agent.test.ts
    │   │   │   ├── agent.ts
    │   │   │   ├── cot.ts
    │   │   │   ├── prompts.test.ts
    │   │   │   └── rag.ts
    │   │   ├── trace/
    │   │   │   └── trace.ts
    │   │   └── util/
    │   │       ├── apicall.ts
    │   │       ├── log.ts
    │   │       ├── other.ts
    │   │       ├── rate-limit.ts
    │   │       ├── sse.ts
    │   │       ├── stream.ts
    │   │       └── transform.ts
    │   ├── docs/
    │   │   ├── abort-requests.md
    │   │   ├── astro.config.mjs
    │   │   ├── package.json
    │   │   ├── tailwind.config.mjs
    │   │   ├── tsconfig.json
    │   │   ├── .gitignore
    │   │   ├── src/
    │   │   │   ├── env.d.ts
    │   │   │   ├── components/
    │   │   │   │   ├── Footer.astro
    │   │   │   │   ├── Header.astro
    │   │   │   │   └── Navigation.astro
    │   │   │   ├── content/
    │   │   │   │   ├── config.ts
    │   │   │   │   └── docs/
    │   │   │   │       ├── index.mdx
    │   │   │   │       ├── .gitignore
    │   │   │   │       ├── 02-guides/
    │   │   │   │       │   ├── 01-dsp.md
    │   │   │   │       │   ├── 02-functions.md
    │   │   │   │       │   └── 03-tuning.md
    │   │   │   │       └── 03-apidocs/
    │   │   │   │           ├── README.md
    │   │   │   │           ├── Class.AxAgent.md
    │   │   │   │           ├── Class.AxAI.md
    │   │   │   │           ├── Class.AxAIAnthropic.md
    │   │   │   │           ├── Class.AxAIAzureOpenAI.md
    │   │   │   │           ├── Class.AxAICohere.md
    │   │   │   │           ├── Class.AxAIDeepSeek.md
    │   │   │   │           ├── Class.AxAIGoogleGemini.md
    │   │   │   │           ├── Class.AxAIGroq.md
    │   │   │   │           ├── Class.AxAIHuggingFace.md
    │   │   │   │           ├── Class.AxAIMistral.md
    │   │   │   │           ├── Class.AxAIOllama.md
    │   │   │   │           ├── Class.AxAIOpenAI.md
    │   │   │   │           ├── Class.AxAIReka.md
    │   │   │   │           ├── Class.AxAITogether.md
    │   │   │   │           ├── Class.AxApacheTika.md
    │   │   │   │           ├── Class.AxAssertionError.md
    │   │   │   │           ├── Class.AxBalancer.md
    │   │   │   │           ├── Class.AxBaseAI.md
    │   │   │   │           ├── Class.AxBootstrapFewShot.md
    │   │   │   │           ├── Class.AxChainOfThought.md
    │   │   │   │           ├── Class.AxDB.md
    │   │   │   │           ├── Class.AxDBBase.md
    │   │   │   │           ├── Class.AxDBCloudflare.md
    │   │   │   │           ├── Class.AxDBManager.md
    │   │   │   │           ├── Class.AxDBMemory.md
    │   │   │   │           ├── Class.AxDBPinecone.md
    │   │   │   │           ├── Class.AxDBWeaviate.md
    │   │   │   │           ├── Class.AxDefaultQueryRewriter.md
    │   │   │   │           ├── Class.AxDefaultResultReranker.md
    │   │   │   │           ├── Class.AxDockerSession.md
    │   │   │   │           ├── Class.AxEmbeddingAdapter.md
    │   │   │   │           ├── Class.AxFunctionProcessor.md
    │   │   │   │           ├── Class.AxGen.md
    │   │   │   │           ├── Class.AxHFDataLoader.md
    │   │   │   │           ├── Class.AxInstanceRegistry.md
    │   │   │   │           ├── Class.AxJSInterpreter.md
    │   │   │   │           ├── Class.AxMemory.md
    │   │   │   │           ├── Class.AxProgram.md
    │   │   │   │           ├── Class.AxProgramWithSignature.md
    │   │   │   │           ├── Class.AxPromptTemplate.md
    │   │   │   │           ├── Class.AxRAG.md
    │   │   │   │           ├── Class.AxRateLimiterTokenUsage.md
    │   │   │   │           ├── Class.AxSignature.md
    │   │   │   │           ├── Class.AxTestPrompt.md
    │   │   │   │           ├── Enumeration.AxAIAnthropicModel.md
    │   │   │   │           ├── Enumeration.AxAICohereEmbedModel.md
    │   │   │   │           ├── Enumeration.AxAICohereModel.md
    │   │   │   │           ├── Enumeration.AxAIDeepSeekModel.md
    │   │   │   │           ├── Enumeration.AxAIGoogleGeminiEmbedModel.md
    │   │   │   │           ├── Enumeration.AxAIGoogleGeminiModel.md
    │   │   │   │           ├── Enumeration.AxAIGoogleGeminiSafetyCategory.md
    │   │   │   │           ├── Enumeration.AxAIGoogleGeminiSafetyThreshold.md
    │   │   │   │           ├── Enumeration.AxAIGroqModel.md
    │   │   │   │           ├── Enumeration.AxAIHuggingFaceModel.md
    │   │   │   │           ├── Enumeration.AxAIMistralEmbedModels.md
    │   │   │   │           ├── Enumeration.AxAIMistralModel.md
    │   │   │   │           ├── Enumeration.AxAIOpenAIEmbedModel.md
    │   │   │   │           ├── Enumeration.AxAIOpenAIModel.md
    │   │   │   │           ├── Enumeration.AxAIRekaModel.md
    │   │   │   │           ├── Enumeration.AxJSInterpreterPermission.md
    │   │   │   │           ├── Enumeration.AxLLMRequestTypeValues.md
    │   │   │   │           ├── Enumeration.AxSpanKindValues.md
    │   │   │   │           ├── Interface.AxAgentic.md
    │   │   │   │           ├── Interface.AxAIAnthropicArgs.md
    │   │   │   │           ├── Interface.AxAIAnthropicContentBlockDeltaEvent.md
    │   │   │   │           ├── Interface.AxAIAnthropicContentBlockStartEvent.md
    │   │   │   │           ├── Interface.AxAIAnthropicContentBlockStopEvent.md
    │   │   │   │           ├── Interface.AxAIAnthropicErrorEvent.md
    │   │   │   │           ├── Interface.AxAIAnthropicMessageDeltaEvent.md
    │   │   │   │           ├── Interface.AxAIAnthropicMessageStartEvent.md
    │   │   │   │           ├── Interface.AxAIAnthropicMessageStopEvent.md
    │   │   │   │           ├── Interface.AxAIAnthropicPingEvent.md
    │   │   │   │           ├── Interface.AxAICohereArgs.md
    │   │   │   │           ├── Interface.AxAIGoogleGeminiArgs.md
    │   │   │   │           ├── Interface.AxAIGoogleGeminiOptionsTools.md
    │   │   │   │           ├── Interface.AxAIHuggingFaceArgs.md
    │   │   │   │           ├── Interface.AxAIMemory.md
    │   │   │   │           ├── Interface.AxAIOpenAIArgs.md
    │   │   │   │           ├── Interface.AxAIOpenAIResponseDelta.md
    │   │   │   │           ├── Interface.AxAIRekaArgs.md
    │   │   │   │           ├── Interface.AxAIService.md
    │   │   │   │           ├── Interface.AxAIServiceImpl.md
    │   │   │   │           ├── Interface.AxAIServiceMetrics.md
    │   │   │   │           ├── Interface.AxApacheTikaArgs.md
    │   │   │   │           ├── Interface.AxApacheTikaConvertOptions.md
    │   │   │   │           ├── Interface.AxAssertion.md
    │   │   │   │           ├── Interface.AxBaseAIArgs.md
    │   │   │   │           ├── Interface.AxDBBaseArgs.md
    │   │   │   │           ├── Interface.AxDBBaseOpOptions.md
    │   │   │   │           ├── Interface.AxDBCloudflareArgs.md
    │   │   │   │           ├── Interface.AxDBLoaderOptions.md
    │   │   │   │           ├── Interface.AxDBManagerArgs.md
    │   │   │   │           ├── Interface.AxDBMatch.md
    │   │   │   │           ├── Interface.AxDBMemoryArgs.md
    │   │   │   │           ├── Interface.AxDBPineconeArgs.md
    │   │   │   │           ├── Interface.AxDBQueryService.md
    │   │   │   │           ├── Interface.AxDBService.md
    │   │   │   │           ├── Interface.AxDBWeaviateArgs.md
    │   │   │   │           ├── Interface.AxDockerContainer.md
    │   │   │   │           ├── Interface.AxField.md
    │   │   │   │           ├── Interface.AxProgramWithSignatureOptions.md
    │   │   │   │           ├── Interface.AxRateLimiterTokenUsageOptions.md
    │   │   │   │           ├── Interface.AxResponseHandlerArgs.md
    │   │   │   │           ├── Interface.AxStreamingAssertion.md
    │   │   │   │           ├── Interface.AxTunable.md
    │   │   │   │           ├── Interface.AxUsable.md
    │   │   │   │           ├── TypeAlias.AxAgentOptions.md
    │   │   │   │           ├── TypeAlias.AxAIAnthropicChatError.md
    │   │   │   │           ├── TypeAlias.AxAIAnthropicChatRequest.md
    │   │   │   │           ├── TypeAlias.AxAIAnthropicChatRequestCacheParam.md
    │   │   │   │           ├── TypeAlias.AxAIAnthropicChatResponse.md
    │   │   │   │           ├── TypeAlias.AxAIAnthropicChatResponseDelta.md
    │   │   │   │           ├── TypeAlias.AxAIAnthropicConfig.md
    │   │   │   │           ├── TypeAlias.AxAIArgs.md
    │   │   │   │           ├── TypeAlias.AxAICohereChatRequest.md
    │   │   │   │           ├── TypeAlias.AxAICohereChatRequestToolResults.md
    │   │   │   │           ├── TypeAlias.AxAICohereChatResponse.md
    │   │   │   │           ├── TypeAlias.AxAICohereChatResponseDelta.md
    │   │   │   │           ├── TypeAlias.AxAICohereChatResponseToolCalls.md
    │   │   │   │           ├── TypeAlias.AxAICohereConfig.md
    │   │   │   │           ├── TypeAlias.AxAICohereEmbedRequest.md
    │   │   │   │           ├── TypeAlias.AxAICohereEmbedResponse.md
    │   │   │   │           ├── TypeAlias.AxAIEmbedModels.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiBatchEmbedRequest.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiBatchEmbedResponse.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiChatRequest.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiChatResponse.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiChatResponseDelta.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiConfig.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiContent.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiGenerationConfig.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiSafetySettings.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiTool.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiToolConfig.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiToolFunctionDeclaration.md
    │   │   │   │           ├── TypeAlias.AxAIGoogleGeminiToolGoogleSearchRetrieval.md
    │   │   │   │           ├── TypeAlias.AxAIHuggingFaceConfig.md
    │   │   │   │           ├── TypeAlias.AxAIHuggingFaceRequest.md
    │   │   │   │           ├── TypeAlias.AxAIHuggingFaceResponse.md
    │   │   │   │           ├── TypeAlias.AxAIModels.md
    │   │   │   │           ├── TypeAlias.AxAIOllamaAIConfig.md
    │   │   │   │           ├── TypeAlias.AxAIOllamaArgs.md
    │   │   │   │           ├── TypeAlias.AxAIOpenAIChatRequest.md
    │   │   │   │           ├── TypeAlias.AxAIOpenAIChatResponse.md
    │   │   │   │           ├── TypeAlias.AxAIOpenAIChatResponseDelta.md
    │   │   │   │           ├── TypeAlias.AxAIOpenAIConfig.md
    │   │   │   │           ├── TypeAlias.AxAIOpenAIEmbedRequest.md
    │   │   │   │           ├── TypeAlias.AxAIOpenAIEmbedResponse.md
    │   │   │   │           ├── TypeAlias.AxAIOpenAILogprob.md
    │   │   │   │           ├── TypeAlias.AxAIOpenAIUsage.md
    │   │   │   │           ├── TypeAlias.AxAIPromptConfig.md
    │   │   │   │           ├── TypeAlias.AxAIRekaChatRequest.md
    │   │   │   │           ├── TypeAlias.AxAIRekaChatResponse.md
    │   │   │   │           ├── TypeAlias.AxAIRekaChatResponseDelta.md
    │   │   │   │           ├── TypeAlias.AxAIRekaConfig.md
    │   │   │   │           ├── TypeAlias.AxAIRekaUsage.md
    │   │   │   │           ├── TypeAlias.AxAIServiceActionOptions.md
    │   │   │   │           ├── TypeAlias.AxAIServiceOptions.md
    │   │   │   │           ├── TypeAlias.AxBalancerOptions.md
    │   │   │   │           ├── TypeAlias.AxChatRequest.md
    │   │   │   │           ├── TypeAlias.AxChatResponse.md
    │   │   │   │           ├── TypeAlias.AxChatResponseFunctionCall.md
    │   │   │   │           ├── TypeAlias.AxChatResponseResult.md
    │   │   │   │           ├── TypeAlias.AxDataRow.md
    │   │   │   │           ├── TypeAlias.AxDBArgs.md
    │   │   │   │           ├── TypeAlias.AxDBCloudflareOpOptions.md
    │   │   │   │           ├── TypeAlias.AxDBMemoryOpOptions.md
    │   │   │   │           ├── TypeAlias.AxDBPineconeOpOptions.md
    │   │   │   │           ├── TypeAlias.AxDBQueryRequest.md
    │   │   │   │           ├── TypeAlias.AxDBQueryResponse.md
    │   │   │   │           ├── TypeAlias.AxDBState.md
    │   │   │   │           ├── TypeAlias.AxDBUpsertRequest.md
    │   │   │   │           ├── TypeAlias.AxDBUpsertResponse.md
    │   │   │   │           ├── TypeAlias.AxDBWeaviateOpOptions.md
    │   │   │   │           ├── TypeAlias.AxEmbedRequest.md
    │   │   │   │           ├── TypeAlias.AxEmbedResponse.md
    │   │   │   │           ├── TypeAlias.AxEvaluateArgs.md
    │   │   │   │           ├── TypeAlias.AxExample.md
    │   │   │   │           ├── TypeAlias.AxFieldTemplateFn.md
    │   │   │   │           ├── TypeAlias.AxFieldValue.md
    │   │   │   │           ├── TypeAlias.AxFunction.md
    │   │   │   │           ├── TypeAlias.AxFunctionHandler.md
    │   │   │   │           ├── TypeAlias.AxFunctionJSONSchema.md
    │   │   │   │           ├── TypeAlias.AxGenerateResult.md
    │   │   │   │           ├── TypeAlias.AxGenIn.md
    │   │   │   │           ├── TypeAlias.AxGenOut.md
    │   │   │   │           ├── TypeAlias.AxIField.md
    │   │   │   │           ├── TypeAlias.AxInputFunctionType.md
    │   │   │   │           ├── TypeAlias.AxInternalChatRequest.md
    │   │   │   │           ├── TypeAlias.AxInternalEmbedRequest.md
    │   │   │   │           ├── TypeAlias.AxMetricFn.md
    │   │   │   │           ├── TypeAlias.AxMetricFnArgs.md
    │   │   │   │           ├── TypeAlias.AxModelConfig.md
    │   │   │   │           ├── TypeAlias.AxModelInfo.md
    │   │   │   │           ├── TypeAlias.AxModelInfoWithProvider.md
    │   │   │   │           ├── TypeAlias.AxOptimizerArgs.md
    │   │   │   │           ├── TypeAlias.AxProgramDemos.md
    │   │   │   │           ├── TypeAlias.AxProgramExamples.md
    │   │   │   │           ├── TypeAlias.AxProgramForwardOptions.md
    │   │   │   │           ├── TypeAlias.AxProgramTrace.md
    │   │   │   │           ├── TypeAlias.AxProgramUsage.md
    │   │   │   │           ├── TypeAlias.AxRateLimiterFunction.md
    │   │   │   │           ├── TypeAlias.AxRerankerIn.md
    │   │   │   │           ├── TypeAlias.AxRerankerOut.md
    │   │   │   │           ├── TypeAlias.AxRewriteIn.md
    │   │   │   │           ├── TypeAlias.AxRewriteOut.md
    │   │   │   │           └── TypeAlias.AxTokenUsage.md
    │   │   │   ├── pages/
    │   │   │   │   ├── api.astro
    │   │   │   │   ├── index.astro
    │   │   │   │   └── optimize.astro
    │   │   │   └── styles/
    │   │   │       ├── custom.css
    │   │   │       └── shared.css
    │   │   └── .vscode/
    │   │       ├── extensions.json
    │   │       └── launch.json
    │   └── examples/
    │       ├── abort-patterns.ts
    │       ├── abort-simple.ts
    │       ├── agent.ts
    │       ├── ax-template.ts
    │       ├── balancer.ts
    │       ├── chain-of-thought.ts
    │       ├── chat.ts
    │       ├── checkpoint-recovery.ts
    │       ├── customer-support.ts
    │       ├── debug-logging.ts
    │       ├── docker.ts
    │       ├── dope-or-nope.ts
    │       ├── embed.ts
    │       ├── extract-test.ts
    │       ├── extract.ts
    │       ├── fibonacci.ts
    │       ├── food-search.ts
    │       ├── function.ts
    │       ├── marketing.ts
    │       ├── mcp-client-blender.ts
    │       ├── mcp-client-memory.ts
    │       ├── mcp-client-pipedream.ts
    │       ├── meetings.ts
    │       ├── mipro-chained-optimize.ts
    │       ├── mipro-optimize.ts
    │       ├── mipro-use-optimized.ts
    │       ├── multi-modal.ts
    │       ├── openai-responses.ts
    │       ├── package.json
    │       ├── prime.ts
    │       ├── rag-docs.ts
    │       ├── rag.ts
    │       ├── react.ts
    │       ├── reasoning-o3-example.ts
    │       ├── show-thoughts.ts
    │       ├── simple-classify.ts
    │       ├── smart-home.ts
    │       ├── streaming1.ts
    │       ├── streaming2.ts
    │       ├── streaming3.ts
    │       ├── summarize.ts
    │       ├── telemetry.ts
    │       ├── template-signatures.ts
    │       ├── thinking-token-budget.ts
    │       ├── tsconfig.json
    │       ├── use-examples.ts
    │       └── vectordb.ts
    ├── .circleci/
    │   └── config.yml
    ├── .cspell/
    │   └── project-words.txt
    ├── .cursor/
    │   └── rules/
    │       └── default.mdc
    └── .github/
        ├── CONTRIBUTING.md
        ├── dependabot.yml
        ├── ISSUE_TEMPLATE.md
        ├── PULL_REQUEST_TEMPLATE.md
        └── workflows/
            ├── npm-publish.yml
            ├── pull-request-ci.yml
            └── static.yml

================================================
FILE: README.md
================================================
# Ax, DSPy for Typescript

Working with LLMs is complex they don't always do what you want. DSPy makes it easier to build amazing things with LLMs. Just define your inputs and outputs (signature) and an efficient prompt is auto-generated and used. Connect together various signatures to build complex systems and workflows using LLMs

And to help you really use this in production we have everything else you need like observability, streaming, support for other modalities (images,audio, etc), error-correction, multi-step function calling, MCP, RAG, etc


[![NPM Package](https://img.shields.io/npm/v/@ax-llm/ax?style=for-the-badge&color=green)](https://www.npmjs.com/package/@ax-llm/ax)
[![Twitter](https://img.shields.io/twitter/follow/dosco?style=for-the-badge&color=red)](https://twitter.com/dosco)
[![Discord Chat](https://dcbadge.vercel.app/api/server/DSHg3dU7dW?style=for-the-badge)](https://discord.gg/DSHg3dU7dW)


<!-- header -->

## Why use Ax?

- Standard interface across all top LLMs
- Prompts compiled from simple signatures
- Full native end-to-end streaming
- Support for thinking budget and though tokens
- Build Agents that can call other agents
- Built in MCP, Model Context Protocol support
- Convert docs of any format to text
- RAG, smart chunking, embedding, querying
- Works with Vercel AI SDK
- Output validation while streaming
- Multi-modal DSPy supported
- Automatic prompt tuning using optimizers
- OpenTelemetry tracing / observability
- Production ready Typescript code
- Lite weight, zero-dependencies

## Production Ready

- No breaking changes (minor versions)
- Large test coverage
- Builtin Open Telemetry `gen_ai` support
- Widely used by startups in prod

## What's a prompt signature?

<img width="860" alt="shapes at 24-03-31 00 05 55" src="https://github.com/dosco/llm-client/assets/832235/0f0306ea-1812-4a0a-9ed5-76cd908cd26b">

Efficient type-safe prompts are auto-generated from a simple signature. A prompt
signature is made up of a
`"task description" inputField:type "field description" -> "outputField:type`.
The idea behind prompt signatures is based on work done in the
"Demonstrate-Search-Predict" paper.

You can have multiple input and output fields, and each field can be of the
types `string`, `number`, `boolean`, `date`, `datetime`,
`class "class1, class2"`, `code`, `json`, `image`, `audio`, or an array of any of these, e.g., `string[]`.
When a type is not defined, it defaults to `string`. 

### Field Modifiers

- **Optional fields**: Add `?` after the field name to make it optional (e.g., `fieldName?:string`)
- **Internal fields**: Add `!` after the field name to make it internal - useful for reasoning steps that shouldn't be in the final output (e.g., `reasoning!:string`)
- **Combined**: You can combine modifiers (e.g., `optionalReasoning?!:string`)

### Tagged Template Literals (New!)

For a more ergonomic and type-safe way to create signatures, you can use tagged template literals:

```typescript
import { s, f } from '@ax-llm/ax'

// Basic usage
const sig1 = s`question:string -> answer:string`

// With field types and descriptions
const sig2 = s`
  input:${f.string('User input')} -> 
  category:${f.class(['tech', 'business', 'sports'], 'Content category')},
  confidence:${f.number('Confidence score 0-1')}
`

// With modifiers
const sig3 = s`
  text:string -> 
  summary:${f.optional(f.string('Brief summary'))},
  reasoning:${f.internal(f.string('Internal reasoning'))}
`
```

### Ax Tagged Template Literals

For an even more streamlined experience, you can use the `ax` tagged template literal to create `AxGen` instances directly:

```typescript
import { ax, f } from '@ax-llm/ax'

// Basic AxGen creation
const gen = ax`question:string -> answer:string`

// With field types and descriptions
const sentimentGen = ax`
  text:${f.string('Text to analyze')} -> 
  sentiment:${f.class(['positive', 'negative', 'neutral'], 'Sentiment classification')},
  confidence:${f.number('Confidence score 0-1')}
`

// Direct usage with AI
const result = await sentimentGen.forward(ai, {
  text: 'I love this product!'
})
```

The `ax` template literal creates ready-to-use `AxGen` instances. If you need just the signature, use `s` instead.

## Output Field Types

| Type                        | Description                           | Usage Example                           | Example Output                                     |
| --------------------------- | ------------------------------------- | --------------------------------------- | -------------------------------------------------- |
| `string`                    | A sequence of characters              | `fullName:string`                       | `"John Doe"`                                       |
| `number`                    | A numerical value                     | `price:number`                          | `42`                                               |
| `boolean`                   | A true or false value                 | `isValid:boolean`                       | `true`, `false`                                    |
| `date`                      | A date value                          | `startDate:date`                        | `"2023-10-01"`                                     |
| `datetime`                  | A date and time value                 | `createdAt:datetime`                    | `"2023-10-01T12:00:00Z"`                           |
| `json`                      | A JSON object                         | `metadata:json`                         | `{"key": "value"}`                                 |
| `image`                     | An image (input only)                 | `photo:image`                           | Base64 encoded image data                          |
| `audio`                     | An audio file (input only)           | `recording:audio`                       | Base64 encoded audio data                          |
| `class "option1,option2"`   | Classification with predefined options| `category:class "urgent,normal,low"`    | `"urgent"`                                         |
| `code`                      | A code block                          | `solution:code "Python solution"`       | `print('Hello, world!')`                           |
| `string[]`                  | An array of strings                   | `tags:string[]`                         | `["example1", "example2"]`                         |
| `number[]`                  | An array of numbers                   | `scores:number[]`                       | `[1, 2, 3]`                                        |
| `boolean[]`                 | An array of boolean values            | `permissions:boolean[]`                 | `[true, false, true]`                              |
| `date[]`                    | An array of dates                     | `holidayDates:date[]`                   | `["2023-10-01", "2023-10-02"]`                     |
| `datetime[]`                | An array of date and time values      | `logTimestamps:datetime[]`              | `["2023-10-01T12:00:00Z", "2023-10-02T12:00:00Z"]` |
| `class[] "option1,option2"` | Array of classifications              | `categories:class[] "tech,business"`    | `["tech", "business"]`                             |

### Important Notes on Field Types

- **Class fields**: Use `class "option1,option2,option3"` to specify the available options. The LLM will choose from these predefined options.
- **Code fields**: Use `code "description"` for code blocks. Unlike class fields, code fields don't take language parameters in the signature - just a description of what code is expected.
- **Arrays**: Add `[]` after any type to make it an array (e.g., `string[]`, `class[] "a,b,c"`)
- **Descriptions**: Add quoted descriptions after field types to provide context to the LLM

By default, Ax enforces strict naming rules for signature fields. To allow generic names like `text`, `input`, etc., set `axGlobals.signatureStrict = false`. Use with caution as it may reduce signature clarity.

## LLMs Supported

`Google Gemini`, `OpenAI`, `Azure OpenAI`, `Anthropic`, `X Grok`, `TogetherAI`, `Cohere`, `Mistral`, `Groq`, `DeepSeek`, `Ollama`, `Reka`,
`Hugging Face`

## Install

```bash
npm install @ax-llm/ax
# or
yarn add @ax-llm/ax
```

## Example: Using chain-of-thought to summarize text

```typescript
import { AxAI, AxChainOfThought } from '@ax-llm/ax'

const textToSummarize = `
The technological singularity—or simply the singularity[1]—is a hypothetical future point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization.[2][3] ...`

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

const gen = new AxChainOfThought(
  `textToSummarize -> textType:class "note, email, reminder", shortSummary "summarize in 5 to 10 words"`
)

const res = await gen.forward(ai, { textToSummarize })

console.log('>', res)
```

## Example: Using tagged template literals for type-safe signatures

```typescript
import { AxAI, AxChainOfThought, s, f } from '@ax-llm/ax'

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

// Create a signature using tagged template literals
const gen = new AxChainOfThought(
  s`
    userInput:${f.string('User message or question')} -> 
    category:${f.class(['question', 'request', 'complaint'], 'Message type')},
    priority:${f.class(['high', 'medium', 'low'], 'Urgency level')},
    response:${f.string('Appropriate response')},
    reasoning:${f.internal(f.string('Internal reasoning for classification'))}
  `
)

const res = await gen.forward(ai, { 
  userInput: "My order hasn't arrived and I need it urgently!" 
})

console.log('Category:', res.category)
console.log('Priority:', res.priority) 
console.log('Response:', res.response)
// Note: reasoning is internal and won't appear in final output
```

## Example: Building an agent

Use the agent prompt (framework) to build agents that work with other agents to
complete tasks. Agents are easy to make with prompt signatures. Try out the
agent example.

```typescript
# npm run tsx ./src/examples/agent.ts

const researcher = new AxAgent({
  name: 'researcher',
  description: 'Researcher agent',
  signature: `physicsQuestion "physics questions" -> answer "reply in bullet points"`
});

const summarizer = new AxAgent({
  name: 'summarizer',
  description: 'Summarizer agent',
  signature: `text "text so summarize" -> shortSummary "summarize in 5 to 10 words"`
});

const agent = new AxAgent({
  name: 'agent',
  description: 'A an agent to research complex topics',
  signature: `question -> answer`,
  agents: [researcher, summarizer]
});

agent.forward(ai, { questions: "How many atoms are there in the universe" })
```

## Thinking Models Support

Ax provides native support for models with thinking capabilities, allowing you to control the thinking token budget and access the model's thoughts. This feature helps in understanding the model's reasoning process and optimizing token usage.

```typescript
const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string,
  config: {
    model: AxAIGoogleGeminiModel.Gemini25Flash,
    thinking: { includeThoughts: true },
  },
})

// Or control thinking budget per request
const gen = new AxChainOfThought(`question -> answer`)
const res = await gen.forward(
  ai,
  { question: 'What is quantum entanglement?' },
  { thinkingTokenBudget: 'medium' } // 'minimal', 'low', 'medium', or 'high'
)

// Access thoughts in the response
console.log(res.thoughts) // Shows the model's reasoning process
```

## Vector DBs Supported

Vector databases are critical to building LLM workflows. We have clean
abstractions over popular vector databases and our own quick in-memory vector
database.

| Provider   | Tested  |
| ---------- | ------- |
| In Memory  | 🟢 100% |
| Weaviate   | 🟢 100% |
| Cloudflare | 🟡 50%  |
| Pinecone   | 🟡 50%  |

```typescript
// Create embeddings from text using an LLM
const ret = await this.ai.embed({ texts: 'hello world' })

// Create an in memory vector db
const db = new axDB('memory')

// Insert into vector db
await this.db.upsert({
  id: 'abc',
  table: 'products',
  values: ret.embeddings[0],
})

// Query for similar entries using embeddings
const matches = await this.db.query({
  table: 'products',
  values: embeddings[0],
})
```

Alternatively you can use the `AxDBManager` which handles smart chunking,
embedding and querying everything for you, it makes things almost too easy.

```typescript
const manager = new AxDBManager({ ai, db })
await manager.insert(text)

const matches = await manager.query(
  'John von Neumann on human intelligence and singularity.'
)
console.log(matches)
```

## RAG Documents

Using documents like PDF, DOCX, PPT, XLS, etc., with LLMs is a huge pain. We
make it easy with Apache Tika, an open-source document processing engine.

Launch Apache Tika

```shell
docker run -p 9998:9998 apache/tika
```

Convert documents to text and embed them for retrieval using the `AxDBManager`,
which also supports a reranker and query rewriter. Two default implementations,
`AxDefaultResultReranker` and `AxDefaultQueryRewriter`, are available.

```typescript
const tika = new AxApacheTika()
const text = await tika.convert('/path/to/document.pdf')

const manager = new AxDBManager({ ai, db })
await manager.insert(text)

const matches = await manager.query('Find some text')
console.log(matches)
```

## Multi-modal DSPy

When using models like `GPT-4o` and `Gemini` that support multi-modal prompts,
we support using image fields, and this works with the whole DSP pipeline.

```typescript
const image = fs
  .readFileSync('./src/examples/assets/kitten.jpeg')
  .toString('base64')

const gen = new AxChainOfThought(`question, animalImage:image -> answer`)

const res = await gen.forward(ai, {
  question: 'What family does this animal belong to?',
  animalImage: { mimeType: 'image/jpeg', data: image },
})
```

When using models like `gpt-4o-audio-preview` that support multi-modal prompts
with audio support, we support using audio fields, and this works with the whole
DSP pipeline.

```typescript
const audio = fs
  .readFileSync('./src/examples/assets/comment.wav')
  .toString('base64')

const gen = new AxGen(`question, commentAudio:audio -> answer`)

const res = await gen.forward(ai, {
  question: 'What family does this animal belong to?',
  commentAudio: { format: 'wav', data: audio },
})
```

## DSPy Chat API

Inspired by DSPy's demonstration weaving, Ax provides `AxMessage` for seamless conversation history management. This allows you to build chatbots and conversational agents that maintain context across multiple turns while leveraging the full power of prompt signatures. See the example for more details.

```shell
GOOGLE_APIKEY=api-key npm run tsx ./src/examples/chat.ts
```

```typescript
// Create a chat assistant using modern template literals
const chatBot = ax`
  message:${f.string('A casual message from the user')} -> 
  reply:${f.string('A friendly, casual response')}
`

// Start a conversation with message history
const chat: AxMessage<{ message: string }>[] = [
  { role: 'user', values: { message: 'Hi! How are you doing today?' } },
]

// Get first response
let response = await chatBot.forward(ai, chat)
console.log(response.reply)

// Add response to chat history
chat.push({ role: 'assistant', values: { message: response.reply as string } })

// Continue conversation with context
chat.push({
  role: 'user', values: { message: "That's great! Can you tell me a fun fact?" },
})

response = await chatBot.forward(ai, chat)
console.log(response.reply)
```

The conversation history is automatically woven into the prompt, allowing the model to maintain context and provide coherent responses. This works seamlessly with all Ax features including streaming, function calling, and chain-of-thought reasoning.

## Streaming

### Assertions

We support parsing output fields and function execution while streaming. This
allows for fail-fast and error correction without waiting for the whole output,
saving tokens and costs and reducing latency. Assertions are a powerful way to
ensure the output matches your requirements; they also work with streaming.

```typescript
// setup the prompt program
const gen = new AxChainOfThought(
  ai,
  `startNumber:number -> next10Numbers:number[]`
)

// add a assertion to ensure that the number 5 is not in an output field
gen.addAssert(({ next10Numbers }: Readonly<{ next10Numbers: number[] }>) => {
  return next10Numbers ? !next10Numbers.includes(5) : undefined
}, 'Numbers 5 is not allowed')

// run the program with streaming enabled
const res = await gen.forward({ startNumber: 1 }, { stream: true })

// or run the program with end-to-end streaming
const generator = await gen.streamingForward(
  { startNumber: 1 },
  {
    stream: true,
  }
)
for await (const res of generator) {
}
```

The above example allows you to validate entire output fields as they are
streamed in. This validation works with streaming and when not streaming and is
triggered when the whole field value is available. For true validation while
streaming, check out the example below. This will massively improve performance
and save tokens at scale in production.

```typescript
// add a assertion to ensure all lines start with a number and a dot.
gen.addStreamingAssert(
  'answerInPoints',
  (value: string) => {
    const re = /^\d+\./

    // split the value by lines, trim each line,
    // filter out empty lines and check if all lines match the regex
    return value
      .split('\n')
      .map((x) => x.trim())
      .filter((x) => x.length > 0)
      .every((x) => re.test(x))
  },
  'Lines must start with a number and a dot. Eg: 1. This is a line.'
)

// run the program with streaming enabled
const res = await gen.forward(
  {
    question: 'Provide a list of optimizations to speedup LLM inference.',
  },
  { stream: true, debug: true }
)
```

### Field Processors

Field processors are a powerful way to process fields in a prompt. They are used
to process fields in a prompt before the prompt is sent to the LLM.

```typescript
const gen = new AxChainOfThought(
  ai,
  `startNumber:number -> next10Numbers:number[]`
)

const streamValue = false

const processorFunction = (value) => {
  return value.map((x) => x + 1)
}

// Add a field processor to the program
const processor = new AxFieldProcessor(
  gen,
  'next10Numbers',
  processorFunction,
  streamValue
)

const res = await gen.forward({ startNumber: 1 })
```

## Model Context Protocol (MCP)

Ax provides seamless integration with the Model Context Protocol (MCP), allowing
your agents to access external tools, and resources through a standardized
interface.

### Using AxMCPClient

The `AxMCPClient` allows you to connect to any MCP-compatible server and use its
capabilities within your Ax agents:

```typescript
import { AxMCPClient, AxMCPStdioTransport } from '@ax-llm/ax'

// Initialize an MCP client with a transport
const transport = new AxMCPStdioTransport({
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-memory'],
})

// Create the client with optional debug mode
const client = new AxMCPClient(transport, { debug: true })

// Initialize the connection
await client.init()

// Use the client's functions in an agent
const memoryAgent = new AxAgent({
  name: 'MemoryAssistant',
  description: 'An assistant with persistent memory',
  signature: 'input, userId -> response',
  functions: [client], // Pass the client as a function provider
})

// Or use the client with AxGen
const memoryGen = new AxGen('input, userId -> response', {
  functions: [client],
})
```

### Using AxMCPClient with a Remote Server

Calling a remote MCP server with Ax is straightforward. For example, here's how you can use the DeepWiki MCP server to ask questions about nearly any public GitHub repository. The DeepWiki MCP server is available at `https://mcp.deepwiki.com/mcp`.

```typescript
import {
  AxAgent,
  AxAI,
  AxAIOpenAIModel,
  AxMCPClient,
  AxMCPStreambleHTTPTransport,
} from '@ax-llm/ax'

// 1. Initialize the MCP transport to the DeepWiki server
const transport = new AxMCPStreambleHTTPTransport(
  'https://mcp.deepwiki.com/mcp'
)

// 2. Create the MCP client
const mcpClient = new AxMCPClient(transport, { debug: false })
await mcpClient.init() // Initialize the connection

// 3. Initialize your AI model (e.g., OpenAI)
// Ensure your OPENAI_APIKEY environment variable is set
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

// 4. Create an AxAgent that uses the MCP client
const deepwikiAgent = new AxAgent<
  {
    // Define input types for clarity, matching a potential DeepWiki function
    questionAboutRepo: string
    githubRepositoryUrl: string
  },
  {
    answer: string
  }
>({
  name: 'DeepWikiQueryAgent',
  description: 'Agent to query public GitHub repositories via DeepWiki MCP.',
  signature: 'questionAboutRepo, githubRepositoryUrl -> answer',
  functions: [mcpClient], // Provide the MCP client to the agent
})

// 5. Formulate a question and call the agent
const result = await deepwikiAgent.forward(ai, {
  questionAboutRepo: 'What is the main purpose of this library?',
  githubRepositoryUrl: 'https://github.com/dosco/ax', // Example: Ax library itself
})
console.log('DeepWiki Answer:', result.answer)
```

This example shows how to connect to a public MCP server and use it within an Ax agent. The agent's signature (`questionAboutRepo, githubRepositoryUrl -> answer`) is an assumption of how one might interact with the DeepWiki service; you would typically discover the available functions and their signatures from the MCP server itself (e.g., via an `mcp.getFunctions` call if supported, or documentation).

For a more complex example involving authentication and custom headers with a remote MCP server, please refer to the `src/examples/mcp-client-pipedream.ts` file in this repository.

## AI Routing and Load Balancing

Ax provides two powerful ways to work with multiple AI services: a load balancer
for high availability and a router for model-specific routing.

### Load Balancer

The load balancer automatically distributes requests across multiple AI services
based on performance and availability. If one service fails, it automatically
fails over to the next available service.

```typescript
import { AxAI, AxBalancer } from '@ax-llm/ax'

// Setup multiple AI services
const openai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY,
})

const ollama = new AxAI({
  name: 'ollama',
  config: { model: 'nous-hermes2' },
})

const gemini = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY,
})

// Create a load balancer with all services
const balancer = new AxBalancer([openai, ollama, gemini])

// Use like a regular AI service - automatically uses the best available service
const response = await balancer.chat({
  chatPrompt: [{ role: 'user', content: 'Hello!' }],
})

// Or use the balance with AxGen
const gen = new AxGen(`question -> answer`)
const res = await gen.forward(balancer, { question: 'Hello!' })
```

### Multi-Service Router

The router lets you use multiple AI services through a single interface,
automatically routing requests to the right service based on the model
specified.

```typescript
import { AxAI, AxAIOpenAIModel, AxMultiServiceRouter } from '@ax-llm/ax'

// Setup OpenAI with model list
const openai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY,
  models: [
    {
      key: 'basic',
      model: AxAIOpenAIModel.GPT4OMini,
      description:
        'Model for very simple tasks such as answering quick short questions',
    },
    {
      key: 'medium',
      model: AxAIOpenAIModel.GPT4O,
      description:
        'Model for semi-complex tasks such as summarizing text, writing code, and more',
    },
  ],
})

// Setup Gemini with model list
const gemini = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY,
  models: [
    {
      key: 'deep-thinker',
      model: 'gemini-2.0-flash-thinking',
      description:
        'Model that can think deeply about a task, best for tasks that require planning',
    },
    {
      key: 'expert',
      model: 'gemini-2.0-pro',
      description:
        'Model that is the best for very complex tasks such as writing large essays, complex coding, and more',
    },
  ],
})

const ollama = new AxAI({
  name: 'ollama',
  config: { model: 'nous-hermes2' },
})

const secretService = {
  key: 'sensitive-secret',
  service: ollama,
  description: 'Model for sensitive secrets tasks',
}

// Create a router with all services
const router = new AxMultiServiceRouter([openai, gemini, secretService])

// Route to OpenAI's expert model
const openaiResponse = await router.chat({
  chatPrompt: [{ role: 'user', content: 'Hello!' }],
  model: 'expert',
})

// Or use the router with AxGen
const gen = new AxGen(`question -> answer`)
const res = await gen.forward(router, { question: 'Hello!' })
```

The load balancer is ideal for high availability while the router is perfect
when you need specific models for specific tasks Both can be used with any of
Ax's features like streaming, function calling, and chain-of-thought prompting.

You can also use the balancer and the router together either the multiple
balancers can be used with the router or the router can be used with the
balancer.

## OpenTelemetry support

The ability to trace and observe your llm workflow is critical to building
production workflows. OpenTelemetry is an industry-standard, and we support the
new `gen_ai` attribute namespace. Checkout `src/examples/telemetry.ts` for more
information.

```typescript
import { trace } from '@opentelemetry/api'
import {
  BasicTracerProvider,
  ConsoleSpanExporter,
  SimpleSpanProcessor,
} from '@opentelemetry/sdk-trace-base'

const provider = new BasicTracerProvider()
provider.addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporter()))
trace.setGlobalTracerProvider(provider)

const tracer = trace.getTracer('test')

const ai = new AxAI({
  name: 'ollama',
  config: { model: 'nous-hermes2' },
  options: { tracer },
})

const gen = new AxChainOfThought(
  ai,
  `text -> shortSummary "summarize in 5 to 10 words"`
)

const res = await gen.forward({ text })
```

```json
{
  "traceId": "ddc7405e9848c8c884e53b823e120845",
  "name": "Chat Request",
  "id": "d376daad21da7a3c",
  "kind": "SERVER",
  "timestamp": 1716622997025000,
  "duration": 14190456.542,
  "attributes": {
    "gen_ai.system": "Ollama",
    "gen_ai.request.model": "nous-hermes2",
    "gen_ai.request.max_tokens": 500,
    "gen_ai.request.temperature": 0.1,
    "gen_ai.request.top_p": 0.9,
    "gen_ai.request.frequency_penalty": 0.5,
    "gen_ai.request.llm_is_streaming": false,
    "http.request.method": "POST",
    "url.full": "http://localhost:11434/v1/chat/completions",
    "gen_ai.usage.completion_tokens": 160,
    "gen_ai.usage.prompt_tokens": 290
  }
}
```

## Tuning the prompts (Basic)

You can tune your prompts using a larger model to help them run more efficiently
and give you better results. This is done by using an optimizer like
`AxBootstrapFewShot` with and examples from the popular `HotPotQA` dataset. The
optimizer generates demonstrations `demos` which when used with the prompt help
improve its efficiency.

```typescript
// Download the HotPotQA dataset from huggingface
const hf = new AxHFDataLoader({
  dataset: 'hotpot_qa',
  split: 'train',
})

const examples = await hf.getData<{ question: string; answer: string }>({
  count: 100,
  fields: ['question', 'answer'],
})

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

// Setup the program to tune
const program = new AxChainOfThought<{ question: string }, { answer: string }>(
  ai,
  `question -> answer "in short 2 or 3 words"`
)

// Setup a Bootstrap Few Shot optimizer to tune the above program
const optimize = new AxBootstrapFewShot({
  studentAI: ai,
  examples,
  options: {
    maxRounds: 3,
    maxDemos: 4,
    verboseMode: true,
  },
})

// Setup a evaluation metric em, f1 scores are a popular way measure retrieval performance.
const metricFn: AxMetricFn = ({ prediction, example }) =>
  emScore(prediction.answer as string, example.answer as string)

// Run the optimizer and remember to save the result to use later
const result = await optimize.compile(program, metricFn);

// Save the generated demos to a file
// import fs from 'fs'; // Ensure fs is imported in your actual script
fs.writeFileSync('bootstrap-demos.json', JSON.stringify(result.demos, null, 2));
console.log('Demos saved to bootstrap-demos.json');
```

<img width="853" alt="tune-prompt" src="https://github.com/dosco/llm-client/assets/832235/f924baa7-8922-424c-9c2c-f8b2018d8d74">
```

## Tuning the prompts (Advanced, Mipro v2)

MiPRO v2 is an advanced prompt optimization framework that uses Bayesian
optimization to automatically find the best instructions, demonstrations, and
examples for your LLM programs. By systematically exploring different prompt
configurations, MiPRO v2 helps maximize model performance without manual tuning. 

### Key Features

- **Instruction optimization**: Automatically generates and tests multiple
  instruction candidates
- **Few-shot example selection**: Finds optimal demonstrations from your dataset
- **Smart Bayesian optimization**: Uses UCB (Upper Confidence Bound) strategy to
  efficiently explore configurations
- **Early stopping**: Stops optimization when improvements plateau to save
  compute
- **Program and data-aware**: Considers program structure and dataset
  characteristics

### How It Works

1. Generates various instruction candidates
2. Bootstraps few-shot examples from your data
3. Selects labeled examples directly from your dataset
4. Uses Bayesian optimization to find the optimal combination
5. Applies the best configuration to your program

### Basic Usage

```typescript
import { AxAI, AxChainOfThought, AxMiPRO } from '@ax-llm/ax'

// 1. Setup your AI service
const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY,
})

// 2. Create your program
const program = new AxChainOfThought(`input -> output`)

// 3. Configure the optimizer
const optimizer = new AxMiPRO({
  studentAI: ai,
  examples: trainingData, // Your training examples
  options: {
    numTrials: 20, // Number of configurations to try
    verbose: true,
  },
})

// 4. Define your evaluation metric
const metricFn = ({ prediction, example }) => {
  return prediction.output === example.output
}

// 5. Run the optimization
const result = await optimizer.compile(program, metricFn, {
  valset: validationData, // Optional validation set
  auto: 'medium', // Optimization level
})

// 6. Use the optimized program
const result = await optimizedProgram.forward(ai, { input: 'test input' })
```

### Configuration Options

MiPRO v2 provides extensive configuration options:

| Option                    | Description                                   | Default |
| ------------------------- | --------------------------------------------- | ------- |
| `numCandidates`           | Number of instruction candidates to generate  | 5       |
| `numTrials`               | Number of optimization trials                 | 30      |
| `maxBootstrappedDemos`    | Maximum number of bootstrapped demonstrations | 3       |
| `maxLabeledDemos`         | Maximum number of labeled examples            | 4       |
| `minibatch`               | Use minibatching for faster evaluation        | true    |
| `minibatchSize`           | Size of evaluation minibatches                | 25      |
| `earlyStoppingTrials`     | Stop if no improvement after N trials         | 5       |
| `minImprovementThreshold` | Minimum score improvement threshold           | 0.01    |
| `programAwareProposer`    | Use program structure for better proposals    | true    |
| `dataAwareProposer`       | Consider dataset characteristics              | true    |
| `verbose`                 | Show detailed optimization progress           | false   |
| abort-patterns.ts | Example on how to abort requests |

### Optimization Levels

You can quickly configure optimization intensity with the `auto` parameter:

```typescript
// Light optimization (faster, less thorough)
const result = await optimizer.compile(program, metricFn, { auto: 'light' })

// Medium optimization (balanced)
const result = await optimizer.compile(program, metricFn, { auto: 'medium' })

// Heavy optimization (slower, more thorough)
const result = await optimizer.compile(program, metricFn, { auto: 'heavy' })
```

### Advanced Example: Sentiment Analysis

```typescript
// Create sentiment analysis program
const classifyProgram = new AxChainOfThought<
  { productReview: string },
  { label: string }
>(`productReview -> label:string "positive" or "negative"`)

// Configure optimizer with advanced settings
const optimizer = new AxMiPRO({
  studentAI: ai,
  examples: trainingData,
  options: {
    numCandidates: 3,
    numTrials: 10,
    maxBootstrappedDemos: 2,
    maxLabeledDemos: 3,
    earlyStoppingTrials: 3,
    programAwareProposer: true,
    dataAwareProposer: true,
    verbose: true,
  },
})

// Run optimization and save the result
const result = await optimizer.compile(classifyProgram, metricFn, {
  valset: validationData,
})

// Save configuration for future use
const programConfig = JSON.stringify(optimizedProgram, null, 2);
await fs.promises.writeFile("./optimized-config.json", programConfig);
console.log('> Done. Optimized program config saved to optimized-config.json');
```

## Using the Tuned Prompts

Both the basic Bootstrap Few Shot optimizer and the advanced MiPRO v2 optimizer generate **demos** (demonstrations) that significantly improve your program's performance. These demos are examples that show the LLM how to properly handle similar tasks.

### What are Demos?

Demos are input-output examples that get automatically included in your prompts to guide the LLM. They act as few-shot learning examples, showing the model the expected behavior for your specific task.

### Loading and Using Demos

Whether you used Bootstrap Few Shot or MiPRO v2, the process of using the generated demos is the same:

```typescript
import fs from 'fs'
import { AxAI, AxGen, AxChainOfThought } from '@ax-llm/ax'

// 1. Setup your AI service
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY,
})

// 2. Create your program (same signature as used during tuning)
const program = new AxChainOfThought(`question -> answer "in short 2 or 3 words"`)

// 3. Load the demos from the saved file
const demos = JSON.parse(fs.readFileSync('bootstrap-demos.json', 'utf8'))

// 4. Apply the demos to your program
program.setDemos(demos)

// 5. Use your enhanced program
const result = await program.forward(ai, {
  question: 'What castle did David Gregory inherit?'
})

console.log(result) // Now performs better with the learned examples
```

### Simple Example: Text Classification

Here's a complete example showing how demos improve a classification task:

```typescript
// Create a classification program
const classifier = new AxGen(`text -> category:class "positive, negative, neutral"`)

// Load demos generated from either Bootstrap or MiPRO tuning
const savedDemos = JSON.parse(fs.readFileSync('classification-demos.json', 'utf8'))
classifier.setDemos(savedDemos)

// Now the classifier has learned from examples and performs better
const result = await classifier.forward(ai, {
  text: "This product exceeded my expectations!"
})

console.log(result.category) // More accurate classification
```

### Key Benefits of Using Demos

- **Improved Accuracy**: Programs perform significantly better with relevant examples
- **Consistent Output**: Demos help maintain consistent response formats


- **Reduced Hallucination**: Examples guide the model toward expected behaviors
- **Cost Effective**: Better results without needing larger/more expensive models

### Best Practices

1. **Save Your Demos**: Always save generated demos to files for reuse
2. **Match Signatures**: Use the exact same signature when loading demos
3. **Version Control**: Keep demo files in version control for reproducibility
4. **Regular Updates**: Re-tune periodically with new data to improve demos

Both Bootstrap Few Shot and MiPRO v2 generate demos in the same format, so you can use this same loading pattern regardless of which optimizer you used for tuning.

## 📖 Complete Optimization Guide

For comprehensive documentation on optimization strategies, teacher-student architectures, cost management, and advanced techniques, see our detailed [**Optimization Guide**](./OPTIMIZE.md).

## Built-in Functions

| Function           | Name               | Description                                  |
| ------------------ | ------------------ | -------------------------------------------- |
| JS Interpreter     | AxJSInterpreter    | Execute JS code in a sandboxed env           |
| Docker Sandbox     | AxDockerSession    | Execute commands within a docker environment |
| Embeddings Adapter | AxEmbeddingAdapter | Fetch and pass embedding to your function    |

## Check out all the examples

Use the `tsx` command to run the examples. It makes the node run typescript
code. It also supports using an `.env` file to pass the AI API Keys instead of
putting them in the command line.

```shell
OPENAI_APIKEY=api-key npm run tsx ./src/examples/marketing.ts
```

| Example                 | Description                                             |
| ----------------------- | ------------------------------------------------------- |
| [customer-support.ts](https://github.com/ax-llm/ax/blob/main/src/examples/customer-support.ts)     | Extract valuable details from customer communications   |
| [debug-logging.ts](https://github.com/ax-llm/ax/blob/main/src/examples/debug-logging.ts)        | Debug and custom logging examples with different loggers |
| [function.ts](https://github.com/ax-llm/ax/blob/main/src/examples/function.ts)             | Simple single function calling example                  |
| [food-search.ts](https://github.com/ax-llm/ax/blob/main/src/examples/food-search.ts)          | Multi-step, multi-function calling example              |
| [marketing.ts](https://github.com/ax-llm/ax/blob/main/src/examples/marketing.ts)            | Generate short effective marketing sms messages         |
| [vectordb.ts](https://github.com/ax-llm/ax/blob/main/src/examples/vectordb.ts)             | Chunk, embed and search text                            |
| [fibonacci.ts](https://github.com/ax-llm/ax/blob/main/src/examples/fibonacci.ts)            | Use the JS code interpreter to compute fibonacci        |
| [summarize.ts](https://github.com/ax-llm/ax/blob/main/src/examples/summarize.ts)            | Generate a short summary of a large block of text       |
| [chain-of-thought.ts](https://github.com/ax-llm/ax/blob/main/src/examples/chain-of-thought.ts)     | Use chain-of-thought prompting to answer questions      |
| [template-signatures.ts](https://github.com/ax-llm/ax/blob/main/src/examples/template-signatures.ts) | Type-safe signatures using tagged template literals     |
| [ax-template.ts](https://github.com/ax-llm/ax/blob/main/src/examples/ax-template.ts) | Create AxGen instances using tagged template literals   |
| [rag.ts](https://github.com/ax-llm/ax/blob/main/src/examples/rag.ts)                  | Use multi-hop retrieval to answer questions             |
| [rag-docs.ts](https://github.com/ax-llm/ax/blob/main/src/examples/rag-docs.ts)             | Convert PDF to text and embed for rag search            |
| [react.ts](https://github.com/ax-llm/ax/blob/main/src/examples/react.ts)                | Use function calling and reasoning to answer questions  |
| [agent.ts](https://github.com/ax-llm/ax/blob/main/src/examples/agent.ts)                | Agent framework, agents can use other agents, tools etc |
| [streaming1.ts](https://github.com/ax-llm/ax/blob/main/src/examples/streaming1.ts)           | Output fields validation while streaming                |
| [streaming2.ts](https://github.com/ax-llm/ax/blob/main/src/examples/streaming2.ts)           | Per output field validation while streaming             |
| [streaming3.ts](https://github.com/ax-llm/ax/blob/main/src/examples/streaming3.ts)           | End-to-end streaming example `streamingForward()`       |
| [smart-hone.ts](https://github.com/ax-llm/ax/blob/main/src/examples/smart-hone.ts)           | Agent looks for dog in smart home                       |
| [multi-modal.ts](https://github.com/ax-llm/ax/blob/main/src/examples/multi-modal.ts)          | Use an image input along with other text inputs         |
| [balancer.ts](https://github.com/ax-llm/ax/blob/main/src/examples/balancer.ts)             | Balance between various llm's based on cost, etc        |
| [docker.ts](https://github.com/ax-llm/ax/blob/main/src/examples/docker.ts)               | Use the docker sandbox to find files by description     |
| [prime.ts](https://github.com/ax-llm/ax/blob/main/src/examples/prime.ts)                | Using field processors to process fields in a prompt    |
| [simple-classify.ts](https://github.com/ax-llm/ax/blob/main/src/examples/simple-classify.ts)      | Use a simple classifier to classify stuff               |
| [mcp-client-memory.ts](https://github.com/ax-llm/ax/blob/main/src/examples/mcp-client-memory.ts)    | Example of using an MCP server for memory with Ax       |
| [mcp-client-blender.ts](https://github.com/ax-llm/ax/blob/main/src/examples/mcp-client-blender.ts)   | Example of using an MCP server for Blender with Ax      |
| [mcp-client-pipedream.ts](https://github.com/ax-llm/ax/blob/main/src/examples/mcp-client-pipedream.ts) | Example of integrating with a remote MCP                |
| [tune-bootstrap.ts](https://github.com/ax-llm/ax/blob/main/src/examples/tune-bootstrap.ts)       | Use bootstrap optimizer to improve prompt efficiency    |
| [tune-mipro.ts](https://github.com/ax-llm/ax/blob/main/src/examples/tune-mipro.ts)           | Use mipro v2 optimizer to improve prompt efficiency     |
| [mipro-optimize.ts](https://github.com/ax-llm/ax/blob/main/src/examples/mipro-optimize.ts) | Complex reasoning optimization with teacher model & save |
| [mipro-chained-optimize.ts](https://github.com/ax-llm/ax/blob/main/src/examples/mipro-chained-optimize.ts) | Teacher-student pipeline with cost optimization & overrides |
| [mipro-use-optimized.ts](https://github.com/ax-llm/ax/blob/main/src/examples/mipro-use-optimized.ts) | Load and use saved optimization with cheaper models |
| [checkpoint-recovery.ts](https://github.com/ax-llm/ax/blob/main/src/examples/checkpoint-recovery.ts) | Fault-tolerant optimization with checkpoint recovery |
| [tune-usage.ts](https://github.com/ax-llm/ax/blob/main/src/examples/tune-usage.ts)           | Use the optimized tuned prompts                         |
| [telemetry.ts](https://github.com/ax-llm/ax/blob/main/src/examples/telemetry.ts)            | Trace and push traces to a Jaeger service               |
| [openai-responses.ts](https://github.com/ax-llm/ax/blob/main/src/examples/openai-responses.ts)     | Example using the new OpenAI Responses API              |
| [show-thoughts.ts](https://github.com/ax-llm/ax/blob/main/src/examples/show-thoughts.ts)       | Control and display model reasoning thoughts             |
| [reasoning-o3-example.ts](https://github.com/ax-llm/ax/blob/main/src/examples/reasoning-o3-example.ts) | Advanced reasoning with OpenAI o3/o4 models             |
| [use-examples.ts](https://github.com/ax-llm/ax/blob/main/src/examples/use-examples.ts) | Example of using 'examples' to direct the llm |
| [thinking-token-budget.ts](https://github.com/ax-llm/ax/blob/main/src/examples/thinking-token-budget.ts) | Configurable thinking token budget levels for Google Gemini and reasoning control |

## Our Goal

Large language models (LLMs) are becoming really powerful and have reached a
point where they can work as the backend for your entire product. However,
there's still a lot of complexity to manage from using the correct prompts,
models, streaming, function calls, error correction, and much more. We aim to
package all this complexity into a well-maintained, easy-to-use library that can
work with all state-of-the-art LLMs. Additionally, we are using the latest
research to add new capabilities like DSPy to the library.

## How to use this library?

### 1. Pick an AI to work with

```ts
// Pick a LLM
const ai = new AxOpenAI({ apiKey: process.env.OPENAI_APIKEY } as AxOpenAIArgs)
```

### 2. Create a prompt signature based on your usecase

```ts
// Signature defines the inputs and outputs of your prompt program
const cot = new ChainOfThought(ai, `question:string -> answer:string`, { mem })
```

### 3. Execute this new prompt program

```ts
// Pass in the input fields defined in the above signature
const res = await cot.forward({ question: 'Are we in a simulation?' })
```

### 4. Or if you just want to directly use the LLM

```ts
const res = await ai.chat([
  { role: "system", content: "Help the customer with his questions" }
  { role: "user", content: "I'm looking for a Macbook Pro M2 With 96GB RAM?" }
]);
```

## How do you use function calling

### 1. Define the functions

```ts
// define one or more functions and a function handler
const functions = [
  {
    name: 'getCurrentWeather',
    description: 'get the current weather for a location',
    parameters: {
      type: 'object',
      properties: {
        location: {
          type: 'string',
          description: 'location to get weather for',
        },
        units: {
          type: 'string',
          enum: ['imperial', 'metric'],
          default: 'imperial',
          description: 'units to use',
        },
      },
      required: ['location'],
    },
    func: async (args: Readonly<{ location: string; units: string }>) => {
      return `The weather in ${args.location} is 72 degrees`
    },
  },
]
```

### 2. Pass the functions to a prompt

```ts
const cot = new AxGen(ai, `question:string -> answer:string`, { functions })
```

## Enable debug logs

```ts
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY,
} as AxOpenAIArgs)
ai.setOptions({ debug: true })
```

## Custom Logger

You can provide a custom logger function to control how debug information and other messages are output. This is useful for integrating with logging frameworks or customizing the output format.

```ts
// Custom logger that prefixes messages with timestamp
const customLogger = (message: string) => {
  const timestamp = new Date().toISOString()
  process.stdout.write(`[${timestamp}] ${message}`)
}

// Set logger on AI service
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY,
  options: {
    debug: true,
    logger: customLogger
  }
})

// Or set logger on generation programs
const gen = new AxGen(
  'question -> answer:string',
  { logger: customLogger }
)

// Logger can also be passed through options
const result = await gen.forward(ai, { question: 'Hello' }, {
  logger: customLogger
})
```

The logger function receives a string message and is responsible for outputting it. If no logger is provided, messages are written to `process.stdout.write` by default.

## Reach out

We're happy to help reach out if you have questions or join the Discord
[twitter/dosco](https://twitter.com/dosco)

## FAQ

### 1. The LLM can't find the correct function to use

Improve the function naming and description. Be very clear about what the
function does. Also, ensure the function parameters have good descriptions. The
descriptions can be a little short but need to be precise.

### 2. How do I change the configuration of the LLM I'm using?

You can pass a configuration object as the second parameter when creating a new
LLM object.

```ts
const apiKey = process.env.OPENAI_APIKEY
const conf = AxOpenAIBestConfig()
const ai = new AxOpenAI({ apiKey, conf } as AxOpenAIArgs)
```

## 3. My prompt is too long / can I change the max tokens?

```ts
const conf = axOpenAIDefaultConfig() // or OpenAIBestOptions()
conf.maxTokens = 2000
```

## 4. How do I change the model? (e.g., I want to use GPT4)

```ts
const conf = axOpenAIDefaultConfig() // or OpenAIBestOptions()
conf.model = OpenAIModel.GPT4Turbo
```

## Monorepo tips & tricks

It is essential to remember that we should only run `npm install` from the root
directory. This prevents the creation of nested `package-lock.json` files and
avoids non-deduplicated `node_modules`.

[![Ask DeepWiki](https://deepwiki.com/badge.svg?style=for-the-badge)](https://deepwiki.com/ax-llm/ax)

Adding new dependencies in packages should be done with e.g.
`npm install lodash --workspace=ax` (or just modify the appropriate
`package.json` and run `npm install` from root).



================================================
FILE: CHANGELOG.md
================================================
# Changelog

## [12.0.8](https://github.com/ax-llm/ax/compare/12.0.6...12.0.7) (2025-06-23)

### Features

* introduce comprehensive LLM optimization guide and checkpointing functionality ([d8b5e90](https://github.com/ax-llm/ax/commit/d8b5e904e8169baf454de511f321a365c76042e3))
## [12.0.7](https://github.com/ax-llm/ax/compare/12.0.6...12.0.7) (2025-06-20)

## [12.0.7](https://github.com/ax-llm/ax/compare/12.0.5...12.0.6) (2025-06-20)
## [12.0.6](https://github.com/ax-llm/ax/compare/12.0.5...12.0.6) (2025-06-19)

## [12.0.6](https://github.com/ax-llm/ax/compare/12.0.4...12.0.5) (2025-06-19)
## [12.0.5](https://github.com/ax-llm/ax/compare/12.0.4...12.0.5) (2025-06-19)

## [12.0.5](https://github.com/ax-llm/ax/compare/12.0.3...12.0.4) (2025-06-19)
## [12.0.4](https://github.com/ax-llm/ax/compare/12.0.3...12.0.4) (2025-06-19)

### Bug Fixes

* **mistral:** remove unsupported params and fix image compatibility ([#247](https://github.com/ax-llm/ax/issues/247)) ([2f3d4d6](https://github.com/ax-llm/ax/commit/2f3d4d6208c1067df0e26824ef5bc582ace9dde1))

## [12.0.4](https://github.com/ax-llm/ax/compare/12.0.2...12.0.3) (2025-06-19)

### Bug Fixes

* **mistral:** remove unsupported params and fix image compatibility ([#247](https://github.com/ax-llm/ax/issues/247)) ([2f3d4d6](https://github.com/ax-llm/ax/commit/2f3d4d6208c1067df0e26824ef5bc582ace9dde1))
## [12.0.3](https://github.com/ax-llm/ax/compare/12.0.2...12.0.3) (2025-06-19)

### Features

* add configurable thinking token budget levels for Google Gemini ([fc30ce4](https://github.com/ax-llm/ax/commit/fc30ce48174385e612afd4019e83976a77d51434))

## [12.0.3](https://github.com/ax-llm/ax/compare/12.0.1...12.0.2) (2025-06-19)

### Features

* add configurable thinking token budget levels for Google Gemini ([fc30ce4](https://github.com/ax-llm/ax/commit/fc30ce48174385e612afd4019e83976a77d51434))
## [12.0.2](https://github.com/ax-llm/ax/compare/12.0.1...12.0.2) (2025-06-18)

### Features

* enhance AxGen and AxSignature validation and parsing ([433b232](https://github.com/ax-llm/ax/commit/433b232ce843460ac8b41e3d73aaad63c5cb6f3d))

## [12.0.2](https://github.com/ax-llm/ax/compare/12.0.0...12.0.1) (2025-06-18)

### Features

* enhance AxGen and AxSignature validation and parsing ([433b232](https://github.com/ax-llm/ax/commit/433b232ce843460ac8b41e3d73aaad63c5cb6f3d))
## [12.0.1](https://github.com/ax-llm/ax/compare/12.0.0...12.0.1) (2025-06-18)

### Features

* add validation for chat prompt and AxMessage array ([ab3f3d9](https://github.com/ax-llm/ax/commit/ab3f3d9beb500af3b20262e7c70caba0a8018844))

## [12.0.1](https://github.com/ax-llm/ax/compare/11.0.67...12.0.0) (2025-06-18)

### Features

* add validation for chat prompt and AxMessage array ([ab3f3d9](https://github.com/ax-llm/ax/commit/ab3f3d9beb500af3b20262e7c70caba0a8018844))
## [12.0.0](https://github.com/ax-llm/ax/compare/11.0.67...12.0.0) (2025-06-18)

### Features

* update AxSignature and related components for improved usability ([53d8e72](https://github.com/ax-llm/ax/commit/53d8e7215677684d3a02a4837482da35a22f7aa6))

## [12.0.0](https://github.com/ax-llm/ax/compare/11.0.66...11.0.67) (2025-06-18)

### Features

* update AxSignature and related components for improved usability ([53d8e72](https://github.com/ax-llm/ax/commit/53d8e7215677684d3a02a4837482da35a22f7aa6))
## [11.0.67](https://github.com/ax-llm/ax/compare/11.0.66...11.0.67) (2025-06-17)

### Features

* enhance tagged template literals for AxGen and AxSignature ([9003b9f](https://github.com/ax-llm/ax/commit/9003b9f8866d27a50b27a4f42d7ed9287de9a33f))

## [11.0.67](https://github.com/ax-llm/ax/compare/11.0.65...11.0.66) (2025-06-17)

### Features

* enhance tagged template literals for AxGen and AxSignature ([9003b9f](https://github.com/ax-llm/ax/commit/9003b9f8866d27a50b27a4f42d7ed9287de9a33f))
## [11.0.66](https://github.com/ax-llm/ax/compare/11.0.65...11.0.66) (2025-06-16)

### Bug Fixes

* add null checks for config parameter in AI implementations ([#240](https://github.com/ax-llm/ax/issues/240)) ([28664e3](https://github.com/ax-llm/ax/commit/28664e358ae87fdd9922d27966de0b962a1e6e01))
* add null checks for config parameter in AI implementations ([#241](https://github.com/ax-llm/ax/issues/241)) ([da148d8](https://github.com/ax-llm/ax/commit/da148d89779218aece1b33ea27177574af413f52))

## [11.0.66](https://github.com/ax-llm/ax/compare/11.0.64...11.0.65) (2025-06-16)

### Bug Fixes

* add null checks for config parameter in AI implementations ([#240](https://github.com/ax-llm/ax/issues/240)) ([28664e3](https://github.com/ax-llm/ax/commit/28664e358ae87fdd9922d27966de0b962a1e6e01))
* add null checks for config parameter in AI implementations ([#241](https://github.com/ax-llm/ax/issues/241)) ([da148d8](https://github.com/ax-llm/ax/commit/da148d89779218aece1b33ea27177574af413f52))
## [11.0.65](https://github.com/ax-llm/ax/compare/11.0.64...11.0.65) (2025-06-15)

### Features

* Introduce tagged template literals for type-safe signatures ([f52267c](https://github.com/ax-llm/ax/commit/f52267c965c6d050f14d86b1ce5c2e5fe9a4498a))

## [11.0.65](https://github.com/ax-llm/ax/compare/11.0.63...11.0.64) (2025-06-15)

### Features

* Introduce tagged template literals for type-safe signatures ([f52267c](https://github.com/ax-llm/ax/commit/f52267c965c6d050f14d86b1ce5c2e5fe9a4498a))
## [11.0.64](https://github.com/ax-llm/ax/compare/11.0.63...11.0.64) (2025-06-13)

## [11.0.64](https://github.com/ax-llm/ax/compare/11.0.62...11.0.63) (2025-06-13)
## [11.0.63](https://github.com/ax-llm/ax/compare/11.0.62...11.0.63) (2025-06-13)

## [11.0.63](https://github.com/ax-llm/ax/compare/11.0.61...11.0.62) (2025-06-13)
## [11.0.62](https://github.com/ax-llm/ax/compare/11.0.61...11.0.62) (2025-06-12)

### Features

* Introduce AxAIOpenAIResponsesModel and enhance responses API integration ([0ab61f8](https://github.com/ax-llm/ax/commit/0ab61f8020afb3e402c5e178ce9a82da00e797ac))

## [11.0.62](https://github.com/ax-llm/ax/compare/11.0.60...11.0.61) (2025-06-12)

### Features

* Introduce AxAIOpenAIResponsesModel and enhance responses API integration ([0ab61f8](https://github.com/ax-llm/ax/commit/0ab61f8020afb3e402c5e178ce9a82da00e797ac))
## [11.0.61](https://github.com/ax-llm/ax/compare/11.0.60...11.0.61) (2025-06-12)

## [11.0.61](https://github.com/ax-llm/ax/compare/11.0.59...11.0.60) (2025-06-12)
## [11.0.60](https://github.com/ax-llm/ax/compare/11.0.59...11.0.60) (2025-06-11)

## [11.0.60](https://github.com/ax-llm/ax/compare/11.0.58...11.0.59) (2025-06-11)
## [11.0.59](https://github.com/ax-llm/ax/compare/11.0.58...11.0.59) (2025-06-10)

### Features

* Add showThoughts feature to enhance model reasoning visibility ([fabc76d](https://github.com/ax-llm/ax/commit/fabc76d5ef5b3d745b78f75615d6f43946d130af))

## [11.0.59](https://github.com/ax-llm/ax/compare/11.0.57...11.0.58) (2025-06-10)

### Features

* Add showThoughts feature to enhance model reasoning visibility ([fabc76d](https://github.com/ax-llm/ax/commit/fabc76d5ef5b3d745b78f75615d6f43946d130af))
## [11.0.58](https://github.com/ax-llm/ax/compare/11.0.57...11.0.58) (2025-06-10)

### Features

* Enhance logging capabilities with structured tags ([2bb76d3](https://github.com/ax-llm/ax/commit/2bb76d3926d08d32c1a12fc651ee3434d3876bc9))
* Introduce custom logger functionality for AI services ([a5eaed1](https://github.com/ax-llm/ax/commit/a5eaed118a1c880cdaef32a81763a7f4d6aa4fce))

## [11.0.58](https://github.com/ax-llm/ax/compare/11.0.56...11.0.57) (2025-06-10)

### Features

* Enhance logging capabilities with structured tags ([2bb76d3](https://github.com/ax-llm/ax/commit/2bb76d3926d08d32c1a12fc651ee3434d3876bc9))
* Introduce custom logger functionality for AI services ([a5eaed1](https://github.com/ax-llm/ax/commit/a5eaed118a1c880cdaef32a81763a7f4d6aa4fce))
## [11.0.57](https://github.com/ax-llm/ax/compare/11.0.56...11.0.57) (2025-06-09)

### Features

* Add initPackage script for creating new packages in the Ax monorepo ([08746e8](https://github.com/ax-llm/ax/commit/08746e86f33b1b8eee3f978fe5031e8e3c8206fe))
* Add maxTokens field to AxModelInfo and update Anthropic model configurations ([f2645e6](https://github.com/ax-llm/ax/commit/f2645e684091b03d9740fa5c58641c3ef0047153))

## [11.0.57](https://github.com/ax-llm/ax/compare/11.0.55...11.0.56) (2025-06-09)

### Features

* Add initPackage script for creating new packages in the Ax monorepo ([08746e8](https://github.com/ax-llm/ax/commit/08746e86f33b1b8eee3f978fe5031e8e3c8206fe))
* Add maxTokens field to AxModelInfo and update Anthropic model configurations ([f2645e6](https://github.com/ax-llm/ax/commit/f2645e684091b03d9740fa5c58641c3ef0047153))
## [11.0.56](https://github.com/ax-llm/ax/compare/11.0.55...11.0.56) (2025-06-08)

### Features

* Enhance JSON schema validation with flexible handling of union types ([967610d](https://github.com/ax-llm/ax/commit/967610df7cee8e9de11fd9a27835f35398d43c66))

## [11.0.56](https://github.com/ax-llm/ax/compare/11.0.54...11.0.55) (2025-06-08)

### Features

* Enhance JSON schema validation with flexible handling of union types ([967610d](https://github.com/ax-llm/ax/commit/967610df7cee8e9de11fd9a27835f35398d43c66))
## [11.0.55](https://github.com/ax-llm/ax/compare/11.0.54...11.0.55) (2025-06-07)

### Features

* Add DeepWiki links to navigation component ([48c0194](https://github.com/ax-llm/ax/commit/48c01944ec54fc2e2e5f62cc738d4ab34cdace83))
* Allow all fields to be optional in examples and simplify prompt template validation ([18cd73b](https://github.com/ax-llm/ax/commit/18cd73b478622516c6bdaac49d8141ae0e1f530e))

## [11.0.55](https://github.com/ax-llm/ax/compare/11.0.53...11.0.54) (2025-06-07)

### Features

* Add DeepWiki links to navigation component ([48c0194](https://github.com/ax-llm/ax/commit/48c01944ec54fc2e2e5f62cc738d4ab34cdace83))
* Allow all fields to be optional in examples and simplify prompt template validation ([18cd73b](https://github.com/ax-llm/ax/commit/18cd73b478622516c6bdaac49d8141ae0e1f530e))
## [11.0.54](https://github.com/ax-llm/ax/compare/11.0.53...11.0.54) (2025-06-06)

### Features

* Enhance abortable request functionality and documentation ([0b0495e](https://github.com/ax-llm/ax/commit/0b0495eaaf6f8fd265bd47d81424cb3f75ee15d2))

### Bug Fixes

* support for Gemini Flash <= 2.0 ([#233](https://github.com/ax-llm/ax/issues/233)) ([6424329](https://github.com/ax-llm/ax/commit/64243297a3bbc24aee512a1e1445a8f28fec7b58))

## [11.0.54](https://github.com/ax-llm/ax/compare/11.0.52...11.0.53) (2025-06-06)

### Features

* Enhance abortable request functionality and documentation ([0b0495e](https://github.com/ax-llm/ax/commit/0b0495eaaf6f8fd265bd47d81424cb3f75ee15d2))

### Bug Fixes

* support for Gemini Flash <= 2.0 ([#233](https://github.com/ax-llm/ax/issues/233)) ([6424329](https://github.com/ax-llm/ax/commit/64243297a3bbc24aee512a1e1445a8f28fec7b58))
## [11.0.53](https://github.com/ax-llm/ax/compare/11.0.52...11.0.53) (2025-06-06)

### Features

* Implement abortable AI requests with AxAbortableAI utility ([b8f5201](https://github.com/ax-llm/ax/commit/b8f5201c5d75d19549e79805a378936118ebf8f2))
* Introduce optional output fields in examples and enhance prompt template validation ([71ac8f1](https://github.com/ax-llm/ax/commit/71ac8f1d1b30bfa9950503f52e91f7851096f6a8))

## [11.0.53](https://github.com/ax-llm/ax/compare/11.0.51...11.0.52) (2025-06-06)

### Features

* Implement abortable AI requests with AxAbortableAI utility ([b8f5201](https://github.com/ax-llm/ax/commit/b8f5201c5d75d19549e79805a378936118ebf8f2))
* Introduce optional output fields in examples and enhance prompt template validation ([71ac8f1](https://github.com/ax-llm/ax/commit/71ac8f1d1b30bfa9950503f52e91f7851096f6a8))
## [11.0.52](https://github.com/ax-llm/ax/compare/11.0.51...11.0.52) (2025-06-05)

## [11.0.52](https://github.com/ax-llm/ax/compare/11.0.50...11.0.51) (2025-06-05)
## [11.0.51](https://github.com/ax-llm/ax/compare/11.0.50...11.0.51) (2025-06-05)

### Features

* Add conversational memory weaving example to README ([b0ca31d](https://github.com/ax-llm/ax/commit/b0ca31dcbee044ed2d705890e7ce95959e3a284e))
* Add Model Context Protocol (MCP) integration to README ([484f2e8](https://github.com/ax-llm/ax/commit/484f2e8a127ed417a697a49e11a614c96e480914))
* Add Pull Request CI workflow ([38be189](https://github.com/ax-llm/ax/commit/38be189c492cfb1329154f6e604ae1dddd9a01c1))
* Allow custom field name for thought in AxGen ([#227](https://github.com/ax-llm/ax/issues/227)) ([924bf1b](https://github.com/ax-llm/ax/commit/924bf1b7e17d51443d2ceac62a9e3ecfabc7cf9b))
* Allow disabling thought token budget with override ([#229](https://github.com/ax-llm/ax/issues/229)) ([89e00e4](https://github.com/ax-llm/ax/commit/89e00e45356f9c0ac784f9398b580030a0b1fb9b))
* Enable chat history and multi-turn inputs for AxGen and AxPromp… ([#230](https://github.com/ax-llm/ax/issues/230)) ([2bdd6ec](https://github.com/ax-llm/ax/commit/2bdd6ec1db03aee4fe0a425b4008b7b520065de3))
* Update thinkingTokenBudget options and clean up tests ([1b0351a](https://github.com/ax-llm/ax/commit/1b0351a34d632d10d73cebf3dd241839906c5049))

## [11.0.51](https://github.com/ax-llm/ax/compare/11.0.49...11.0.50) (2025-06-05)

### Features

* Add conversational memory weaving example to README ([b0ca31d](https://github.com/ax-llm/ax/commit/b0ca31dcbee044ed2d705890e7ce95959e3a284e))
* Add Model Context Protocol (MCP) integration to README ([484f2e8](https://github.com/ax-llm/ax/commit/484f2e8a127ed417a697a49e11a614c96e480914))
* Add Pull Request CI workflow ([38be189](https://github.com/ax-llm/ax/commit/38be189c492cfb1329154f6e604ae1dddd9a01c1))
* Allow custom field name for thought in AxGen ([#227](https://github.com/ax-llm/ax/issues/227)) ([924bf1b](https://github.com/ax-llm/ax/commit/924bf1b7e17d51443d2ceac62a9e3ecfabc7cf9b))
* Allow disabling thought token budget with override ([#229](https://github.com/ax-llm/ax/issues/229)) ([89e00e4](https://github.com/ax-llm/ax/commit/89e00e45356f9c0ac784f9398b580030a0b1fb9b))
* Enable chat history and multi-turn inputs for AxGen and AxPromp… ([#230](https://github.com/ax-llm/ax/issues/230)) ([2bdd6ec](https://github.com/ax-llm/ax/commit/2bdd6ec1db03aee4fe0a425b4008b7b520065de3))
* Update thinkingTokenBudget options and clean up tests ([1b0351a](https://github.com/ax-llm/ax/commit/1b0351a34d632d10d73cebf3dd241839906c5049))
## [11.0.50](https://github.com/ax-llm/ax/compare/11.0.49...11.0.50) (2025-06-03)

### Features

* integrate new transport classes and enhance OpenAI response handling ([5b3ea86](https://github.com/ax-llm/ax/commit/5b3ea860fc4aa640307a441e1d5785f0176b7219))

## [11.0.50](https://github.com/ax-llm/ax/compare/11.0.48...11.0.49) (2025-06-03)

### Features

* integrate new transport classes and enhance OpenAI response handling ([5b3ea86](https://github.com/ax-llm/ax/commit/5b3ea860fc4aa640307a441e1d5785f0176b7219))
## [11.0.49](https://github.com/ax-llm/ax/compare/11.0.48...11.0.49) (2025-05-29)

### Bug Fixes

* **google-gemini:** implement missing googleSearch option ([#221](https://github.com/ax-llm/ax/issues/221)) ([414a89f](https://github.com/ax-llm/ax/commit/414a89fd06f904e8de13986ccbecc0c07a5214aa))
* relaxed model info check ([3f1fffb](https://github.com/ax-llm/ax/commit/3f1fffb6b28dedcdc56f8d473b9be5b7964eebb2))

## [11.0.49](https://github.com/ax-llm/ax/compare/11.0.47...11.0.48) (2025-05-29)

### Bug Fixes

* **google-gemini:** implement missing googleSearch option ([#221](https://github.com/ax-llm/ax/issues/221)) ([414a89f](https://github.com/ax-llm/ax/commit/414a89fd06f904e8de13986ccbecc0c07a5214aa))
* relaxed model info check ([3f1fffb](https://github.com/ax-llm/ax/commit/3f1fffb6b28dedcdc56f8d473b9be5b7964eebb2))
## [11.0.48](https://github.com/ax-llm/ax/compare/11.0.47...11.0.48) (2025-05-28)

### Bug Fixes

* tracing fixes ([2aa7f04](https://github.com/ax-llm/ax/commit/2aa7f0410ea9120aaf3b772704302269e05d4ebd))

## [11.0.48](https://github.com/ax-llm/ax/compare/11.0.46...11.0.47) (2025-05-28)

### Bug Fixes

* tracing fixes ([2aa7f04](https://github.com/ax-llm/ax/commit/2aa7f0410ea9120aaf3b772704302269e05d4ebd))
## [11.0.47](https://github.com/ax-llm/ax/compare/11.0.46...11.0.47) (2025-05-27)

### Bug Fixes

* axgen now uses the underlying tracer provided by the ai ([36d80c8](https://github.com/ax-llm/ax/commit/36d80c867e33180ca528dcb4477887c25f8a522e))

## [11.0.47](https://github.com/ax-llm/ax/compare/11.0.45...11.0.46) (2025-05-27)

### Bug Fixes

* axgen now uses the underlying tracer provided by the ai ([36d80c8](https://github.com/ax-llm/ax/commit/36d80c867e33180ca528dcb4477887c25f8a522e))
## [11.0.46](https://github.com/ax-llm/ax/compare/11.0.45...11.0.46) (2025-05-27)

### Features

* Add support for thinking models and enhance AI response handling ([e4489f9](https://github.com/ax-llm/ax/commit/e4489f9b0b4638b40cbaef6b293c960612d91a93))

## [11.0.46](https://github.com/ax-llm/ax/compare/11.0.44...11.0.45) (2025-05-27)

### Features

* Add support for thinking models and enhance AI response handling ([e4489f9](https://github.com/ax-llm/ax/commit/e4489f9b0b4638b40cbaef6b293c960612d91a93))
## [11.0.45](https://github.com/ax-llm/ax/compare/11.0.44...11.0.45) (2025-05-26)

### Features

* Enhance thinking token budget configuration and introduce Grok AI support ([0d73693](https://github.com/ax-llm/ax/commit/0d736936aac8ba5065b2a75989b5db653bc33bc1))

## [11.0.45](https://github.com/ax-llm/ax/compare/11.0.43...11.0.44) (2025-05-26)

### Features

* Enhance thinking token budget configuration and introduce Grok AI support ([0d73693](https://github.com/ax-llm/ax/commit/0d736936aac8ba5065b2a75989b5db653bc33bc1))
## [11.0.44](https://github.com/ax-llm/ax/compare/11.0.43...11.0.44) (2025-05-25)

### Features

* Introduce thought handling and enhance thinking configuration ([8c9c8c4](https://github.com/ax-llm/ax/commit/8c9c8c443d23b70a04e6c7578d29aff7277a9d84))

## [11.0.44](https://github.com/ax-llm/ax/compare/11.0.42...11.0.43) (2025-05-25)

### Features

* Introduce thought handling and enhance thinking configuration ([8c9c8c4](https://github.com/ax-llm/ax/commit/8c9c8c443d23b70a04e6c7578d29aff7277a9d84))
## [11.0.43](https://github.com/ax-llm/ax/compare/11.0.42...11.0.43) (2025-05-25)

### Features

* Enhance OpenTelemetry integration and introduce thinking token budget ([a8a08dc](https://github.com/ax-llm/ax/commit/a8a08dc2525dd1dbe02e5dc964aefcebcf24a185))

### Bug Fixes

* Ensure token usage is consistently included in traces ([#207](https://github.com/ax-llm/ax/issues/207)) ([9721640](https://github.com/ax-llm/ax/commit/97216403626ca84c3afc1eb2522cac0261d183e9))

## [11.0.43](https://github.com/ax-llm/ax/compare/11.0.41...11.0.42) (2025-05-25)

### Features

* Enhance OpenTelemetry integration and introduce thinking token budget ([a8a08dc](https://github.com/ax-llm/ax/commit/a8a08dc2525dd1dbe02e5dc964aefcebcf24a185))

### Bug Fixes

* Ensure token usage is consistently included in traces ([#207](https://github.com/ax-llm/ax/issues/207)) ([9721640](https://github.com/ax-llm/ax/commit/97216403626ca84c3afc1eb2522cac0261d183e9))
## [11.0.42](https://github.com/ax-llm/ax/compare/11.0.41...11.0.42) (2025-05-15)

### Bug Fixes

* Array elements repeating in Gen response, while OK in model response (Gemini) [#193](https://github.com/ax-llm/ax/issues/193) ([94d3d2d](https://github.com/ax-llm/ax/commit/94d3d2d815607bc7a3deb14c0929204c3cdb98f8))

## [11.0.42](https://github.com/ax-llm/ax/compare/11.0.40...11.0.41) (2025-05-15)

### Bug Fixes

* Array elements repeating in Gen response, while OK in model response (Gemini) [#193](https://github.com/ax-llm/ax/issues/193) ([94d3d2d](https://github.com/ax-llm/ax/commit/94d3d2d815607bc7a3deb14c0929204c3cdb98f8))
## [11.0.41](https://github.com/ax-llm/ax/compare/11.0.40...11.0.41) (2025-05-03)

### Bug Fixes

* build fix ([eb4b08b](https://github.com/ax-llm/ax/commit/eb4b08bc75b5bdaaf12708d2c48f3f0ece862b3f))

## [11.0.41](https://github.com/ax-llm/ax/compare/11.0.39...11.0.40) (2025-05-03)

### Bug Fixes

* build fix ([eb4b08b](https://github.com/ax-llm/ax/commit/eb4b08bc75b5bdaaf12708d2c48f3f0ece862b3f))
## [11.0.40](https://github.com/ax-llm/ax/compare/11.0.39...11.0.40) (2025-05-03)

### Features

* new AxGenerateError ([eac0996](https://github.com/ax-llm/ax/commit/eac09967cd683e5e05d47ad38b639abfffbe3fae))

## [11.0.40](https://github.com/ax-llm/ax/compare/11.0.38...11.0.39) (2025-05-03)

### Features

* new AxGenerateError ([eac0996](https://github.com/ax-llm/ax/commit/eac09967cd683e5e05d47ad38b639abfffbe3fae))
## [11.0.39](https://github.com/ax-llm/ax/compare/11.0.38...11.0.39) (2025-05-03)

### Features

* wrapped errors to add more details ([164bf94](https://github.com/ax-llm/ax/commit/164bf949b490429e7372a4bc40e707bd56f94f9c))

## [11.0.39](https://github.com/ax-llm/ax/compare/11.0.37...11.0.38) (2025-05-03)

### Features

* wrapped errors to add more details ([164bf94](https://github.com/ax-llm/ax/commit/164bf949b490429e7372a4bc40e707bd56f94f9c))
## [11.0.38](https://github.com/ax-llm/ax/compare/11.0.37...11.0.38) (2025-04-30)

### Bug Fixes

* extended error messages ([140e50c](https://github.com/ax-llm/ax/commit/140e50cb063596d1b673034f8af58c36dad94b9b))

## [11.0.38](https://github.com/ax-llm/ax/compare/11.0.36...11.0.37) (2025-04-30)

### Bug Fixes

* extended error messages ([140e50c](https://github.com/ax-llm/ax/commit/140e50cb063596d1b673034f8af58c36dad94b9b))
## [11.0.37](https://github.com/ax-llm/ax/compare/11.0.36...11.0.37) (2025-04-20)

### Bug Fixes

* bug with embed model selection ([7ba9f4d](https://github.com/ax-llm/ax/commit/7ba9f4de5b61877131dc747a97c0b0038883afec))

## [11.0.37](https://github.com/ax-llm/ax/compare/11.0.35...11.0.36) (2025-04-20)

### Bug Fixes

* bug with embed model selection ([7ba9f4d](https://github.com/ax-llm/ax/commit/7ba9f4de5b61877131dc747a97c0b0038883afec))
## [11.0.36](https://github.com/ax-llm/ax/compare/11.0.35...11.0.36) (2025-04-20)

### Bug Fixes

* various fixes to multiservice router ([16bcd22](https://github.com/ax-llm/ax/commit/16bcd22d2d9a85c77df67d1f462d3382f8a45a6c))

## [11.0.36](https://github.com/ax-llm/ax/compare/11.0.34...11.0.35) (2025-04-20)

### Bug Fixes

* various fixes to multiservice router ([16bcd22](https://github.com/ax-llm/ax/commit/16bcd22d2d9a85c77df67d1f462d3382f8a45a6c))
## [11.0.35](https://github.com/ax-llm/ax/compare/11.0.34...11.0.35) (2025-04-19)

### Features

* gemini 2.5 flash with thinking budget config ([da5bfd1](https://github.com/ax-llm/ax/commit/da5bfd16cd5ef4390873e983e9f303ec463e25b8))

## [11.0.35](https://github.com/ax-llm/ax/compare/11.0.33...11.0.34) (2025-04-19)

### Features

* gemini 2.5 flash with thinking budget config ([da5bfd1](https://github.com/ax-llm/ax/commit/da5bfd16cd5ef4390873e983e9f303ec463e25b8))
## [11.0.34](https://github.com/ax-llm/ax/compare/11.0.33...11.0.34) (2025-04-05)

### Bug Fixes

* malformed response [#191](https://github.com/ax-llm/ax/issues/191) ([8728eed](https://github.com/ax-llm/ax/commit/8728eed42ef16bef94dfc28062c62c283016d328))

## [11.0.34](https://github.com/ax-llm/ax/compare/11.0.32...11.0.33) (2025-04-05)

### Bug Fixes

* malformed response [#191](https://github.com/ax-llm/ax/issues/191) ([8728eed](https://github.com/ax-llm/ax/commit/8728eed42ef16bef94dfc28062c62c283016d328))
## [11.0.33](https://github.com/ax-llm/ax/compare/11.0.32...11.0.33) (2025-04-03)

### Features

* improved errors ([f57592e](https://github.com/ax-llm/ax/commit/f57592e5ebb528ed2d5f1b90cd029f0782a88267))

## [11.0.33](https://github.com/ax-llm/ax/compare/11.0.31...11.0.32) (2025-04-03)

### Features

* improved errors ([f57592e](https://github.com/ax-llm/ax/commit/f57592e5ebb528ed2d5f1b90cd029f0782a88267))
## [11.0.32](https://github.com/ax-llm/ax/compare/11.0.31...11.0.32) (2025-03-31)

### Bug Fixes

* vertex embeddings api changes ([5e5fdaf](https://github.com/ax-llm/ax/commit/5e5fdaf6e6818df5659c7156194bb4fcb94508a3))

## [11.0.32](https://github.com/ax-llm/ax/compare/11.0.30...11.0.31) (2025-03-31)

### Bug Fixes

* vertex embeddings api changes ([5e5fdaf](https://github.com/ax-llm/ax/commit/5e5fdaf6e6818df5659c7156194bb4fcb94508a3))
## [11.0.31](https://github.com/ax-llm/ax/compare/11.0.30...11.0.31) (2025-03-31)

### Features

* new gemini embedding ([278cec0](https://github.com/ax-llm/ax/commit/278cec07dce03dc4ce152d9fcfc66b99e98d70ba))

## [11.0.31](https://github.com/ax-llm/ax/compare/11.0.29...11.0.30) (2025-03-31)

### Features

* new gemini embedding ([278cec0](https://github.com/ax-llm/ax/commit/278cec07dce03dc4ce152d9fcfc66b99e98d70ba))
## [11.0.30](https://github.com/ax-llm/ax/compare/11.0.29...11.0.30) (2025-03-28)

### Bug Fixes

* streaming parser overrun ([b7a6a15](https://github.com/ax-llm/ax/commit/b7a6a1536950b856fc3d5955f11a265fb8990cea))

## [11.0.30](https://github.com/ax-llm/ax/compare/11.0.28...11.0.29) (2025-03-28)

### Bug Fixes

* streaming parser overrun ([b7a6a15](https://github.com/ax-llm/ax/commit/b7a6a1536950b856fc3d5955f11a265fb8990cea))
## [11.0.29](https://github.com/ax-llm/ax/compare/11.0.28...11.0.29) (2025-03-26)

### Bug Fixes

* Azure OpenAI chat/completion call failed [#180](https://github.com/ax-llm/ax/issues/180) ([#181](https://github.com/ax-llm/ax/issues/181)) ([d3c333a](https://github.com/ax-llm/ax/commit/d3c333a0c26e1212ae572403d1bfacea04c31e12))
* streaming parser overflow ([9bad370](https://github.com/ax-llm/ax/commit/9bad370ee3938007164014018986eacb7e01452d))

## [11.0.29](https://github.com/ax-llm/ax/compare/11.0.27...11.0.28) (2025-03-26)

### Bug Fixes

* Azure OpenAI chat/completion call failed [#180](https://github.com/ax-llm/ax/issues/180) ([#181](https://github.com/ax-llm/ax/issues/181)) ([d3c333a](https://github.com/ax-llm/ax/commit/d3c333a0c26e1212ae572403d1bfacea04c31e12))
* streaming parser overflow ([9bad370](https://github.com/ax-llm/ax/commit/9bad370ee3938007164014018986eacb7e01452d))
## [11.0.28](https://github.com/ax-llm/ax/compare/11.0.27...11.0.28) (2025-03-24)

### Features

* mipro v2 ([a7e3ddd](https://github.com/ax-llm/ax/commit/a7e3ddd1b0aa9aaf633f1f3d9cbbaebb871a9f9a))

## [11.0.28](https://github.com/ax-llm/ax/compare/11.0.26...11.0.27) (2025-03-24)

### Features

* mipro v2 ([a7e3ddd](https://github.com/ax-llm/ax/commit/a7e3ddd1b0aa9aaf633f1f3d9cbbaebb871a9f9a))
## [11.0.27](https://github.com/ax-llm/ax/compare/11.0.26...11.0.27) (2025-03-17)

### Bug Fixes

* missing exported functions and variables ([e0bc6c9](https://github.com/ax-llm/ax/commit/e0bc6c92ec73371804b6923c3778575efff35d16))

## [11.0.27](https://github.com/ax-llm/ax/compare/11.0.25...11.0.26) (2025-03-17)

### Bug Fixes

* missing exported functions and variables ([e0bc6c9](https://github.com/ax-llm/ax/commit/e0bc6c92ec73371804b6923c3778575efff35d16))
## [11.0.26](https://github.com/ax-llm/ax/compare/11.0.25...11.0.26) (2025-03-17)

### Bug Fixes

* mcp init issue ([00a732c](https://github.com/ax-llm/ax/commit/00a732c4a765e6cca7e27ade3658c93c83315c6a))

## [11.0.26](https://github.com/ax-llm/ax/compare/11.0.24...11.0.25) (2025-03-17)

### Bug Fixes

* mcp init issue ([00a732c](https://github.com/ax-llm/ax/commit/00a732c4a765e6cca7e27ade3658c93c83315c6a))
## [11.0.25](https://github.com/ax-llm/ax/compare/11.0.24...11.0.25) (2025-03-17)

### Bug Fixes

* build issues ([69871d7](https://github.com/ax-llm/ax/commit/69871d745a7d1988907368de7df02a8a72fc98d1))

## [11.0.25](https://github.com/ax-llm/ax/compare/11.0.23...11.0.24) (2025-03-17)

### Bug Fixes

* build issues ([69871d7](https://github.com/ax-llm/ax/commit/69871d745a7d1988907368de7df02a8a72fc98d1))
## [11.0.24](https://github.com/ax-llm/ax/compare/11.0.23...11.0.24) (2025-03-16)

### Bug Fixes

* evalUtils missing from exports in index.ts ([#173](https://github.com/ax-llm/ax/issues/173)) ([b103f41](https://github.com/ax-llm/ax/commit/b103f41aa8726175ca7a87a78d925bcd1bac06b9))

## [11.0.24](https://github.com/ax-llm/ax/compare/11.0.22...11.0.23) (2025-03-16)

### Bug Fixes

* evalUtils missing from exports in index.ts ([#173](https://github.com/ax-llm/ax/issues/173)) ([b103f41](https://github.com/ax-llm/ax/commit/b103f41aa8726175ca7a87a78d925bcd1bac06b9))
## [11.0.23](https://github.com/ax-llm/ax/compare/11.0.22...11.0.23) (2025-02-26)

## [11.0.23](https://github.com/ax-llm/ax/compare/11.0.22...11.0.23) (2025-02-23)

### Features

* Add support for Claude 3.7 models (#162) ([766bbbf] (https://github.com/ax-llm/ax/commit/766bbbf9ed267a2029b3da6ccb5bb65b496c1fd8))

## [11.0.22](https://github.com/ax-llm/ax/compare/11.0.20...11.0.21) (2025-02-23)

### Features

* new multi service router ([6886416](https://github.com/ax-llm/ax/commit/688641644aeb18d6dea1a307c5d6872df982cd36))
* rename `max_tokens` to `max_completion_tokens` in `AxAIOpenAI` ([#156](https://github.com/ax-llm/ax/issues/156)) ([76f1e53](https://github.com/ax-llm/ax/commit/76f1e53f33743ee460569bb94d0bd3620db6e328))

### Bug Fixes

* old router is now simple classifier ([0c9f4f4](https://github.com/ax-llm/ax/commit/0c9f4f49537ec729093b8a91aa6b593ddd4f285c))
## [11.0.21](https://github.com/ax-llm/ax/compare/11.0.20...11.0.21) (2025-02-19)

## [11.0.21](https://github.com/ax-llm/ax/compare/11.0.20...11.0.21) (2025-02-19)

### Bug Fixes

* Rename endpoint -> endpointId (to match Google docs) (#155) ([cc322a9](https://github.com/ax-llm/ax/commit/cc322a95895888529ccf302a95ff86fde3482d3f))

## [11.0.20](https://github.com/ax-llm/ax/compare/11.0.18...11.0.19) (2025-02-19)
## [11.0.19](https://github.com/ax-llm/ax/compare/11.0.18...11.0.19) (2025-02-19)

### Bug Fixes

* major fix for issue with streaming deltas ([91f5253](https://github.com/ax-llm/ax/commit/91f5253e8f00a2b51b867401a5f823546a21aea9))

## [11.0.19](https://github.com/ax-llm/ax/compare/11.0.17...11.0.18) (2025-02-19)

### Bug Fixes

* major fix for issue with streaming deltas ([91f5253](https://github.com/ax-llm/ax/commit/91f5253e8f00a2b51b867401a5f823546a21aea9))
## [11.0.18](https://github.com/ax-llm/ax/compare/11.0.17...11.0.18) (2025-02-18)

### Bug Fixes

* build issue ([879ef38](https://github.com/ax-llm/ax/commit/879ef381693ba0e62eaf9d8fbec28477ff0c582d))

## [11.0.18](https://github.com/ax-llm/ax/compare/11.0.16...11.0.17) (2025-02-18)

### Bug Fixes

* build issue ([879ef38](https://github.com/ax-llm/ax/commit/879ef381693ba0e62eaf9d8fbec28477ff0c582d))
## [11.0.17](https://github.com/ax-llm/ax/compare/11.0.16...11.0.17) (2025-02-18)

### Features

* add field processing functions to output fields ([fb996da](https://github.com/ax-llm/ax/commit/fb996da34ee714c0bb906e4943feedf87ae8717f))
* added fastFail to agents and axgen ([eac6a71](https://github.com/ax-llm/ax/commit/eac6a71b7e158cef7a6b235a25776926d14f96bd))

## [11.0.17](https://github.com/ax-llm/ax/compare/11.0.15...11.0.16) (2025-02-18)

### Features

* add field processing functions to output fields ([fb996da](https://github.com/ax-llm/ax/commit/fb996da34ee714c0bb906e4943feedf87ae8717f))
* added fastFail to agents and axgen ([eac6a71](https://github.com/ax-llm/ax/commit/eac6a71b7e158cef7a6b235a25776926d14f96bd))
## [11.0.16](https://github.com/ax-llm/ax/compare/11.0.15...11.0.16) (2025-02-17)

## [11.0.16](https://github.com/ax-llm/ax/compare/11.0.15...11.0.16) (2025-02-14)

### Features

* Add support for Vertex API custom model endpoints (#146) ([94aa007](https://github.com/ax-llm/ax/commit/94aa007b6056de5a230ef38e3304c917881c8285))

## [11.0.15](https://github.com/ax-llm/ax/compare/11.0.14...11.0.15) (2025-02-14)

### Bug Fixes

* Allow json examples to pass validation (#144) ([0ec2694](https://github.com/ax-llm/ax/commit/0ec26946c0478a92739bef97859d5dee23c1dcc7))


## [11.0.14](https://github.com/ax-llm/ax/compare/11.0.13...11.0.14) (2025-02-14)

### Features

* new earlyFail option ([0bac127](https://github.com/ax-llm/ax/commit/0bac127134a3905bbf893f69ef9ee333a9c6f48e))
## [11.0.13](https://github.com/ax-llm/ax/compare/11.0.12...11.0.13) (2025-02-13)

### Bug Fixes

* prompt ordering ([80dd8f2](https://github.com/ax-llm/ax/commit/80dd8f28c9812bbbea77754aa36c75e2967b5a7b))

## [11.0.13](https://github.com/ax-llm/ax/compare/11.0.11...11.0.12) (2025-02-13)

### Bug Fixes

* prompt ordering ([80dd8f2](https://github.com/ax-llm/ax/commit/80dd8f28c9812bbbea77754aa36c75e2967b5a7b))
## [11.0.12](https://github.com/ax-llm/ax/compare/11.0.11...11.0.12) (2025-02-13)

### Features

* added additional tests for agent ([e463f20](https://github.com/ax-llm/ax/commit/e463f209103152ea585af06fb4dd974bd22d5124))

## [11.0.12](https://github.com/ax-llm/ax/compare/11.0.10...11.0.11) (2025-02-13)

### Features

* added additional tests for agent ([e463f20](https://github.com/ax-llm/ax/commit/e463f209103152ea585af06fb4dd974bd22d5124))
## [11.0.11](https://github.com/ax-llm/ax/compare/11.0.10...11.0.11) (2025-02-13)

### Bug Fixes

* build issue ([201d331](https://github.com/ax-llm/ax/commit/201d33126c69dca4907101fab974d6e5e6ba42fd))

## [11.0.11](https://github.com/ax-llm/ax/compare/11.0.9...11.0.10) (2025-02-13)

### Bug Fixes

* build issue ([201d331](https://github.com/ax-llm/ax/commit/201d33126c69dca4907101fab974d6e5e6ba42fd))
## [11.0.10](https://github.com/ax-llm/ax/compare/11.0.9...11.0.10) (2025-02-13)

### Features

* seperate description and definition for agents ([bbf644c](https://github.com/ax-llm/ax/commit/bbf644c497501905cba3aee691e552961543ce8e))

## [11.0.10](https://github.com/ax-llm/ax/compare/11.0.8...11.0.9) (2025-02-13)

### Features

* seperate description and definition for agents ([bbf644c](https://github.com/ax-llm/ax/commit/bbf644c497501905cba3aee691e552961543ce8e))
## [11.0.9](https://github.com/ax-llm/ax/compare/11.0.8...11.0.9) (2025-02-10)

### Bug Fixes

* issue with agent set description ([7c9af34](https://github.com/ax-llm/ax/commit/7c9af34276ac527f0fe8bbaa3994690ca7b335d9))

## [11.0.9](https://github.com/ax-llm/ax/compare/11.0.7...11.0.8) (2025-02-10)

### Bug Fixes

* issue with agent set description ([7c9af34](https://github.com/ax-llm/ax/commit/7c9af34276ac527f0fe8bbaa3994690ca7b335d9))
## [11.0.8](https://github.com/ax-llm/ax/compare/11.0.7...11.0.8) (2025-02-10)

### Bug Fixes

* whitespace streaming extract issue ([9706b4f](https://github.com/ax-llm/ax/commit/9706b4f1fecb6db3d74cde2271e8627208204c45))

## [11.0.8](https://github.com/ax-llm/ax/compare/11.0.6...11.0.7) (2025-02-10)

### Bug Fixes

* whitespace streaming extract issue ([9706b4f](https://github.com/ax-llm/ax/commit/9706b4f1fecb6db3d74cde2271e8627208204c45))
## [11.0.7](https://github.com/ax-llm/ax/compare/11.0.6...11.0.7) (2025-02-09)

### Features

* agents can now have pass through fields in agent swarms ([2e1c021](https://github.com/ax-llm/ax/commit/2e1c021f330e17227b5340316a27a7aed6cf46df))

## [11.0.7](https://github.com/ax-llm/ax/compare/11.0.5...11.0.6) (2025-02-09)

### Features

* agents can now have pass through fields in agent swarms ([2e1c021](https://github.com/ax-llm/ax/commit/2e1c021f330e17227b5340316a27a7aed6cf46df))
## [11.0.6](https://github.com/ax-llm/ax/compare/11.0.5...11.0.6) (2025-02-07)

### Bug Fixes

* TypeError: Cannot read properties of undefined (reading 'length') ([#131](https://github.com/ax-llm/ax/issues/131)) ([a997f5b](https://github.com/ax-llm/ax/commit/a997f5be14be512fd3457c67f9aa2948f01c0d4a))

## [11.0.6](https://github.com/ax-llm/ax/compare/11.0.5...11.0.6) (2025-02-07)

### Bug fixes

* fix: TypeError: Cannot read properties of undefined (reading 'length') (#131) ([a997f5b](https://github.com/ax-llm/ax/commit/a997f5be14be512fd3457c67f9aa2948f01c0d4a))

## [11.0.5](https://github.com/ax-llm/ax/compare/11.0.4...11.0.5) (2025-02-07)

### Bug Fixes

* Fix: allow Anthropic Vertex API models in model list ([348c71e](https://github.com/ax-llm/ax/commit/348c71ecde4397fe7c99a879317f6ead90ed81e1))

## [11.0.4](https://github.com/ax-llm/ax/compare/11.0.3...11.0.4) (2025-02-07)

### Features

* Add Gemini 1.5 Flash 002 model, since Vertex defaults to 001 (#130) ([d9ddc68](https://github.com/ax-llm/ax/commit/d9ddc68b1aacc8e94bb0a2f84dbb852ca52a8ed5))

## [11.0.3](https://github.com/ax-llm/ax/compare/11.0.2...11.0.3) (2025-02-07)

### Bug Fixes

* Fix: deepseek r1 on together.ai returning empty result (#128) ([250ed54](https://github.com/ax-llm/ax/commit/250ed54e9d7e0d1f40aa5cc8b58e684badd4583d))

## [11.0.2](https://github.com/ax-llm/ax/compare/11.0.1...11.0.2) (2025-02-07)

### Bug Fixes

* option to disable smart routing in agents ([ce1b25f](https://github.com/ax-llm/ax/commit/ce1b25ff4e288647d01f032afad109a762940f4b))
## [11.0.1](https://github.com/ax-llm/ax/compare/11.0.0...11.0.1) (2025-02-06)

### Bug Fixes

* types cleanup, all model inputs are clearly typed ([192d9d4](https://github.com/ax-llm/ax/commit/192d9d43d0524ced16bf9257b20610b9a3040112))

## [11.0.1](https://github.com/ax-llm/ax/compare/10.0.50...11.0.0) (2025-02-06)

### Bug Fixes

* types cleanup, all model inputs are clearly typed ([192d9d4](https://github.com/ax-llm/ax/commit/192d9d43d0524ced16bf9257b20610b9a3040112))
## [11.0.0](https://github.com/ax-llm/ax/compare/10.0.50...11.0.0) (2025-02-06)

### Features

* smart model routing for agents and sub-agents [Breaking Changes] ([1d313b4](https://github.com/ax-llm/ax/commit/1d313b450db62f6da9dd8bf4f4fd52a37b89120b))

### Bug Fixes

* package upgrades ([f969bd7](https://github.com/ax-llm/ax/commit/f969bd790d7e813ea4e450158d1f212598489039))

## [11.0.0](https://github.com/ax-llm/ax/compare/10.0.49...10.0.50) (2025-02-06)

### Features

* smart model routing for agents and sub-agents [Breaking Changes] ([1d313b4](https://github.com/ax-llm/ax/commit/1d313b450db62f6da9dd8bf4f4fd52a37b89120b))

### Bug Fixes

* package upgrades ([f969bd7](https://github.com/ax-llm/ax/commit/f969bd790d7e813ea4e450158d1f212598489039))
## [10.0.50](https://github.com/ax-llm/ax/compare/10.0.49...10.0.50) (2025-02-03)

### Bug Fixes

* required values validation ([f997236](https://github.com/ax-llm/ax/commit/f997236f698fe1745fb3db49afda0af772f82d58))

## [10.0.50](https://github.com/ax-llm/ax/compare/10.0.48...10.0.49) (2025-02-03)

### Bug Fixes

* required values validation ([f997236](https://github.com/ax-llm/ax/commit/f997236f698fe1745fb3db49afda0af772f82d58))
## [10.0.49](https://github.com/ax-llm/ax/compare/10.0.48...10.0.49) (2025-02-02)

### Features

* improved function argument error correction ([4325101](https://github.com/ax-llm/ax/commit/4325101b9b951556d9d8c44b4b835058cc87ad81))

## [10.0.49](https://github.com/ax-llm/ax/compare/10.0.47...10.0.48) (2025-02-02)

### Features

* improved function argument error correction ([4325101](https://github.com/ax-llm/ax/commit/4325101b9b951556d9d8c44b4b835058cc87ad81))
## [10.0.48](https://github.com/ax-llm/ax/compare/10.0.47...10.0.48) (2025-02-01)

### Features

* new AxFunctionError for function arg error correction ([6f14c0d](https://github.com/ax-llm/ax/commit/6f14c0dd491167b52ef7673412e68560485072e0))

## [10.0.48](https://github.com/ax-llm/ax/compare/10.0.46...10.0.47) (2025-02-01)

### Features

* new AxFunctionError for function arg error correction ([6f14c0d](https://github.com/ax-llm/ax/commit/6f14c0dd491167b52ef7673412e68560485072e0))
## [10.0.47](https://github.com/ax-llm/ax/compare/10.0.46...10.0.47) (2025-02-01)

### Bug Fixes

* path fix in new apicall: ([2afc899](https://github.com/ax-llm/ax/commit/2afc8993f6820269d76f99c273c600de645cc864))
* retry logic in apicall ([db83ba4](https://github.com/ax-llm/ax/commit/db83ba4b6a36286ca56ab99f6d6ace5fb7871f34))

## [10.0.47](https://github.com/ax-llm/ax/compare/10.0.45...10.0.46) (2025-02-01)

### Bug Fixes

* path fix in new apicall: ([2afc899](https://github.com/ax-llm/ax/commit/2afc8993f6820269d76f99c273c600de645cc864))
* retry logic in apicall ([db83ba4](https://github.com/ax-llm/ax/commit/db83ba4b6a36286ca56ab99f6d6ace5fb7871f34))
## [10.0.46](https://github.com/ax-llm/ax/compare/10.0.45...10.0.46) (2025-01-31)

### Bug Fixes

* allow google auth lib to manage token lifecycle ([#119](https://github.com/ax-llm/ax/issues/119)) ([48a2322](https://github.com/ax-llm/ax/commit/48a2322f8f4b29dbd165223fc4c186666e2d6b11))

## [10.0.46](https://github.com/ax-llm/ax/compare/10.0.45...10.0.46) (2025-01-31)

### Bug fixes

* fix: allow google auth lib to manage token lifecycle (#119) ([48a2322](https://github.com/ax-llm/ax/commit/48a2322f8f4b29dbd165223fc4c186666e2d6b11))

## [10.0.45](https://github.com/ax-llm/ax/compare/10.0.44...10.0.45) (2025-01-31)

### Bug fixes

* fix: don't swallow error in AxBalancer (#118) ([aa25c7a](https://github.com/ax-llm/ax/commit/aa25c7a3afc2f71af8537ddb2425633d693e43c0))

## [10.0.44](https://github.com/ax-llm/ax/compare/10.0.43...10.0.44) (2025-01-31)

### Features

* apicall and sse updates ([74d70b6](https://github.com/ax-llm/ax/commit/74d70b61de38664dca7ce97ff4619f5f516ae27e))
## [10.0.43](https://github.com/ax-llm/ax/compare/10.0.42...10.0.43) (2025-01-30)

### Bug Fixes

* anthropic function calling ([73f5491](https://github.com/ax-llm/ax/commit/73f5491137dc738c1793411d0388c1c2012829f9))
* cleanup ([e005c68](https://github.com/ax-llm/ax/commit/e005c681652036ddd04075f2c3ca9ba372525f55))

## [10.0.43](https://github.com/ax-llm/ax/compare/10.0.41...10.0.42) (2025-01-30)

### Bug Fixes

* anthropic function calling ([73f5491](https://github.com/ax-llm/ax/commit/73f5491137dc738c1793411d0388c1c2012829f9))
* cleanup ([e005c68](https://github.com/ax-llm/ax/commit/e005c681652036ddd04075f2c3ca9ba372525f55))
## [10.0.42](https://github.com/ax-llm/ax/compare/10.0.41...10.0.42) (2025-01-29)

### Bug Fixes

* more streaming fixes ([ac3948b](https://github.com/ax-llm/ax/commit/ac3948bcedf4c4304ebfc1a62a1c70d8e69e1c87))

## [10.0.42](https://github.com/ax-llm/ax/compare/10.0.40...10.0.41) (2025-01-29)

### Bug Fixes

* more streaming fixes ([ac3948b](https://github.com/ax-llm/ax/commit/ac3948bcedf4c4304ebfc1a62a1c70d8e69e1c87))
## [10.0.41](https://github.com/ax-llm/ax/compare/10.0.40...10.0.41) (2025-01-29)

### Bug Fixes

* parsing while end-to-end streaming ([fee7775](https://github.com/ax-llm/ax/commit/fee7775ae9283903aa7e8815c04a149727bcdbd1))

## [10.0.41](https://github.com/ax-llm/ax/compare/10.0.39...10.0.40) (2025-01-29)

### Bug Fixes

* parsing while end-to-end streaming ([fee7775](https://github.com/ax-llm/ax/commit/fee7775ae9283903aa7e8815c04a149727bcdbd1))
## [10.0.40](https://github.com/ax-llm/ax/compare/10.0.39...10.0.40) (2025-01-27)

### Features

* end-to-end streaming with parsing, error-correction, validation and function calling ([3b59665](https://github.com/ax-llm/ax/commit/3b596658221d8b6fef089e972bb32b44d0df600e))

### Bug Fixes

* build fixes ([81809a4](https://github.com/ax-llm/ax/commit/81809a4129cd0508b9740ae7a382413445edd79e))
* doc build fix ([b6c110b](https://github.com/ax-llm/ax/commit/b6c110b151c78b2096b21b4ec32f573796a3b9de))
* don't render extraneous period at the end of task prompt ([#111](https://github.com/ax-llm/ax/issues/111)) ([3c30c47](https://github.com/ax-llm/ax/commit/3c30c47d06c1f5dbcb425eb840166d436e9ac709))

## [10.0.40](https://github.com/ax-llm/ax/compare/10.0.38...10.0.39) (2025-01-27)

### Features

* end-to-end streaming with parsing, error-correction, validation and function calling ([3b59665](https://github.com/ax-llm/ax/commit/3b596658221d8b6fef089e972bb32b44d0df600e))

### Bug Fixes

* build fixes ([81809a4](https://github.com/ax-llm/ax/commit/81809a4129cd0508b9740ae7a382413445edd79e))
* doc build fix ([b6c110b](https://github.com/ax-llm/ax/commit/b6c110b151c78b2096b21b4ec32f573796a3b9de))
* don't render extraneous period at the end of task prompt ([#111](https://github.com/ax-llm/ax/issues/111)) ([3c30c47](https://github.com/ax-llm/ax/commit/3c30c47d06c1f5dbcb425eb840166d436e9ac709))
## [10.0.39](https://github.com/ax-llm/ax/compare/10.0.38...10.0.39) (2025-01-27)

### Bug Fixes

* embedding requests on Google Vertex API ([#107](https://github.com/ax-llm/ax/issues/107)) ([25282f6](https://github.com/ax-llm/ax/commit/25282f6277e1f5d52aceebd86503256d19218b6d))

## [10.0.39](https://github.com/ax-llm/ax/compare/10.0.38...10.0.39) (2025-01-27)

### Features

* Add auth for Google Vertex API (#106) ([e6c661a](https://github.com/ax-llm/ax/commit/e6c661aea4dbef01a89565ca4a1694e9fd6a53d2))
* Add support for Google text-embedding-005 model (#109) ([ee9f1f6](https://github.com/ax-llm/ax/commit/ee9f1f6d953f54ede04c4977102a2f975010beb7))

### Bug Fixes

* Fix: embedding requests on Google Vertex API (#107) ([25282f6](https://github.com/ax-llm/ax/commit/25282f6277e1f5d52aceebd86503256d19218b6d))


## [10.0.38](https://github.com/ax-llm/ax/compare/10.0.37...10.0.38) (2025-01-24)

### Bug Fixes

* Move service comparators inside AxBalancer class (#104) ([0be9db5](https://github.com/ax-llm/ax/commit/0be9db5bad13ae709c17031a3fca4797e2e768f2))

## [10.0.37](https://github.com/ax-llm/ax/compare/10.0.36...10.0.37) (2025-01-23)

### Features

* Add logging for balancer failover (#101) ([de5287a](https://github.com/ax-llm/ax/commit/de5287a4652e209d0911a25aa609cc131db21135))

## [10.0.36](https://github.com/ax-llm/ax/compare/10.0.34...10.0.35) (2025-01-21)

### Features

* new tagging api for memory ([2538a46](https://github.com/ax-llm/ax/commit/2538a460894634b16dc8fb5b64b1db68e6024709))
## [10.0.35](https://github.com/ax-llm/ax/compare/10.0.34...10.0.35) (2025-01-20)

### Bug Fixes

* gemini non-streaming endpoint fix ([11179ad](https://github.com/ax-llm/ax/commit/11179ad312989b56b79c9144527e5e8371a1c281))

## [10.0.35](https://github.com/ax-llm/ax/compare/10.0.33...10.0.34) (2025-01-20)

### Bug Fixes

* gemini non-streaming endpoint fix ([11179ad](https://github.com/ax-llm/ax/commit/11179ad312989b56b79c9144527e5e8371a1c281))
## [10.0.34](https://github.com/ax-llm/ax/compare/10.0.33...10.0.34) (2025-01-19)

### Bug Fixes

* ci failure ([#96](https://github.com/ax-llm/ax/issues/96)) ([ba835f4](https://github.com/ax-llm/ax/commit/ba835f4620b1a79367cc7706aa7b5539c0517f49))

## [10.0.34](https://github.com/ax-llm/ax/compare/10.0.33...10.0.34) (2025-01-19)

### Bug Fixes

- Fix: ci failure (#96)
  ([ba835f4](https://github.com/ax-llm/ax/commit/ba835f4620b1a79367cc7706aa7b5539c0517f49))

## [10.0.33](https://github.com/ax-llm/ax/compare/10.0.31...10.0.32) (2025-01-19)

### Bug Fixes

- gemini flash function calling issue
  ([6480d2c](https://github.com/ax-llm/ax/commit/6480d2c450f96b77b8fbb30815cc375a49875168))

## [10.0.32](https://github.com/ax-llm/ax/compare/10.0.31...10.0.32) (2025-01-18)

### Bug Fixes

- don't fail validation on missing optional field
  ([#94](https://github.com/ax-llm/ax/issues/94))
  ([432f8fc](https://github.com/ax-llm/ax/commit/432f8fc53980a2316a0b0953cff4811592641ff0))

## [10.0.32](https://github.com/ax-llm/ax/compare/10.0.31...10.0.32) (2025-01-18)

### Bug Fixes

- Fix: don't fail validation on missing optional field (#94)
  ([432f8fc](https://github.com/ax-llm/ax/commit/432f8fc53980a2316a0b0953cff4811592641ff0))

## [10.0.31](https://github.com/ax-llm/ax/compare/10.0.29...10.0.30) (2025-01-16)

### Bug Fixes

- debug logs
  ([7939cde](https://github.com/ax-llm/ax/commit/7939cde6d82a42c79daa8197d27c2f25140c636b))

## [10.0.30](https://github.com/ax-llm/ax/compare/10.0.29...10.0.30) (2025-01-16)

### Bug Fixes

- prompt updates
  ([6f51a92](https://github.com/ax-llm/ax/commit/6f51a92e26a1e543a5546321f4ab5bf9e39233b0))

## [10.0.30](https://github.com/ax-llm/ax/compare/10.0.28...10.0.29) (2025-01-16)

### Bug Fixes

- prompt updates
  ([6f51a92](https://github.com/ax-llm/ax/commit/6f51a92e26a1e543a5546321f4ab5bf9e39233b0))

## [10.0.29](https://github.com/ax-llm/ax/compare/10.0.28...10.0.29) (2025-01-15)

### Bug Fixes

- prompt improvements
  ([79891d6](https://github.com/ax-llm/ax/commit/79891d6c756385bae19b9fa4ed674c9d597d725c))

## [10.0.29](https://github.com/ax-llm/ax/compare/10.0.27...10.0.28) (2025-01-15)

### Bug Fixes

- prompt improvements
  ([79891d6](https://github.com/ax-llm/ax/commit/79891d6c756385bae19b9fa4ed674c9d597d725c))

## [10.0.28](https://github.com/ax-llm/ax/compare/10.0.27...10.0.28) (2025-01-14)

### Bug Fixes

- file path issue in ax build
  ([3264a11](https://github.com/ax-llm/ax/commit/3264a11387272387efeb029872b5406156ea3fa4))

## [10.0.28](https://github.com/ax-llm/ax/compare/10.0.27...10.0.28) (2025-01-14)

### Bug Fixes

- Fix: file path issue in ax build
  ([3264a11](https://github.com/ax-llm/ax/commit/3264a11387272387efeb029872b5406156ea3fa4))

## [10.0.27](https://github.com/ax-llm/ax/compare/10.0.26...10.0.27) (2025-01-14)

### Bug Fixes

- Use OpenTelemetry api types directly for tracing (#91)
  ([2b6dc4f](https://github.com/ax-llm/ax/commit/2b6dc4fad36a0e96cf034a2d108976c7811b748e))

## [10.0.26](https://github.com/ax-llm/ax/compare/10.0.25...10.0.26) (2025-01-14)

### Features

- redesigned docs, improved system prompts and other fixes
  ([6cd870e](https://github.com/ax-llm/ax/commit/6cd870e7ae89aa32f1d73b87da31de886303cf9d))

### Bug Fixes

- big refactor and improved tooling
  ([e83059f](https://github.com/ax-llm/ax/commit/e83059f7bb695f9eb201bfcb5c4db39233265c61))
- issue with doc:build
  ([a504956](https://github.com/ax-llm/ax/commit/a504956bbd7c3569dea49393d9f007b6ec917232))

## [10.0.25](https://github.com/ax-llm/ax/compare/10.0.24...10.0.25) (2025-01-10)

### Bug Fixes

- Add missing getMetrics call in AxBalancer and test mock (#83)
  [383a9cf](https://github.com/ax-llm/ax/commit/383a9cffe2255f98eb6697a5e2b9d8b06d07365e)

## [10.0.24](https://github.com/ax-llm/ax/compare/10.0.23...10.0.24) (2025-01-10)

### Features

- new getMetrics() method on AxAIService for latency and error metrics
  ([088aaca](https://github.com/ax-llm/ax/commit/088aaca85b2d4b75718f377f48094c22fb978832))

## [10.0.23](https://github.com/ax-llm/ax/compare/10.0.22...10.0.23) (2025-01-09)

### Bug Fixes

- refactor to ensure config values are correctly handled
  ([ee5b068](https://github.com/ax-llm/ax/commit/ee5b06859fe60533b620b115a6b954b9b25eebe2))

## [10.0.23](https://github.com/ax-llm/ax/compare/10.0.21...10.0.22) (2025-01-09)

### Bug Fixes

- refactor to ensure config values are correctly handled
  ([ee5b068](https://github.com/ax-llm/ax/commit/ee5b06859fe60533b620b115a6b954b9b25eebe2))

## [10.0.22](https://github.com/ax-llm/ax/compare/10.0.21...10.0.22) (2025-01-09)

### Features

- Add configurable comparator for AxBalance service order
  ([#81](https://github.com/ax-llm/ax/issues/81))
  ([9f9864b](https://github.com/ax-llm/ax/commit/9f9864b0796df1ff5fe5c0d7a8400ad100b8d7d4))

## [10.0.22](https://github.com/ax-llm/ax/compare/10.0.20...10.0.21) (2025-01-09)

### Features

- Add configurable comparator for AxBalance service order
  ([#81](https://github.com/ax-llm/ax/issues/81))
  ([9f9864b](https://github.com/ax-llm/ax/commit/9f9864b0796df1ff5fe5c0d7a8400ad100b8d7d4))

## [10.0.21](https://github.com/ax-llm/ax/compare/10.0.20...10.0.21) (2025-01-09)

### Bug Fixes

- added claude 35 haiku to the info list
  ([6c6f446](https://github.com/ax-llm/ax/commit/6c6f446ccfde0f2634aa1aaeb19e6cd0a2d72293))
- improved model matching for info search
  ([5c8c8e3](https://github.com/ax-llm/ax/commit/5c8c8e3d5c325872ca2217c813f224394273ce6a))
- type issue
  ([9b16404](https://github.com/ax-llm/ax/commit/9b1640457be7092d0abf8a7f492a5d2a987549dc))

## [10.0.21](https://github.com/ax-llm/ax/compare/10.0.19...10.0.20) (2025-01-09)

### Bug Fixes

- added claude 35 haiku to the info list
  ([6c6f446](https://github.com/ax-llm/ax/commit/6c6f446ccfde0f2634aa1aaeb19e6cd0a2d72293))
- improved model matching for info search
  ([5c8c8e3](https://github.com/ax-llm/ax/commit/5c8c8e3d5c325872ca2217c813f224394273ce6a))
- type issue
  ([9b16404](https://github.com/ax-llm/ax/commit/9b1640457be7092d0abf8a7f492a5d2a987549dc))

## [10.0.20](https://github.com/ax-llm/ax/compare/10.0.19...10.0.20) (2025-01-09)

### Bug Fixes

- various issues including [#80](https://github.com/ax-llm/ax/issues/80)
  ([9a3d5d4](https://github.com/ax-llm/ax/commit/9a3d5d4bec68ce2a221a5133eaaa31dd3382b4b7))

## [10.0.20](https://github.com/ax-llm/ax/compare/10.0.18...10.0.19) (2025-01-09)

### Bug Fixes

- various issues including [#80](https://github.com/ax-llm/ax/issues/80)
  ([9a3d5d4](https://github.com/ax-llm/ax/commit/9a3d5d4bec68ce2a221a5133eaaa31dd3382b4b7))

## [10.0.19](https://github.com/ax-llm/ax/compare/10.0.18...10.0.19) (2025-01-02)

### Features

- add input audio type compatibility
  ([#78](https://github.com/ax-llm/ax/issues/78))
  ([23189d4](https://github.com/ax-llm/ax/commit/23189d443de85fc7045d560223181aad9e1e528c))

## [10.0.19](https://github.com/ax-llm/ax/compare/10.0.17...10.0.18) (2025-01-02)

### Features

- add input audio type compatibility
  ([#78](https://github.com/ax-llm/ax/issues/78))
  ([23189d4](https://github.com/ax-llm/ax/commit/23189d443de85fc7045d560223181aad9e1e528c))

## [10.0.18](https://github.com/ax-llm/ax/compare/10.0.17...10.0.18) (2024-12-19)

### Bug Fixes

- gemini function calling issues
  ([ad865d7](https://github.com/ax-llm/ax/commit/ad865d74c1b95e8d61a3bc5c259924867eb9c1e0))

## [10.0.18](https://github.com/ax-llm/ax/compare/10.0.16...10.0.17) (2024-12-19)

### Bug Fixes

- gemini function calling issues
  ([ad865d7](https://github.com/ax-llm/ax/commit/ad865d74c1b95e8d61a3bc5c259924867eb9c1e0))

## [10.0.17](https://github.com/ax-llm/ax/compare/10.0.16...10.0.17) (2024-12-18)

### Features

- major prompt refactor for better performance
  ([3b718a0](https://github.com/ax-llm/ax/commit/3b718a00ecc727bc10c4a4657e1d24f3ec9fe455))

## [10.0.17](https://github.com/ax-llm/ax/compare/10.0.15...10.0.16) (2024-12-18)

### Features

- major prompt refactor for better performance
  ([3b718a0](https://github.com/ax-llm/ax/commit/3b718a00ecc727bc10c4a4657e1d24f3ec9fe455))

## [10.0.16](https://github.com/ax-llm/ax/compare/10.0.15...10.0.16) (2024-12-16)

### Bug Fixes

- functions are optional for agents
  ([13f6251](https://github.com/ax-llm/ax/commit/13f625188c51c2cac208ce391cc771414e4471b3))

## [10.0.16](https://github.com/ax-llm/ax/compare/10.0.14...10.0.15) (2024-12-16)

### Bug Fixes

- functions are optional for agents
  ([13f6251](https://github.com/ax-llm/ax/commit/13f625188c51c2cac208ce391cc771414e4471b3))

## [10.0.15](https://github.com/ax-llm/ax/compare/10.0.14...10.0.15) (2024-12-16)

### Bug Fixes

- vertex ai and streaming fixes
  ([8c0ade9](https://github.com/ax-llm/ax/commit/8c0ade90bd39134882563c717a2205adf30a7d61))

## [10.0.15](https://github.com/ax-llm/ax/compare/10.0.13...10.0.14) (2024-12-16)

### Bug Fixes

- vertex ai and streaming fixes
  ([8c0ade9](https://github.com/ax-llm/ax/commit/8c0ade90bd39134882563c717a2205adf30a7d61))

## [10.0.14](https://github.com/ax-llm/ax/compare/10.0.13...10.0.14) (2024-12-13)

### Bug Fixes

- minor
  ([ef0cda2](https://github.com/ax-llm/ax/commit/ef0cda2c6fcdf4b7d11af7f33d9f71a9d2d91ef8))

## [10.0.14](https://github.com/ax-llm/ax/compare/10.0.12...10.0.13) (2024-12-13)

### Bug Fixes

- minor
  ([ef0cda2](https://github.com/ax-llm/ax/commit/ef0cda2c6fcdf4b7d11af7f33d9f71a9d2d91ef8))

## [10.0.13](https://github.com/ax-llm/ax/compare/10.0.12...10.0.13) (2024-12-13)

### Features

- new stopFunction option to return after a function is called
  ([4a56c9c](https://github.com/ax-llm/ax/commit/4a56c9cbbb589eaabfec57908899714f2d7a55d0))

## [10.0.13](https://github.com/ax-llm/ax/compare/10.0.11...10.0.12) (2024-12-13)

### Features

- new stopFunction option to return after a function is called
  ([4a56c9c](https://github.com/ax-llm/ax/commit/4a56c9cbbb589eaabfec57908899714f2d7a55d0))

## [10.0.12](https://github.com/ax-llm/ax/compare/10.0.11...10.0.12) (2024-12-05)

## [10.0.12](https://github.com/ax-llm/ax/compare/10.0.10...10.0.11) (2024-12-05)

## [10.0.11](https://github.com/ax-llm/ax/compare/10.0.10...10.0.11) (2024-12-04)

### Bug Fixes

- minor fixes
  ([e5f6f15](https://github.com/ax-llm/ax/commit/e5f6f151bd42a5b58e84d6d84266737c0f3a960a))

## [10.0.11](https://github.com/ax-llm/ax/compare/10.0.9...10.0.10) (2024-12-04)

### Bug Fixes

- minor fixes
  ([e5f6f15](https://github.com/ax-llm/ax/commit/e5f6f151bd42a5b58e84d6d84266737c0f3a960a))

## [10.0.10](https://github.com/ax-llm/ax/compare/10.0.9...10.0.10) (2024-11-22)

### Features

- added tests for field extraction functions
  ([4818f09](https://github.com/ax-llm/ax/commit/4818f09ccc9ea7dd69d7897b8fa3ed9fad3de921))

## [10.0.10](https://github.com/ax-llm/ax/compare/10.0.8...10.0.9) (2024-11-22)

### Features

- added tests for field extraction functions
  ([4818f09](https://github.com/ax-llm/ax/commit/4818f09ccc9ea7dd69d7897b8fa3ed9fad3de921))

## [10.0.9](https://github.com/ax-llm/ax/compare/10.0.8...10.0.9) (2024-11-21)

### Bug Fixes

- field extraction issue
  ([9d4a083](https://github.com/ax-llm/ax/commit/9d4a083af3b845b057294badc096685fb781ed27))

## [10.0.9](https://github.com/ax-llm/ax/compare/10.0.7...10.0.8) (2024-11-21)

### Bug Fixes

- field extraction issue
  ([9d4a083](https://github.com/ax-llm/ax/commit/9d4a083af3b845b057294badc096685fb781ed27))

## [10.0.8](https://github.com/ax-llm/ax/compare/10.0.7...10.0.8) (2024-11-20)

### Bug Fixes

- bug in traces, missing input values
  ([d8a8ee5](https://github.com/ax-llm/ax/commit/d8a8ee5544214c30a1ac341b7c11fb9fd717a57b))

## [10.0.8](https://github.com/ax-llm/ax/compare/10.0.6...10.0.7) (2024-11-20)

### Bug Fixes

- bug in traces, missing input values
  ([d8a8ee5](https://github.com/ax-llm/ax/commit/d8a8ee5544214c30a1ac341b7c11fb9fd717a57b))

## [10.0.7](https://github.com/ax-llm/ax/compare/10.0.6...10.0.7) (2024-11-18)

### Features

- added google search retrieval for gemini
  ([f659dc6](https://github.com/ax-llm/ax/commit/f659dc6151f837d4b59cd14ab4ed8525b8c57c0c))

## [10.0.7](https://github.com/ax-llm/ax/compare/10.0.5...10.0.6) (2024-11-18)

### Features

- added google search retrieval for gemini
  ([f659dc6](https://github.com/ax-llm/ax/commit/f659dc6151f837d4b59cd14ab4ed8525b8c57c0c))

## [10.0.6](https://github.com/ax-llm/ax/compare/10.0.5...10.0.6) (2024-11-03)

### Bug Fixes

- gemini function calling
  ([df0237d](https://github.com/ax-llm/ax/commit/df0237dda0b9f66a25ef80d1b78849eb68e6f0ea))

## [10.0.6](https://github.com/ax-llm/ax/compare/10.0.4...10.0.5) (2024-11-03)

### Bug Fixes

- gemini function calling
  ([df0237d](https://github.com/ax-llm/ax/commit/df0237dda0b9f66a25ef80d1b78849eb68e6f0ea))

## [10.0.5](https://github.com/ax-llm/ax/compare/10.0.4...10.0.5) (2024-11-02)

## [10.0.5](https://github.com/ax-llm/ax/compare/10.0.3...10.0.4) (2024-11-02)

## [10.0.4](https://github.com/ax-llm/ax/compare/10.0.3...10.0.4) (2024-11-01)

### Features

- pass functions in forward()
  ([0c6a58e](https://github.com/ax-llm/ax/commit/0c6a58e18858f83d9460331911f5cb2d580058da))

## [10.0.4](https://github.com/ax-llm/ax/compare/10.0.2...10.0.3) (2024-11-01)

### Features

- pass functions in forward()
  ([0c6a58e](https://github.com/ax-llm/ax/commit/0c6a58e18858f83d9460331911f5cb2d580058da))

## [10.0.3](https://github.com/ax-llm/ax/compare/10.0.2...10.0.3) (2024-10-28)

### Features

- added support for o1 models
  ([8f06b16](https://github.com/ax-llm/ax/commit/8f06b162330fed4b5aebd0c8f0bcafb28072d46b))

## [10.0.3](https://github.com/ax-llm/ax/compare/10.0.1...10.0.2) (2024-10-28)

### Features

- added support for o1 models
  ([8f06b16](https://github.com/ax-llm/ax/commit/8f06b162330fed4b5aebd0c8f0bcafb28072d46b))

## [10.0.2](https://github.com/ax-llm/ax/compare/10.0.1...10.0.2) (2024-10-23)

### Bug Fixes

- passing model in forward
  ([a485edf](https://github.com/ax-llm/ax/commit/a485edfddbf2e10244c8b611bbc47097b79c8ce7))

## [10.0.2](https://github.com/ax-llm/ax/compare/10.0.0...10.0.1) (2024-10-23)

### Bug Fixes

- passing model in forward
  ([a485edf](https://github.com/ax-llm/ax/commit/a485edfddbf2e10244c8b611bbc47097b79c8ce7))

## [10.0.1](https://github.com/ax-llm/ax/compare/10.0.0...10.0.1) (2024-10-21)

### Bug Fixes

- build issue
  ([f7687ee](https://github.com/ax-llm/ax/commit/f7687ee3bbd0bd675787d9747a253ec701b3d330))

## [10.0.1](https://github.com/ax-llm/ax/compare/9.0.61...10.0.0) (2024-10-21)

### Bug Fixes

- build issue
  ([f7687ee](https://github.com/ax-llm/ax/commit/f7687ee3bbd0bd675787d9747a253ec701b3d330))

## [10.0.0](https://github.com/ax-llm/ax/compare/9.0.61...10.0.0) (2024-10-21)

### Features

- new api allows for more flexibility
  ([fde4794](https://github.com/ax-llm/ax/commit/fde479493e376d6212d13612b99d84e0ab1c595c))

## [10.0.0](https://github.com/ax-llm/ax/compare/9.0.60...9.0.61) (2024-10-21)

### Features

- new api allows for more flexibility
  ([fde4794](https://github.com/ax-llm/ax/commit/fde479493e376d6212d13612b99d84e0ab1c595c))

## [9.0.61](https://github.com/ax-llm/ax/compare/9.0.60...9.0.61) (2024-10-16)

### Bug Fixes

- gemini embedding response fix
  ([6f93b0b](https://github.com/ax-llm/ax/commit/6f93b0bd5ad171768123898925d49ddc64b3ff06))

## [9.0.61](https://github.com/ax-llm/ax/compare/9.0.59...9.0.60) (2024-10-16)

### Bug Fixes

- gemini embedding response fix
  ([6f93b0b](https://github.com/ax-llm/ax/commit/6f93b0bd5ad171768123898925d49ddc64b3ff06))

## [9.0.60](https://github.com/ax-llm/ax/compare/9.0.59...9.0.60) (2024-10-16)

### Bug Fixes

- build fix
  ([e5000fa](https://github.com/ax-llm/ax/commit/e5000fa0728f18957b70d0b74655dcf6aa4671c9))

## [9.0.60](https://github.com/ax-llm/ax/compare/9.0.58...9.0.59) (2024-10-16)

### Bug Fixes

- build fix
  ([e5000fa](https://github.com/ax-llm/ax/commit/e5000fa0728f18957b70d0b74655dcf6aa4671c9))

## [9.0.59](https://github.com/ax-llm/ax/compare/9.0.58...9.0.59) (2024-10-16)

### Bug Fixes

- gemini batch embed endpoint
  ([4ebad97](https://github.com/ax-llm/ax/commit/4ebad972fc7e9bef96ba20b707ab836aa2f2b73f))

## [9.0.59](https://github.com/ax-llm/ax/compare/9.0.57...9.0.58) (2024-10-16)

### Bug Fixes

- gemini batch embed endpoint
  ([4ebad97](https://github.com/ax-llm/ax/commit/4ebad972fc7e9bef96ba20b707ab836aa2f2b73f))

## [9.0.58](https://github.com/ax-llm/ax/compare/9.0.57...9.0.58) (2024-10-11)

### Features

- new classification type in dspy signature
  ([d152eb7](https://github.com/ax-llm/ax/commit/d152eb70085e5da2ebf7b92fc7a6de3be54cb337))
- new classification type in dspy signature
  ([3816f80](https://github.com/ax-llm/ax/commit/3816f8015068090ec7cd2309b8a7b5f516168825))

## [9.0.58](https://github.com/ax-llm/ax/compare/9.0.56...9.0.57) (2024-10-11)

### Features

- new classification type in dspy signature
  ([d152eb7](https://github.com/ax-llm/ax/commit/d152eb70085e5da2ebf7b92fc7a6de3be54cb337))
- new classification type in dspy signature
  ([3816f80](https://github.com/ax-llm/ax/commit/3816f8015068090ec7cd2309b8a7b5f516168825))

## [9.0.57](https://github.com/ax-llm/ax/compare/9.0.56...9.0.57) (2024-10-08)

### Bug Fixes

- date time with seconds support
  ([abae15e](https://github.com/ax-llm/ax/commit/abae15eeb5fcaac38b046ee75e453771eec63ef6))

## [9.0.57](https://github.com/ax-llm/ax/compare/9.0.55...9.0.56) (2024-10-08)

### Bug Fixes

- date time with seconds support
  ([abae15e](https://github.com/ax-llm/ax/commit/abae15eeb5fcaac38b046ee75e453771eec63ef6))

## [9.0.56](https://github.com/ax-llm/ax/compare/9.0.55...9.0.56) (2024-10-08)

## [9.0.56](https://github.com/ax-llm/ax/compare/9.0.54...9.0.55) (2024-10-08)

## [9.0.55](https://github.com/ax-llm/ax/compare/9.0.54...9.0.55) (2024-10-07)

### Bug Fixes

- value parseing
  ([5a6c0e3](https://github.com/ax-llm/ax/commit/5a6c0e349e4868f68f2f3b7fe63dfeb14d5f9a13))

## [9.0.55](https://github.com/ax-llm/ax/compare/9.0.53...9.0.54) (2024-10-07)

### Bug Fixes

- value parseing
  ([5a6c0e3](https://github.com/ax-llm/ax/commit/5a6c0e349e4868f68f2f3b7fe63dfeb14d5f9a13))

## [9.0.54](https://github.com/ax-llm/ax/compare/9.0.53...9.0.54) (2024-10-07)

### Bug Fixes

- optional fields issue
  ([a4ecdcd](https://github.com/ax-llm/ax/commit/a4ecdcdbacdbfa8cd99fa1070bdd769870d53b14))

## [9.0.54](https://github.com/ax-llm/ax/compare/9.0.52...9.0.53) (2024-10-07)

### Bug Fixes

- optional fields issue
  ([a4ecdcd](https://github.com/ax-llm/ax/commit/a4ecdcdbacdbfa8cd99fa1070bdd769870d53b14))

## [9.0.53](https://github.com/ax-llm/ax/compare/9.0.52...9.0.53) (2024-10-07)

### Bug Fixes

- test issue
  ([91b15c1](https://github.com/ax-llm/ax/commit/91b15c1cfd808b3d071db960dd58b8014fe09260))

## [9.0.53](https://github.com/ax-llm/ax/compare/9.0.51...9.0.52) (2024-10-07)

### Bug Fixes

- test issue
  ([91b15c1](https://github.com/ax-llm/ax/commit/91b15c1cfd808b3d071db960dd58b8014fe09260))

## [9.0.52](https://github.com/ax-llm/ax/compare/9.0.51...9.0.52) (2024-10-07)

### Features

- added datetime field support
  ([bd05b0e](https://github.com/ax-llm/ax/commit/bd05b0ef940abc3f279667d87330f368a37cd8d0))

## [9.0.52](https://github.com/ax-llm/ax/compare/9.0.50...9.0.51) (2024-10-07)

### Features

- added datetime field support
  ([bd05b0e](https://github.com/ax-llm/ax/commit/bd05b0ef940abc3f279667d87330f368a37cd8d0))

## [9.0.51](https://github.com/ax-llm/ax/compare/9.0.50...9.0.51) (2024-10-04)

### Bug Fixes

- minor fix
  ([0bd2c54](https://github.com/ax-llm/ax/commit/0bd2c547dce6fe6f34df36035718573e7a3811ef))

## [9.0.51](https://github.com/ax-llm/ax/compare/9.0.49...9.0.50) (2024-10-04)

### Bug Fixes

- minor fix
  ([0bd2c54](https://github.com/ax-llm/ax/commit/0bd2c547dce6fe6f34df36035718573e7a3811ef))

## [9.0.50](https://github.com/ax-llm/ax/compare/9.0.49...9.0.50) (2024-10-04)

### Features

- added multi-modal chat to rome
  ([7e8f8a7](https://github.com/ax-llm/ax/commit/7e8f8a7e641603ed169fbea48555c04cb8e1c549))
- better image display for ax rome
  ([9035a35](https://github.com/ax-llm/ax/commit/9035a359809d4ec3b0165e77daa2e1a822408f28))
- improve code blocks in rome
  ([ab58949](https://github.com/ax-llm/ax/commit/ab589496f6b663b4b378d3db0acd8d4099f90ac9))
- new models
  ([e1bb27b](https://github.com/ax-llm/ax/commit/e1bb27b7aac9f32ce64b6e1b1f4164c5fe4757bf))

### Bug Fixes

- card layout fix
  ([7c7e59c](https://github.com/ax-llm/ax/commit/7c7e59c5ee64156f5f3e9a1700484fea2db85511))

## [9.0.50](https://github.com/ax-llm/ax/compare/9.0.48...9.0.49) (2024-10-04)

### Features

- added multi-modal chat to rome
  ([7e8f8a7](https://github.com/ax-llm/ax/commit/7e8f8a7e641603ed169fbea48555c04cb8e1c549))
- better image display for ax rome
  ([9035a35](https://github.com/ax-llm/ax/commit/9035a359809d4ec3b0165e77daa2e1a822408f28))
- improve code blocks in rome
  ([ab58949](https://github.com/ax-llm/ax/commit/ab589496f6b663b4b378d3db0acd8d4099f90ac9))
- new models
  ([e1bb27b](https://github.com/ax-llm/ax/commit/e1bb27b7aac9f32ce64b6e1b1f4164c5fe4757bf))

### Bug Fixes

- card layout fix
  ([7c7e59c](https://github.com/ax-llm/ax/commit/7c7e59c5ee64156f5f3e9a1700484fea2db85511))

## [9.0.49](https://github.com/ax-llm/ax/compare/9.0.48...9.0.49) (2024-09-21)

### Features

- added email auth
  ([f8fac72](https://github.com/ax-llm/ax/commit/f8fac723f25dfd62cece50c4f3ef8cec98b8eb87))

### Bug Fixes

- system role bug in anthropic
  ([e566eb2](https://github.com/ax-llm/ax/commit/e566eb270115b87f288bcdd9c297a084a51a81a0))
- update readme
  ([5b73fd1](https://github.com/ax-llm/ax/commit/5b73fd1caa8b0b0e703b3a1ae72ef2803c211a09))

## [9.0.49](https://github.com/ax-llm/ax/compare/9.0.47...9.0.48) (2024-09-21)

### Features

- added email auth
  ([f8fac72](https://github.com/ax-llm/ax/commit/f8fac723f25dfd62cece50c4f3ef8cec98b8eb87))

### Bug Fixes

- system role bug in anthropic
  ([e566eb2](https://github.com/ax-llm/ax/commit/e566eb270115b87f288bcdd9c297a084a51a81a0))
- update readme
  ([5b73fd1](https://github.com/ax-llm/ax/commit/5b73fd1caa8b0b0e703b3a1ae72ef2803c211a09))

## [9.0.48](https://github.com/ax-llm/ax/compare/9.0.47...9.0.48) (2024-09-20)

### Features

- rome version 1 beta
  ([1510bd4](https://github.com/ax-llm/ax/commit/1510bd42b4944d4d65e02bafda54fbd848302109))

## [9.0.48](https://github.com/ax-llm/ax/compare/9.0.46...9.0.47) (2024-09-20)

### Features

- rome version 1 beta
  ([1510bd4](https://github.com/ax-llm/ax/commit/1510bd42b4944d4d65e02bafda54fbd848302109))

## [9.0.47](https://github.com/ax-llm/ax/compare/9.0.46...9.0.47) (2024-09-16)

### Features

- ax web first commit
  ([bccb572](https://github.com/ax-llm/ax/commit/bccb5722302f0c9746e9f3d3567f97c6fff8de32))
- first release of rome
  ([7629b77](https://github.com/ax-llm/ax/commit/7629b77be1e139ad9e1a6d93a30e6b62423bb82f))
- moved comm. core into useChat hook
  ([f04c35f](https://github.com/ax-llm/ax/commit/f04c35fc65d5ece9de5cea8a26a8873a15274cde))
- rome is rising
  ([5d7c0f3](https://github.com/ax-llm/ax/commit/5d7c0f377ecfde91fb5c7fb142cf367e56e3a7ab))

## [9.0.47](https://github.com/ax-llm/ax/compare/9.0.45...9.0.46) (2024-09-16)

### Features

- ax web first commit
  ([bccb572](https://github.com/ax-llm/ax/commit/bccb5722302f0c9746e9f3d3567f97c6fff8de32))
- first release of rome
  ([7629b77](https://github.com/ax-llm/ax/commit/7629b77be1e139ad9e1a6d93a30e6b62423bb82f))
- moved comm. core into useChat hook
  ([f04c35f](https://github.com/ax-llm/ax/commit/f04c35fc65d5ece9de5cea8a26a8873a15274cde))
- rome is rising
  ([5d7c0f3](https://github.com/ax-llm/ax/commit/5d7c0f377ecfde91fb5c7fb142cf367e56e3a7ab))

## [9.0.46](https://github.com/ax-llm/ax/compare/9.0.45...9.0.46) (2024-08-16)

### Bug Fixes

- Bind agent functions to instances for correct 'this' context"
  ([#61](https://github.com/ax-llm/ax/issues/61))
  ([ce684ff](https://github.com/ax-llm/ax/commit/ce684ff507e6493b4bfcdae195df5da3ea362e3f))

## [9.0.46](https://github.com/ax-llm/ax/compare/9.0.44...9.0.45) (2024-08-16)

### Bug Fixes

- Bind agent functions to instances for correct 'this' context"
  ([#61](https://github.com/ax-llm/ax/issues/61))
  ([ce684ff](https://github.com/ax-llm/ax/commit/ce684ff507e6493b4bfcdae195df5da3ea362e3f))

## [9.0.45](https://github.com/ax-llm/ax/compare/9.0.44...9.0.45) (2024-07-31)

### Features

- added reka models
  ([ef1f267](https://github.com/ax-llm/ax/commit/ef1f2677220073253a7c020668842c3635d26924))

## [9.0.45](https://github.com/ax-llm/ax/compare/9.0.43...9.0.44) (2024-07-31)

### Features

- added reka models
  ([ef1f267](https://github.com/ax-llm/ax/commit/ef1f2677220073253a7c020668842c3635d26924))

## [9.0.44](https://github.com/ax-llm/ax/compare/9.0.43...9.0.44) (2024-07-29)

### Bug Fixes

- updates to the ai sdk provider
  ([01fca9a](https://github.com/ax-llm/ax/commit/01fca9abf00cc8a24e649575a7c0f5558fe21d66))
- updates to the ai sdk provider
  ([ff77e1f](https://github.com/ax-llm/ax/commit/ff77e1f4959e8aad71b8b87e4b084cf992972522))

## [9.0.44](https://github.com/ax-llm/ax/compare/9.0.42...9.0.43) (2024-07-29)

### Bug Fixes

- updates to the ai sdk provider
  ([01fca9a](https://github.com/ax-llm/ax/commit/01fca9abf00cc8a24e649575a7c0f5558fe21d66))
- updates to the ai sdk provider
  ([ff77e1f](https://github.com/ax-llm/ax/commit/ff77e1f4959e8aad71b8b87e4b084cf992972522))

## [9.0.43](https://github.com/ax-llm/ax/compare/9.0.42...9.0.43) (2024-07-29)

### Bug Fixes

- updates to the ai sdk provider
  ([148e692](https://github.com/ax-llm/ax/commit/148e692d4d2aadf0c04260ec6030cb2c7aa6141f))

## [9.0.43](https://github.com/ax-llm/ax/compare/9.0.41...9.0.42) (2024-07-29)

### Bug Fixes

- updates to the ai sdk provider
  ([148e692](https://github.com/ax-llm/ax/commit/148e692d4d2aadf0c04260ec6030cb2c7aa6141f))

## [9.0.42](https://github.com/ax-llm/ax/compare/9.0.41...9.0.42) (2024-07-28)

### Bug Fixes

- updates to ai sdk provider
  ([ca62b91](https://github.com/ax-llm/ax/commit/ca62b91d4eb117cda29695c0b4842a21e95caba3))

## [9.0.42](https://github.com/ax-llm/ax/compare/9.0.40...9.0.41) (2024-07-28)

### Bug Fixes

- updates to ai sdk provider
  ([ca62b91](https://github.com/ax-llm/ax/commit/ca62b91d4eb117cda29695c0b4842a21e95caba3))

## [9.0.41](https://github.com/ax-llm/ax/compare/9.0.40...9.0.41) (2024-07-28)

### Bug Fixes

- ax ai provider
  ([b87bf02](https://github.com/ax-llm/ax/commit/b87bf0275b0d2b9edc1435ab30de4c8bbb878197))

## [9.0.41](https://github.com/ax-llm/ax/compare/9.0.39...9.0.40) (2024-07-28)

### Bug Fixes

- ax ai provider
  ([b87bf02](https://github.com/ax-llm/ax/commit/b87bf0275b0d2b9edc1435ab30de4c8bbb878197))

## [9.0.40](https://github.com/ax-llm/ax/compare/9.0.39...9.0.40) (2024-07-28)

### Bug Fixes

- automatic zod schema creation for ai sdk provider tools
  ([7ea8600](https://github.com/ax-llm/ax/commit/7ea86007bcbe455c9edaa03bcc01e5f22ca780b4))

## [9.0.40](https://github.com/ax-llm/ax/compare/9.0.38...9.0.39) (2024-07-28)

### Bug Fixes

- automatic zod schema creation for ai sdk provider tools
  ([7ea8600](https://github.com/ax-llm/ax/commit/7ea86007bcbe455c9edaa03bcc01e5f22ca780b4))

## [9.0.39](https://github.com/ax-llm/ax/compare/9.0.38...9.0.39) (2024-07-27)

### Bug Fixes

- ai sdk agent provider update
  ([096ad0c](https://github.com/ax-llm/ax/commit/096ad0cca337feae4079293aae032c2325267b8a))

## [9.0.39](https://github.com/ax-llm/ax/compare/9.0.37...9.0.38) (2024-07-27)

### Bug Fixes

- ai sdk agent provider update
  ([096ad0c](https://github.com/ax-llm/ax/commit/096ad0cca337feae4079293aae032c2325267b8a))

## [9.0.38](https://github.com/ax-llm/ax/compare/9.0.37...9.0.38) (2024-07-27)

### Features

- added a ai sdk agent provider
  ([9f030c0](https://github.com/ax-llm/ax/commit/9f030c0d99e4dd91090fc25350455d9da1a28bb5))

## [9.0.38](https://github.com/ax-llm/ax/compare/9.0.36...9.0.37) (2024-07-27)

### Features

- added a ai sdk agent provider
  ([9f030c0](https://github.com/ax-llm/ax/commit/9f030c0d99e4dd91090fc25350455d9da1a28bb5))

## [9.0.37](https://github.com/ax-llm/ax/compare/9.0.36...9.0.37) (2024-07-26)

### Bug Fixes

- streaming fix in ai sdk provider
  ([192adac](https://github.com/ax-llm/ax/commit/192adacba1aafd0fea8703904c2e5d6177159c23))

## [9.0.37](https://github.com/ax-llm/ax/compare/9.0.35...9.0.36) (2024-07-26)

### Bug Fixes

- streaming fix in ai sdk provider
  ([192adac](https://github.com/ax-llm/ax/commit/192adacba1aafd0fea8703904c2e5d6177159c23))

## [9.0.36](https://github.com/ax-llm/ax/compare/9.0.35...9.0.36) (2024-07-24)

### Bug Fixes

- spelling
  ([cbe25eb](https://github.com/ax-llm/ax/commit/cbe25eb09b0ab1c77336bfd8965c489403be26d0))

## [9.0.36](https://github.com/ax-llm/ax/compare/9.0.34...9.0.35) (2024-07-24)

### Bug Fixes

- spelling
  ([cbe25eb](https://github.com/ax-llm/ax/commit/cbe25eb09b0ab1c77336bfd8965c489403be26d0))

## [9.0.35](https://github.com/ax-llm/ax/compare/9.0.34...9.0.35) (2024-07-24)

### Bug Fixes

- build issues
  ([e574f3a](https://github.com/ax-llm/ax/commit/e574f3ae1f9c7e4e6aa9291f3909a33744dfc5a4))

## [9.0.35](https://github.com/ax-llm/ax/compare/9.0.33...9.0.34) (2024-07-24)

### Bug Fixes

- build issues
  ([e574f3a](https://github.com/ax-llm/ax/commit/e574f3ae1f9c7e4e6aa9291f3909a33744dfc5a4))

## [9.0.34](https://github.com/ax-llm/ax/compare/9.0.33...9.0.34) (2024-07-24)

### Bug Fixes

- package.json for publishing
  ([2f1b72e](https://github.com/ax-llm/ax/commit/2f1b72e332762ba0e9b33f8ed3db1138d9d985ea))

## [9.0.34](https://github.com/ax-llm/ax/compare/9.0.32...9.0.33) (2024-07-24)

### Bug Fixes

- package.json for publishing
  ([2f1b72e](https://github.com/ax-llm/ax/commit/2f1b72e332762ba0e9b33f8ed3db1138d9d985ea))

## [9.0.33](https://github.com/ax-llm/ax/compare/9.0.32...9.0.33) (2024-07-23)

### Features

- new ai-sdk-provider
  ([60e646f](https://github.com/ax-llm/ax/commit/60e646f64736c06a3017ffe1a853baf296b31308))

## [9.0.33](https://github.com/ax-llm/ax/compare/9.0.31...9.0.32) (2024-07-23)

### Features

- new ai-sdk-provider
  ([60e646f](https://github.com/ax-llm/ax/commit/60e646f64736c06a3017ffe1a853baf296b31308))

## [9.0.32](https://github.com/ax-llm/ax/compare/9.0.31...9.0.32) (2024-07-18)

### Features

- added new models for mistral and openai
  ([b0ae470](https://github.com/ax-llm/ax/commit/b0ae470dd911323aedb977313ec5242a7f80ebec))

### Bug Fixes

- corrected embeddings endpoint ([#51](https://github.com/ax-llm/ax/issues/51))
  ([d1a733e](https://github.com/ax-llm/ax/commit/d1a733e632d0dbd3f77f31e79e784b016c0e8844))

## [9.0.32](https://github.com/ax-llm/ax/compare/9.0.30...9.0.31) (2024-07-18)

### Features

- added new models for mistral and openai
  ([b0ae470](https://github.com/ax-llm/ax/commit/b0ae470dd911323aedb977313ec5242a7f80ebec))

### Bug Fixes

- corrected embeddings endpoint ([#51](https://github.com/ax-llm/ax/issues/51))
  ([d1a733e](https://github.com/ax-llm/ax/commit/d1a733e632d0dbd3f77f31e79e784b016c0e8844))

## [9.0.31](https://github.com/ax-llm/ax/compare/9.0.30...9.0.31) (2024-07-14)

## [9.0.31](https://github.com/ax-llm/ax/compare/9.0.29...9.0.30) (2024-07-14)

## [9.0.30](https://github.com/ax-llm/ax/compare/9.0.29...9.0.30) (2024-07-09)

### Bug Fixes

- more fixes related to model mapping
  ([b01fcb7](https://github.com/ax-llm/ax/commit/b01fcb79dc3375aabb3815fae396ec567faf7987))

## [9.0.30](https://github.com/ax-llm/ax/compare/9.0.28...9.0.29) (2024-07-09)

### Bug Fixes

- more fixes related to model mapping
  ([b01fcb7](https://github.com/ax-llm/ax/commit/b01fcb79dc3375aabb3815fae396ec567faf7987))

## [9.0.29](https://github.com/ax-llm/ax/compare/9.0.28...9.0.29) (2024-07-09)

### Bug Fixes

- redesigned model map feature
  ([7049914](https://github.com/ax-llm/ax/commit/704991418fdda832ef3d6aff33496432c3b152eb))

## [9.0.29](https://github.com/ax-llm/ax/compare/9.0.27...9.0.28) (2024-07-09)

### Bug Fixes

- redesigned model map feature
  ([7049914](https://github.com/ax-llm/ax/commit/704991418fdda832ef3d6aff33496432c3b152eb))

## [9.0.28](https://github.com/ax-llm/ax/compare/9.0.27...9.0.28) (2024-07-09)

### Bug Fixes

- issue with model map feature
  ([d33d9be](https://github.com/ax-llm/ax/commit/d33d9be6fe3da6d1e38213f5203746952a7790b1))

## [9.0.28](https://github.com/ax-llm/ax/compare/9.0.26...9.0.27) (2024-07-09)

### Bug Fixes

- issue with model map feature
  ([d33d9be](https://github.com/ax-llm/ax/commit/d33d9be6fe3da6d1e38213f5203746952a7790b1))

## [9.0.27](https://github.com/ax-llm/ax/compare/9.0.26...9.0.27) (2024-07-09)

### Bug Fixes

- model map issue
  ([ab29d6e](https://github.com/ax-llm/ax/commit/ab29d6e6cf39255a6b1f488043cb378387bcb5ac))

All notable changes to this project will be documented in this file. See
[standard-version](https://github.com/conventional-changelog/standard-version)
for commit guidelines.

## 9.1.0 (2024-06-21)

### Features

- add anthropic claude llms
  ([1e09f67](https://github.com/ax-llm/ax/commit/1e09f6720f34aa8025a37410df45c0cdedcfec49))
- add api rate-limiter support
  ([e4a8863](https://github.com/ax-llm/ax/commit/e4a8863e8fbbe3b7123737493bbb5c786eb51d96))
- add azure openai
  ([4478ed1](https://github.com/ax-llm/ax/commit/4478ed12c23abba3e935e84d37550a401f4562fb))
- add built-in function for embeddings
  ([37dfa99](https://github.com/ax-llm/ax/commit/37dfa99cb67eb36fabce79273727a3f201a3aa0b))
- add busines information extraction prompt
  ([cb2dca5](https://github.com/ax-llm/ax/commit/cb2dca5b34ffda2c0d03b45ac4c2c9d240615cc1))
- add caching proxy
  ([ba57bf9](https://github.com/ax-llm/ax/commit/ba57bf9417a74b719daa795afcd501235da1d3af))
- add caching proxy
  ([335dcbd](https://github.com/ax-llm/ax/commit/335dcbdbc4311784d095cc6be66b57d2a0d5909c))
- add google gemini safety controls
  ([7783bbe](https://github.com/ax-llm/ax/commit/7783bbee545d13a7b9f8a899d64ec2e59d1c931f))
- add google palm models
  ([cf6bf11](https://github.com/ax-llm/ax/commit/cf6bf11e30dee95d0799e6d19baa573a2a9765b9))
- add gpt-4 support
  ([405b87e](https://github.com/ax-llm/ax/commit/405b87e60fbb5942646e013c3a56fbc13d120c24))
- add ollama
  ([c1181e0](https://github.com/ax-llm/ax/commit/c1181e02e775f218a928dfdd0013d306c8e19106))
- add semantic router
  ([2096158](https://github.com/ax-llm/ax/commit/209615831a9f814bc10071280857d2b4f51c2a3a))
- add streaming support for gemini and cohere
  ([a946d52](https://github.com/ax-llm/ax/commit/a946d521f01267208ca863b0fd52b1f1d91d6929))
- add streaming support to proxy
  ([5edd33c](https://github.com/ax-llm/ax/commit/5edd33c1905a00a6fb1f05f395090e569ea954e5))
- add support for embeddings to use with vector search
  ([4bd4ba4](https://github.com/ax-llm/ax/commit/4bd4ba4cb9d3edd1dabea3ec8b3c3201b06b18da))
- add support for json type and other fixes
  ([3249746](https://github.com/ax-llm/ax/commit/32497461524b6138bf0c6142f71fe1d5b96386a2))
- add together compute llm api support
  ([37fc9cf](https://github.com/ax-llm/ax/commit/37fc9cf27e0b75e0068e7b58956b784ead6934cf))
- add vector db and embeddings example
  ([141ad9f](https://github.com/ax-llm/ax/commit/141ad9f1dd4d4f19c8ef07b362c57cb628f42e37))
- added a new llm alephalpha
  ([bff5f51](https://github.com/ax-llm/ax/commit/bff5f51812bcf22a8f6c89e58c98866208f14e1a))
- added agent tracing
  ([4bc9ae7](https://github.com/ax-llm/ax/commit/4bc9ae7ca5e02f194a23ed73b3aa8dcbbda43e4a))
- added claude3, gemini and fixed openai azure
  ([1c902d1](https://github.com/ax-llm/ax/commit/1c902d102fc8bce226c7c29bdafdb6e98b4ce170))
- added dsp
  ([fc9c292](https://github.com/ax-llm/ax/commit/fc9c292838fd7cdbb9e36633d7ad847206349c64))
- added in memory vector db with serialize to disk
  ([5036933](https://github.com/ax-llm/ax/commit/50369334388332ee9414b80b92835ab3915e786e))
- added mistral support
  ([67747a0](https://github.com/ax-llm/ax/commit/67747a0dd0840e429fda5c9c98f36fce125133e5))
- added more tests
  ([fe33451](https://github.com/ax-llm/ax/commit/fe33451711c9870144cafa8e242fa05fc3152f09))
- added multi-modal support to anthropic api and other fixes
  ([95a0680](https://github.com/ax-llm/ax/commit/95a0680ec61d8d9803c6cea0b2732abebf046461))
- added openai chat-gpt api support
  ([eb4b151](https://github.com/ax-llm/ax/commit/eb4b151c160bb33560c2072240e4770572b4f0ff))
- added prefix Ax across type namespace
  ([3a9daf0](https://github.com/ax-llm/ax/commit/3a9daf0e45de834fc7b8719c2908f1b90800e0e2))
- added proxy bin
  ([65adabe](https://github.com/ax-llm/ax/commit/65adabe6de137a886a3055d6f9ea32f2304635e1))
- added the dsp style bootstrap few stop optimizer
  ([eab69c8](https://github.com/ax-llm/ax/commit/eab69c811c510235fe28377c83db662b15489909))
- agent framework, agents can use other agents
  ([93cbfb3](https://github.com/ax-llm/ax/commit/93cbfb3912e13e7e353ae70311be4467a2c97568))
- agent framework, agents can use other agents
  ([a7420e7](https://github.com/ax-llm/ax/commit/a7420e7256bf12667449c96a35d84c1a0f66d2ef))
- ai balancer to pick the cheapest llm with automatic fallback
  ([a8f7b7b](https://github.com/ax-llm/ax/commit/a8f7b7b9772691056d94a5cfec4d94f064df4a8f))
- auto-fix json syntax errors
  ([dc27812](https://github.com/ax-llm/ax/commit/dc27812ec9c9521dcc38d526e23191e9466e7d4e))
- automatic long term memory
  ([e94ffd5](https://github.com/ax-llm/ax/commit/e94ffd50d910ff6b17c25e7131ee87c38b2eba56))
- automatic vectordb retrieval augmented generation in proxy
  ([d081c18](https://github.com/ax-llm/ax/commit/d081c189f4cb78a217f7cfeeb127f528153a8813))
- aws bedrock support
  ([acdc89b](https://github.com/ax-llm/ax/commit/acdc89b49c733b6a31bb5e17694c6abe28d324eb))
- big [breaking] refactor
  ([c97395d](https://github.com/ax-llm/ax/commit/c97395d6d7ea5e259151675c19b0cb2f21e0c2a2))
- convert any document format to text and a full RAG engine builtin
  ([7f3f28c](https://github.com/ax-llm/ax/commit/7f3f28c0c185506fc479bfd61c1f35588e65cfd6))
- dbmanager handles chunking, embedding and search for text
  ([5c125f8](https://github.com/ax-llm/ax/commit/5c125f87d54fba405407bc4085701ffbf4748a45))
- deepseek and cohere function calling
  ([5341700](https://github.com/ax-llm/ax/commit/5341700a39b80115e9bce50b0176a1c9760a6064))
- enable remote logging with LLMC_APIKEY env var
  ([e04b257](https://github.com/ax-llm/ax/commit/e04b25797676bced2ecdc10c7368983d54ca2e19))
- gpt-4o added
  ([a388219](https://github.com/ax-llm/ax/commit/a388219ec52cfcef132199453f55ecb7c489156e))
- huggingface data loader
  ([47c6c0e](https://github.com/ax-llm/ax/commit/47c6c0efcfa468466dc54af2c92cc970821d30e2))
- improve trace logging
  ([12776be](https://github.com/ax-llm/ax/commit/12776be18d2d4795a018ff3e2bf710288586b589))
- improved debug logs
  ([38e869e](https://github.com/ax-llm/ax/commit/38e869e1be07ca7a0193bbb908819bd6759b561a))
- include reasoning in tracing
  ([e11f665](https://github.com/ax-llm/ax/commit/e11f665626ab34f462c73e7e05dd74db7b27d1fd))
- iterate to completion if max token length reached
  ([f9d0f50](https://github.com/ax-llm/ax/commit/f9d0f508609355dd93090e0021b73693733f3a52))
- JS code interpreter function
  ([b3de309](https://github.com/ax-llm/ax/commit/b3de30939e1f1f91e59c851d2a9f9600ca4ebed9))
- library is now down to 1 single dependency
  ([efaaa03](https://github.com/ax-llm/ax/commit/efaaa0338dbd8d2e8f272c7965bf5afb999e4276))
- llm converts meeting notes to trello tasks example
  ([633cb95](https://github.com/ax-llm/ax/commit/633cb956e3c04cced5006d2b32198dd3b42e13db))
- lots of api improvements and many bug fixes
  ([036cd06](https://github.com/ax-llm/ax/commit/036cd0662b80b3ef8e5e4994d00746ac74024a0b))
- major refactor to enable traceing and usage tracking
  ([a7c980c](https://github.com/ax-llm/ax/commit/a7c980cb3f2e50ca1bd012c280a7bd8147978b91))
- make it easier to customize prompts
  ([1870ee7](https://github.com/ax-llm/ax/commit/1870ee77a0a3491a34570033197efeb87a6f632a))
- migrated from commonjs to ES2022
  ([c8ad44b](https://github.com/ax-llm/ax/commit/c8ad44b6a61246602afb1c3307d46de6b13e8152))
- multi-modal dsp, use images in input fields
  ([a170b55](https://github.com/ax-llm/ax/commit/a170b555072baa13a2bc577248ae9d67f8c7db6f))
- new agent framework
  ([1e7040c](https://github.com/ax-llm/ax/commit/1e7040ce2049afa270efee5528ea5b954f66188e))
- new agent prompt
  ([6c4df2c](https://github.com/ax-llm/ax/commit/6c4df2c50d84adcfc2f18c42033ad82aa7ca6be6))
- new llm proxy for tracing usage
  ([ab36530](https://github.com/ax-llm/ax/commit/ab36530aca00510aa1fc339c38317897caa24064))
- new llmclient command and crawler to embed and vectorize websites
  ([47a61f2](https://github.com/ax-llm/ax/commit/47a61f25bd4aa84acc7e0c7e59f73e10338372cc))
- new llmclient command and crawler to embed and vectorize websites
  ([ede47c5](https://github.com/ax-llm/ax/commit/ede47c5b01fe17056a813fd44ad659186865f134))
- openapi wispher support
  ([50e864f](https://github.com/ax-llm/ax/commit/50e864f91806c2d723fe6edd46bc3a6a2ecd17d8))
- parsing and processing output fields and functions while streaming
  ([95a7a93](https://github.com/ax-llm/ax/commit/95a7a93b9c40f8e7b25a2dd14b3b43d84a8d50fc))
- proxy support for all llms
  ([1e1edc3](https://github.com/ax-llm/ax/commit/1e1edc3a6b61dedbb4b45af011c79974f9fdef1b))
- req tracing added to ai classes
  ([dad8c3c](https://github.com/ax-llm/ax/commit/dad8c3caa4f02d70364a3785d9349575b9c102b6))
- spider to embed website
  ([56f4598](https://github.com/ax-llm/ax/commit/56f45984f894a790f93819464e0dc0a91b4bc66f))
- streaming support
  ([65839a9](https://github.com/ax-llm/ax/commit/65839a9fc041853af10971474bb2f1417919d0d3))
- support for google vertex
  ([49ee383](https://github.com/ax-llm/ax/commit/49ee3833e5f2fc423ca8c059670157b20acc8ac6))
- support for Hugging Face and other updates
  ([8f64432](https://github.com/ax-llm/ax/commit/8f644328ab10fcd409b98b02807a96fdccbc79e7))
- support for remote tracing
  ([033a67a](https://github.com/ax-llm/ax/commit/033a67ab5f6e1f2778ec435fa0e6f181223b6728))
- track token usage
  ([bd4f798](https://github.com/ax-llm/ax/commit/bd4f79824a29a89fed60b38bcef28e2935cebb86))
- true realtime output validation while streaming
  ([4308b99](https://github.com/ax-llm/ax/commit/4308b99a8855595527fbd161920ae6968292650c))
- updates to agent framework api
  ([472efbf](https://github.com/ax-llm/ax/commit/472efbfcfe8f9718a1031263a0363a9a7f72f918))
- vector db query rewriting
  ([52fad9c](https://github.com/ax-llm/ax/commit/52fad9cea59c619fd5d9b74ae5139abbec9c4834))
- vector db query rewriting
  ([bce6d19](https://github.com/ax-llm/ax/commit/bce6d198c7f807f4e5a97b8e1211107fecaebb9a))
- vector db support
  ([0ea1c7f](https://github.com/ax-llm/ax/commit/0ea1c7f0963946ead1ffc0908a8c5c1be5ce00fd))
- welcome llm-client
  ([225ec5a](https://github.com/ax-llm/ax/commit/225ec5aa24cf422ed3018e6fd19e248a0a763391))

### Bug Fixes

- add opentelemetry support and other fixes
  ([685fe80](https://github.com/ax-llm/ax/commit/685fe80f1687f97282f708d279e8588023e2213c))
- Add Polyfill for TextDecoderStream to Ensure Compatibility with Bun
  [#21](https://github.com/ax-llm/ax/issues/21)
  ([540348d](https://github.com/ax-llm/ax/commit/540348d9b25a361077b0e3574064fb4f2975b632))
- add tools support to anthropic
  ([1cc96b7](https://github.com/ax-llm/ax/commit/1cc96b7910127c9e00820b572b5fb6ca27662b1e))
- added missing typescript docs
  ([2459a28](https://github.com/ax-llm/ax/commit/2459a282e5cdd8ccc827665fe41f58974023bcfb))
- added system prompt to trace
  ([335bb40](https://github.com/ax-llm/ax/commit/335bb406eec22414014bcde8e264bb45bb44ff12))
- anthropic header issue
  ([40dbce0](https://github.com/ax-llm/ax/commit/40dbce0bd2ec03f1c9184e66cf88c8dfec31883c))
- anthropic proxy endpoint ([#7](https://github.com/ax-llm/ax/issues/7))
  ([cf7c793](https://github.com/ax-llm/ax/commit/cf7c7939c393e85d63721762a6c7cc55c68502d2))
- anthropic, updated other models
  ([6e83d34](https://github.com/ax-llm/ax/commit/6e83d34f5acb8be282e172b47d9feeef0ce67436))
- Azure OpenAI chat/completion call failed
  ([#19](https://github.com/ax-llm/ax/issues/19))
  ([#20](https://github.com/ax-llm/ax/issues/20))
  ([0fad4f9](https://github.com/ax-llm/ax/commit/0fad4f9c3bd909c687b20193a5d0dbef4730481a))
- banner fixes
  ([fdf453b](https://github.com/ax-llm/ax/commit/fdf453b1ad02c337bcd0b8c213be3802a054eb9b))
- blank response with stream
  ([ab7c62d](https://github.com/ax-llm/ax/commit/ab7c62d52db231ae9661531f85a9d6a4cadfe222))
- bug in new open ai chat model
  ([654282d](https://github.com/ax-llm/ax/commit/654282d15c98d617840dc6f6014d0e961393bcd2))
- bug with exporting enums
  ([4fc0a3b](https://github.com/ax-llm/ax/commit/4fc0a3b5a7dd5413d8f6d4d3cfe18d2af54941c6))
- bug with exporting enums
  ([4ca8c5d](https://github.com/ax-llm/ax/commit/4ca8c5d23ec5b7320cc78936b3a663920ae6946c))
- build error
  ([e4d29c3](https://github.com/ax-llm/ax/commit/e4d29c34297c31bfe91def1af3468e6566554ce2))
- build fixes
  ([d8d4a47](https://github.com/ax-llm/ax/commit/d8d4a478e70ddfbff785d123f19ff78946f97789))
- build issue
  ([7733463](https://github.com/ax-llm/ax/commit/773346339acec1c7f7f9640cdf183b92fee28615))
- build issue
  ([071f476](https://github.com/ax-llm/ax/commit/071f476fe8046b561f54786e364517cf52fc91cb))
- build issue with previous version
  ([cfe92fd](https://github.com/ax-llm/ax/commit/cfe92fdbe5a2205815da3978a6c9903dcc46b617))
- build issues
  ([dd346c4](https://github.com/ax-llm/ax/commit/dd346c4b03aa43b2725ca3da40bab522ffb9297f))
- build issues
  ([33394df](https://github.com/ax-llm/ax/commit/33394dfd250e5c0f16bf9baa5c2b23d4d1777ef8))
- change name in package
  ([9697d19](https://github.com/ax-llm/ax/commit/9697d190526bfd923baa244aacd8e7522845a340))
- cleaup gitignore
  ([6627ff3](https://github.com/ax-llm/ax/commit/6627ff315aacddcfd321d014f7d129cd20142655))
- common llm model config to ensure more deterministic outputs
  ([0dce599](https://github.com/ax-llm/ax/commit/0dce59998bc731153a5d3588245e8fbfb7635727))
- examples
  ([973eb51](https://github.com/ax-llm/ax/commit/973eb51a23e0a6b4042d37b0e9967de2c0a76234))
- extra comma in package.json
  ([16b36f5](https://github.com/ax-llm/ax/commit/16b36f507e9b9e4cde6a823cb0f844f4ec0b3ee1))
- fix in proxy
  ([f778c9d](https://github.com/ax-llm/ax/commit/f778c9d2a8337730bc4ab08a0b00e304758d2500))
- fix in proxy
  ([f007d26](https://github.com/ax-llm/ax/commit/f007d269abd3768954d9e3428fe81e2ab2110b1c))
- fix in proxy
  ([ab87118](https://github.com/ax-llm/ax/commit/ab87118222de01ae4409aa5aaa65cdaa81eaf526))
- google gemini function calling
  ([a9214f3](https://github.com/ax-llm/ax/commit/a9214f3e6d2d96b724734e7a128276cbb76ca24d))
- google gemini now works great
  ([a6d6528](https://github.com/ax-llm/ax/commit/a6d6528e5f4a3a66be991ef8395159fb66bad1b8))
- import issues
  ([ce87294](https://github.com/ax-llm/ax/commit/ce87294cb62e293c6186a922b2a179bcde25baf1))
- improve examples
  ([6e656cb](https://github.com/ax-llm/ax/commit/6e656cbe631ff8eb127aae49e799a77cc55cecfb))
- improved the customer suppot example
  ([103b072](https://github.com/ax-llm/ax/commit/103b072c241140e380b0695d2c8fbaf5a91d3966))
- issue with cspell
  ([806cba1](https://github.com/ax-llm/ax/commit/806cba130fe61f96f8629d8d44344c80306c0611))
- issue with rate limiter
  ([0648ad7](https://github.com/ax-llm/ax/commit/0648ad7263493ebc34492cd72ec20704971c088f))
- json5 build issue
  ([fe6de9c](https://github.com/ax-llm/ax/commit/fe6de9ce995bc51996b12db57d9f3787bda2abd9))
- major fixes to function calling
  ([d44a373](https://github.com/ax-llm/ax/commit/d44a37300f4c427ede9a803939f5b90430e17a30))
- make mistral function calling work
  ([6bd9cf7](https://github.com/ax-llm/ax/commit/6bd9cf78b72ddd1b190ab798b47aedeb9a888001))
- make stop sequence optional
  ([d18addc](https://github.com/ax-llm/ax/commit/d18addcd287ce17dcd2a2c5feb8b8917d4f4f0e3))
- migrate npm package to llmclient
  ([97a4a07](https://github.com/ax-llm/ax/commit/97a4a07ed8e614563c7b7100141ce8bfde6aedb9))
- minor build fix
  ([32f04b3](https://github.com/ax-llm/ax/commit/32f04b3e5174a4915d8099c4a32c41979b0c652b))
- minor fix
  ([62fbf38](https://github.com/ax-llm/ax/commit/62fbf3807d60e1e367560a08ee40c25b9081137b))
- minor fixes
  ([3792700](https://github.com/ax-llm/ax/commit/3792700363172567b836cb5c562a62c41a703ce4))
- minor fixes
  ([574f73f](https://github.com/ax-llm/ax/commit/574f73f715f8972dbefa73e09978abf2de8e562c))
- minor fixes
  ([5ebf283](https://github.com/ax-llm/ax/commit/5ebf2831a8ecfef56df775ca127c546f0a562516))
- minor fixes
  ([5bb612d](https://github.com/ax-llm/ax/commit/5bb612d45a3089d8dac338a2cc8a21d388c161f9))
- minor fixes
  ([0fa4687](https://github.com/ax-llm/ax/commit/0fa4687ea70113321c829e9950e5b136da2e830d))
- minor fixes
  ([47eef31](https://github.com/ax-llm/ax/commit/47eef314ab5227940700938b08cfdbf39e390a7a))
- minor fixes
  ([0da9daf](https://github.com/ax-llm/ax/commit/0da9dafeb6375bdc819b1b0023253bf321f2ff07))
- minor fixes
  ([15bd72f](https://github.com/ax-llm/ax/commit/15bd72f9c8fff5b461792076f91e9689e7a55246))
- minor issue with incorrect error
  ([65e7ea8](https://github.com/ax-llm/ax/commit/65e7ea8847c98dc1d7ff72c6cb4e305936941330))
- missing imports
  ([9071c9e](https://github.com/ax-llm/ax/commit/9071c9e109921ef20d923f51a4d42ccfbb8bb5cd))
- new ai balancer to route based on token pricing in case of error
  ([7ea79a9](https://github.com/ax-llm/ax/commit/7ea79a90e0cf633d7517ce32701a9df18ba57b37))
- openai function tracing fixes
  ([d623f03](https://github.com/ax-llm/ax/commit/d623f03f6e8c3ad41fe5e919ef9433135bc199d9))
- opentelemetry tracing added to ai and vectordb
  ([1918410](https://github.com/ax-llm/ax/commit/1918410f4d83676fbcd9720b5707e5ab664761a6))
- prettier config
  ([8f4ca77](https://github.com/ax-llm/ax/commit/8f4ca77ecfe59605295e4f3f465db420e7380b9b))
- proxy command
  ([9eaf6e7](https://github.com/ax-llm/ax/commit/9eaf6e757422232135f21250300353735e4d6120))
- proxy port can be set using the env var PORT
  ([c08af8d](https://github.com/ax-llm/ax/commit/c08af8d3cac10d544794c618a8ddb6c19684ee7b))
- refactored request, response tracing
  ([1ac7023](https://github.com/ax-llm/ax/commit/1ac702334cd09dec9bc2f17944e67397762298ac))
- refactored usage reporting and other fixes
  ([84bf661](https://github.com/ax-llm/ax/commit/84bf661389ae806f2730bdd9d9edce2f5b932ede))
- remove comments
  ([73e3a30](https://github.com/ax-llm/ax/commit/73e3a3021d63e0b1fb2dcd6fc4b3e7a8267de4b1))
- remove index folder committed by mistake
  ([4d327ab](https://github.com/ax-llm/ax/commit/4d327abbbc7fb30041266f8cfdc426c7435c0a5f))
- removed crawler
  ([ab4ac6e](https://github.com/ax-llm/ax/commit/ab4ac6e10742611516067d937ab0350338973a3e))
- removed extra packages
  ([faae6d2](https://github.com/ax-llm/ax/commit/faae6d2512415cd8419105129a2a63527ec05371))
- renamed emailprompt to messageprompt
  ([3063a90](https://github.com/ax-llm/ax/commit/3063a907ed5383c63ed6f79cf1bcc27bf1fd04ac))
- renamed responseSchema to resultSchema for clarity
  ([b238b88](https://github.com/ax-llm/ax/commit/b238b88561cea813f3183d419b09b7f3386d16aa))
- resolved all typescript strict mode errors and warnings
  ([4f08fac](https://github.com/ax-llm/ax/commit/4f08face90d761faf97609213f88bbc84922d57c))
- result error-correction fixes
  ([eeaa12e](https://github.com/ax-llm/ax/commit/eeaa12e605f210df66c82a6f40e368d0ac6f0289))
- rewrite or error-correction code and other fixes
  ([37b620e](https://github.com/ax-llm/ax/commit/37b620e576982660d1013547043b07a1642b9892))
- seperated embed usage data from completion usage
  ([feb5619](https://github.com/ax-llm/ax/commit/feb5619f4df104e31edfbdd24f909a6c1b255a7f))
- set default model for openai to gpt3-turbo
  ([14ba73c](https://github.com/ax-llm/ax/commit/14ba73cc1fc80436c2073c85f5717215d03655a5))
- signature parser
  ([a149361](https://github.com/ax-llm/ax/commit/a149361263cae6e4bdc8a425f1abadd38ef9da56))
- streamlined the llm apis
  ([0bbc8b0](https://github.com/ax-llm/ax/commit/0bbc8b0729ef95657642ae3459fb43f5bbc666ff))
- system prompt fixes
  ([b56201c](https://github.com/ax-llm/ax/commit/b56201caf00df323925d2864f5c70f9ff70ee234))
- tests breaking
  ([4c047ce](https://github.com/ax-llm/ax/commit/4c047ce964d626129e0219e2dfef6ce7344f3747))
- ts cleanup
  ([be645d9](https://github.com/ax-llm/ax/commit/be645d952bec4d1b5022732a58a8705479147fbd))
- tuning and optimization fixes
  ([d0b892c](https://github.com/ax-llm/ax/commit/d0b892c7dd56f5720b75f8fe438cff8a5a29e535))
- type validation logic
  ([88eec1e](https://github.com/ax-llm/ax/commit/88eec1ebb4faa126ec491785c552a4958369f030))
- update model defaults
  ([1c70dd7](https://github.com/ax-llm/ax/commit/1c70dd7b2631f865216ae4d90c304db56880a806))
- update model defaults
  ([cc7e82f](https://github.com/ax-llm/ax/commit/cc7e82f0033f4881bc473dec53dc770023c32eab))
- update model defaults
  ([1251372](https://github.com/ax-llm/ax/commit/12513727f3b7f683858eed549f4ecea87883f91e))
- update package name
  ([ed5346c](https://github.com/ax-llm/ax/commit/ed5346c029e8228e37bae6494337496db5a4d774))
- Updated Cohere reqValue to include input_type (required since v3), Groq model
  to llama3-70b-8192 (llama2-70b-4096 was depreciated), and added a temporary
  fix to the marketing.py example (messageGuidelines expects a string, not a
  string array). ([#22](https://github.com/ax-llm/ax/issues/22))
  ([5885877](https://github.com/ax-llm/ax/commit/5885877ecb2294566713abe323344c1b67eae9ba))
- updates to debugging proxy
  ([6476a23](https://github.com/ax-llm/ax/commit/6476a23a6b297f216b45afff12d1f37883714a92))
- valid healthcheck path for proxy
  ([3adea76](https://github.com/ax-llm/ax/commit/3adea76b081cc433450229c449f0c65bcb2a8cf7))
- various fixes
  ([a0099a8](https://github.com/ax-llm/ax/commit/a0099a8958fae739d431a82a8715cf86bc2e74b5))
- various fixes
  ([7b75342](https://github.com/ax-llm/ax/commit/7b753421b438d2f01ae20b0a25549c994bdd07b3))
- various fixes
  ([440cb84](https://github.com/ax-llm/ax/commit/440cb842a8c39f00b1ba7fbb6c4523a1d1275387))
- various fixes
  ([516fbcb](https://github.com/ax-llm/ax/commit/516fbcbf69f42d4a3d0a9169098087a0d603e945))
- various fixes
  ([0978b29](https://github.com/ax-llm/ax/commit/0978b2904454b1928f5254f1f241797f77a64ac2))
- various proxy fixes
  ([61b693a](https://github.com/ax-llm/ax/commit/61b693a9c95b4f173ca48bcc91b9154cfabc2963))
- version update
  ([c4794a3](https://github.com/ax-llm/ax/commit/c4794a3e1853c58b60f7e9357d755dab4bca6e4e))
- zprompt type spec
  ([db1f7e7](https://github.com/ax-llm/ax/commit/db1f7e75c4ac176ea3ca424e5fc276d5e43081be))



================================================
FILE: cspell.json
================================================
{
  "dictionaryDefinitions": [
    {
      "name": "project-words",
      "path": "./.cspell/project-words.txt",
      "addWords": true
    }
  ],
  "dictionaries": ["project-words"],
  "ignorePaths": [
    "CHANGELOG.md",
    "node_modules",
    "./src/ax/dsp/stopwords.ts",
    "./src/examples",
    "./scripts",
    "./build",
    "./dist"
  ]
}



================================================
FILE: eslint.config.js
================================================
import tsParser from '@typescript-eslint/parser';
import tsPlugin from '@typescript-eslint/eslint-plugin';
import importPlugin from 'eslint-plugin-import';
import eslintCommentsPlugin from 'eslint-plugin-eslint-comments';
import functionalPlugin from 'eslint-plugin-functional';
import monorepoCopPlugin from 'eslint-plugin-monorepo-cop';
import prettierConfig from 'eslint-config-prettier';

export default [
    {
        ignores: [
            '**/node_modules/**',
            '**/dist/**',
            '**/coverage/**',
            '**/site/**',
            '**/.tsimp/**',
            '**/*.json'
        ]
    },
    {
        languageOptions: {
            parser: tsParser,
            parserOptions: {
                project: ['./tsconfig.json', './src/*/tsconfig.json'],
                ecmaVersion: 2020,
                sourceType: 'module',
            },
            globals: {
                BigInt: true,
                console: true,
                WebAssembly: true,
            },
        },
        plugins: {
            '@typescript-eslint': tsPlugin,
            'import': importPlugin,
            'eslint-comments': eslintCommentsPlugin,
            'functional': functionalPlugin,
            'monorepo-cop': monorepoCopPlugin,
        },
        settings: {
            'import/parsers': {
                '@typescript-eslint/parser': ['.ts', '.tsx'],
            },
        },
        files: ['**/*.ts', '**/*.tsx'],  // Explicitly only match TypeScript files
        rules: {
            ...tsPlugin.configs.recommended.rules,
            ...eslintCommentsPlugin.configs.recommended.rules,
            ...functionalPlugin.configs.lite.rules,
            ...prettierConfig.rules,

            'import/extensions': [
                'error',
                'ignorePackages',
                { js: 'always', ts: 'never', tsx: 'never' }
            ],
            'functional/no-class-inheritance': 'off',
            'functional/no-mixed-types': 'off',
            'functional/no-classes': 'off',
            'functional/no-return-void': 'off',
            'functional/no-let': 'off',
            'functional/no-loop-statements': 'off',
            'functional/no-throw-statements': 'off',
            'functional/immutable-data': 'off',
            '@typescript-eslint/explicit-module-boundary-types': 'off',
            'eslint-comments/disable-enable-pair': [
                'error',
                { allowWholeFile: true }
            ],
            'eslint-comments/no-unused-disable': 'error',
            'import/order': [
                'error',
                { 'newlines-between': 'always', alphabetize: { order: 'asc' } }
            ],
            'sort-imports': [
                'error',
                { ignoreDeclarationSort: true, ignoreCase: true }
            ],
            'monorepo-cop/no-relative-import-outside-package': 'error',
            '@typescript-eslint/naming-convention': [
                'error',
                {
                    selector: ['variable', 'function'],
                    format: ['camelCase'],
                    leadingUnderscore: 'allow',
                },
                {
                    selector: ['variable'],
                    modifiers: ['exported'],
                    format: ['PascalCase','camelCase'],
                },
                {
                    selector: 'class',
                    format: ['PascalCase'],
                },
                {
                    selector: ['classMethod'],
                    format: ['camelCase'],
                    leadingUnderscore: 'allow'
                },
                {
                    selector: 'parameter',
                    format: ['camelCase'],
                    leadingUnderscore: 'allow'
                },
                {
                    selector: 'typeLike',
                    format: ['PascalCase']
                }
            ]
        }
    },
    {
        plugins: {
            '@typescript-eslint': tsPlugin,
        },
        // Only apply to package index files, excluding test files and non-root index files
        files: ['./src/*/index.ts'],
        rules: {
            '@typescript-eslint/naming-convention': [
                'error',
                {
                    selector: ['variable', 'function'],
                    modifiers: ['exported'],
                    format: ['PascalCase'],
                    prefix: ['Ax']
                },
                {
                    selector: ['class', 'interface', 'typeAlias', 'enum', 'typeParameter'],
                    modifiers: ['exported'],
                    format: ['PascalCase'],
                    prefix: ['Ax']
                }
            ]
        }
    }
];


================================================
FILE: LICENSE
================================================
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



================================================
FILE: OPTIMIZE.md
================================================
# LLM Optimization Made Simple: A Beginner's Guide to Ax

**🎯 Goal**: Learn how to make your AI programs smarter, faster, and cheaper through automatic optimization.
**⏱️ Time to first results**: 5 minutes  
**💰 Cost**: Start with $1-2 for experimentation

## 📋 Table of Contents

- [What is LLM Optimization?](#what-is-llm-optimization)
- [🚀 5-Minute Quick Start](#-5-minute-quick-start) ← **Start here!**
- [📚 Understanding the Basics](#-understanding-the-basics)
- [🎯 Common Use Cases](#-common-use-cases-copy--paste-ready)
- [💰 Saving Money: Teacher-Student Setup](#-saving-money-teacher-student-setup)
- [🔧 Making It Better: Practical Tips](#-making-it-better-practical-tips)
- [🛠️ Troubleshooting Guide](#️-troubleshooting-guide)
- [🎓 Next Steps: Level Up Your Skills](#-next-steps-level-up-your-skills)
- [📖 Complete Working Example](#-complete-working-example)
- [🎯 Key Takeaways](#-key-takeaways)

---

## What is LLM Optimization?

Think of optimization like having a writing tutor for your AI. Instead of manually tweaking prompts and examples, Ax automatically:

- **Writes better prompts** for your AI programs
- **Picks the best examples** to show your AI what you want
- **Saves you money** by making cheaper models work as well as expensive ones
- **Improves accuracy** without you having to be a prompt engineering expert

**Real example**: A sentiment analysis that goes from 70% accuracy to 90% accuracy automatically, while reducing costs by 80%.

### 🗺️ Learning Path
```
Beginner     → Intermediate → Advanced
     ↓              ↓           ↓
Quick Start → Use Cases → Teacher-Student → Multi-Objective
(5 min)      (15 min)    (30 min)         (1 hour)
```

---

## 🚀 5-Minute Quick Start

### Step 1: Install and Setup

```bash
npm install @ax-llm/ax
```

```typescript
// Create a .env file with your OpenAI API key
// OPENAI_APIKEY=your_key_here

import { ax, AxAI, AxMiPRO, f } from '@ax-llm/ax'
```

### Step 2: Create Your First Optimizable Program

```typescript
// This is a simple sentiment analyzer - we'll make it smarter!
const sentimentAnalyzer = ax`
  reviewText:${f.string('Customer review')} -> 
  sentiment:${f.class(['positive', 'negative', 'neutral'], 'How the customer feels')}
`

// Set up your AI
const ai = new AxAI({ 
  name: 'openai', 
  apiKey: process.env.OPENAI_APIKEY!,
  config: { model: 'gpt-4o-mini' } // Start with the cheaper model
})
```

### Step 3: Provide Training Examples

```typescript
// Just 3-5 examples are enough to start!
const examples = [
  { reviewText: 'I love this product!', sentiment: 'positive' },
  { reviewText: 'This is terrible quality', sentiment: 'negative' },
  { reviewText: 'It works fine, nothing special', sentiment: 'neutral' },
  { reviewText: 'Best purchase ever!', sentiment: 'positive' },
  { reviewText: 'Waste of money', sentiment: 'negative' }
]
```

### Step 4: Define Success (Your Metric)

```typescript
// This tells the optimizer what "good" looks like
const metric = ({ prediction, example }) => {
  // Simple: 1 point for correct answer, 0 for wrong
  return prediction.sentiment === example.sentiment ? 1 : 0
}
```

### Step 5: Run the Magic ✨

```typescript
// Create the optimizer
const optimizer = new AxMiPRO({
  studentAI: ai,
  examples,
  options: { verbose: true } // Show progress
})

// Let it optimize (takes 1-2 minutes)
console.log('🔄 Optimizing your AI program...')
const result = await optimizer.compile(sentimentAnalyzer, metric)

// Apply the improvements
if (result.demos) {
  sentimentAnalyzer.setDemos(result.demos)
}

console.log(`✅ Done! Improved from baseline to ${result.bestScore * 100}% accuracy`)
```

### Step 6: Test Your Improved AI

```typescript
// Test it out!
const testReview = "The product arrived quickly but the quality was disappointing"
const analysis = await sentimentAnalyzer.forward(ai, { reviewText: testReview })

console.log('Analysis:', analysis.sentiment) // Much more accurate now!
```

**🎉 Congratulations!** You just automatically improved an AI program. The optimizer found better prompts and examples without you having to manually experiment.

---

## 📚 Understanding the Basics

### What Just Happened?

1. **The Optimizer** tried different ways to ask your AI the question
2. **It tested** each approach using your examples
3. **It kept** the best-performing version
4. **Your program** now uses the optimized prompt and examples

### Key Terms (Simple Explanations)

- **Student AI**: The model you want to optimize (usually cheaper/faster)
- **Teacher AI**: Optional expensive model that helps create better instructions
- **Examples**: Your training data showing correct answers
- **Metric**: How you measure if the AI is doing well
- **Demos**: The best examples the optimizer found to show your AI

### When to Use Optimization

> **🎯 Perfect for beginners**: Start with classification tasks like sentiment analysis, email categorization, or content moderation where you have clear right/wrong answers.

✅ **Great for:**
- Classification tasks (sentiment, categories, etc.)
- When you have some example data (even just 5-10 examples!)
- When accuracy matters more than speed
- When you want to save money on API calls
- Repetitive tasks you do often

❌ **Skip for now:**
- Simple one-off tasks
- When you have no training examples
- Creative writing tasks (poems, stories)
- When you need results immediately (optimization takes 1-5 minutes)

---

## 🎯 Common Use Cases (Copy & Paste Ready)

### 1. Email Classification

```typescript
const emailClassifier = ax`
  emailContent:${f.string('Email text')} -> 
  category:${f.class(['urgent', 'normal', 'spam'], 'Email priority')},
  needsReply:${f.class(['yes', 'no'], 'Does this need a response?')}
`

const examples = [
  { 
    emailContent: 'URGENT: Server is down!', 
    category: 'urgent', 
    needsReply: 'yes' 
  },
  { 
    emailContent: 'Thanks for your help yesterday', 
    category: 'normal', 
    needsReply: 'no' 
  },
  { 
    emailContent: 'You won a million dollars! Click here!', 
    category: 'spam', 
    needsReply: 'no' 
  }
]

const metric = ({ prediction, example }) => {
  let score = 0
  if (prediction.category === example.category) score += 0.7
  if (prediction.needsReply === example.needsReply) score += 0.3
  return score
}

// Same optimization pattern as before...
```

### 2. Customer Support Routing

```typescript
const supportRouter = ax`
  customerMessage:${f.string('Customer inquiry')} -> 
  department:${f.class(['billing', 'technical', 'general'], 'Which team should handle this')},
  urgency:${f.class(['low', 'medium', 'high'], 'How urgent is this')}
`

const examples = [
  { 
    customerMessage: 'I was charged twice for my subscription', 
    department: 'billing', 
    urgency: 'high' 
  },
  { 
    customerMessage: 'How do I reset my password?', 
    department: 'technical', 
    urgency: 'medium' 
  },
  { 
    customerMessage: 'What are your business hours?', 
    department: 'general', 
    urgency: 'low' 
  }
]
```

### 3. Content Moderation

```typescript
const contentModerator = ax`
  userPost:${f.string('User-generated content')} -> 
  safe:${f.class(['yes', 'no'], 'Is this content appropriate?')},
  reason:${f.string('Why was this flagged (if unsafe)')}
`

const examples = [
  { userPost: 'Great weather today!', safe: 'yes', reason: '' },
  { userPost: 'This product sucks and so do you!', safe: 'no', reason: 'Inappropriate language' },
  { userPost: 'Check out my new blog post', safe: 'yes', reason: '' }
]
```

---

## 💰 Saving Money: Teacher-Student Setup

**The Problem**: GPT-4 is smart but expensive. GPT-4-mini is cheap but sometimes not as accurate.

**The Solution**: Use GPT-4 as a "teacher" to make GPT-4-mini as smart as GPT-4, but at 1/10th the cost!

### Simple Teacher-Student Setup

```typescript
// Teacher: Smart but expensive (only used during optimization)
const teacherAI = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: { model: 'gpt-4o' } // The expensive one
})

// Student: Fast and cheap (used for actual work)
const studentAI = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: { model: 'gpt-4o-mini' } // The cheap one
})

const optimizer = new AxMiPRO({
  studentAI,    // This is what gets optimized
  teacherAI,    // This helps create better instructions
  examples,
  options: { verbose: true }
})

// The magic: cheap model performs like expensive model!
const result = await optimizer.compile(program, metric)
```

**Real savings**: Instead of paying $0.03 per 1K tokens, you pay $0.0006 per 1K tokens after optimization - that's 50x cheaper!

---

## 🔧 Making It Better: Practical Tips

### 1. Better Examples = Better Results

❌ **Bad examples** (too similar):
```typescript
const badExamples = [
  { text: 'I love it', sentiment: 'positive' },
  { text: 'I like it', sentiment: 'positive' },
  { text: 'I enjoy it', sentiment: 'positive' }
]
```

✅ **Good examples** (diverse):
```typescript
const goodExamples = [
  { text: 'I love this product!', sentiment: 'positive' },
  { text: 'Terrible quality, broke immediately', sentiment: 'negative' },
  { text: 'It works fine, nothing special', sentiment: 'neutral' },
  { text: 'Best purchase ever made!', sentiment: 'positive' },
  { text: 'Completely useless waste of money', sentiment: 'negative' }
]
```

### 2. Better Metrics = Better Optimization

❌ **Too simple**:
```typescript
const simpleMetric = ({ prediction, example }) => {
  return prediction.category === example.category ? 1 : 0
}
```

✅ **More nuanced**:
```typescript
const betterMetric = ({ prediction, example }) => {
  let score = 0
  
  // Main task (80% of score)
  if (prediction.category === example.category) {
    score += 0.8
  }
  
  // Bonus for confidence (20% of score)
  if (prediction.confidence && prediction.confidence > 0.7) {
    score += 0.2
  }
  
  return score
}
```

### 3. Start Small, Then Scale

**Phase 1**: Start with 5-10 examples
```typescript
const optimizer = new AxMiPRO({
  studentAI,
  examples: examples.slice(0, 10), // Just first 10
  options: { 
    numTrials: 3,  // Quick test
    verbose: true 
  }
})
```

**Phase 2**: Scale up if results are good
```typescript
const optimizer = new AxMiPRO({
  studentAI,
  teacherAI,
  examples: allExamples, // All your data
  options: { 
    numTrials: 8,  // More thorough
    verbose: true 
  }
})
```

---

## 🛠️ Troubleshooting Guide

### "My optimization score is low!"

**Check your examples**:
```typescript
// Are they diverse enough?
console.log('Unique categories:', [...new Set(examples.map(e => e.category))])

// Are they correct?
examples.forEach((ex, i) => {
  console.log(`Example ${i}: ${ex.text} -> ${ex.category}`)
})
```

**Try a better metric**:
```typescript
// Add logging to see what's happening
const debugMetric = ({ prediction, example }) => {
  const correct = prediction.category === example.category
  console.log(`Predicted: ${prediction.category}, Expected: ${example.category}, Correct: ${correct}`)
  return correct ? 1 : 0
}
```

### "It's too expensive!"

**Set a budget**:
```typescript
import { AxDefaultCostTracker } from '@ax-llm/ax'

const costTracker = new AxDefaultCostTracker({
  maxTokens: 10000,  // Stop after 10K tokens
  maxCost: 5,        // Stop after $5
})

const optimizer = new AxMiPRO({
  studentAI,
  examples,
  costTracker, // Automatic budget control
  options: { 
    numTrials: 3,              // Fewer trials
    earlyStoppingTrials: 2,    // Stop early if no improvement
  }
})
```

### "It's taking too long!"

**Speed it up**:
```typescript
const optimizer = new AxMiPRO({
  studentAI,
  examples: examples.slice(0, 20), // Fewer examples
  options: {
    numCandidates: 3,    // Fewer candidates to try
    numTrials: 5,        // Fewer trials
    minibatch: true,     // Process in smaller batches
    verbose: true
  }
})
```

### "Results are inconsistent!"

**Make it reproducible**:
```typescript
const optimizer = new AxMiPRO({
  studentAI: new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY!,
    config: { 
      model: 'gpt-4o-mini',
      temperature: 0.1  // Lower = more consistent
    }
  }),
  examples,
  seed: 42,  // Same results every time
  options: { verbose: true }
})
```

---

## 🎓 Next Steps: Level Up Your Skills

### 1. Try Different Optimizers

**For few-shot learning** (when you have good examples):
```typescript
import { AxBootstrapFewShot } from '@ax-llm/ax'

const optimizer = new AxBootstrapFewShot({
  studentAI,
  examples,
  options: {
    maxDemos: 5,        // Show 5 examples to AI
    maxRounds: 3,       // 3 rounds of improvement
    verboseMode: true
  }
})
```

### 2. Multi-Objective Optimization

**When you care about multiple things**:
```typescript
const multiMetric = ({ prediction, example }) => ({
  accuracy: prediction.category === example.category ? 1 : 0,
  speed: 1 / (prediction.responseTime || 1),
  confidence: prediction.confidence || 0
})

// Find the best trade-offs automatically
const result = await optimizer.compilePareto(program, multiMetric)
console.log(`Found ${result.paretoFrontSize} optimal solutions`)
```

### 3. Chain Multiple Programs

```typescript
// First program: Extract key info
const extractor = ax`
  email:${f.string('Email content')} -> 
  keyPoints:${f.array(f.string('Important points'))}
`

// Second program: Classify based on extracted info
const classifier = ax`
  keyPoints:${f.array(f.string('Key points'))} -> 
  priority:${f.class(['low', 'medium', 'high'], 'Email priority')}
`

// Optimize them separately, then chain them
const extractResult = await extractOptimizer.compile(extractor, extractMetric)
const classifyResult = await classifyOptimizer.compile(classifier, classifyMetric)

// Use them together
const email = "Meeting moved to 3pm tomorrow, please confirm"
const keyPoints = await extractor.forward(ai, { email })
const priority = await classifier.forward(ai, { keyPoints: keyPoints.keyPoints })
```

---

## 📖 Complete Working Example

Here's a full example you can copy, paste, and run:

```typescript
import { ax, AxAI, AxMiPRO, f } from '@ax-llm/ax'

// 1. Define the task
const productReviewer = ax`
  productReview:${f.string('Customer product review')} -> 
  rating:${f.class(['1', '2', '3', '4', '5'], 'Star rating 1-5')},
  aspect:${f.class(['quality', 'price', 'shipping', 'service'], 'Main concern')},
  recommendation:${f.class(['buy', 'avoid', 'maybe'], 'Would you recommend?')}
`

// 2. Training examples
const examples = [
  { 
    productReview: 'Amazing quality, worth every penny!', 
    rating: '5', 
    aspect: 'quality', 
    recommendation: 'buy' 
  },
  { 
    productReview: 'Too expensive for what you get', 
    rating: '2', 
    aspect: 'price', 
    recommendation: 'avoid' 
  },
  { 
    productReview: 'Good product but took forever to arrive', 
    rating: '3', 
    aspect: 'shipping', 
    recommendation: 'maybe' 
  },
  { 
    productReview: 'Great value, fast delivery, happy customer!', 
    rating: '5', 
    aspect: 'price', 
    recommendation: 'buy' 
  },
  { 
    productReview: 'Customer service was rude when I had issues', 
    rating: '1', 
    aspect: 'service', 
    recommendation: 'avoid' 
  }
]

// 3. AI setup
const ai = new AxAI({ 
  name: 'openai', 
  apiKey: process.env.OPENAI_APIKEY!,
  config: { model: 'gpt-4o-mini' }
})

// 4. Success metric
const metric = ({ prediction, example }) => {
  let score = 0
  if (prediction.rating === example.rating) score += 0.5
  if (prediction.aspect === example.aspect) score += 0.3
  if (prediction.recommendation === example.recommendation) score += 0.2
  return score
}

// 5. Optimize
const optimizer = new AxMiPRO({
  studentAI: ai,
  examples,
  options: { verbose: true }
})

console.log('🔄 Starting optimization...')
const result = await optimizer.compile(productReviewer, metric)

if (result.demos) {
  productReviewer.setDemos(result.demos)
}

console.log(`✅ Optimization complete! Score improved to ${(result.bestScore * 100).toFixed(1)}%`)

// 6. Test it
const testReview = "The item was okay but customer support was unhelpful when I had questions"
const analysis = await productReviewer.forward(ai, { productReview: testReview })

console.log('Analysis:', analysis)
// Expected: rating: '2' or '3', aspect: 'service', recommendation: 'avoid' or 'maybe'
```

---

## 🎯 Key Takeaways

1. **Start simple**: 5 examples and basic optimization can give you 20-30% improvement
2. **Teacher-student saves money**: Use expensive models to teach cheap ones
3. **Good examples matter more than lots of examples**: 10 diverse examples beat 100 similar ones
4. **Measure what matters**: Your metric defines what the AI optimizes for
5. **Iterate and improve**: Start basic, then add complexity as you learn

**Ready to optimize your first AI program?** Copy the examples above and start experimenting! 

**Questions?** Check the `src/examples/` folder for more real-world examples, or refer to the troubleshooting section above.

---

## 📚 Quick Reference

### Essential Imports
```typescript
import { ax, AxAI, AxMiPRO, f } from '@ax-llm/ax'
```

### Basic Pattern (Copy This!)
```typescript
// 1. Define program
const program = ax`input:${f.string('description')} -> output:${f.class(['a', 'b'], 'description')}`

// 2. Create AI
const ai = new AxAI({ name: 'openai', apiKey: process.env.OPENAI_APIKEY!, config: { model: 'gpt-4o-mini' }})

// 3. Add examples
const examples = [{ input: 'example', output: 'a' }]

// 4. Define metric
const metric = ({ prediction, example }) => prediction.output === example.output ? 1 : 0

// 5. Optimize
const optimizer = new AxMiPRO({ studentAI: ai, examples, options: { verbose: true }})
const result = await optimizer.compile(program, metric)
if (result.demos) program.setDemos(result.demos)
```

### Common Field Types
- `f.string('description')` - Text input/output
- `f.class(['option1', 'option2'], 'description')` - Classification
- `f.number('description')` - Numeric values
- `f.array(f.string('item description'))` - Lists
- `f.boolean('description')` - True/false

### Budget Control
```typescript
import { AxDefaultCostTracker } from '@ax-llm/ax'
const costTracker = new AxDefaultCostTracker({ maxTokens: 10000, maxCost: 5 })
// Add to optimizer: costTracker
```

### Teacher-Student (Cost Savings)
```typescript
const teacherAI = new AxAI({ name: 'openai', config: { model: 'gpt-4o' }})      // Expensive
const studentAI = new AxAI({ name: 'openai', config: { model: 'gpt-4o-mini' }}) // Cheap
// Use both in optimizer: { studentAI, teacherAI, ... }
```

---

*💡 Remember: Optimization is like having a personal AI tutor. You provide the examples and goals, and it figures out the best way to teach your AI. Start simple, measure results, and gradually make it more sophisticated as you learn what works!*

---

## 💾 Checkpointing (Fault Tolerance)

Long-running optimizations can be expensive and time-consuming. Ax provides simple function-based checkpointing to save optimization progress and recover from failures.

### Why Use Checkpointing?

- **Cost Protection**: Don't lose expensive optimization work due to crashes
- **Fault Tolerance**: Resume optimization after interruptions
- **Experimentation**: Save optimization state at different points for analysis

### How It Works

Implement two simple functions to save and load checkpoint data:

```typescript
import { type AxCheckpointSaveFn, type AxCheckpointLoadFn } from '@ax-llm/ax'

const checkpointSave: AxCheckpointSaveFn = async (checkpoint) => {
  // JSON serialize the checkpoint and save it wherever you want:
  // - Memory: map.set(id, checkpoint)
  // - localStorage: localStorage.setItem(id, JSON.stringify(checkpoint))
  // - Database: await db.create({ data: checkpoint })
  // - Files: await fs.writeFile(`${id}.json`, JSON.stringify(checkpoint))
  // - Cloud: await s3.putObject({ Key: id, Body: JSON.stringify(checkpoint) })
  
  const id = `checkpoint_${Date.now()}`
  // Your storage implementation here
  return id
}

const checkpointLoad: AxCheckpointLoadFn = async (id) => {
  // Load and JSON parse the checkpoint data
  // Return null if not found
  return /* your loaded checkpoint */ || null
}

// Use with any optimizer
const optimizer = new AxMiPRO({
  studentAI: ai,
  examples,
  checkpointSave,
  checkpointLoad,
  checkpointInterval: 10, // Save every 10 rounds
  resumeFromCheckpoint: 'checkpoint_12345', // Resume from specific checkpoint
  options: { numTrials: 50, verbose: true }
})
```

### Key Points

- **Simple**: Just two functions - save and load
- **Storage Agnostic**: Works with any storage (memory, files, databases, cloud)
- **JSON Serializable**: Checkpoint data is just JSON - store it anywhere
- **Complete State**: Contains all optimization progress (scores, configurations, examples)
- **Browser Compatible**: No filesystem dependencies

The checkpoint contains complete optimization state, so you can resume exactly where you left off, even after crashes or interruptions.


================================================
FILE: package.json
================================================
{
  "name": "@ax-llm/ax-monorepo",
  "type": "module",
  "description": "Monorepo for the best library to work with LLMs - Ax",
  "repository": {
    "type": "git",
    "url": "https://github.com/ax-llm/ax.git"
  },
  "license": "Apache-2.0",
  "keywords": [],
  "scripts": {
    "build": "npm run build --workspaces --workspace='!@ax-llm/ax-docs' --if-present",
    "fix": "npm run fix --workspaces --if-present",
    "test": "run-s test:*",
    "test:tests": "npm run test --workspaces --if-present",
    "test:spelling": "cspell \"{README.md,.github/*.md,src/**/*.ts}\" --quiet --color --config cspell.json",
    "coverage": "npm run fix --workspaces --if-present",
    "doc:build": "run-s doc:build:markdown doc:build:html",
    "doc:build:markdown": "npm run doc:build:markdown --workspaces --if-present",
    "doc:build:html": "npm run build --workspace=@ax-llm/ax-docs",
    "version": "standard-version",
    "prepare": "npm run test",
    "release": "npm run release --workspaces --if-present && release-it --no-increment",
    "publish": "npm run publish --workspaces  --if-present -- --provenance --access public",
    "git-cz": "npx git-cz",
    "dependencies:rebuild": "rm -rf package-lock.json && rm -rf node_modules && rm -rf */*/node_modules && npm i --no-audit --no-fund",
    "tsx": "node --env-file=.env --import=tsx",
    "fix:format": "prettier --write README.md",
    "init-package": "node scripts/initPackage.js"
  },
  "engines": {
    "node": ">=20"
  },
  "devDependencies": {
    "@release-it/bumper": "^7.0.5",
    "@release-it/conventional-changelog": "^10.0.1",
    "@total-typescript/tsconfig": "^1.0.4",
    "@types/node": "^22.13.10",
    "@typescript-eslint/eslint-plugin": "^8.26.1",
    "@typescript-eslint/parser": "^8.26.1",
    "c8": "^10.1.3",
    "cspell": "^8.17.3",
    "cz-conventional-changelog": "^3.3.0",
    "eslint": "^9.22.0",
    "eslint-config-prettier": "^10.1.1",
    "eslint-plugin-eslint-comments": "^3.2.0",
    "eslint-plugin-functional": "^8.0.0",
    "eslint-plugin-import": "^2.31.0",
    "eslint-plugin-monorepo-cop": "^1.0.2",
    "eslint-plugin-require-extensions": "^0.1.3",
    "gh-pages": "^6.1.1",
    "glob": "^11.0.1",
    "husky": "^9.0.0",
    "prettier": "^3.5.3",
    "release-it": "^19.0.3",
    "standard-version": "^9.5.0",
    "tsd": "^0.32.0",
    "tsimp": "^2.0.12",
    "tsup": "^8.5.0",
    "tsx": "^4.19.4",
    "typedoc": "^0.28.5",
    "typedoc-plugin-frontmatter": "^1.2.1",
    "typedoc-plugin-markdown": "^4.4.2",
    "typescript": "^5.8.3",
    "vitest": "^3.2.1",
    "npm-run-all2": "^8.0.4"
  },
  "config": {
    "commitizen": {
      "path": "cz-conventional-changelog"
    }
  },
  "bugs": {
    "url": "https://github.com/@ax-llm/ax/issues"
  },
  "homepage": "https://github.com/@ax-llm/ax#readme",
  "directories": {
    "example": "examples"
  },
  "workspaces": [
    "src/*"
  ],
  "author": "Vikram <https://twitter.com/dosco>",
  "private": "true",
  "version": "12.0.8"
}



================================================
FILE: SECURITY.md
================================================
# Security Policy

## Supported Versions

Use this section to tell people about which versions of your project are
currently being supported with security updates.

| Version | Supported          |
| ------- | ------------------ |
| latest   | :white_check_mark: |

## Reporting a Vulnerability

To report vulnerabilities please email use the private reporting feature of Github.
https://docs.github.com/en/code-security/security-advisories/guidance-on-reporting-and-writing/privately-reporting-a-security-vulnerability#privately-reporting-a-security-vulnerability



================================================
FILE: tsconfig.json
================================================
{
  "extends": "@total-typescript/tsconfig/tsc/no-dom/library",
  "compilerOptions": {
    "jsx": "react",
    "esModuleInterop": true,
    "moduleResolution": "NodeNext",
    "outDir": "build/module",
    "pretty": true,
    "baseUrl": ".",
    "paths": {
      "@ax-llm/*": ["src/*"]
    }
  },
  "exclude": ["node_modules/**", "dist/**", "src/*/dist/**"]
}



================================================
FILE: typedoc.json
================================================
{
  "$schema": "https://typedoc.org/schema.json",
  "plugin": [
    "typedoc-plugin-markdown",
    "typedoc-plugin-frontmatter",
    "./scripts/customFrontmatter.mjs"
  ],
  "pretty": true,
  "cleanOutputDir": true,
  "hidePageTitle": true,
  "hideGroupHeadings": true,
  "parametersFormat": "table",
  "typeDeclarationVisibility": "compact",
  "hidePageHeader": true,
  "hideBreadcrumbs": true,
  "useHTMLAnchors": true,
  "preserveAnchorCasing": true,
  "excludePrivate": true,
  "excludeProtected": true,
  "flattenOutputFiles": true,
  "mergeReadme": false,
  "interfacePropertiesFormat": "table",
  "classPropertiesFormat": "table",
  "enumMembersFormat": "table",
  "typeDeclarationFormat": "table",
  "indexFormat": "table",
  "expandParameters": true,
  "useCodeBlocks": true,
  "blockTagsPreserveOrder": ["@example", "@remarks", "@deprecated", "@see"],
  "tableColumnSettings": {
    "hideDefaults": false,
    "hideInherited": false,
    "hideModifiers": false,
    "hideOverrides": false,
    "hideSources": true,
    "hideValues": false,
    "leftAlignHeaders": true
  },
  "pageTitleTemplates": {
    "index": "{projectName} API Documentation",
    "module": "{name}",
    "member": "{kind}: {name}"
  }
}



================================================
FILE: .editorconfig
================================================
# http://editorconfig.org
root = true

[*]
charset = utf-8
end_of_line = lf
indent_size = 2
indent_style = space
insert_final_newline = true
max_line_length = 80
trim_trailing_whitespace = true

[*.md]
max_line_length = 0
trim_trailing_whitespace = false



================================================
FILE: .node-version
================================================
v20



================================================
FILE: .prettierrc
================================================
{
  "semi": false,
  "singleQuote": true,
  "trailingComma": "es5",
  "printWidth": 80
}



================================================
FILE: .release-it.json
================================================
{
  "npm": {
    "publish": false
  },
  "git": {
    "commitMessage": "chore: release v${version}",
    "requireCleanWorkingDir": false
  },
  "github": {
    "release": true,
    "web": true,
    "releaseName": "Release ${version}",
    "releaseNotes": "git log --no-merges --pretty=format:\"* %s %h\" ${latestTag}...main"
  },
  "plugins": {
    "@release-it/conventional-changelog": {
      "preset": {
        "name": "conventionalcommits"
      },
      "infile": "CHANGELOG.md"
    }
  }
}



================================================
FILE: scripts/README.md
================================================
# initPackage Script

A script to create new packages in the Ax monorepo using the `src/ax` package as a skeleton template, copying configuration files and filtering dependencies appropriately.

## Usage

```bash
# Create a new package with default description
npm run init-package <package-name>

# Create a new package with custom description
npm run init-package <package-name> "Custom package description"

# Create a new package with additional dependencies
npm run init-package <package-name> "Custom description" "dep1,dep2,dep3"
```

## Examples

```bash
# Create a new package called "my-extension"
npm run init-package my-extension

# Create a new package with custom description
npm run init-package vector-store "Vector store implementation for Ax"

# Create a new package with additional dependencies
npm run init-package ai-provider "Custom AI provider" "zod,uuid,lodash"
```

## What it creates

The script creates a new package under `src/<package-name>/` with the following structure:

```
src/<package-name>/
├── package.json          # Package configuration with proper workspace setup
├── tsconfig.json         # TypeScript configuration extending root config
├── tsup.config.ts        # Build configuration for ESM/CJS/DTS output
├── index.ts              # Main entry point
├── lib.ts                # Main implementation file
├── index.test.ts         # Vitest test file
├── README.md             # Package documentation
├── .prettierignore       # Prettier ignore rules
└── .release-it.json      # Release configuration
```

## Package Features

Each generated package includes:

- **TypeScript**: Full TypeScript support with proper configuration
- **Build System**: tsup configuration for ESM, CJS, and TypeScript declarations
- **Testing**: Vitest test setup with example tests
- **Linting**: ESLint and Prettier configuration
- **Versioning**: Integrated with monorepo versioning system
- **Publishing**: Ready for npm publishing with proper scoping

## Package Naming

- Package names must be lowercase
- Must start with a letter
- Can contain letters, numbers, and hyphens
- Will be published as `@ax-llm/ax-<package-name>`

## After Creation

After creating a package, you can:

1. Install dependencies: `npm install`
2. Build the package: `npm run build --workspace=@ax-llm/ax-<package-name>`
3. Run tests: `npm run test --workspace=@ax-llm/ax-<package-name>`
4. Start development: `npm run dev --workspace=@ax-llm/ax-<package-name>`

## Template Structure

The script uses the `src/ax` package as a template, ensuring consistency with:

- **Package.json**: Copies structure and scripts from `src/ax`, filtering out package-specific scripts like `build:index`
- **Configuration Files**: Copies `tsconfig.json`, `tsup.config.ts`, `.prettierignore`, and `.release-it.json` directly from `src/ax`
- **Dependencies**: Intelligently filters dependencies, keeping only core ones (`@ax-llm/ax`) plus any additional specified dependencies
- **Scripts**: Inherits all scripts from `src/ax` except package-specific ones, with build script simplified to just `tsup`

## Dependency Management

The script intelligently handles dependencies:

1. **Core Dependencies**: Always includes `@ax-llm/ax` with current monorepo version
2. **Additional Dependencies**: Looks for specified dependencies in:
   - `src/ax/package.json` dependencies
   - Root `package.json` dependencies  
   - Falls back to `^latest` if not found (with warning)
3. **Filtered Dependencies**: Removes all other dependencies from `src/ax` to keep packages lean

## Configuration File Copying

Instead of generating configuration files, the script copies them directly from `src/ax`:

- **tsconfig.json**: Ensures consistent TypeScript configuration
- **tsup.config.ts**: Maintains consistent build setup
- **.prettierignore**: Keeps formatting rules consistent
- **.release-it.json**: Ensures proper release configuration 


================================================
FILE: scripts/clean.js
================================================
import path  from 'path';
import process from 'process';

import fs from 'fs-extra';

process.argv.slice(1).map((fpath) => {
  const packagePath = process.cwd();
  const targetPath = path.join(packagePath, fpath);
  if (fs.existsSync(targetPath)) {
    console.log(`Cleaning folder ${targetPath}`);
    fs.rmdirSync(targetPath, { recursive: true });
  }
});

process.exit(0);



================================================
FILE: scripts/customFrontmatter.mjs
================================================
// @ts-check
import { MarkdownPageEvent } from 'typedoc-plugin-markdown';

/**
 * @param {import('typedoc-plugin-markdown').MarkdownApplication} app
 */
export function load(app) {
  app.renderer.on(MarkdownPageEvent.BEGIN, (page) => {
    // Update frontmatter with the page title
    page.frontmatter = {
      title: page.model?.name,
      ...page.frontmatter,
    };
  });


  app.renderer.on(MarkdownPageEvent.END, (page) => {
    // Transform specific link patterns in the page content
    page.contents = replaceAndFormat(page.contents);
  });
}

/**
 * Transforms markdown link paths to a specific format.
 * Examples:
 * [`AxChatResponse`](TypeAlias.AxChatResponse.md) -> [`AxChatResponse`](#typealiasaxchatresponse)
 * 
 * @param {string | undefined} input - The input markdown content
 * @returns {string | undefined} Transformed markdown content
 */
function replaceAndFormat(input) {
    if (!input) return input;
  
    return input.replace(
      /(\[`?[^`\]]+`?\]\()([^)]+)(\))/g,
      (match, linkText, path, closing) => {

        if (path.startsWith('https://')) {
            return path;
        }

        // Remove file extension
        let transformedPath = path.replace(/\.md$/, '');

        // Remove special characters like dots and convert to lowercase
        transformedPath = transformedPath
          .toLowerCase()
          .replace(/[^a-z0-9-]/g, '');

        transformedPath = '/api/#03-apidocs/' + transformedPath;

        console.log(transformedPath)

        return `${linkText}${transformedPath}${closing}`;
      }
    );
  }


================================================
FILE: scripts/generateIndex.ts
================================================
#!/usr/bin/env tsx
import * as fs from 'node:fs'
import * as path from 'node:path'

import * as ts from 'typescript'

/**
 * Represents an exported symbol from a TypeScript file
 */
interface ExportInfo {
  /** Original name of the exported symbol */
  originalName: string
  /** Name with prefix (same as originalName currently) */
  prefixedName: string
  /** Whether this is a type or value export */
  kind: 'type' | 'value'
  /** Whether this is a default export */
  isDefault?: boolean
}

/**
 * Checks if a symbol name starts with the expected prefixes (ax or Ax) or is a special case
 */
function hasValidPrefix(name: string): boolean {
  return (
    name.startsWith('ax') ||
    name.startsWith('Ax') ||
    name === 'f' ||
    name === 's'
  )
}

/**
 * Processes an export declaration node to extract exports with valid prefixes
 */
function processExportDeclaration(node: ts.ExportDeclaration): ExportInfo[] {
  const exportsMap = new Map<string, ExportInfo>()

  if (node.exportClause && ts.isNamedExports(node.exportClause)) {
    for (const element of node.exportClause.elements) {
      const originalName = element.name.text
      if (hasValidPrefix(originalName)) {
        // Only add if not already present
        const key = `${originalName}:${element.isTypeOnly ? 'type' : 'value'}`
        if (!exportsMap.has(key)) {
          exportsMap.set(key, {
            originalName,
            prefixedName: originalName,
            kind: element.isTypeOnly ? 'type' : 'value',
          })
        }
      }
    }
  }

  return Array.from(exportsMap.values())
}

/**
 * Processes an export assignment (default export) node
 */
function processExportAssignment(node: ts.ExportAssignment): ExportInfo[] {
  const exports: ExportInfo[] = []

  if (ts.isIdentifier(node.expression)) {
    const originalName = node.expression.text
    if (hasValidPrefix(originalName)) {
      exports.push({
        originalName,
        prefixedName: originalName,
        kind: 'value',
        isDefault: true,
      })
    }
  }

  return exports
}

/**
 * Processes a declaration node (class, interface, or type alias)
 */
function processDeclaration(
  node:
    | ts.ClassDeclaration
    | ts.InterfaceDeclaration
    | ts.TypeAliasDeclaration
    | ts.EnumDeclaration
    | ts.FunctionDeclaration
): ExportInfo[] {
  const exports: ExportInfo[] = []

  if (
    node.name &&
    node.modifiers?.some((m) => m.kind === ts.SyntaxKind.ExportKeyword)
  ) {
    const originalName = node.name.text
    if (hasValidPrefix(originalName)) {
      const isTypeNode =
        ts.isInterfaceDeclaration(node) || ts.isTypeAliasDeclaration(node)
      exports.push({
        originalName,
        prefixedName: originalName,
        kind: isTypeNode ? 'type' : 'value',
      })
    }
  }

  return exports
}

/**
 * Processes a variable statement node to extract exported variables with valid prefixes
 */
function processVariableStatement(node: ts.VariableStatement): ExportInfo[] {
  const exports: ExportInfo[] = []
  // Check if the variable statement has an export modifier
  if (
    !node.modifiers ||
    !node.modifiers.some((m) => m.kind === ts.SyntaxKind.ExportKeyword)
  ) {
    return exports
  }

  for (const declaration of node.declarationList.declarations) {
    if (ts.isIdentifier(declaration.name)) {
      const originalName = declaration.name.text
      if (hasValidPrefix(originalName)) {
        exports.push({
          originalName,
          prefixedName: originalName,
          kind: 'value',
        })
      }
    }
  }
  return exports
}

/**
 * Processes a TypeScript source file to extract all exports with valid prefixes
 */
function processFile(
  filePath: string,
  rootDir: string,
  exportMap: Map<string, ExportInfo[]>
): void {
  const sourceFile = ts.createSourceFile(
    filePath,
    fs.readFileSync(filePath, 'utf-8'),
    ts.ScriptTarget.Latest,
    true
  )

  const exports: ExportInfo[] = []

  function visit(node: ts.Node) {
    if (ts.isExportDeclaration(node)) {
      exports.push(...processExportDeclaration(node))
    } else if (ts.isExportAssignment(node)) {
      exports.push(...processExportAssignment(node))
    } else if (ts.isVariableStatement(node)) {
      exports.push(...processVariableStatement(node))
    } else if (
      ts.isClassDeclaration(node) ||
      ts.isInterfaceDeclaration(node) ||
      ts.isTypeAliasDeclaration(node) ||
      ts.isEnumDeclaration(node) ||
      ts.isFunctionDeclaration(node)
    ) {
      exports.push(...processDeclaration(node))
    }

    ts.forEachChild(node, visit)
  }

  visit(sourceFile)

  if (exports.length > 0) {
    const relativePath = path.relative(rootDir, filePath).replace(/\.ts$/, '')

    // Deduplicate exports based on originalName and kind
    const uniqueExports = exports.reduce((acc: ExportInfo[], curr) => {
      const exists = acc.some(
        (exp) =>
          exp.originalName === curr.originalName && exp.kind === curr.kind
      )
      if (!exists) {
        acc.push(curr)
      }
      return acc
    }, [])

    exportMap.set(relativePath, uniqueExports)
  }
}

/**
 * Recursively finds all TypeScript files in a directory
 */
function findTsFiles(dir: string): string[] {
  const entries = fs.readdirSync(dir, { withFileTypes: true })
  return entries.flatMap((entry) => {
    const fullPath = path.join(dir, entry.name)
    if (entry.isDirectory()) {
      return findTsFiles(fullPath)
    }
    if (isTargetTsFile(entry.name)) {
      return [fullPath]
    }
    return []
  })
}

/**
 * Checks if a filename matches our target TypeScript files
 */
function isTargetTsFile(filename: string): boolean {
  return (
    filename.endsWith('.ts') &&
    !filename.endsWith('.test.ts') &&
    !filename.endsWith('.d.ts') &&
    filename !== 'index.ts'
  )
}

/**
 * Formats import items for better readability with line breaks
 */
function formatImportItems(imports: string[]): string {
  if (imports.length <= 1) {
    return imports.join(', ')
  }

  return `\n  ${imports.join(',\n  ')}\n`
}

/**
 * Generates an import statement for a file's exports
 */
function generateImportStatement(
  filePath: string,
  exports: ExportInfo[]
): string {
  // Deduplicate value exports by name
  const uniqueValues = [
    ...new Set(
      exports
        .filter((exp) => exp.kind === 'value')
        .map((exp) => exp.originalName)
    ),
  ].sort()

  // Deduplicate type exports by name
  const uniqueTypes = [
    ...new Set(
      exports
        .filter((exp) => exp.kind === 'type')
        .map((exp) => exp.originalName)
    ),
  ]
    .map((name) => `type ${name}`)
    .sort()

  const allImports = [...uniqueValues, ...uniqueTypes]

  if (allImports.length === 0) {
    return ''
  }

  return `import {${formatImportItems(allImports)}} from './${filePath}.js';`
}

/**
 * Generates export statements for the collected exports
 */
function generateExportStatements(exportMap: Map<string, ExportInfo[]>): {
  valueExports: string[]
  typeExports: string[]
} {
  const valueExports: string[] = []
  const typeExports: string[] = []

  for (const [, exports] of exportMap) {
    for (const exp of exports) {
      if (exp.kind === 'type') {
        typeExports.push(`export type { ${exp.originalName} };`)
      } else {
        const exportLine = exp.isDefault
          ? `export { ${exp.originalName} as default };`
          : `export { ${exp.originalName} };`
        valueExports.push(exportLine)
      }
    }
  }

  return {
    valueExports: valueExports.sort(),
    typeExports: typeExports.sort(),
  }
}

/**
 * Generates the content for the index.ts file
 */
function generateIndexContent(exportMap: Map<string, ExportInfo[]>): string {
  let content =
    '/* eslint import/order: 0 sort-imports: 0 */\n// Auto-generated index file - Do not edit\n\n'

  // Generate and sort imports
  const imports = Array.from(exportMap.entries())
    .map(([filePath, exports]) => generateImportStatement(filePath, exports))
    .filter(Boolean)
    .sort()
  content = `${content}${imports.join('\n')}\n\n`

  // Generate exports
  const { valueExports, typeExports } = generateExportStatements(exportMap)

  if (valueExports.length > 0) {
    content = `${content}// Value exports\n${valueExports.join('\n')}\n\n`
  }

  if (typeExports.length > 0) {
    content = `${content}// Type exports\n${typeExports.join('\n')}\n`
  }

  return content
}

/**
 * Main function to generate the index.ts file
 */
function generateIndex(): void {
  const currentDir = process.cwd()
  const exportMap = new Map<string, ExportInfo[]>()

  // Find and process all TypeScript files
  const tsFiles = findTsFiles(currentDir)
  for (const file of tsFiles) {
    processFile(file, currentDir, exportMap)
  }

  if (exportMap.size === 0) {
    console.log('No ax/Ax exports found')
    return
  }

  // Generate and write index.ts
  const indexContent = generateIndexContent(exportMap)
  const indexPath = path.join(currentDir, 'index.ts')
  fs.writeFileSync(indexPath, indexContent)
  console.log(`Generated ${indexPath} successfully!`)
}

// Run the script
try {
  generateIndex()
} catch (error) {
  console.error('Failed to generate index:', error)
  process.exit(1)
}



================================================
FILE: scripts/initPackage.js
================================================
#!/usr/bin/env node

import fs from 'fs/promises'
import path from 'path'
import { fileURLToPath } from 'url'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

// Core dependencies that should be included in new packages
const CORE_DEPENDENCIES = [
  '@ax-llm/ax'
]

// Files to copy from src/ax (excluding generated files and directories)
const FILES_TO_COPY = [
  'tsconfig.json',
  'tsup.config.ts', 
  '.prettierignore',
  '.release-it.json'
]

// Scripts to exclude from ax package.json (package-specific scripts)
const SCRIPTS_TO_EXCLUDE = [
  'build:index',  // This is specific to the main ax package
  'doc:build:markdown'  // This might be specific to main package
]

async function initPackage() {
  const packageName = process.argv[2]
  const packageDescription = process.argv[3] || `${packageName} package for Ax`
  const additionalDeps = process.argv[4] ? process.argv[4].split(',').map(dep => dep.trim()) : []

  if (!packageName) {
    console.error('Usage: node scripts/initPackage.js <package-name> [description] [additional-deps]')
    console.error('Example: node scripts/initPackage.js my-new-package "My new package description"')
    console.error('Example: node scripts/initPackage.js vector-store "Vector store impl" "zod,uuid"')
    process.exit(1)
  }

  // Validate package name
  if (!/^[a-z][a-z0-9-]*$/.test(packageName)) {
    console.error('Package name must be lowercase, start with a letter, and contain only letters, numbers, and hyphens')
    process.exit(1)
  }

  const rootDir = path.resolve(__dirname, '..')
  const srcDir = path.join(rootDir, 'src')
  const packageDir = path.join(srcDir, packageName)
  const axDir = path.join(srcDir, 'ax')

  // Check if package already exists
  try {
    await fs.access(packageDir)
    console.error(`Package '${packageName}' already exists at ${packageDir}`)
    process.exit(1)
  } catch {
    // Package doesn't exist, which is what we want
  }

  // Read root package.json to get current version
  const rootPackageJson = JSON.parse(await fs.readFile(path.join(rootDir, 'package.json'), 'utf8'))
  const currentVersion = rootPackageJson.version

  // Read ax package.json to get base structure
  const axPackageJson = JSON.parse(await fs.readFile(path.join(axDir, 'package.json'), 'utf8'))

  console.log(`Creating new package: ${packageName}`)
  console.log(`Package directory: ${packageDir}`)
  if (additionalDeps.length > 0) {
    console.log(`Additional dependencies: ${additionalDeps.join(', ')}`)
  }

  // Create package directory
  await fs.mkdir(packageDir, { recursive: true })

  // Create package.json based on ax package.json but filtered
  const filteredScripts = { ...axPackageJson.scripts }
  SCRIPTS_TO_EXCLUDE.forEach(script => {
    delete filteredScripts[script]
  })
  
  // Fix the build script to not include build:index
  if (filteredScripts.build && filteredScripts.build.includes('build:index')) {
    filteredScripts.build = 'tsup'
  }

  const packageJson = {
    ...axPackageJson,
    name: `@ax-llm/ax-${packageName}`,
    version: currentVersion,
    description: packageDescription,
    scripts: filteredScripts,
    // Filter dependencies to only include core ones and additional specified deps
    dependencies: [...CORE_DEPENDENCIES, ...additionalDeps].reduce((deps, dep) => {
      if (dep === '@ax-llm/ax') {
        deps[dep] = currentVersion
      } else if (axPackageJson.dependencies && axPackageJson.dependencies[dep]) {
        deps[dep] = axPackageJson.dependencies[dep]
      } else if (rootPackageJson.dependencies && rootPackageJson.dependencies[dep]) {
        deps[dep] = rootPackageJson.dependencies[dep]
      } else if (additionalDeps.includes(dep)) {
        // For additional deps not found in existing packages, use latest
        deps[dep] = '^latest'
        console.warn(`  ⚠ Dependency '${dep}' not found in existing packages, using '^latest'`)
      }
      return deps
    }, {}),
    // Keep devDependencies empty for new packages
    devDependencies: {},
    // Remove ax-specific fields
    ava: undefined,
    tsd: undefined,
    files: ['**/*']
  }

  await fs.writeFile(
    path.join(packageDir, 'package.json'),
    JSON.stringify(packageJson, null, 2) + '\n'
  )

  // Copy configuration files from src/ax
  console.log('Copying configuration files from src/ax...')
  for (const file of FILES_TO_COPY) {
    const sourcePath = path.join(axDir, file)
    const destPath = path.join(packageDir, file)
    
    try {
      await fs.copyFile(sourcePath, destPath)
      console.log(`  ✓ Copied ${file}`)
    } catch (error) {
      console.warn(`  ⚠ Could not copy ${file}: ${error.message}`)
    }
  }

  // Create index.ts
  const indexTs = `// Export your main functionality here
export * from './lib.js'
`

  await fs.writeFile(path.join(packageDir, 'index.ts'), indexTs)

  // Create lib.ts (main implementation file)
  const libTs = `/**
 * ${packageDescription}
 */

export class ${toPascalCase(packageName)} {
  constructor() {
    // Initialize your class here
  }

  /**
   * Example method
   */
  hello(): string {
    return 'Hello from ${packageName}!'
  }
}

/**
 * Example function
 */
export function create${toPascalCase(packageName)}(): ${toPascalCase(packageName)} {
  return new ${toPascalCase(packageName)}()
}
`

  await fs.writeFile(path.join(packageDir, 'lib.ts'), libTs)

  // Create index.test.ts
  const indexTest = `import { describe, expect, it } from 'vitest'

import { ${toPascalCase(packageName)}, create${toPascalCase(packageName)} } from './index.js'

describe('${toPascalCase(packageName)}', () => {
  it('should create instance', () => {
    const instance = new ${toPascalCase(packageName)}()
    expect(instance).toBeInstanceOf(${toPascalCase(packageName)})
  })

  it('should say hello', () => {
    const instance = create${toPascalCase(packageName)}()
    expect(instance.hello()).toBe('Hello from ${packageName}!')
  })
})
`

  await fs.writeFile(path.join(packageDir, 'index.test.ts'), indexTest)

  // Create README.md
  const readme = `# @ax-llm/ax-${packageName}

${packageDescription}

## Installation

\`\`\`shell
npm i @ax-llm/ax-${packageName}
\`\`\`

## Usage

\`\`\`typescript
import { ${toPascalCase(packageName)}, create${toPascalCase(packageName)} } from '@ax-llm/ax-${packageName}'

// Create an instance
const instance = create${toPascalCase(packageName)}()

// Use the instance
console.log(instance.hello())
\`\`\`

## API

### \`${toPascalCase(packageName)}\`

Main class for ${packageName} functionality.

#### Methods

- \`hello(): string\` - Returns a greeting message

### \`create${toPascalCase(packageName)}()\`

Factory function to create a new \`${toPascalCase(packageName)}\` instance.

## License

Apache-2.0
`

  await fs.writeFile(path.join(packageDir, 'README.md'), readme)

  console.log(`✅ Package '${packageName}' created successfully!`)
  console.log('\nNext steps:')
  console.log(`1. Install dependencies: npm install`)
  console.log(`2. Build the package: npm run build --workspace=@ax-llm/ax-${packageName}`)
  console.log(`3. Run tests: npm run test --workspace=@ax-llm/ax-${packageName}`)
  console.log(`4. Start developing in: ${packageDir}`)
}

function toPascalCase(str) {
  return str
    .split('-')
    .map(word => word.charAt(0).toUpperCase() + word.slice(1))
    .join('')
}

initPackage().catch(console.error) 


================================================
FILE: scripts/postbuild.js
================================================
import path from 'path';

import fs from 'fs-extra';

 
const packagePath = process.cwd();
const buildPath = path.join(packagePath, './dist');

const packageJsonData = await fs.readFile(path.resolve(packagePath, './package.json'), 'utf8');
const packageJson = JSON.parse(packageJsonData);

// Modify the package.json object
packageJson.main = './index.cjs';
packageJson.module = './index.js';
packageJson.types = './index.d.ts';
packageJson.exports = {
  ".": {
    "import": "./index.js",
    "require": "./index.cjs"
  },
  "./*": {
    "import": "./*.js",
    "require": "./*.cjs"
  }
};

// Remove devDependencies and scripts
delete packageJson.devDependencies;
delete packageJson.scripts;

// Write the modified package.json to the build folder
await fs.writeJson(path.resolve(buildPath, './package.json'), packageJson, { spaces: 2 });

console.log('package.json has been modified and copied to the build folder.');


================================================
FILE: src/ai-sdk-provider/README.md
================================================
## Vercel AI SDK Integration

Install the ax provider package

```shell
npm i @ax-llm/ax-ai-sdk-provider
```

Then use it with the AI SDK, you can either use the AI provider or the Agent
Provider

```typescript
const ai = new AxAI({
    name: "openai",
    apiKey: process.env["OPENAI_APIKEY"] ?? "",
});

// Create a model using the provider
const model = new AxAIProvider(ai);

export const foodAgent = new AxAgent({
    name: "food-search",
    description:
        "Use this agent to find restaurants based on what the customer wants",
    signature,
    functions,
});

// Get vercel ai sdk state
const aiState = getMutableAIState();

// Create an agent for a specific task
const foodAgent = new AxAgentProvider(ai, {
    agent: foodAgent,
    updateState: (state) => {
        aiState.done({ ...aiState.get(), state });
    },
    generate: async ({ restaurant, priceRange }) => {
        return (
            <BotCard>
                <h1>{restaurant as string} {priceRange as string}</h1>
            </BotCard>
        );
    },
});

// Use with streamUI a critical part of building chat UIs in the AI SDK
const result = await streamUI({
    model,
    initial: <SpinnerMessage />,
    messages: [
        // ...
    ],
    text: ({ content, done, delta }) => {
        // ...
    },
    tools: {
        // @ts-ignore
        "find-food": foodAgent,
    },
});
```



================================================
FILE: src/ai-sdk-provider/index.test.ts
================================================
// import { describe, expect, it } from 'vitest'

// import { AxAgentProvider, AxAIProvider } from './index.js'

// describe('AxAgentProvider', () => {
//   it('should be defined', () => {
//     expect(AxAgentProvider).toBeDefined()
//   })

//   it('should create an instance without errors', () => {
//     const instance = new AxAgentProvider({
//       agent: {
//         name: 'test',
//         description: 'test',
//         functions: [],
//       },
//     })
//     expect(instance).toBeInstanceOf(AxAgentProvider)
//   })

//   // Add more tests for specific functionalities or methods if they exist.
// })

// describe('AxAIProvider', () => {
//   it('should be defined', () => {
//     expect(AxAIProvider).toBeDefined()
//   })

//   it('should create an instance without errors', () => {
//     const instance = new AxAIProvider({
//       ai: {
//         name: 'test',
//         description: 'test',
//         functions: [],
//       },
//     })
//     expect(instance).toBeInstanceOf(AxAIProvider)
//   })

//   // Add more tests for additional functionalities or methods as needed.
// })



================================================
FILE: src/ai-sdk-provider/index.ts
================================================
import { AxAgentProvider } from './provider.js'
import { AxAIProvider } from './provider.js'

export { AxAgentProvider, AxAIProvider }



================================================
FILE: src/ai-sdk-provider/package.json
================================================
{
  "name": "@ax-llm/ax-ai-sdk-provider",
  "version": "12.0.8",
  "type": "module",
  "description": "Ax AI SDK Provider for the Vercel AI SDK",
  "repository": {
    "type": "git",
    "url": "https://github.com/ax-llm/ax.git"
  },
  "publishConfig": {
    "access": "public"
  },
  "license": "Apache-2.0",
  "keywords": [],
  "scripts": {
    "dev": "tsup --watch",
    "build": "tsup",
    "clean": "rm -rf dist",
    "test": "run-s test:*",
    "test:type-check": "tsc --noEmit",
    "test:lint": "eslint",
    "test:format": "prettier --check \"**/*.{ts,json,md}\"",
    "fix": "run-s fix:*",
    "fix:lint": "eslint --fix",
    "fix:format": "prettier --write \"**/*.{ts,json,md}\"",
    "coverage": "c8 ava",
    "prepare": "husky install",
    "tsx": "node --env-file=.env --import=tsx",
    "release": "release-it",
    "publish": "npm run build && cd dist && npm publish",
    "postbuild": "node ../../scripts/postbuild.js"
  },
  "dependencies": {
    "@ai-sdk/provider-utils": "^2.1.13",
    "@ax-llm/ax": "12.0.8",
    "ai": "^4.1.61",
    "zod": "^3.23.8"
  },
  "bugs": {
    "url": "https://github.com/@ax-llm/ax/issues"
  },
  "homepage": "https://github.com/@ax-llm/ax#readme",
  "author": "Vikram <https://twitter.com/dosco>",
  "devDependencies": {
    "@types/react": "^19.0.5"
  }
}



================================================
FILE: src/ai-sdk-provider/provider.ts
================================================
// cspell:ignore Streamable

import {
  type ReadableStream,
  TransformStream,
  TransformStreamDefaultController,
} from 'stream/web'

import {
  type LanguageModelV1,
  type LanguageModelV1CallWarning,
  type LanguageModelV1FinishReason,
  type LanguageModelV1FunctionTool,
  type LanguageModelV1FunctionToolCall,
  type LanguageModelV1Prompt,
  type LanguageModelV1StreamPart,
} from '@ai-sdk/provider'
import type {
  AxAgentic,
  AxAIService,
  AxChatRequest,
  AxChatResponse,
  AxChatResponseResult,
  AxFunction,
  AxFunctionJSONSchema,
  AxGenIn,
  AxGenOut,
} from '@ax-llm/ax/index.js'
import type { CoreMessage } from 'ai'
import { customAlphabet } from 'nanoid'
import type { ReactNode } from 'react'
import { z } from 'zod'

type Writeable<T> = { -readonly [P in keyof T]: T[P] }
type AxChatRequestChatPrompt = Writeable<AxChatRequest['chatPrompt'][0]>

type AxConfig = {
  fetch?: typeof fetch
}

type Streamable = ReactNode | Promise<ReactNode>
type Renderer<T> = (
  args: T
) =>
  | Streamable
  | Generator<Streamable, Streamable, void>
  | AsyncGenerator<Streamable, Streamable, void>

const nanoid = customAlphabet(
  '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz',
  7
)

export class AxAgentProvider<IN extends AxGenIn, OUT extends AxGenOut> {
  private readonly config?: AxConfig
  private readonly funcInfo: AxFunction
  private generateFunction: Renderer<OUT>
  private updateState: (msgs: readonly CoreMessage[]) => void

  constructor({
    agent,
    updateState,
    generate,
    config,
  }: Readonly<{
    agent: AxAgentic<IN, OUT>
    updateState: (msgs: readonly CoreMessage[]) => void
    generate: Renderer<OUT>
    config?: Readonly<AxConfig>
  }>) {
    this.funcInfo = agent.getFunction()
    this.generateFunction = generate
    this.updateState = updateState
    this.config = config
  }

  get description() {
    return this.funcInfo.description
  }

  get parameters(): z.ZodTypeAny {
    const schema = this.funcInfo.parameters ?? {
      type: 'object',
      properties: {},
    }

    return convertToZodSchema(schema)
  }

  get generate(): Renderer<IN> {
    const fn = async (input: IN) => {
      const res = (await this.funcInfo.func(input)) as OUT
      const toolCallId = nanoid()

      this.updateState([
        {
          role: 'assistant',
          content: [
            {
              type: 'tool-call',
              toolName: this.funcInfo.name,
              toolCallId,
              args: input,
            },
          ],
        },
        {
          role: 'tool',
          content: [
            {
              type: 'tool-result',
              toolName: this.funcInfo.name,
              toolCallId,
              result: res,
            },
          ],
        },
      ])

      return this.generateFunction(res)
    }
    return fn as Renderer<IN>
  }
}

export class AxAIProvider implements LanguageModelV1 {
  readonly specificationVersion = 'v1'
  readonly defaultObjectGenerationMode = 'json'

  private readonly ai: AxAIService
  private readonly config?: AxConfig

  public modelId: string

  constructor(ai: AxAIService, config?: Readonly<AxConfig>) {
    this.ai = ai
    this.config = config
    this.modelId = this.ai.getName()
  }

  get provider(): string {
    return this.ai.getName()
  }

  async doGenerate(
    options: Readonly<Parameters<LanguageModelV1['doGenerate']>[0]>
  ): Promise<Awaited<ReturnType<LanguageModelV1['doGenerate']>>> {
    const { req, warnings } = createChatRequest(options)
    const res = (await this.ai.chat(req)) as AxChatResponse
    const choice = res.results.at(0)

    if (!choice) {
      throw new Error('No choice returned')
    }

    return {
      text: choice.content ?? undefined,
      toolCalls: choice.functionCalls?.map((tc) => ({
        toolCallType: 'function',
        toolCallId: tc.id,
        toolName: tc.function.name,
        args:
          typeof tc.function.params === 'string'
            ? tc.function.params
            : JSON.stringify(tc.function.params),
      })),
      finishReason: mapAxFinishReason(choice.finishReason),
      usage: {
        promptTokens: res.modelUsage?.tokens?.promptTokens ?? 0,
        completionTokens: res.modelUsage?.tokens?.completionTokens ?? 0,
      },
      rawCall: { rawPrompt: '', rawSettings: req.modelConfig ?? {} },
      warnings,
    }
  }

  async doStream(
    options: Readonly<Parameters<LanguageModelV1['doStream']>[0]>
  ): Promise<Awaited<ReturnType<LanguageModelV1['doStream']>>> {
    const { req, warnings } = createChatRequest(options)

    const res = (await this.ai.chat(req, {
      stream: true,
    })) as ReadableStream<AxChatResponse>

    return {
      stream: res.pipeThrough(new AxToSDKTransformer()),
      rawCall: { rawPrompt: '', rawSettings: req.modelConfig ?? {} },
      warnings,
    }
  }
}

function prepareToolsAndToolChoice(
  mode: Readonly<
    Parameters<LanguageModelV1['doGenerate']>[0]['mode'] & { type: 'regular' }
  >
): Pick<AxChatRequest, 'functions' | 'functionCall'> {
  // when the tools array is empty, change it to undefined to prevent errors:
  if (!mode.tools || mode.tools.length === 0) {
    return {}
  }

  const tools = mode.tools as Array<LanguageModelV1FunctionTool>
  const functions = tools.map((f) => ({
    name: f.name,
    description: 'description' in f ? (f.description ?? '') : '',
    parameters: f.parameters as AxFunctionJSONSchema,
  }))

  const toolChoice = mode.toolChoice
  if (!toolChoice) {
    return { functions }
  }

  const type = toolChoice.type

  switch (type) {
    case 'auto':
      return { functions, functionCall: 'auto' }
    case 'none':
      return { functions, functionCall: 'none' }
    case 'required':
      return { functions, functionCall: 'required' }
    case 'tool':
      return {
        functions,
        functionCall: {
          type: 'function',
          function: { name: toolChoice.toolName },
        },
      }
    default: {
      const _exhaustiveCheck: never = type
      throw new Error(`Unsupported tool choice type: ${_exhaustiveCheck}`)
    }
  }
}

function convertToAxChatPrompt(
  prompt: Readonly<LanguageModelV1Prompt>
): AxChatRequest['chatPrompt'] {
  const messages: AxChatRequest['chatPrompt'] = []

  for (const { role, content } of prompt) {
    switch (role) {
      case 'system': {
        messages.push({ role: 'system', content })
        break
      }

      case 'user': {
        messages.push({
          role: 'user',
          content: content.map((part) => {
            switch (part.type) {
              case 'text': {
                return { type: 'text', text: part.text }
              }
              case 'image': {
                if (!part.mimeType) {
                  throw new Error('Image part must have a mimeType')
                }
                if (!ArrayBuffer.isView(part.image)) {
                  throw new Error('Image part must have an ArrayBuffer')
                }
                const image = Buffer.from(part.image).toString('base64')
                return {
                  type: 'image',
                  mimeType: part.mimeType,
                  image,
                }
              }
              default:
                throw new Error(`Unsupported part: ${part}`)
              //   case 'audio': {
              //     if (!part.data) {
              //       throw new Error('Audio part must have a audio');
              //     }
              //     if (!ArrayBuffer.isView(part.data)) {
              //       throw new Error('Audio part must have an ArrayBuffer');
              //     }
              //     const data = Buffer.from(part.data).toString('base64');
              //     return {
              //       type: 'audio',
              //       format: 'wav',
              //       data
              //     };
              //   }
            }
          }),
        })
        break
      }

      case 'assistant': {
        let text = ''
        const toolCalls: Extract<
          AxChatRequestChatPrompt,
          { role: 'assistant' }
        >['functionCalls'] = []

        for (const part of content) {
          switch (part.type) {
            case 'text': {
              text += part.text
              break
            }
            case 'tool-call': {
              toolCalls.push({
                id: part.toolCallId,
                type: 'function',
                function: {
                  name: part.toolName,
                  params: part.args as Record<string, unknown>,
                },
              })
              break
            }

            default: {
              const _exhaustiveCheck = part
              throw new Error(`Unsupported part: ${_exhaustiveCheck}`)
            }
          }
        }

        const functionCalls = toolCalls.length === 0 ? undefined : toolCalls

        if (functionCalls || text.length > 0) {
          messages.push({
            role: 'assistant',
            content: text,
            functionCalls,
          })
        }

        break
      }
      case 'tool': {
        for (const part of content) {
          messages.push({
            role: 'function' as const,
            functionId: part.toolCallId,
            result: JSON.stringify(part.result, null, 2),
          })
        }
        break
      }
      default: {
        const _exhaustiveCheck: never = role
        throw new Error(`Unsupported role: ${_exhaustiveCheck}`)
      }
    }
  }

  return messages
}

function mapAxFinishReason(
  finishReason: AxChatResponseResult['finishReason']
): LanguageModelV1FinishReason {
  switch (finishReason) {
    case 'stop':
      return 'stop'
    case 'length':
      return 'length'
    case 'function_call':
      return 'tool-calls'
    default:
      return 'other'
  }
}

function createChatRequest({
  mode,
  prompt,
  maxTokens,
  temperature,
  topP,
  frequencyPenalty,
  presencePenalty,
  //seed,
}: Readonly<Parameters<LanguageModelV1['doGenerate']>[0]>): {
  req: AxChatRequest
  warnings: LanguageModelV1CallWarning[]
} {
  const req: AxChatRequest = {
    chatPrompt: convertToAxChatPrompt(prompt),
    ...(frequencyPenalty != null ? { frequencyPenalty } : {}),
    ...(presencePenalty != null ? { presencePenalty } : {}),
    ...(maxTokens != null ? { maxTokens } : {}),
    ...(temperature != null ? { temperature } : {}),
    ...(topP != null ? { topP } : {}),
  }

  const warnings: LanguageModelV1CallWarning[] = []

  switch (mode.type) {
    case 'regular': {
      return {
        req: { ...req, ...prepareToolsAndToolChoice(mode) },
        warnings,
      }
    }

    case 'object-json': {
      return {
        req,
        warnings,
      }
    }

    case 'object-tool': {
      const tool = {
        type: 'function',
        function: {
          name: mode.tool.name,
          params: mode.tool.parameters,
        },
      }
      return {
        req: { ...req, ...tool },
        warnings,
      }
    }

    default: {
      throw new Error('Unsupported type')
    }
  }
}

class AxToSDKTransformer extends TransformStream<
  AxChatResponse,
  LanguageModelV1StreamPart
> {
  private usage: Extract<
    LanguageModelV1StreamPart,
    { type: 'finish' }
  >['usage'] = {
    promptTokens: 0,
    completionTokens: 0,
  }

  private finishReason: Extract<
    LanguageModelV1StreamPart,
    { type: 'finish' }
  >['finishReason'] = 'other'

  private functionCalls: LanguageModelV1FunctionToolCall[] = []

  constructor() {
    const transformer = {
      transform: (
        chunk: Readonly<AxChatResponse>,
        controller: TransformStreamDefaultController<LanguageModelV1StreamPart>
      ) => {
        const choice = chunk.results.at(0)
        if (!choice) {
          const val = {
            type: 'finish' as const,
            finishReason: this.finishReason,
            usage: this.usage,
          }
          controller.enqueue(val)
          return
        }

        if (chunk.modelUsage) {
          this.usage = {
            promptTokens:
              this.usage.promptTokens +
              (chunk.modelUsage?.tokens?.promptTokens ?? 0),
            completionTokens:
              this.usage.completionTokens +
              (chunk.modelUsage.tokens?.completionTokens ?? 0),
          }
        }

        if (choice.functionCalls) {
          for (const fc of choice.functionCalls) {
            const index = this.functionCalls.findIndex(
              (f) => f.toolCallId === fc.id
            )
            if (index === -1) {
              this.functionCalls.push({
                toolCallType: 'function' as const,
                toolCallId: fc.id,
                toolName: fc.function.name,
                args:
                  typeof fc.function.params === 'string'
                    ? fc.function.params
                    : JSON.stringify(fc.function.params),
              })
            } else {
              const obj = this.functionCalls[index]
              if (!obj) {
                continue
              }
              if (typeof fc.function.params === 'string') {
                obj.args = (obj.args ?? '') + fc.function.params
              } else {
                obj.args = JSON.stringify(fc.function.params)
              }
            }
            this.finishReason = 'tool-calls'
          }
        }

        if (choice.content && choice.content.length > 0) {
          controller.enqueue({
            type: 'text-delta',
            textDelta: choice.content ?? '',
          })
          this.finishReason = mapAxFinishReason(choice.finishReason)
        }
      },
      flush: (
        controller: TransformStreamDefaultController<LanguageModelV1StreamPart>
      ) => {
        for (const fc of this.functionCalls) {
          const tc = {
            type: 'tool-call' as const,
            ...fc,
          }
          controller.enqueue(tc)
        }

        const val = {
          type: 'finish' as const,
          finishReason: this.finishReason,
          usage: this.usage,
        }
        controller.enqueue(val)
        controller.terminate()
      },
    }

    super(transformer)
  }
}

type AnyZod =
  | z.AnyZodObject
  | z.ZodString
  | z.ZodNumber
  | z.ZodBoolean
  | z.ZodArray<AnyZod>
  | z.ZodOptional<AnyZod>

function convertToZodSchema(
  jsonSchema: Readonly<AxFunctionJSONSchema>
): AnyZod {
  const { type, properties, required, items } = jsonSchema

  switch (type) {
    case 'string':
      return z.string()
    case 'number':
      return z.number()
    case 'boolean':
      return z.boolean()
    case 'array':
      if (!items) {
        throw new Error("Array type must have 'items' property.")
      }
      return z.array(convertToZodSchema(items))
    case 'object': {
      if (!properties) {
        throw new Error("Object type must have 'properties' property.")
      }
      const shape: Record<string, AnyZod> = {}

      for (const [key, value] of Object.entries(properties)) {
        const schema = convertToZodSchema(value)
        let val = required?.includes(key) ? schema : schema.optional()
        val = value.description ? val.describe(value.description) : val
        shape[key] = val
      }
      return z.object(shape)
    }
    default:
      throw new Error(`Unsupported type: ${type}`)
  }
}



================================================
FILE: src/ai-sdk-provider/tsconfig.json
================================================
{
  "extends": ["../../tsconfig.json"]
}



================================================
FILE: src/ai-sdk-provider/tsup.config.ts
================================================
import { defineConfig } from 'tsup'

export default defineConfig({
  entry: ['index.ts'],
  format: ['esm', 'cjs'],
  dts: true,
  splitting: false,
  clean: true,
  sourcemap: true,
  minify: false,
})



================================================
FILE: src/ai-sdk-provider/util.ts
================================================
import type { AxFunctionJSONSchema } from '@ax-llm/ax/index.js'
import { z } from 'zod'

type AnyZod =
  | z.AnyZodObject
  | z.ZodString
  | z.ZodNumber
  | z.ZodBoolean
  | z.ZodArray<AnyZod>
  | z.ZodOptional<AnyZod>

export function convertToZodSchema(
  jsonSchema: Readonly<AxFunctionJSONSchema>
): AnyZod {
  const { type, properties, required, items } = jsonSchema

  switch (type) {
    case 'string':
      return z.string()
    case 'number':
      return z.number()
    case 'boolean':
      return z.boolean()
    case 'array':
      if (!items) {
        throw new Error("Array type must have 'items' property.")
      }
      return z.array(convertToZodSchema(items))
    case 'object': {
      if (!properties) {
        throw new Error("Object type must have 'properties' property.")
      }
      const shape: Record<string, AnyZod> = {}

      for (const [key, value] of Object.entries(properties)) {
        const schema = convertToZodSchema(value)

        let val = required?.includes(key) ? schema : schema.optional()
        val = value.description ? val.describe(value.description) : val

        shape[key] = val
      }
      return z.object(shape)
    }
    default:
      throw new Error(`Unsupported type: ${type}`)
  }
}



================================================
FILE: src/ai-sdk-provider/.prettierignore
================================================
# Package files are formatted by package managers
package.json
package-lock.json
yarn.lock
pnpm-lock.yaml

# Build outputs and distributions
dist
build

# Generated indexes
index.ts

# Dependencies
node_modules
.pnpm-store

# Documentation
docs

# Cache directories
.cache
.temp


================================================
FILE: src/ai-sdk-provider/.release-it.json
================================================
{
  "npm": {
    "publish": false
  },
  "git": false,
  "plugins": {
    "@release-it/bumper": {
      "out": [
        {
          "file": "../../package.json",
          "path": ["version"]
        }
      ]
    }
  }
}



================================================
FILE: src/ax/index.test-d.ts
================================================
// // index.test-d.ts
// import type { ReadableStream } from 'stream/web'

// import { expectError, expectType } from 'tsd'

// import type {
//   AxAIService,
//   AxAIServiceMetrics,
//   AxAIServiceOptions,
//   AxChatRequest,
//   AxChatResponse,
//   AxEmbedResponse,
//   AxFunction,
//   AxModelConfig,
//   AxModelInfo,
//   AxModelInfoWithProvider,
//   AxTokenUsage,
// } from './index.js'

// // Test AxModelInfo structure
// expectType<AxModelInfo>({
//   name: 'gpt-4',
//   currency: 'USD',
//   promptTokenCostPer1M: 30,
//   completionTokenCostPer1M: 60,
//   aliases: ['gpt4'],
// })

// // Test AxTokenUsage structure
// expectType<AxTokenUsage>({
//   promptTokens: 100,
//   completionTokens: 50,
//   totalTokens: 150,
// })

// // Test AxModelConfig
// expectType<AxModelConfig>({
//   maxTokens: 1000,
//   temperature: 0.7,
//   topP: 0.9,
//   stopSequences: ['\n', 'Stop'],
//   stream: true,
// })

// // Test AxFunction
// expectType<AxFunction>({
//   name: 'getData',
//   description: 'Fetches data',
//   parameters: {
//     type: 'object',
//     properties: {
//       id: {
//         type: 'string',
//         description: 'The data ID',
//       },
//     },
//     required: ['id'],
//   },
//   func: async (args) => ({ data: 'test' }),
// })

// // Test chat request structure
// expectType<AxChatRequest>({
//   chatPrompt: [
//     { role: 'system', content: 'You are a helpful assistant' },
//     { role: 'user', content: 'Hello' },
//     {
//       role: 'assistant',
//       content: 'Hi there!',
//       functionCalls: [
//         {
//           id: '123',
//           type: 'function',
//           function: { name: 'getData', params: { id: '123' } },
//         },
//       ],
//     },
//   ],
//   model: 'gpt-4',
//   modelConfig: { temperature: 0.7 },
// })

// // Test chat response
// expectType<AxChatResponse>({
//   sessionId: '123',
//   remoteId: '456',
//   results: [
//     {
//       content: 'Hello',
//       id: '789',
//       finishReason: 'stop',
//     },
//   ],
//   modelUsage: {
//     promptTokens: 10,
//     completionTokens: 5,
//     totalTokens: 15,
//   },
// })

// // Test embed response
// expectType<AxEmbedResponse>({
//   sessionId: '123',
//   embeddings: [[0.1, 0.2, 0.3]],
//   modelUsage: {
//     promptTokens: 10,
//     completionTokens: 0,
//     totalTokens: 10,
//   },
// })

// // Test service options
// expectType<AxAIServiceOptions>({
//   debug: true,
//   fetch: fetch,
//   rateLimiter: async (req, info) => req(),
// })

// // Test complex chat prompt with different content types
// expectType<AxChatRequest['chatPrompt'][number]>({
//   role: 'user',
//   content: [
//     {
//       type: 'text',
//       text: 'Analyze this image',
//       cache: true,
//     },
//     {
//       type: 'image',
//       mimeType: 'image/jpeg',
//       image: 'base64string',
//       details: 'high',
//     },
//     {
//       type: 'audio',
//       data: 'base64string',
//       format: 'wav',
//     },
//   ],
// })

// // Test error cases
// expectError<AxModelInfo>({
//   name: 123, // Should be string
// })

// expectError<AxChatRequest>({
//   chatPrompt: [
//     { role: 'invalid', content: 'test' }, // Invalid role
//   ],
// })

// expectError<AxModelConfig>({
//   temperature: 'hot', // Should be number
// })

// expectError<AxChatResponse['results'][number]>({
//   finishReason: 'invalid', // Invalid finish reason
// })

// // Test AxAIService implementation
// const mockService: AxAIService = {
//   getName: () => 'test-service',

//   getModelConfig: () => ({
//     maxTokens: 1000,
//     temperature: 0.7,
//   }),

//   getFeatures: (model) => ({
//     functions: true,
//     streaming: true,
//   }),

//   getModelList: () => ({
//     'gpt-4': 'openai/gpt-4',
//   }),

//   getMetrics: () => ({
//     latency: {
//       chat: { mean: 1000, p95: 2000, p99: 3000, samples: [800, 1200] },
//       embed: { mean: 200, p95: 400, p99: 600, samples: [150, 250] },
//     },
//     errors: {
//       chat: { count: 10, rate: 0.01, total: 1000 },
//       embed: { count: 5, rate: 0.005, total: 1000 },
//     },
//   }),

//   chat: async (req, options) => ({
//     results: [{ content: 'Hello' }],
//     sessionId: '123',
//   }),

//   embed: async (req, options) => ({
//     embeddings: [[0.1, 0.2, 0.3]],
//     sessionId: '123',
//   }),

//   setOptions: (options) => {},
// }

// // Test return types of service methods
// expectType<string>(mockService.getName())
// expectType<Readonly<AxModelInfoWithProvider>>(mockService.getModelInfo())

// expectType<{ functions: boolean; streaming: boolean }>(
//   mockService.getFeatures()
// )
// expectType<AxAIServiceMetrics>(mockService.getMetrics())

// // Test async method return types
// const chatResponse = await mockService.chat({
//   chatPrompt: [{ role: 'user', content: 'Hello' }],
// })
// expectType<AxChatResponse | ReadableStream<AxChatResponse>>(chatResponse)

// const embedResponse = await mockService.embed({
//   texts: ['Hello world'],
// })
// expectType<AxEmbedResponse>(embedResponse)

// // Test error cases
// expectError<AxAIService>({
//   ...mockService,
//   getName: () => 123, // Should return string
// })

// expectError<AxAIService>({
//   ...mockService,
//   getFeatures: () => ({
//     // Missing required properties
//     functions: true,
//   }),
// })



================================================
FILE: src/ax/index.ts
================================================
/* eslint import/order: 0 sort-imports: 0 */
// Auto-generated index file - Do not edit

import {
  AxAI,
  type AxAIArgs,
  type AxAIEmbedModels,
  type AxAIModels
} from './ai/wrap.js';
import {
  AxAIAnthropic,
  axAIAnthropicDefaultConfig,
  axAIAnthropicVertexDefaultConfig,
  type AxAIAnthropicArgs
} from './ai/anthropic/api.js';
import {
  AxAIAnthropicModel,
  AxAIAnthropicVertexModel,
  type AxAIAnthropicChatError,
  type AxAIAnthropicChatRequest,
  type AxAIAnthropicChatRequestCacheParam,
  type AxAIAnthropicChatResponse,
  type AxAIAnthropicChatResponseDelta,
  type AxAIAnthropicConfig,
  type AxAIAnthropicContentBlockDeltaEvent,
  type AxAIAnthropicContentBlockStartEvent,
  type AxAIAnthropicContentBlockStopEvent,
  type AxAIAnthropicErrorEvent,
  type AxAIAnthropicMessageDeltaEvent,
  type AxAIAnthropicMessageStartEvent,
  type AxAIAnthropicMessageStopEvent,
  type AxAIAnthropicPingEvent
} from './ai/anthropic/types.js';
import {
  AxAIAzureOpenAI,
  axAIAzureOpenAIBestConfig,
  axAIAzureOpenAICreativeConfig,
  axAIAzureOpenAIDefaultConfig,
  axAIAzureOpenAIFastConfig,
  type AxAIAzureOpenAIArgs,
  type AxAIAzureOpenAIConfig
} from './ai/azure-openai/api.js';
import {
  AxAICohere,
  axAICohereCreativeConfig,
  axAICohereDefaultConfig,
  type AxAICohereArgs
} from './ai/cohere/api.js';
import {
  AxAICohereEmbedModel,
  AxAICohereModel,
  type AxAICohereChatRequest,
  type AxAICohereChatRequestToolResults,
  type AxAICohereChatResponse,
  type AxAICohereChatResponseDelta,
  type AxAICohereChatResponseToolCalls,
  type AxAICohereConfig,
  type AxAICohereEmbedRequest,
  type AxAICohereEmbedResponse
} from './ai/cohere/types.js';
import {
  AxAIDeepSeek,
  axAIDeepSeekCodeConfig,
  axAIDeepSeekDefaultConfig,
  type AxAIDeepSeekArgs
} from './ai/deepseek/api.js';
import {
  AxAIGoogleGemini,
  axAIGoogleGeminiDefaultConfig,
  axAIGoogleGeminiDefaultCreativeConfig,
  type AxAIGoogleGeminiArgs,
  type AxAIGoogleGeminiOptionsTools
} from './ai/google-gemini/api.js';
import {
  AxAIGoogleGeminiEmbedModel,
  AxAIGoogleGeminiEmbedTypes,
  AxAIGoogleGeminiModel,
  AxAIGoogleGeminiSafetyCategory,
  AxAIGoogleGeminiSafetyThreshold,
  type AxAIGoogleGeminiBatchEmbedRequest,
  type AxAIGoogleGeminiBatchEmbedResponse,
  type AxAIGoogleGeminiChatRequest,
  type AxAIGoogleGeminiChatResponse,
  type AxAIGoogleGeminiChatResponseDelta,
  type AxAIGoogleGeminiConfig,
  type AxAIGoogleGeminiContent,
  type AxAIGoogleGeminiContentPart,
  type AxAIGoogleGeminiGenerationConfig,
  type AxAIGoogleGeminiSafetySettings,
  type AxAIGoogleGeminiThinkingConfig,
  type AxAIGoogleGeminiThinkingTokenBudgetLevels,
  type AxAIGoogleGeminiTool,
  type AxAIGoogleGeminiToolConfig,
  type AxAIGoogleGeminiToolFunctionDeclaration,
  type AxAIGoogleGeminiToolGoogleSearchRetrieval,
  type AxAIGoogleVertexBatchEmbedRequest,
  type AxAIGoogleVertexBatchEmbedResponse
} from './ai/google-gemini/types.js';
import {
  AxAIGrok,
  axAIGrokBestConfig,
  axAIGrokDefaultConfig,
  type AxAIGrokArgs,
  type AxAIGrokChatRequest,
  type AxAIGrokOptionsTools,
  type AxAIGrokSearchSource
} from './ai/x-grok/api.js';
import {
  AxAIGrokEmbedModels,
  AxAIGrokModel
} from './ai/x-grok/types.js';
import {
  AxAIGroq,
  type AxAIGroqArgs
} from './ai/groq/api.js';
import {
  AxAIHuggingFace,
  axAIHuggingFaceCreativeConfig,
  axAIHuggingFaceDefaultConfig,
  type AxAIHuggingFaceArgs
} from './ai/huggingface/api.js';
import {
  AxAIHuggingFaceModel,
  type AxAIHuggingFaceConfig,
  type AxAIHuggingFaceRequest,
  type AxAIHuggingFaceResponse
} from './ai/huggingface/types.js';
import {
  AxAIMistral,
  axAIMistralBestConfig,
  axAIMistralDefaultConfig,
  type AxAIMistralArgs,
  type AxAIMistralChatRequest
} from './ai/mistral/api.js';
import {
  AxAIMistralEmbedModels,
  AxAIMistralModel
} from './ai/mistral/types.js';
import {
  AxAIOllama,
  axAIOllamaDefaultConfig,
  axAIOllamaDefaultCreativeConfig,
  type AxAIOllamaAIConfig,
  type AxAIOllamaArgs
} from './ai/ollama/api.js';
import {
  AxAIOpenAI,
  AxAIOpenAIBase,
  axAIOpenAIBestConfig,
  axAIOpenAICreativeConfig,
  axAIOpenAIDefaultConfig,
  axAIOpenAIFastConfig,
  type AxAIOpenAIArgs,
  type AxAIOpenAIBaseArgs
} from './ai/openai/api.js';
import {
  AxAIOpenAIEmbedModel,
  AxAIOpenAIModel,
  type AxAIOpenAIChatRequest,
  type AxAIOpenAIChatResponse,
  type AxAIOpenAIChatResponseDelta,
  type AxAIOpenAIConfig,
  type AxAIOpenAIEmbedRequest,
  type AxAIOpenAIEmbedResponse,
  type AxAIOpenAILogprob,
  type AxAIOpenAIResponseDelta,
  type AxAIOpenAIUsage
} from './ai/openai/chat_types.js';
import {
  AxAIOpenAIResponses,
  AxAIOpenAIResponsesBase,
  axAIOpenAIResponsesBestConfig,
  axAIOpenAIResponsesCreativeConfig,
  axAIOpenAIResponsesDefaultConfig,
  type AxAIOpenAIResponsesArgs
} from './ai/openai/responses_api_base.js';
import {
  AxAIOpenAIResponsesModel,
  type AxAIOpenAIResponsesCodeInterpreterToolCall,
  type AxAIOpenAIResponsesComputerToolCall,
  type AxAIOpenAIResponsesConfig,
  type AxAIOpenAIResponsesContentPartAddedEvent,
  type AxAIOpenAIResponsesContentPartDoneEvent,
  type AxAIOpenAIResponsesDefineFunctionTool,
  type AxAIOpenAIResponsesErrorEvent,
  type AxAIOpenAIResponsesFileSearchCallCompletedEvent,
  type AxAIOpenAIResponsesFileSearchCallInProgressEvent,
  type AxAIOpenAIResponsesFileSearchCallSearchingEvent,
  type AxAIOpenAIResponsesFileSearchToolCall,
  type AxAIOpenAIResponsesFunctionCallArgumentsDeltaEvent,
  type AxAIOpenAIResponsesFunctionCallArgumentsDoneEvent,
  type AxAIOpenAIResponsesFunctionCallItem,
  type AxAIOpenAIResponsesImageGenerationCallCompletedEvent,
  type AxAIOpenAIResponsesImageGenerationCallGeneratingEvent,
  type AxAIOpenAIResponsesImageGenerationCallInProgressEvent,
  type AxAIOpenAIResponsesImageGenerationCallPartialImageEvent,
  type AxAIOpenAIResponsesImageGenerationToolCall,
  type AxAIOpenAIResponsesInputAudioContentPart,
  type AxAIOpenAIResponsesInputContentPart,
  type AxAIOpenAIResponsesInputFunctionCallItem,
  type AxAIOpenAIResponsesInputFunctionCallOutputItem,
  type AxAIOpenAIResponsesInputImageUrlContentPart,
  type AxAIOpenAIResponsesInputItem,
  type AxAIOpenAIResponsesInputMessageItem,
  type AxAIOpenAIResponsesInputTextContentPart,
  type AxAIOpenAIResponsesLocalShellToolCall,
  type AxAIOpenAIResponsesMCPCallArgumentsDeltaEvent,
  type AxAIOpenAIResponsesMCPCallArgumentsDoneEvent,
  type AxAIOpenAIResponsesMCPCallCompletedEvent,
  type AxAIOpenAIResponsesMCPCallFailedEvent,
  type AxAIOpenAIResponsesMCPCallInProgressEvent,
  type AxAIOpenAIResponsesMCPListToolsCompletedEvent,
  type AxAIOpenAIResponsesMCPListToolsFailedEvent,
  type AxAIOpenAIResponsesMCPListToolsInProgressEvent,
  type AxAIOpenAIResponsesMCPToolCall,
  type AxAIOpenAIResponsesOutputItem,
  type AxAIOpenAIResponsesOutputItemAddedEvent,
  type AxAIOpenAIResponsesOutputItemDoneEvent,
  type AxAIOpenAIResponsesOutputMessageItem,
  type AxAIOpenAIResponsesOutputRefusalContentPart,
  type AxAIOpenAIResponsesOutputTextAnnotationAddedEvent,
  type AxAIOpenAIResponsesOutputTextContentPart,
  type AxAIOpenAIResponsesOutputTextDeltaEvent,
  type AxAIOpenAIResponsesOutputTextDoneEvent,
  type AxAIOpenAIResponsesReasoningDeltaEvent,
  type AxAIOpenAIResponsesReasoningDoneEvent,
  type AxAIOpenAIResponsesReasoningItem,
  type AxAIOpenAIResponsesReasoningSummaryDeltaEvent,
  type AxAIOpenAIResponsesReasoningSummaryDoneEvent,
  type AxAIOpenAIResponsesReasoningSummaryPart,
  type AxAIOpenAIResponsesReasoningSummaryPartAddedEvent,
  type AxAIOpenAIResponsesReasoningSummaryPartDoneEvent,
  type AxAIOpenAIResponsesReasoningSummaryTextDeltaEvent,
  type AxAIOpenAIResponsesReasoningSummaryTextDoneEvent,
  type AxAIOpenAIResponsesRefusalDeltaEvent,
  type AxAIOpenAIResponsesRefusalDoneEvent,
  type AxAIOpenAIResponsesRequest,
  type AxAIOpenAIResponsesResponse,
  type AxAIOpenAIResponsesResponseCompletedEvent,
  type AxAIOpenAIResponsesResponseCreatedEvent,
  type AxAIOpenAIResponsesResponseDelta,
  type AxAIOpenAIResponsesResponseFailedEvent,
  type AxAIOpenAIResponsesResponseInProgressEvent,
  type AxAIOpenAIResponsesResponseIncompleteEvent,
  type AxAIOpenAIResponsesResponseQueuedEvent,
  type AxAIOpenAIResponsesStreamEvent,
  type AxAIOpenAIResponsesStreamEventBase,
  type AxAIOpenAIResponsesToolCall,
  type AxAIOpenAIResponsesToolCallBase,
  type AxAIOpenAIResponsesToolChoice,
  type AxAIOpenAIResponsesToolDefinition,
  type AxAIOpenAIResponsesWebSearchCallCompletedEvent,
  type AxAIOpenAIResponsesWebSearchCallInProgressEvent,
  type AxAIOpenAIResponsesWebSearchCallSearchingEvent,
  type AxAIOpenAIResponsesWebSearchToolCall
} from './ai/openai/responses_types.js';
import {
  AxAIReka,
  axAIRekaBestConfig,
  axAIRekaCreativeConfig,
  axAIRekaDefaultConfig,
  axAIRekaFastConfig,
  type AxAIRekaArgs
} from './ai/reka/api.js';
import {
  AxAIRekaModel,
  type AxAIRekaChatRequest,
  type AxAIRekaChatResponse,
  type AxAIRekaChatResponseDelta,
  type AxAIRekaConfig,
  type AxAIRekaUsage
} from './ai/reka/types.js';
import {
  AxAIServiceAbortedError,
  AxAIServiceAuthenticationError,
  AxAIServiceError,
  AxAIServiceNetworkError,
  AxAIServiceResponseError,
  AxAIServiceStatusError,
  AxAIServiceStreamTerminatedError,
  AxAIServiceTimeoutError,
  type AxAPI,
  type AxAPIConfig
} from './util/apicall.js';
import {
  AxAITogether,
  axAITogetherDefaultConfig,
  type AxAITogetherArgs
} from './ai/together/api.js';
import {
  AxAgent,
  type AxAgentFeatures,
  type AxAgentOptions,
  type AxAgentic
} from './prompts/agent.js';
import {
  AxApacheTika,
  type AxApacheTikaArgs,
  type AxApacheTikaConvertOptions
} from './docs/tika.js';
import {
  AxAssertionError,
  type AxAssertion,
  type AxStreamingAssertion
} from './dsp/asserts.js';
import {
  AxBalancer,
  type AxBalancerOptions
} from './ai/balance.js';
import {
  AxBaseAI,
  axBaseAIDefaultConfig,
  axBaseAIDefaultCreativeConfig,
  type AxAIFeatures,
  type AxBaseAIArgs
} from './ai/base.js';
import {
  AxBaseOptimizer,
  AxDefaultCostTracker,
  type AxCheckpointLoadFn,
  type AxCheckpointSaveFn,
  type AxOptimizationCheckpoint,
  type AxBootstrapCompileOptions,
  type AxBootstrapOptimizerOptions,
  type AxCompileOptions,
  type AxCostTracker,
  type AxCostTrackerOptions,
  type AxExample,
  type AxMetricFn,
  type AxMetricFnArgs,
  type AxMiPROCompileOptions,
  type AxMiPROOptimizerOptions,
  type AxMultiMetricFn,
  type AxOptimizationProgress,
  type AxOptimizationStats,
  type AxOptimizer,
  type AxOptimizerArgs,
  type AxOptimizerResult,
  type AxParetoResult
} from './dsp/optimizer.js';
import {
  AxDB,
  type AxDBArgs
} from './db/wrap.js';
import {
  AxDBBase,
  type AxDBBaseArgs,
  type AxDBBaseOpOptions
} from './db/base.js';
import {
  AxDBCloudflare,
  type AxDBCloudflareArgs,
  type AxDBCloudflareOpOptions
} from './db/cloudflare.js';
import {
  AxDBManager,
  type AxDBLoaderOptions,
  type AxDBManagerArgs,
  type AxDBMatch,
  type AxRerankerIn,
  type AxRerankerOut,
  type AxRewriteIn,
  type AxRewriteOut
} from './docs/manager.js';
import {
  AxDBMemory,
  type AxDBMemoryArgs,
  type AxDBMemoryOpOptions,
  type AxDBState
} from './db/memory.js';
import {
  AxDBPinecone,
  type AxDBPineconeArgs,
  type AxDBPineconeOpOptions
} from './db/pinecone.js';
import {
  AxDBWeaviate,
  type AxDBWeaviateArgs,
  type AxDBWeaviateOpOptions
} from './db/weaviate.js';
import {
  AxDefaultQueryRewriter,
  AxRewriter
} from './docs/rewriter.js';
import {
  AxDockerSession,
  type AxDockerContainer
} from './funcs/docker.js';
import {
  AxFunctionError,
  AxFunctionProcessor,
  type AxChatResponseFunctionCall,
  type AxInputFunctionType
} from './dsp/functions.js';
import {
  AxGen,
  AxGenerateError,
  type AxGenerateErrorDetails,
  type AxGenerateResult,
  type AxResponseHandlerArgs,
  type AxStreamingEvent
} from './dsp/generate.js';
import {
  AxHFDataLoader,
  type AxDataRow
} from './dsp/loader.js';
import {
  AxJSInterpreter,
  AxJSInterpreterPermission
} from './funcs/code.js';
import {
  AxLLMRequestTypeValues,
  AxSpanKindValues,
  axSpanAttributes,
  axSpanEvents
} from './trace/trace.js';
import {
  AxMCPHTTPSSETransport,
  AxMCPStreambleHTTPTransport,
  type AxMCPStreamableHTTPTransportOptions
} from './mcp/httpTransport.js';
import {
  AxMiPRO,
  type AxMiPROResult
} from './dsp/optimizers/miproV2.js';
import {
  AxMockAIService,
  type AxMockAIServiceConfig
} from './ai/mock/api.js';
import {
  AxProgram,
  AxProgramWithSignature,
  type AxGenDeltaOut,
  type AxGenStreamingOut,
  type AxProgramDemos,
  type AxProgramExamples,
  type AxProgramForwardOptions,
  type AxProgramStreamingForwardOptions,
  type AxProgramTrace,
  type AxProgramUsage,
  type AxProgramWithSignatureOptions,
  type AxSetExamplesOptions,
  type AxTunable,
  type AxUsable
} from './dsp/program.js';
import {
  AxPromptTemplate,
  type AxFieldTemplateFn,
  type AxPromptTemplateOptions
} from './dsp/prompt.js';
import {
  AxRateLimiterTokenUsage,
  type AxRateLimiterTokenUsageOptions
} from './util/rate-limit.js';
import {
  AxSignature,
  type AxField,
  type AxIField,
  type AxSignatureConfig
} from './dsp/sig.js';
import {
  AxSimpleClassifier,
  AxSimpleClassifierClass,
  type AxSimpleClassifierForwardOptions
} from './dsp/classifier.js';
import {
  AxTestPrompt,
  type AxEvaluateArgs
} from './dsp/evaluate.js';
import {
  ax,
  f,
  s,
  type AxFieldDescriptor,
  type AxFieldType,
  type AxSignatureTemplateValue
} from './dsp/template.js';
import {
  type AxAIInputModelList,
  type AxAIModelList,
  type AxAIModelListBase,
  type AxAIPromptConfig,
  type AxAIService,
  type AxAIServiceActionOptions,
  type AxAIServiceImpl,
  type AxAIServiceMetrics,
  type AxAIServiceOptions,
  type AxChatRequest,
  type AxChatResponse,
  type AxChatResponseResult,
  type AxEmbedRequest,
  type AxEmbedResponse,
  type AxFunction,
  type AxFunctionHandler,
  type AxFunctionJSONSchema,
  type AxInternalChatRequest,
  type AxInternalEmbedRequest,
  type AxLoggerFunction,
  type AxLoggerTag,
  type AxModelConfig,
  type AxModelInfo,
  type AxModelInfoWithProvider,
  type AxModelUsage,
  type AxRateLimiterFunction,
  type AxTokenUsage
} from './ai/types.js';
import {
  type AxDBQueryRequest,
  type AxDBQueryResponse,
  type AxDBQueryService,
  type AxDBService,
  type AxDBUpsertRequest,
  type AxDBUpsertResponse
} from './db/types.js';
import {
  type AxFieldProcessor,
  type AxFieldProcessorProcess,
  type AxStreamingFieldProcessorProcess
} from './dsp/fieldProcessor.js';
import {
  type AxFieldValue,
  type AxGenIn,
  type AxGenOut,
  type AxMessage
} from './dsp/types.js';
import {AxAIDeepSeekModel} from './ai/deepseek/types.js';
import {AxAIGroqModel} from './ai/groq/types.js';
import {AxAIOpenAIResponsesImpl} from './ai/openai/responses_api.js';
import {AxBootstrapFewShot} from './dsp/optimizers/bootstrapFewshot.js';
import {AxChainOfThought} from './prompts/cot.js';
import {AxDefaultResultReranker} from './docs/reranker.js';
import {AxEmbeddingAdapter} from './funcs/embed.js';
import {AxEvalUtil} from './dsp/eval.js';
import {AxInstanceRegistry} from './dsp/registry.js';
import {AxMCPClient} from './mcp/client.js';
import {AxMCPStdioTransport} from './mcp/stdioTransport.js';
import {AxMemory} from './mem/memory.js';
import {AxMultiServiceRouter} from './ai/multiservice.js';
import {AxRAG} from './prompts/rag.js';
import {AxStringUtil} from './dsp/strutil.js';
import {axGlobals} from './dsp/globals.js';
import {axModelInfoAnthropic} from './ai/anthropic/info.js';
import {axModelInfoCohere} from './ai/cohere/info.js';
import {axModelInfoDeepSeek} from './ai/deepseek/info.js';
import {axModelInfoGoogleGemini} from './ai/google-gemini/info.js';
import {axModelInfoGrok} from './ai/x-grok/info.js';
import {axModelInfoGroq} from './ai/groq/info.js';
import {axModelInfoHuggingFace} from './ai/huggingface/info.js';
import {axModelInfoMistral} from './ai/mistral/info.js';
import {axModelInfoOpenAI} from './ai/openai/info.js';
import {axModelInfoReka} from './ai/reka/info.js';
import {axModelInfoTogether} from './ai/together/info.js';
import {type AxAIMemory} from './mem/types.js';
import {type AxMCPTransport} from './mcp/transport.js';

// Value exports
export { AxAI };
export { AxAIAnthropic };
export { AxAIAnthropicModel };
export { AxAIAnthropicVertexModel };
export { AxAIAzureOpenAI };
export { AxAICohere };
export { AxAICohereEmbedModel };
export { AxAICohereModel };
export { AxAIDeepSeek };
export { AxAIDeepSeekModel };
export { AxAIGoogleGemini };
export { AxAIGoogleGeminiEmbedModel };
export { AxAIGoogleGeminiEmbedTypes };
export { AxAIGoogleGeminiModel };
export { AxAIGoogleGeminiSafetyCategory };
export { AxAIGoogleGeminiSafetyThreshold };
export { AxAIGrok };
export { AxAIGrokEmbedModels };
export { AxAIGrokModel };
export { AxAIGroq };
export { AxAIGroqModel };
export { AxAIHuggingFace };
export { AxAIHuggingFaceModel };
export { AxAIMistral };
export { AxAIMistralEmbedModels };
export { AxAIMistralModel };
export { AxAIOllama };
export { AxAIOpenAI };
export { AxAIOpenAIBase };
export { AxAIOpenAIEmbedModel };
export { AxAIOpenAIModel };
export { AxAIOpenAIResponses };
export { AxAIOpenAIResponsesBase };
export { AxAIOpenAIResponsesImpl };
export { AxAIOpenAIResponsesModel };
export { AxAIReka };
export { AxAIRekaModel };
export { AxAIServiceAbortedError };
export { AxAIServiceAuthenticationError };
export { AxAIServiceError };
export { AxAIServiceNetworkError };
export { AxAIServiceResponseError };
export { AxAIServiceStatusError };
export { AxAIServiceStreamTerminatedError };
export { AxAIServiceTimeoutError };
export { AxAITogether };
export { AxAgent };
export { AxApacheTika };
export { AxAssertionError };
export { AxBalancer };
export { AxBaseAI };
export { AxBaseOptimizer };
export { AxBootstrapFewShot };
export { AxChainOfThought };
export { AxDB };
export { AxDBBase };
export { AxDBCloudflare };
export { AxDBManager };
export { AxDBMemory };
export { AxDBPinecone };
export { AxDBWeaviate };
export { AxDefaultCostTracker };
export { AxDefaultQueryRewriter };

export { AxDefaultResultReranker };
export { AxDockerSession };
export { AxEmbeddingAdapter };
export { AxEvalUtil };
export { AxFunctionError };
export { AxFunctionProcessor };
export { AxGen };
export { AxGenerateError };
export { AxHFDataLoader };
export { AxInstanceRegistry };
export { AxJSInterpreter };
export { AxJSInterpreterPermission };
export { AxLLMRequestTypeValues };
export { AxMCPClient };
export { AxMCPHTTPSSETransport };
export { AxMCPStdioTransport };
export { AxMCPStreambleHTTPTransport };
export { AxMemory };
export { AxMiPRO };
export { AxMockAIService };
export { AxMultiServiceRouter };
export { AxProgram };
export { AxProgramWithSignature };
export { AxPromptTemplate };
export { AxRAG };
export { AxRateLimiterTokenUsage };
export { AxRewriter };
export { AxSignature };
export { AxSimpleClassifier };
export { AxSimpleClassifierClass };
export { AxSpanKindValues };
export { AxStringUtil };
export { AxTestPrompt };
export { ax };
export { axAIAnthropicDefaultConfig };
export { axAIAnthropicVertexDefaultConfig };
export { axAIAzureOpenAIBestConfig };
export { axAIAzureOpenAICreativeConfig };
export { axAIAzureOpenAIDefaultConfig };
export { axAIAzureOpenAIFastConfig };
export { axAICohereCreativeConfig };
export { axAICohereDefaultConfig };
export { axAIDeepSeekCodeConfig };
export { axAIDeepSeekDefaultConfig };
export { axAIGoogleGeminiDefaultConfig };
export { axAIGoogleGeminiDefaultCreativeConfig };
export { axAIGrokBestConfig };
export { axAIGrokDefaultConfig };
export { axAIHuggingFaceCreativeConfig };
export { axAIHuggingFaceDefaultConfig };
export { axAIMistralBestConfig };
export { axAIMistralDefaultConfig };
export { axAIOllamaDefaultConfig };
export { axAIOllamaDefaultCreativeConfig };
export { axAIOpenAIBestConfig };
export { axAIOpenAICreativeConfig };
export { axAIOpenAIDefaultConfig };
export { axAIOpenAIFastConfig };
export { axAIOpenAIResponsesBestConfig };
export { axAIOpenAIResponsesCreativeConfig };
export { axAIOpenAIResponsesDefaultConfig };
export { axAIRekaBestConfig };
export { axAIRekaCreativeConfig };
export { axAIRekaDefaultConfig };
export { axAIRekaFastConfig };
export { axAITogetherDefaultConfig };
export { axBaseAIDefaultConfig };
export { axBaseAIDefaultCreativeConfig };
export { axGlobals };
export { axModelInfoAnthropic };
export { axModelInfoCohere };
export { axModelInfoDeepSeek };
export { axModelInfoGoogleGemini };
export { axModelInfoGrok };
export { axModelInfoGroq };
export { axModelInfoHuggingFace };
export { axModelInfoMistral };
export { axModelInfoOpenAI };
export { axModelInfoReka };
export { axModelInfoTogether };
export { axSpanAttributes };
export { axSpanEvents };
export { f };
export { s };

// Type exports
export type { AxAIAnthropicArgs };
export type { AxAIAnthropicChatError };
export type { AxAIAnthropicChatRequest };
export type { AxAIAnthropicChatRequestCacheParam };
export type { AxAIAnthropicChatResponse };
export type { AxAIAnthropicChatResponseDelta };
export type { AxAIAnthropicConfig };
export type { AxAIAnthropicContentBlockDeltaEvent };
export type { AxAIAnthropicContentBlockStartEvent };
export type { AxAIAnthropicContentBlockStopEvent };
export type { AxAIAnthropicErrorEvent };
export type { AxAIAnthropicMessageDeltaEvent };
export type { AxAIAnthropicMessageStartEvent };
export type { AxAIAnthropicMessageStopEvent };
export type { AxAIAnthropicPingEvent };
export type { AxAIArgs };
export type { AxAIAzureOpenAIArgs };
export type { AxAIAzureOpenAIConfig };
export type { AxAICohereArgs };
export type { AxAICohereChatRequest };
export type { AxAICohereChatRequestToolResults };
export type { AxAICohereChatResponse };
export type { AxAICohereChatResponseDelta };
export type { AxAICohereChatResponseToolCalls };
export type { AxAICohereConfig };
export type { AxAICohereEmbedRequest };
export type { AxAICohereEmbedResponse };
export type { AxAIDeepSeekArgs };
export type { AxAIEmbedModels };
export type { AxAIFeatures };
export type { AxAIGoogleGeminiArgs };
export type { AxAIGoogleGeminiBatchEmbedRequest };
export type { AxAIGoogleGeminiBatchEmbedResponse };
export type { AxAIGoogleGeminiChatRequest };
export type { AxAIGoogleGeminiChatResponse };
export type { AxAIGoogleGeminiChatResponseDelta };
export type { AxAIGoogleGeminiConfig };
export type { AxAIGoogleGeminiContent };
export type { AxAIGoogleGeminiContentPart };
export type { AxAIGoogleGeminiGenerationConfig };
export type { AxAIGoogleGeminiOptionsTools };
export type { AxAIGoogleGeminiSafetySettings };
export type { AxAIGoogleGeminiThinkingConfig };
export type { AxAIGoogleGeminiThinkingTokenBudgetLevels };
export type { AxAIGoogleGeminiTool };
export type { AxAIGoogleGeminiToolConfig };
export type { AxAIGoogleGeminiToolFunctionDeclaration };
export type { AxAIGoogleGeminiToolGoogleSearchRetrieval };
export type { AxAIGoogleVertexBatchEmbedRequest };
export type { AxAIGoogleVertexBatchEmbedResponse };
export type { AxAIGrokArgs };
export type { AxAIGrokChatRequest };
export type { AxAIGrokOptionsTools };
export type { AxAIGrokSearchSource };
export type { AxAIGroqArgs };
export type { AxAIHuggingFaceArgs };
export type { AxAIHuggingFaceConfig };
export type { AxAIHuggingFaceRequest };
export type { AxAIHuggingFaceResponse };
export type { AxAIInputModelList };
export type { AxAIMemory };
export type { AxAIMistralArgs };
export type { AxAIMistralChatRequest };
export type { AxAIModelList };
export type { AxAIModelListBase };
export type { AxAIModels };
export type { AxAIOllamaAIConfig };
export type { AxAIOllamaArgs };
export type { AxAIOpenAIArgs };
export type { AxAIOpenAIBaseArgs };
export type { AxAIOpenAIChatRequest };
export type { AxAIOpenAIChatResponse };
export type { AxAIOpenAIChatResponseDelta };
export type { AxAIOpenAIConfig };
export type { AxAIOpenAIEmbedRequest };
export type { AxAIOpenAIEmbedResponse };
export type { AxAIOpenAILogprob };
export type { AxAIOpenAIResponseDelta };
export type { AxAIOpenAIResponsesArgs };
export type { AxAIOpenAIResponsesCodeInterpreterToolCall };
export type { AxAIOpenAIResponsesComputerToolCall };
export type { AxAIOpenAIResponsesConfig };
export type { AxAIOpenAIResponsesContentPartAddedEvent };
export type { AxAIOpenAIResponsesContentPartDoneEvent };
export type { AxAIOpenAIResponsesDefineFunctionTool };
export type { AxAIOpenAIResponsesErrorEvent };
export type { AxAIOpenAIResponsesFileSearchCallCompletedEvent };
export type { AxAIOpenAIResponsesFileSearchCallInProgressEvent };
export type { AxAIOpenAIResponsesFileSearchCallSearchingEvent };
export type { AxAIOpenAIResponsesFileSearchToolCall };
export type { AxAIOpenAIResponsesFunctionCallArgumentsDeltaEvent };
export type { AxAIOpenAIResponsesFunctionCallArgumentsDoneEvent };
export type { AxAIOpenAIResponsesFunctionCallItem };
export type { AxAIOpenAIResponsesImageGenerationCallCompletedEvent };
export type { AxAIOpenAIResponsesImageGenerationCallGeneratingEvent };
export type { AxAIOpenAIResponsesImageGenerationCallInProgressEvent };
export type { AxAIOpenAIResponsesImageGenerationCallPartialImageEvent };
export type { AxAIOpenAIResponsesImageGenerationToolCall };
export type { AxAIOpenAIResponsesInputAudioContentPart };
export type { AxAIOpenAIResponsesInputContentPart };
export type { AxAIOpenAIResponsesInputFunctionCallItem };
export type { AxAIOpenAIResponsesInputFunctionCallOutputItem };
export type { AxAIOpenAIResponsesInputImageUrlContentPart };
export type { AxAIOpenAIResponsesInputItem };
export type { AxAIOpenAIResponsesInputMessageItem };
export type { AxAIOpenAIResponsesInputTextContentPart };
export type { AxAIOpenAIResponsesLocalShellToolCall };
export type { AxAIOpenAIResponsesMCPCallArgumentsDeltaEvent };
export type { AxAIOpenAIResponsesMCPCallArgumentsDoneEvent };
export type { AxAIOpenAIResponsesMCPCallCompletedEvent };
export type { AxAIOpenAIResponsesMCPCallFailedEvent };
export type { AxAIOpenAIResponsesMCPCallInProgressEvent };
export type { AxAIOpenAIResponsesMCPListToolsCompletedEvent };
export type { AxAIOpenAIResponsesMCPListToolsFailedEvent };
export type { AxAIOpenAIResponsesMCPListToolsInProgressEvent };
export type { AxAIOpenAIResponsesMCPToolCall };
export type { AxAIOpenAIResponsesOutputItem };
export type { AxAIOpenAIResponsesOutputItemAddedEvent };
export type { AxAIOpenAIResponsesOutputItemDoneEvent };
export type { AxAIOpenAIResponsesOutputMessageItem };
export type { AxAIOpenAIResponsesOutputRefusalContentPart };
export type { AxAIOpenAIResponsesOutputTextAnnotationAddedEvent };
export type { AxAIOpenAIResponsesOutputTextContentPart };
export type { AxAIOpenAIResponsesOutputTextDeltaEvent };
export type { AxAIOpenAIResponsesOutputTextDoneEvent };
export type { AxAIOpenAIResponsesReasoningDeltaEvent };
export type { AxAIOpenAIResponsesReasoningDoneEvent };
export type { AxAIOpenAIResponsesReasoningItem };
export type { AxAIOpenAIResponsesReasoningSummaryDeltaEvent };
export type { AxAIOpenAIResponsesReasoningSummaryDoneEvent };
export type { AxAIOpenAIResponsesReasoningSummaryPart };
export type { AxAIOpenAIResponsesReasoningSummaryPartAddedEvent };
export type { AxAIOpenAIResponsesReasoningSummaryPartDoneEvent };
export type { AxAIOpenAIResponsesReasoningSummaryTextDeltaEvent };
export type { AxAIOpenAIResponsesReasoningSummaryTextDoneEvent };
export type { AxAIOpenAIResponsesRefusalDeltaEvent };
export type { AxAIOpenAIResponsesRefusalDoneEvent };
export type { AxAIOpenAIResponsesRequest };
export type { AxAIOpenAIResponsesResponse };
export type { AxAIOpenAIResponsesResponseCompletedEvent };
export type { AxAIOpenAIResponsesResponseCreatedEvent };
export type { AxAIOpenAIResponsesResponseDelta };
export type { AxAIOpenAIResponsesResponseFailedEvent };
export type { AxAIOpenAIResponsesResponseInProgressEvent };
export type { AxAIOpenAIResponsesResponseIncompleteEvent };
export type { AxAIOpenAIResponsesResponseQueuedEvent };
export type { AxAIOpenAIResponsesStreamEvent };
export type { AxAIOpenAIResponsesStreamEventBase };
export type { AxAIOpenAIResponsesToolCall };
export type { AxAIOpenAIResponsesToolCallBase };
export type { AxAIOpenAIResponsesToolChoice };
export type { AxAIOpenAIResponsesToolDefinition };
export type { AxAIOpenAIResponsesWebSearchCallCompletedEvent };
export type { AxAIOpenAIResponsesWebSearchCallInProgressEvent };
export type { AxAIOpenAIResponsesWebSearchCallSearchingEvent };
export type { AxAIOpenAIResponsesWebSearchToolCall };
export type { AxAIOpenAIUsage };
export type { AxAIPromptConfig };
export type { AxAIRekaArgs };
export type { AxAIRekaChatRequest };
export type { AxAIRekaChatResponse };
export type { AxAIRekaChatResponseDelta };
export type { AxAIRekaConfig };
export type { AxAIRekaUsage };
export type { AxAIService };
export type { AxAIServiceActionOptions };
export type { AxAIServiceImpl };
export type { AxAIServiceMetrics };
export type { AxAIServiceOptions };
export type { AxAITogetherArgs };
export type { AxAPI };
export type { AxAPIConfig };
export type { AxAgentFeatures };
export type { AxAgentOptions };
export type { AxAgentic };
export type { AxApacheTikaArgs };
export type { AxApacheTikaConvertOptions };
export type { AxAssertion };
export type { AxBalancerOptions };
export type { AxBaseAIArgs };
export type { AxBootstrapCompileOptions };
export type { AxBootstrapOptimizerOptions };
export type { AxChatRequest };
export type { AxChatResponse };
export type { AxChatResponseFunctionCall };
export type { AxChatResponseResult };
export type { AxCheckpointLoadFn };
export type { AxCheckpointSaveFn };
export type { AxCompileOptions };
export type { AxCostTracker };
export type { AxCostTrackerOptions };
export type { AxDBArgs };
export type { AxDBBaseArgs };
export type { AxDBBaseOpOptions };
export type { AxDBCloudflareArgs };
export type { AxDBCloudflareOpOptions };
export type { AxDBLoaderOptions };
export type { AxDBManagerArgs };
export type { AxDBMatch };
export type { AxDBMemoryArgs };
export type { AxDBMemoryOpOptions };
export type { AxDBPineconeArgs };
export type { AxDBPineconeOpOptions };
export type { AxDBQueryRequest };
export type { AxDBQueryResponse };
export type { AxDBQueryService };
export type { AxDBService };
export type { AxDBState };
export type { AxDBUpsertRequest };
export type { AxDBUpsertResponse };
export type { AxDBWeaviateArgs };
export type { AxDBWeaviateOpOptions };
export type { AxDataRow };
export type { AxDockerContainer };
export type { AxEmbedRequest };
export type { AxEmbedResponse };
export type { AxEvaluateArgs };
export type { AxExample };
export type { AxField };
export type { AxFieldDescriptor };
export type { AxFieldProcessor };
export type { AxFieldProcessorProcess };
export type { AxFieldTemplateFn };
export type { AxFieldType };
export type { AxFieldValue };
export type { AxFunction };
export type { AxFunctionHandler };
export type { AxFunctionJSONSchema };
export type { AxGenDeltaOut };
export type { AxGenIn };
export type { AxGenOut };
export type { AxGenStreamingOut };
export type { AxGenerateErrorDetails };
export type { AxGenerateResult };
export type { AxIField };
export type { AxInputFunctionType };
export type { AxInternalChatRequest };
export type { AxInternalEmbedRequest };
export type { AxLoggerFunction };
export type { AxLoggerTag };
export type { AxMCPStreamableHTTPTransportOptions };
export type { AxMCPTransport };
export type { AxMessage };
export type { AxMetricFn };
export type { AxMetricFnArgs };
export type { AxMiPROCompileOptions };
export type { AxMiPROOptimizerOptions };
export type { AxMiPROResult };
export type { AxMockAIServiceConfig };
export type { AxModelConfig };
export type { AxModelInfo };
export type { AxModelInfoWithProvider };
export type { AxModelUsage };
export type { AxMultiMetricFn };
export type { AxOptimizationCheckpoint };
export type { AxOptimizationProgress };
export type { AxOptimizationStats };
export type { AxOptimizer };
export type { AxOptimizerArgs };
export type { AxOptimizerResult };
export type { AxParetoResult };
export type { AxProgramDemos };
export type { AxProgramExamples };
export type { AxProgramForwardOptions };
export type { AxProgramStreamingForwardOptions };
export type { AxProgramTrace };
export type { AxProgramUsage };
export type { AxProgramWithSignatureOptions };
export type { AxPromptTemplateOptions };
export type { AxRateLimiterFunction };
export type { AxRateLimiterTokenUsageOptions };
export type { AxRerankerIn };
export type { AxRerankerOut };
export type { AxResponseHandlerArgs };
export type { AxRewriteIn };
export type { AxRewriteOut };
export type { AxSetExamplesOptions };
export type { AxSignatureConfig };
export type { AxSignatureTemplateValue };
export type { AxSimpleClassifierForwardOptions };
export type { AxStreamingAssertion };
export type { AxStreamingEvent };
export type { AxStreamingFieldProcessorProcess };
export type { AxTokenUsage };
export type { AxTunable };
export type { AxUsable };



================================================
FILE: src/ax/package.json
================================================
{
  "name": "@ax-llm/ax",
  "version": "12.0.8",
  "type": "module",
  "description": "The best library to work with LLMs",
  "repository": {
    "type": "git",
    "url": "https://github.com/ax-llm/ax.git"
  },
  "publishConfig": {
    "access": "public"
  },
  "license": "Apache-2.0",
  "keywords": [],
  "scripts": {
    "dev": "tsup --watch",
    "build": "npm run build:index && tsup",
    "build:index": "node --import=tsx ../../scripts/generateIndex.ts",
    "clean": "rm -rf dist",
    "test": "run-s test:*",
    "test:type-check": "tsc --noEmit",
    "test:unit": "vitest run",
    "test:lint": "eslint .",
    "test:format": "prettier --check \"**/*.{ts,json,md}\"",
    "fix": "run-s fix:*",
    "fix:lint": "eslint --fix",
    "fix:format": "prettier --write \"**/*.{ts,json,md}\"",
    "doc:build:markdown": "typedoc --readme none",
    "coverage": "c8 ava",
    "prepare": "husky install",
    "tsx": "node --env-file=.env --import=tsx",
    "release": "release-it",
    "publish": "npm run build && cd dist && npm publish",
    "postbuild": "node ../../scripts/postbuild.js"
  },
  "dependencies": {
    "@opentelemetry/api": "^1.9.0",
    "google-auth-library": "^9.15.1",
    "moment-timezone": "^0.5.47"
  },
  "ava": {
    "failFast": true,
    "timeout": "180s",
    "concurrency": 1,
    "extensions": {
      "ts": "module"
    },
    "nodeArguments": [
      "--import=tsimp"
    ],
    "files": [
      "!dist/**/*"
    ]
  },
  "tsd": {
    "directory": "./"
  },
  "files": [
    "**/*"
  ],
  "bugs": {
    "url": "https://github.com/@ax-llm/ax/issues"
  },
  "homepage": "https://github.com/@ax-llm/ax#readme",
  "author": "Vikram <https://twitter.com/dosco>",
  "devDependencies": {
    "@types/uuid": "^10.0.0"
  }
}



================================================
FILE: src/ax/tsconfig.json
================================================
{
  "extends": ["../../tsconfig.json"]
}



================================================
FILE: src/ax/tsup.config.ts
================================================
import { defineConfig } from 'tsup'

export default defineConfig({
  entry: ['index.ts'],
  format: ['esm', 'cjs'],
  dts: true,
  splitting: false,
  clean: true,
  sourcemap: true,
  minify: false,
})



================================================
FILE: src/ax/typedoc.json
================================================
{
  "extends": ["../../typedoc.json"],
  "entryPoints": ["./index.ts"],
  "out": "../docs/src/content/docs/03-apidocs"
}



================================================
FILE: src/ax/.prettierignore
================================================
# Package files are formatted by package managers
package.json
package-lock.json
yarn.lock
pnpm-lock.yaml

# Build outputs and distributions
dist
build

# Generated indexes
index.ts

# Dependencies
node_modules
.pnpm-store

# Documentation
docs

# Cache directories
.cache
.temp


================================================
FILE: src/ax/.release-it.json
================================================
{
  "npm": {
    "publish": false
  },
  "git": false,
  "plugins": {
    "@release-it/bumper": {
      "out": [
        {
          "file": "../../package.json",
          "path": ["version"]
        },
        {
          "file": "../examples/package.json",
          "path": ["dependencies.@ax-llm/ax"]
        },
        {
          "file": "../ai-sdk-provider/package.json",
          "path": ["dependencies.@ax-llm/ax"]
        }
      ]
    }
  }
}



================================================
FILE: src/ax/ai/balance.test.ts
================================================
import { describe, expect, test } from 'vitest'

import { AxAIServiceNetworkError } from '../util/apicall.js'

import { AxBalancer } from './balance.js'
import { AxMockAIService, type AxMockAIServiceConfig } from './mock/api.js'
import type { AxAIService } from './types.js'

const createMockService = ({
  name = 'test-service',
  latencyMs = 100,
  chatResponse = async () => ({
    results: [
      {
        content: 'test response',
        finishReason: 'stop' as const,
      },
    ],
    modelUsage: {
      ai: 'test-ai',
      model: 'test-model',
      tokens: {
        promptTokens: 20,
        completionTokens: 10,
        totalTokens: 30,
      },
    },
  }),
}: {
  name?: string
  latencyMs?: number
  chatResponse?: AxMockAIServiceConfig['chatResponse']
} = {}) => {
  return new AxMockAIService({
    name,
    modelInfo: {
      name: 'test-model',
      provider: 'test-provider',
      promptTokenCostPer1M: 200,
      completionTokenCostPer1M: 150,
    },
    features: {
      functions: true,
      streaming: true,
    },
    chatResponse,
    latencyMs,
  })
}

describe('AxBalancer', () => {
  test('first service works', async () => {
    let calledService: number | undefined
    const services: AxAIService[] = [
      createMockService({
        name: 'service-0',
        chatResponse: async () => {
          calledService = 0
          return {
            results: [
              {
                content: 'test response',
                finishReason: 'stop' as const,
              },
            ],
            modelUsage: {
              ai: 'test-ai',
              model: 'test-model',
              tokens: {
                promptTokens: 20,
                completionTokens: 10,
                totalTokens: 30,
              },
            },
          }
        },
      }),
      createMockService({
        name: 'service-1',
        latencyMs: 200, // Changed: Made service-1 slower
        chatResponse: async () => {
          calledService = 1
          return {
            results: [
              {
                content: 'test response',
                finishReason: 'stop' as const,
              },
            ],
            modelUsage: {
              ai: 'test-ai',
              model: 'test-model',
              tokens: {
                promptTokens: 20,
                completionTokens: 10,
                totalTokens: 30,
              },
            },
          }
        },
      }),
    ]

    const balancer = new AxBalancer(services)
    await balancer.chat({
      chatPrompt: [{ role: 'user', content: 'test' }],
      model: 'mock',
    })

    expect(calledService).toBe(0) // Changed: Now expecting service-0 to be called
  })

  test('first service fails', async () => {
    let calledService: number | undefined
    const services: AxAIService[] = [
      createMockService({
        name: 'service-0',
        latencyMs: 200,
        chatResponse: async () => {
          calledService = 0
          return {
            results: [
              {
                content: 'test response',
                finishReason: 'stop' as const,
              },
            ],
            modelUsage: {
              ai: 'test-ai',
              model: 'test-model',
              tokens: {
                promptTokens: 20,
                completionTokens: 10,
                totalTokens: 30,
              },
            },
          }
        },
      }),
      createMockService({
        name: 'service-1',
        chatResponse: async () => {
          throw new AxAIServiceNetworkError(
            new Error('test'),
            'test-url',
            {},
            {}
          )
        },
      }),
    ]

    const balancer = new AxBalancer(services, { debug: false })
    await balancer.chat({
      chatPrompt: [{ role: 'user', content: 'test' }],
      model: 'mock',
    })

    expect(calledService).toBe(0)
  })

  test('first service works comparator', async () => {
    let calledService: number | undefined
    const services: AxAIService[] = [
      createMockService({
        name: 'service-0',
        latencyMs: 200,
        chatResponse: async () => {
          calledService = 0
          return {
            results: [
              {
                content: 'test response',
                finishReason: 'stop' as const,
              },
            ],
            modelUsage: {
              ai: 'test-ai',
              model: 'test-model',
              tokens: {
                promptTokens: 20,
                completionTokens: 10,
                totalTokens: 30,
              },
            },
          }
        },
      }),
      createMockService({
        name: 'service-1',
        chatResponse: async () => {
          calledService = 1
          return {
            results: [
              {
                content: 'test response',
                finishReason: 'stop' as const,
              },
            ],
            modelUsage: {
              ai: 'test-ai',
              model: 'test-model',
              tokens: {
                promptTokens: 20,
                completionTokens: 10,
                totalTokens: 30,
              },
            },
          }
        },
      }),
    ]

    const balancer = new AxBalancer(services, {
      comparator: AxBalancer.inputOrderComparator,
      debug: false,
    })

    await balancer.chat({
      chatPrompt: [{ role: 'user', content: 'test' }],
      model: 'mock',
    })

    expect(calledService).toBe(0)
  })

  test('first service fails comparator', async () => {
    let calledService: number | undefined
    const services: AxAIService[] = [
      createMockService({
        name: 'service-0',
        latencyMs: 200,
        chatResponse: async () => {
          throw new AxAIServiceNetworkError(
            new Error('test'),
            'test-url',
            {},
            {}
          )
        },
      }),
      createMockService({
        name: 'service-1',
        chatResponse: async () => {
          calledService = 1
          return {
            results: [
              {
                content: 'test response',
                finishReason: 'stop' as const,
              },
            ],
            modelUsage: {
              ai: 'test-ai',
              model: 'test-model',
              tokens: {
                promptTokens: 20,
                completionTokens: 10,
                totalTokens: 30,
              },
            },
          }
        },
      }),
    ]

    const balancer = new AxBalancer(services, {
      comparator: AxBalancer.inputOrderComparator,
      debug: false,
    })

    await balancer.chat({
      chatPrompt: [{ role: 'user', content: 'test' }],
      model: 'mock',
    })

    expect(calledService).toBe(1)
  })
})



================================================
FILE: src/ax/ai/balance.ts
================================================
import type { ReadableStream } from 'stream/web'

import {
  AxAIServiceAuthenticationError,
  AxAIServiceError,
  AxAIServiceNetworkError,
  AxAIServiceResponseError,
  AxAIServiceStatusError,
  AxAIServiceStreamTerminatedError,
  AxAIServiceTimeoutError,
} from '../util/apicall.js'

import type {
  AxAIModelList,
  AxAIPromptConfig,
  AxAIService,
  AxAIServiceActionOptions,
  AxAIServiceMetrics,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxEmbedRequest,
  AxEmbedResponse,
  AxLoggerFunction,
  AxModelConfig,
} from './types.js'

/**
 * Options for the balancer.
 */
export type AxBalancerOptions = {
  comparator?: (a: AxAIService, b: AxAIService) => number
  debug?: boolean
  initialBackoffMs?: number
  maxBackoffMs?: number
  maxRetries?: number
}

/**
 * Balancer that rotates through services.
 */
export class AxBalancer implements AxAIService<unknown, unknown> {
  private services: AxAIService[]
  private currentServiceIndex: number = 0
  private currentService: AxAIService
  private debug: boolean
  private initialBackoffMs: number
  private maxBackoffMs: number
  private maxRetries: number
  private serviceFailures: Map<
    string,
    { retries: number; lastFailureTime: number }
  > = new Map()

  constructor(services: readonly AxAIService[], options?: AxBalancerOptions) {
    if (services.length === 0) {
      throw new Error('No AI services provided.')
    }

    validateModels(services)

    this.services = [...services].sort(
      options?.comparator ?? AxBalancer.metricComparator
    )

    const cs = this.services[this.currentServiceIndex]
    if (cs === undefined) {
      throw new Error('Error initializing the AI services.') // More specific error message
    }
    this.currentService = cs
    this.debug = options?.debug ?? true
    this.initialBackoffMs = options?.initialBackoffMs ?? 1000
    this.maxBackoffMs = options?.maxBackoffMs ?? 32000
    this.maxRetries = options?.maxRetries ?? 3
  }
  getLastUsedChatModel(): unknown {
    return this.currentService.getLastUsedChatModel()
  }
  getLastUsedEmbedModel(): unknown {
    return this.currentService.getLastUsedEmbedModel()
  }
  getLastUsedModelConfig(): AxModelConfig | undefined {
    return this.currentService.getLastUsedModelConfig()
  }

  /**
   * Service comparator that respects the input order of services.
   */
  public static inputOrderComparator = () => 0

  /**
   * Service comparator that sorts services by cost.
   */

  // Requires a rethink
  /*
    public static costComparator = (a: AxAIService, b: AxAIService) => {
      const aInfo = a.getModelInfo()
      const bInfo = b.getModelInfo()
      const aTotalCost =
        (aInfo.promptTokenCostPer1M || Infinity) +
        (aInfo.completionTokenCostPer1M || Infinity)
      const bTotalCost =
        (bInfo.promptTokenCostPer1M || Infinity) +
        (bInfo.completionTokenCostPer1M || Infinity)
      return aTotalCost - bTotalCost
    }
    */

  public static metricComparator = (a: AxAIService, b: AxAIService) => {
    const aMetrics = a.getMetrics()
    const bMetrics = b.getMetrics()
    // Compare mean chat latency between services
    return aMetrics.latency.chat.mean - bMetrics.latency.chat.mean
  }

  getModelList(): AxAIModelList | undefined {
    return this.currentService.getModelList()
  }

  private getNextService(): boolean {
    const cs = this.services[++this.currentServiceIndex]
    if (cs === undefined) {
      return false
    }
    this.currentService = cs
    return true
  }

  private reset(): void {
    this.currentServiceIndex = 0
    const cs = this.services[this.currentServiceIndex]
    if (cs === undefined) {
      throw new Error('No AI services provided.')
    }
    this.currentService = cs
  }

  getName(): string {
    return this.currentService.getName()
  }

  getId(): string {
    return this.currentService.getId()
  }

  getFeatures(model?: string) {
    return this.currentService.getFeatures(model)
  }

  getMetrics(): AxAIServiceMetrics {
    return this.currentService.getMetrics()
  }

  private canRetryService(): boolean {
    const failure = this.serviceFailures.get(this.currentService.getId())
    if (!failure) return true

    const { retries, lastFailureTime } = failure
    const timeSinceLastFailure = Date.now() - lastFailureTime

    const backoffMs = Math.min(
      this.initialBackoffMs * Math.pow(2, retries),
      this.maxBackoffMs
    )
    return timeSinceLastFailure >= backoffMs
  }

  private handleFailure(): boolean {
    const failure = this.serviceFailures.get(this.currentService.getId())
    const retries = (failure?.retries ?? 0) + 1

    this.serviceFailures.set(this.currentService.getId(), {
      retries,
      lastFailureTime: Date.now(),
    })

    if (this.debug) {
      console.warn(
        `AxBalancer: Service ${this.currentService.getName()} failed (retry ${retries}/${this.maxRetries})`
      )
    }

    if (retries >= this.maxRetries) {
      const gotNextService = this.getNextService()
      if (this.debug) {
        console.warn(
          `AxBalancer: Switching to service ${this.currentService.getName()}`
        )
      }
      return gotNextService
    }

    return true
  }

  private handleSuccess(): void {
    this.serviceFailures.delete(this.currentService.getId())
  }

  async chat(
    req: Readonly<AxChatRequest>,
    options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions> | undefined
  ): Promise<AxChatResponse | ReadableStream<AxChatResponse>> {
    this.reset()

    while (true) {
      if (!this.canRetryService()) {
        if (!this.getNextService()) {
          throw new Error('All services exhausted')
        }
        continue
      }

      try {
        const response = await this.currentService.chat(req, options)
        this.handleSuccess()
        return response
      } catch (e) {
        if (!(e instanceof AxAIServiceError)) {
          throw e
        }

        switch (e.constructor) {
          case AxAIServiceAuthenticationError:
            // Handle authentication failure, e.g., refresh token, prompt user to re-login
            throw e

          case AxAIServiceStatusError:
            // Handle specific HTTP error codes, e.g., display a user-friendly message for a 404 Not Found
            break

          case AxAIServiceNetworkError:
            // Handle network issues, e.g., display a message about checking network connectivity
            break

          case AxAIServiceResponseError:
            // Handle errors related to processing the response, e.g., log the error and retry the request
            break

          case AxAIServiceStreamTerminatedError:
            // Handle unexpected stream termination, e.g., retry the request or display an error message
            break

          case AxAIServiceTimeoutError:
            // Handle request timeouts, e.g., increase timeout, retry, or display an error message
            break

          default:
            throw e
          // Handle unexpected AxAIServiceErrors
        }

        if (!this.handleFailure()) {
          throw e
        }
      }
    }
  }

  async embed(
    req: Readonly<AxEmbedRequest>,
    options?: Readonly<AxAIServiceActionOptions> | undefined
  ): Promise<AxEmbedResponse> {
    this.reset()

    while (true) {
      if (!this.canRetryService()) {
        if (!this.getNextService()) {
          throw new Error('All services exhausted')
        }
        continue
      }

      try {
        const response = await this.currentService.embed(req, options)
        this.handleSuccess()
        return response
      } catch (e) {
        if (!this.handleFailure()) {
          throw e
        }
      }
    }
  }

  setOptions(options: Readonly<AxAIServiceOptions>): void {
    this.currentService.setOptions(options)
  }

  getOptions(): Readonly<AxAIServiceOptions> {
    return this.currentService.getOptions()
  }

  getLogger(): AxLoggerFunction {
    return this.currentService.getLogger()
  }
}

function validateModels(services: readonly AxAIService[]) {
  // Check if any service has a model list.
  const serviceWithModel = services.find(
    (service) => service.getModelList() !== undefined
  )
  if (!serviceWithModel) {
    // No service provides a model list; no validation needed.
    return
  }

  // Use the first service with a model list as the reference.
  const referenceModelList = serviceWithModel.getModelList()
  if (!referenceModelList) {
    throw new Error('No model list found in any service.')
  }
  const referenceKeys = new Set(referenceModelList.map((model) => model.key))

  // Validate that all services provide a model list with the same keys.
  for (let i = 0; i < services.length; i++) {
    const service = services[i]
    if (!service) {
      throw new Error(`Service at index ${i} is undefined`)
    }
    const modelList = service.getModelList()
    if (!modelList) {
      throw new Error(
        `Service at index ${i} (${service.getName()}) has no model list while another service does.`
      )
    }

    const serviceKeys = new Set(modelList.map((model) => model.key))

    // Check for missing keys compared to the reference
    for (const key of referenceKeys) {
      if (!serviceKeys.has(key)) {
        throw new Error(
          `Service at index ${i} (${service.getName()}) is missing model "${key}"`
        )
      }
    }
    // Check for extra keys not in the reference
    for (const key of serviceKeys) {
      if (!referenceKeys.has(key)) {
        throw new Error(
          `Service at index ${i} (${service.getName()}) has extra model "${key}"`
        )
      }
    }
  }
}



================================================
FILE: src/ax/ai/base.test.ts
================================================
import { ReadableStream } from 'stream/web'

import type { Span } from '@opentelemetry/api' // Ensure Span is imported
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest'

import { axSpanAttributes, axSpanEvents } from '../trace/trace.js' // Added import

import {
  AxBaseAI,
  setChatRequestEvents,
  setChatResponseEvents,
} from './base.js' // Import new functions
import type { AxAIFeatures, AxBaseAIArgs } from './base.js'
import type {
  AxAIServiceImpl,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxChatResponseResult,
  AxEmbedRequest,
  AxEmbedResponse,
  AxModelConfig,
  AxModelInfo,
  AxTokenUsage,
} from './types.js'

// Mock OpenTelemetry
const mockSpan = {
  attributes: {} as Record<string, unknown>,
  mockEvents: [] as { name: string; attributes: Record<string, unknown> }[],
  setAttribute: vi.fn((key, value) => {
    mockSpan.attributes[key] = value
  }),
  setAttributes: vi.fn((attrs) => {
    Object.assign(mockSpan.attributes, attrs)
  }),
  addEvent: vi.fn((name, attributes) => {
    mockSpan.mockEvents.push({ name, attributes })
  }),
  end: vi.fn(),
  isRecording: vi.fn(() => true),
  recordException: vi.fn(),
}

const mockTracer = {
  startActiveSpan: vi.fn(
    async (
      name: string,
      options: unknown,
      context: unknown,
      fn: (span: Readonly<typeof mockSpan>) => Promise<unknown>
    ) => {
      // Reset mockSpan for each new span
      mockSpan.attributes = {}
      mockSpan.mockEvents = []
      mockSpan.setAttribute.mockClear()
      mockSpan.setAttributes.mockClear()
      mockSpan.addEvent.mockClear()
      mockSpan.end.mockClear()
      mockSpan.isRecording.mockClear()
      mockSpan.recordException.mockClear()
      mockSpan.isRecording.mockReturnValue(true)
      if (typeof fn === 'function') {
        return await fn(mockSpan)
      }
      return mockSpan
    }
  ),
}

// Create a mock fetch implementation - MOVED TO TOP LEVEL
const createMockFetch = (responseFactory: () => Response) => {
  return async () => {
    // Simulate network delay
    await new Promise((resolve) => setTimeout(resolve, 10))
    return responseFactory()
  }
}

// Create a function that returns a fresh mock response for each call
const createDefaultMockResponse = () =>
  new Response(JSON.stringify({ results: [] }), {
    status: 200,
    headers: { 'Content-Type': 'application/json' },
  })

describe('AxBaseAI', () => {
  // Mock implementation of the AI service
  const mockImpl: AxAIServiceImpl<
    string,
    string,
    unknown,
    unknown,
    unknown,
    unknown,
    unknown
  > = {
    createChatReq: () => [{ name: 'test', headers: {} }, {}],
    createChatResp: () => ({ results: [] }),
    createChatStreamResp: () => ({ results: [] }),
    getModelConfig: () => ({
      maxTokens: 100,
      temperature: 0,
      stream: true,
    }),
    getTokenUsage: () => ({
      totalTokens: 0,
      promptTokens: 0,
      completionTokens: 0,
    }),
  }

  // Base configuration for tests
  const baseConfig: AxBaseAIArgs<string, string> = {
    name: 'test-ai',
    apiURL: 'http://test.com',
    headers: async () => ({}),
    modelInfo: [
      {
        name: 'test-model',
        promptTokenCostPer1M: 100,
        completionTokenCostPer1M: 100,
      } as AxModelInfo,
    ],
    defaults: {
      model: 'test-model',
    },
    supportFor: {
      functions: true,
      streaming: true,
    },
    models: [
      { key: 'model1', model: 'test-model-1', description: 'Test Model 1' },
      { key: 'model2', model: 'test-model-2', description: 'Test Model 2' },
    ],
  }

  // Setup helper to create AI instance with mock fetch
  const createTestAI = (
    responseFactory = createDefaultMockResponse,
    serviceImpl: AxAIServiceImpl<
      string,
      string,
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      any, // Allow 'any' for broader compatibility in tests
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      any,
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      any,
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      any,
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      any
    > = mockImpl,
    config: AxBaseAIArgs<string, string> = baseConfig
  ) => {
    const mockFetch = createMockFetch(responseFactory)
    const ai = new AxBaseAI(serviceImpl, config)
    ai.setOptions({
      fetch: mockFetch,
      tracer: mockTracer as unknown as AxAIServiceOptions['tracer'],
    })
    return ai
  }

  it('should initialize correctly', () => {
    const ai = createTestAI()
    expect(ai.getName()).toBe('test-ai')
    expect(ai.getModelList()).toHaveLength(2)
    expect(ai.getLastUsedChatModel()).toBeUndefined()
  })

  it('should handle features correctly with function', () => {
    const featuresConfig = {
      ...baseConfig,
      supportFor: (model: string) => ({
        functions: model === 'test-model-1',
        streaming: true,
      }),
    }

    const ai = new AxBaseAI(mockImpl, featuresConfig)
    ai.setOptions({ fetch: createMockFetch(createDefaultMockResponse) })

    expect(ai.getFeatures('test-model-1')).toEqual({
      functions: true,
      streaming: true,
    })

    expect(ai.getFeatures('test-model-2')).toEqual({
      functions: false,
      streaming: true,
    })
  })

  it('should handle features correctly with object', () => {
    const features: AxAIFeatures = {
      functions: true,
      streaming: false,
    }

    const featuresConfig = {
      ...baseConfig,
      supportFor: features,
    }

    const ai = new AxBaseAI(mockImpl, featuresConfig)
    ai.setOptions({ fetch: createMockFetch(createDefaultMockResponse) })
    expect(ai.getFeatures()).toEqual(features)
  })

  it('should track metrics correctly', async () => {
    // Mock successful response
    const mockResponse = new Response(JSON.stringify({ results: [] }), {
      status: 200,
      headers: { 'Content-Type': 'application/json' },
    })

    const ai = createTestAI(() => mockResponse)

    // Make a chat request
    const response = await ai.chat({ chatPrompt: [] })

    // If streaming is true, consume the stream
    if (response instanceof ReadableStream) {
      const reader = response.getReader()

      while (!(await reader.read()).done) {}
    }

    const metrics = ai.getMetrics()
    expect(metrics.latency.chat.samples).toHaveLength(1)
    expect(metrics.errors.chat.count).toBe(0)
  }, 10000)

  it('should handle errors in metrics', async () => {
    // Create an implementation that throws an error
    const errorImpl = {
      ...mockImpl,
      getModelConfig: () => ({
        maxTokens: 100,
        temperature: 0,
        stream: false, // Disable streaming for error handling test
      }),
      createChatReq: () => {
        throw new Error('Test error')
      },
    }

    const ai = createTestAI(createDefaultMockResponse, errorImpl)

    // Make a chat request that will error
    try {
      await ai.chat({ chatPrompt: [] })
    } catch {
      // Expected error
    }

    const metrics = ai.getMetrics()
    expect(metrics.errors.chat.count).toBe(1)
    expect(metrics.errors.chat.rate).toBe(1)
  }, 10000)

  it('should update options correctly', () => {
    const ai = createTestAI()

    const options = {
      debug: true,
      fetch: createMockFetch(createDefaultMockResponse),
    }

    ai.setOptions(options)
    expect(ai.getOptions()).toMatchObject(options)
  })

  it('should throw error when no model is defined', () => {
    const invalidConfig: AxBaseAIArgs<string, string> = {
      ...baseConfig,
      defaults: {
        model: '', // Invalid model
      },
    }

    expect(() => {
      createTestAI(undefined, mockImpl, invalidConfig)
    }).toThrow('No model defined')
  })

  it('should handle API URL and headers updates', async () => {
    const ai = createTestAI()

    const newUrl = 'http://new-test.com'
    const newHeaders = async () => ({ 'X-Test': 'test' })

    ai.setAPIURL(newUrl)
    ai.setHeaders(newHeaders)

    // Basic check, more thorough checks would involve actual calls
    expect(ai.getName()).toBe('test-ai')
  })

  describe('function schema cleanup', () => {
    let ai: AxBaseAI<
      string,
      string,
      AxChatRequest,
      AxEmbedRequest,
      AxChatResponse,
      AxChatResponseResult,
      AxEmbedResponse
    >

    beforeEach(() => {
      // Create AI instance with non-streaming model config for function cleanup tests
      const nonStreamingMockImpl = {
        ...mockImpl,
        getModelConfig: () => ({
          maxTokens: 100,
          temperature: 0,
          stream: false, // Disable streaming for function cleanup tests
        }),
      }
      ai = createTestAI(createDefaultMockResponse, nonStreamingMockImpl, {
        ...baseConfig,
        supportFor: {
          functions: true,
          streaming: false, // Disable streaming support entirely for these tests
        },
      }) as AxBaseAI<
        string,
        string,
        AxChatRequest,
        AxEmbedRequest,
        AxChatResponse,
        AxChatResponseResult,
        AxEmbedResponse
      >

      // Ensure tracer is set for proper function execution path
      ai.setOptions({
        fetch: createMockFetch(createDefaultMockResponse),
        tracer: mockTracer as unknown as AxAIServiceOptions['tracer'],
      })
    })

    it('should clean up empty parameters object', async () => {
      const chatReq = {
        chatPrompt: [],
        functions: [
          {
            name: 'testFunc',
            description: 'test function',
            parameters: {
              type: 'object',
              properties: {},
              required: [],
            },
          },
        ],
      }

      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const cleanupSpy = vi.spyOn(ai as any, 'cleanupFunctionSchema')

      const response = await ai.chat(chatReq, { stream: false }) // Explicitly disable streaming
      if (response instanceof ReadableStream) {
        const reader = response.getReader()

        while (!(await reader.read()).done) {}
      }

      expect(cleanupSpy).toHaveBeenCalled()
      const cleanedFunction = cleanupSpy.mock.results?.[0]?.value
      expect(cleanedFunction.parameters).toBeUndefined()
    }, 10000)

    // ... other function schema cleanup tests ...
    it('should clean up empty required array', async () => {
      const chatReq = {
        chatPrompt: [],
        functions: [
          {
            name: 'testFunc',
            description: 'test function',
            parameters: {
              type: 'object',
              properties: {
                someField: {
                  type: 'string',
                  description: 'some field',
                },
              },
              required: [],
            },
          },
        ],
      }

      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const cleanupSpy = vi.spyOn(ai as any, 'cleanupFunctionSchema')

      const response = await ai.chat(chatReq, { stream: false }) // Explicitly disable streaming
      if (response instanceof ReadableStream) {
        const reader = response.getReader()
        while (!(await reader.read()).done) {}
      }

      expect(cleanupSpy).toHaveBeenCalled()
      const cleanedFunction = cleanupSpy.mock.results?.[0]?.value
      expect(cleanedFunction.parameters?.required).toBeUndefined()
      expect(cleanedFunction.parameters?.properties).toBeDefined()
    })

    it('should clean up empty properties object', async () => {
      const chatReq = {
        chatPrompt: [],
        functions: [
          {
            name: 'testFunc',
            description: 'test function',
            parameters: {
              type: 'object',
              properties: {},
              required: ['someField'],
            },
          },
        ],
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const cleanupSpy = vi.spyOn(ai as any, 'cleanupFunctionSchema')

      const response = await ai.chat(chatReq, { stream: false }) // Explicitly disable streaming
      if (response instanceof ReadableStream) {
        const reader = response.getReader()
        while (!(await reader.read()).done) {}
      }

      expect(cleanupSpy).toHaveBeenCalled()
      const cleanedFunction = cleanupSpy.mock.results?.[0]?.value
      expect(cleanedFunction.parameters?.properties).toBeUndefined()
      expect(cleanedFunction.parameters?.required).toBeDefined()
    })

    it('should preserve non-empty schema parts', async () => {
      const chatReq = {
        chatPrompt: [],
        functions: [
          {
            name: 'testFunc',
            description: 'test function',
            parameters: {
              type: 'object',
              properties: {
                someField: {
                  type: 'string',
                  description: 'some field',
                },
              },
              required: ['someField'],
            },
          },
        ],
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const cleanupSpy = vi.spyOn(ai as any, 'cleanupFunctionSchema')

      const response = await ai.chat(chatReq, { stream: false }) // Explicitly disable streaming
      if (response instanceof ReadableStream) {
        const reader = response.getReader()
        while (!(await reader.read()).done) {}
      }

      expect(cleanupSpy).toHaveBeenCalled()
      const cleanedFunction = cleanupSpy.mock.results?.[0]?.value
      expect(cleanedFunction.parameters?.properties?.someField).toBeDefined()
      expect(cleanedFunction.parameters?.required).toEqual(['someField'])
    })

    it('should handle undefined parameters', async () => {
      const chatReq = {
        chatPrompt: [],
        functions: [
          {
            name: 'testFunc',
            description: 'test function',
          },
        ],
      }
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const cleanupSpy = vi.spyOn(ai as any, 'cleanupFunctionSchema')

      const response = await ai.chat(chatReq, { stream: false }) // Explicitly disable streaming
      if (response instanceof ReadableStream) {
        const reader = response.getReader()
        while (!(await reader.read()).done) {}
      }

      expect(cleanupSpy).toHaveBeenCalled()
      const cleanedFunction = cleanupSpy.mock.results?.[0]?.value
      expect(cleanedFunction.parameters).toBeUndefined()
    })

    afterEach(() => {
      vi.clearAllMocks()
    })
  })

  it('should return only non-internal models in getModelList', () => {
    const ai = new AxBaseAI(mockImpl, {
      ...baseConfig,
      models: [
        { key: 'basic', model: 'model-basic', description: 'Basic model' },
        {
          key: 'advanced',
          model: 'model-advanced',
          description: 'Advanced model',
          isInternal: true,
        },
        { key: 'expert', model: 'model-expert', description: 'Expert model' },
      ],
    })
    ai.setOptions({ fetch: createMockFetch(createDefaultMockResponse) })
    const visibleModels = ai.getModelList()
    expect(visibleModels).toHaveLength(2)
    expect(visibleModels?.map((m) => m.key)).toContain('basic')
    expect(visibleModels?.map((m) => m.key)).toContain('expert')
    expect(visibleModels?.map((m) => m.key)).not.toContain('advanced')
  })

  it('should throw an error if duplicate model keys are provided', () => {
    expect(() => {
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      const ai = new AxBaseAI(mockImpl, {
        ...baseConfig,
        models: [
          { key: 'basic', model: 'model-basic', description: 'Basic model' },
          {
            key: 'basic',
            model: 'another-model-basic',
            description: 'Duplicate basic model',
          },
        ],
      })
    }).toThrowError(/Duplicate model key detected: "basic"/)
  })

  it('should throw error for empty content in chat prompt', async () => {
    const ai = createTestAI()

    const chatReq = {
      chatPrompt: [
        { role: 'user', content: 'Hello' },
        { role: 'assistant', content: '' }, // Empty content should trigger validation
        { role: 'user', content: 'Another message' },
      ] as AxChatRequest['chatPrompt'],
    }

    await expect(ai.chat(chatReq)).rejects.toThrow(
      'Chat prompt validation failed: Message at index 1 has empty content'
    )
  })

  it('should throw error for whitespace-only content in chat prompt', async () => {
    const ai = createTestAI()

    const chatReq = {
      chatPrompt: [
        { role: 'user', content: 'Hello' },
        { role: 'assistant', content: '   \n\t  ' }, // Whitespace-only content should trigger validation
        { role: 'user', content: 'Another message' },
      ] as AxChatRequest['chatPrompt'],
    }

    await expect(ai.chat(chatReq)).rejects.toThrow(
      'Chat prompt validation failed: Message at index 1 has empty content'
    )
  })
})

describe('setChatResponseEvents', () => {
  let mockSpanInstance: typeof mockSpan

  beforeEach(() => {
    // Create a fresh mockSpan for each test to avoid interference
    mockSpanInstance = {
      attributes: {},
      mockEvents: [],
      setAttribute: vi.fn((key, value) => {
        mockSpanInstance.attributes[key] = value
      }),
      setAttributes: vi.fn((attrs) => {
        Object.assign(mockSpanInstance.attributes, attrs)
      }),
      addEvent: vi.fn((name, attributes) => {
        mockSpanInstance.mockEvents.push({ name, attributes })
      }),
      end: vi.fn(),
      isRecording: vi.fn(() => true),
      recordException: vi.fn(),
    }
  })

  afterEach(() => {
    vi.clearAllMocks()
  })

  it('should handle Chat Response with results', () => {
    const mockChatResponse: AxChatResponse = {
      modelUsage: {
        ai: 'test-ai',
        model: 'test-model',
        tokens: { promptTokens: 10, completionTokens: 20, totalTokens: 30 },
      },
      results: [
        { content: 'Hello', finishReason: 'stop' },
        {
          content: 'Function call',
          finishReason: 'tool_calls' as AxChatResponseResult['finishReason'],
          functionCalls: [
            {
              id: 'call1',
              type: 'function',
              function: { name: 'funcName', params: { arg1: 'val1' } },
            },
          ],
        },
      ],
    }
    setChatResponseEvents(mockChatResponse, mockSpanInstance as unknown as Span)

    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USAGE,
      {
        [axSpanAttributes.LLM_USAGE_INPUT_TOKENS]: 10,
        [axSpanAttributes.LLM_USAGE_OUTPUT_TOKENS]: 20,
        [axSpanAttributes.LLM_USAGE_TOTAL_TOKENS]: 30,
      }
    )

    expect(mockSpanInstance.addEvent).toHaveBeenCalledTimes(3)
    expect(mockSpanInstance.addEvent).toHaveBeenNthCalledWith(
      2,
      axSpanEvents.GEN_AI_CHOICE,
      {
        finish_reason: 'stop',
        index: 0,
        message: JSON.stringify({ content: 'Hello' }, null, 2),
      }
    )
    expect(mockSpanInstance.addEvent).toHaveBeenNthCalledWith(
      3,
      axSpanEvents.GEN_AI_CHOICE,
      {
        finish_reason: 'tool_calls',
        index: 1,
        message: JSON.stringify(
          {
            content: 'Function call',
            tool_calls: [
              {
                id: 'call1',
                type: 'function',
                function: 'funcName',
                arguments: { arg1: 'val1' },
              },
            ],
          },
          null,
          2
        ),
      }
    )
  })

  it('should handle Chat Response (Empty Results)', () => {
    const mockChatResponse: AxChatResponse = {
      modelUsage: {
        ai: 'test-ai',
        model: 'test-model',
        tokens: { promptTokens: 10, completionTokens: 20, totalTokens: 30 },
      },
      results: [],
    }
    setChatResponseEvents(mockChatResponse, mockSpanInstance as unknown as Span)

    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USAGE,
      {
        [axSpanAttributes.LLM_USAGE_INPUT_TOKENS]: 10,
        [axSpanAttributes.LLM_USAGE_OUTPUT_TOKENS]: 20,
        [axSpanAttributes.LLM_USAGE_TOTAL_TOKENS]: 30,
      }
    )
    expect(mockSpanInstance.addEvent).toHaveBeenCalledTimes(1)
  })

  it('should handle Response without Model Usage', () => {
    const mockChatResponse: AxChatResponse = {
      results: [{ content: 'Hello', finishReason: 'stop' }],
    }
    setChatResponseEvents(mockChatResponse, mockSpanInstance as unknown as Span)

    expect(mockSpanInstance.setAttributes).not.toHaveBeenCalled()
    expect(mockSpanInstance.addEvent).toHaveBeenCalledTimes(1)
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_CHOICE,
      {
        finish_reason: 'stop',
        index: 0,
        message: JSON.stringify({ content: 'Hello' }, null, 2),
      }
    )
  })

  it('should exclude content from telemetry when excludeContentFromTelemetry is true', () => {
    const mockChatResponse: AxChatResponse = {
      modelUsage: {
        ai: 'test-ai',
        model: 'test-model',
        tokens: { promptTokens: 10, completionTokens: 20, totalTokens: 30 },
      },
      results: [
        { content: 'Hello', finishReason: 'stop' },
        {
          content: 'Function call',
          finishReason: 'tool_calls' as AxChatResponseResult['finishReason'],
          functionCalls: [
            {
              id: 'call1',
              type: 'function',
              function: { name: 'funcName', params: { arg1: 'val1' } },
            },
          ],
        },
      ],
    }
    setChatResponseEvents(
      mockChatResponse,
      mockSpanInstance as unknown as Span,
      true
    )

    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USAGE,
      {
        [axSpanAttributes.LLM_USAGE_INPUT_TOKENS]: 10,
        [axSpanAttributes.LLM_USAGE_OUTPUT_TOKENS]: 20,
        [axSpanAttributes.LLM_USAGE_TOTAL_TOKENS]: 30,
      }
    )

    expect(mockSpanInstance.addEvent).toHaveBeenCalledTimes(3)
    // First result should not have content
    expect(mockSpanInstance.addEvent).toHaveBeenNthCalledWith(
      2,
      axSpanEvents.GEN_AI_CHOICE,
      {
        finish_reason: 'stop',
        index: 0,
        message: JSON.stringify({}, null, 2),
      }
    )
    // Second result should not have content but should have tool_calls
    expect(mockSpanInstance.addEvent).toHaveBeenNthCalledWith(
      3,
      axSpanEvents.GEN_AI_CHOICE,
      {
        finish_reason: 'tool_calls',
        index: 1,
        message: JSON.stringify(
          {
            tool_calls: [
              {
                id: 'call1',
                type: 'function',
                function: 'funcName',
                arguments: { arg1: 'val1' },
              },
            ],
          },
          null,
          2
        ),
      }
    )
  })
})

describe('setChatRequestEvents', () => {
  let mockSpanInstance: typeof mockSpan

  beforeEach(() => {
    mockSpanInstance = {
      attributes: {},
      mockEvents: [],
      setAttribute: vi.fn(),
      setAttributes: vi.fn(),
      addEvent: vi.fn(),
      end: vi.fn(),
      isRecording: vi.fn(() => true),
      recordException: vi.fn(),
    }
  })

  afterEach(() => {
    vi.clearAllMocks()
  })

  it('should handle system message', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [{ role: 'system', content: 'System prompt' }],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span)
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_SYSTEM_MESSAGE,
      { content: 'System prompt' }
    )
    // User message event should also be called, even if empty
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USER_MESSAGE,
      { content: '' }
    )
  })

  it('should handle user message string content', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [{ role: 'user', content: 'User message' }],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span)
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USER_MESSAGE,
      { content: 'User message' }
    )
  })

  it('should handle user message array content', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [
        {
          role: 'user',
          content: [
            { type: 'text', text: 'User message part 1' },
            { type: 'text', text: 'User message part 2' },
          ],
        },
      ],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span)
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USER_MESSAGE,
      { content: 'User message part 1\nUser message part 2' }
    )
  })

  it('should handle assistant message', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [{ role: 'assistant', content: 'Assistant message' }],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span)
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_ASSISTANT_MESSAGE,
      { content: 'Assistant message' }
    )
  })

  it('should handle assistant message with function calls', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [
        {
          role: 'assistant',
          content: 'Assistant says something',
          functionCalls: [
            {
              id: 'fc1',
              type: 'function',
              function: { name: 'func_name', params: { argA: 'valA' } },
            },
          ],
        },
      ],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span)
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_ASSISTANT_MESSAGE,
      {
        content: 'Assistant says something',
        function_calls: JSON.stringify(
          [
            {
              id: 'fc1',
              type: 'function',
              function: 'func_name',
              arguments: { argA: 'valA' },
            },
          ],
          null,
          2
        ),
      }
    )
  })

  it('should handle function message', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [
        { role: 'function', functionId: 'fn1', result: 'Function result' },
      ],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span)
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_TOOL_MESSAGE,
      { id: 'fn1', content: 'Function result' }
    )
  })

  it('should handle multiple messages of different roles', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [
        { role: 'system', content: 'System setup' },
        { role: 'user', content: 'Hi there' },
        { role: 'assistant', content: 'Hello!' },
        { role: 'user', content: 'Question?' },
      ],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span)

    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_SYSTEM_MESSAGE,
      { content: 'System setup' }
    )
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_ASSISTANT_MESSAGE,
      { content: 'Hello!' }
    )
    // User messages are aggregated
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USER_MESSAGE,
      { content: 'Hi there\nQuestion?' }
    )
  })

  it('should handle empty chatPrompt', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span)
    // GEN_AI_USER_MESSAGE should still be called with empty content
    expect(mockSpanInstance.addEvent).toHaveBeenCalledTimes(1)
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USER_MESSAGE,
      { content: '' }
    )
  })

  it('should handle chatPrompt with only non-text user content parts', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [
        {
          role: 'user',
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          content: [{ type: 'image_url', image_url: 'test.png' } as any],
        },
      ],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span)
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USER_MESSAGE,
      { content: '' }
    )
  })

  it('should exclude content from telemetry when excludeContentFromTelemetry is true', () => {
    const req: AxChatRequest<unknown> = {
      chatPrompt: [
        { role: 'system', content: 'System prompt' },
        { role: 'user', content: 'User message' },
        { role: 'assistant', content: 'Assistant message' },
        { role: 'function', functionId: 'fn1', result: 'Function result' },
      ],
    }
    setChatRequestEvents(req, mockSpanInstance as unknown as Span, true)

    // System message should not have content
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_SYSTEM_MESSAGE,
      {}
    )

    // Assistant message should not have content
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_ASSISTANT_MESSAGE,
      {}
    )

    // Function message should not have content
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_TOOL_MESSAGE,
      { id: 'fn1' }
    )

    // User message should not have content
    expect(mockSpanInstance.addEvent).toHaveBeenCalledWith(
      axSpanEvents.GEN_AI_USER_MESSAGE,
      {}
    )
  })
})

describe('AxBaseAI Tracing with Token Usage', () => {
  let aiService: AxBaseAI<
    string,
    string,
    AxChatRequest,
    AxEmbedRequest,
    AxChatResponse,
    AxChatResponseResult,
    AxEmbedResponse
  >
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  let mockServiceImpl: any // Use 'any' for easier mocking with Vitest's vi.fn()

  const mockTokenUsage: AxTokenUsage = {
    promptTokens: 10,
    completionTokens: 20,
    totalTokens: 30,
  }
  const mockModelConfig: AxModelConfig = {
    maxTokens: 100,
    temperature: 0,
    stream: false,
  } // Set stream to false for non-streaming tests

  beforeEach(() => {
    // Reset the mock span completely
    mockSpan.attributes = {}
    mockSpan.mockEvents = []
    mockSpan.setAttribute.mockClear()
    mockSpan.setAttributes.mockClear()
    mockSpan.addEvent.mockClear()
    mockSpan.end.mockClear()
    mockSpan.isRecording.mockClear()
    mockSpan.recordException.mockClear()
    mockSpan.isRecording.mockReturnValue(true)

    mockServiceImpl = {
      createChatReq: vi.fn().mockReturnValue([
        { name: 'chat', headers: {} },
        {
          model: 'test-model',
          chatPrompt: [{ role: 'user', content: 'hello' }],
        }, // Added chatPrompt for setChatRequestEvents
      ]),
      createChatResp: vi
        .fn()
        .mockReturnValue({ results: [{ content: 'response' }] }), // No modelUsage initially
      createChatStreamResp: vi
        .fn()
        .mockImplementation((respDelta: unknown) => ({
          results: [respDelta as AxChatResponseResult],
        })), // No modelUsage initially
      createEmbedReq: vi
        .fn()
        .mockReturnValue([
          { name: 'embed', headers: {} },
          { model: 'test-embed-model' },
        ]),
      createEmbedResp: vi.fn().mockReturnValue({ embeddings: [[1, 2, 3]] }), // No modelUsage initially
      getModelConfig: vi.fn().mockReturnValue(mockModelConfig),
      getTokenUsage: vi.fn().mockReturnValue(mockTokenUsage), // Key mock
    }

    aiService = new AxBaseAI(
      mockServiceImpl as AxAIServiceImpl<
        string,
        string,
        AxChatRequest,
        AxEmbedRequest,
        AxChatResponse,
        AxChatResponseResult,
        AxEmbedResponse
      >,
      {
        name: 'mockAI',
        apiURL: 'http://localhost',
        headers: async () => ({}),
        modelInfo: [{ name: 'test-model' } as AxModelInfo],
        defaults: { model: 'test-model', embedModel: 'test-embed-model' },
        supportFor: { functions: false, streaming: false }, // Disable streaming support for non-streaming tests
        options: {
          tracer: mockTracer as unknown as AxAIServiceOptions['tracer'], // Set tracer in constructor
        },
      }
    )
    // Set a mock fetch for apiCall to work - use fresh response for each test
    // Also set tracer again to ensure it's properly set
    aiService.setOptions({
      fetch: createMockFetch(createDefaultMockResponse), // Create fresh response
      tracer: mockTracer as unknown as AxAIServiceOptions['tracer'], // Set tracer again to ensure it's set
    })
    mockTracer.startActiveSpan.mockClear()
    // Clear all individual method mocks in mockServiceImpl
    Object.values(mockServiceImpl).forEach((mockFn) => {
      if (vi.isMockFunction(mockFn)) {
        mockFn.mockClear()
      }
    })
    // Specifically re-mock getTokenUsage for clarity as it's key
    mockServiceImpl.getTokenUsage.mockReturnValue(mockTokenUsage)
    mockServiceImpl.getModelConfig.mockReturnValue(mockModelConfig)
    // Ensure createChatReq is re-mocked for each test if needed, or provide a default that includes chatPrompt
    mockServiceImpl.createChatReq.mockReturnValue([
      { name: 'chat', headers: {} },
      { model: 'test-model', chatPrompt: [{ role: 'user', content: 'hello' }] },
    ])
  })

  afterEach(() => {
    vi.clearAllMocks()
  })

  it('should add token usage to trace for non-streaming chat (fallback to getTokenUsage)', async () => {
    await aiService.chat(
      { chatPrompt: [{ role: 'user', content: 'hello' }] },
      { stream: false } // Explicitly disable streaming
    )
    expect(mockTracer.startActiveSpan).toHaveBeenCalled()
    expect(mockServiceImpl.getTokenUsage).toHaveBeenCalled()
    expect(mockSpan.addEvent).toHaveBeenCalledWith(axSpanEvents.GEN_AI_USAGE, {
      [axSpanAttributes.LLM_USAGE_INPUT_TOKENS]: mockTokenUsage.promptTokens,
      [axSpanAttributes.LLM_USAGE_OUTPUT_TOKENS]:
        mockTokenUsage.completionTokens,
      [axSpanAttributes.LLM_USAGE_TOTAL_TOKENS]: mockTokenUsage.totalTokens,
    })
    // setChatRequestEvents: user (1 event)
    // setChatResponseEvents: usage (1 event), choice (1 event)
    expect(mockSpan.addEvent).toHaveBeenCalledTimes(3)
  })

  it('should add token usage to trace for non-streaming chat (service provides it)', async () => {
    const serviceProvidedUsage: AxTokenUsage = {
      promptTokens: 11,
      completionTokens: 22,
      totalTokens: 33,
    }
    mockServiceImpl.createChatResp.mockReturnValue({
      results: [{ content: 'response' }],
      modelUsage: {
        ai: 'mockAI',
        model: 'test-model',
        tokens: serviceProvidedUsage,
      },
    } as AxChatResponse)

    await aiService.chat(
      { chatPrompt: [{ role: 'user', content: 'hello' }] },
      { stream: false } // Explicitly disable streaming
    )
    expect(mockTracer.startActiveSpan).toHaveBeenCalled()
    expect(mockServiceImpl.getTokenUsage).not.toHaveBeenCalled() // Should use service provided
    expect(mockSpan.addEvent).toHaveBeenCalledWith(axSpanEvents.GEN_AI_USAGE, {
      [axSpanAttributes.LLM_USAGE_INPUT_TOKENS]:
        serviceProvidedUsage.promptTokens,
      [axSpanAttributes.LLM_USAGE_OUTPUT_TOKENS]:
        serviceProvidedUsage.completionTokens,
      [axSpanAttributes.LLM_USAGE_TOTAL_TOKENS]:
        serviceProvidedUsage.totalTokens,
    })
    // setChatRequestEvents: user (1 event)
    // setChatResponseEvents: usage (1 event), choice (1 event)
    expect(mockSpan.addEvent).toHaveBeenCalledTimes(3)
  })

  // Temporarily skip the streaming tests as they require complex setup
  it.skip('should add token usage to trace for streaming chat', async () => {
    // This test is temporarily skipped due to complex streaming mock setup requirements
  })

  it.skip('should add token usage to trace for streaming chat (service provides it on delta)', async () => {
    // This test is temporarily skipped due to complex streaming mock setup requirements
  })

  it('should add token usage to trace for embed requests (fallback to getTokenUsage)', async () => {
    // Ensure non-streaming config for embed test
    const embedModelConfig = { maxTokens: 100, temperature: 0, stream: false }
    mockServiceImpl.getModelConfig.mockReturnValue(embedModelConfig)

    const embedTokenUsage: AxTokenUsage = {
      promptTokens: 15,
      completionTokens: 0, // Embeddings usually don't have completion tokens
      totalTokens: 15, // So total often equals prompt
    }
    mockServiceImpl.getTokenUsage.mockReturnValue(embedTokenUsage) // Specific for embed

    await aiService.embed({ texts: ['embed this'] })

    expect(mockTracer.startActiveSpan).toHaveBeenCalled()
    expect(mockServiceImpl.getTokenUsage).toHaveBeenCalled()
    expect(mockSpan.addEvent).toHaveBeenCalledWith(axSpanEvents.GEN_AI_USAGE, {
      [axSpanAttributes.LLM_USAGE_INPUT_TOKENS]: embedTokenUsage.promptTokens,
      [axSpanAttributes.LLM_USAGE_OUTPUT_TOKENS]:
        embedTokenUsage.completionTokens ?? 0,
      [axSpanAttributes.LLM_USAGE_TOTAL_TOKENS]: embedTokenUsage.totalTokens,
    })
    expect(mockSpan.addEvent).toHaveBeenCalledTimes(1)
  })

  it('should add token usage to trace for embed requests (service provides it)', async () => {
    // Ensure non-streaming config for embed test
    const embedModelConfig = { maxTokens: 100, temperature: 0, stream: false }
    mockServiceImpl.getModelConfig.mockReturnValue(embedModelConfig)

    const serviceProvidedUsage: AxTokenUsage = {
      promptTokens: 16,
      completionTokens: 0,
      totalTokens: 16,
    }
    mockServiceImpl.createEmbedResp.mockReturnValue({
      embeddings: [[1, 2, 3]],
      modelUsage: {
        ai: 'mockAI',
        model: 'test-embed-model',
        tokens: serviceProvidedUsage,
      },
    } as AxEmbedResponse)

    await aiService.embed({ texts: ['embed this'] })

    expect(mockTracer.startActiveSpan).toHaveBeenCalled()
    expect(mockServiceImpl.getTokenUsage).not.toHaveBeenCalled()
    expect(mockSpan.addEvent).toHaveBeenCalledWith(axSpanEvents.GEN_AI_USAGE, {
      [axSpanAttributes.LLM_USAGE_INPUT_TOKENS]:
        serviceProvidedUsage.promptTokens,
      [axSpanAttributes.LLM_USAGE_OUTPUT_TOKENS]:
        serviceProvidedUsage.completionTokens ?? 0,
      [axSpanAttributes.LLM_USAGE_TOTAL_TOKENS]:
        serviceProvidedUsage.totalTokens,
    })
    expect(mockSpan.addEvent).toHaveBeenCalledTimes(1)
  })
})



================================================
FILE: src/ax/ai/base.ts
================================================
import crypto from 'crypto'
import type { ReadableStream } from 'stream/web'

import { context, type Span, SpanKind } from '@opentelemetry/api'

import { axSpanAttributes, axSpanEvents } from '../trace/trace.js'
import { apiCall } from '../util/apicall.js'
import { RespTransformStream } from '../util/transform.js'

import { logChatRequest, logResponse } from './debug.js'
import type {
  AxAIInputModelList,
  AxAIModelList,
  AxAIPromptConfig,
  AxAIService,
  AxAIServiceActionOptions,
  AxAIServiceImpl,
  AxAIServiceMetrics,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxEmbedRequest,
  AxEmbedResponse,
  AxLoggerFunction,
  AxModelConfig,
  AxModelInfo,
  AxModelUsage,
} from './types.js'

export interface AxAIFeatures {
  functions: boolean
  streaming: boolean
  functionCot?: boolean
  hasThinkingBudget?: boolean
  hasShowThoughts?: boolean
}

export interface AxBaseAIArgs<TModel, TEmbedModel> {
  name: string
  apiURL: string
  headers: () => Promise<Record<string, string>>
  modelInfo: Readonly<AxModelInfo[]>
  defaults: Readonly<{ model: TModel; embedModel?: TEmbedModel }>
  options?: Readonly<AxAIServiceOptions>
  supportFor: AxAIFeatures | ((model: TModel) => AxAIFeatures)
  models?: AxAIInputModelList<TModel, TEmbedModel>
}

export const axBaseAIDefaultConfig = (): AxModelConfig =>
  structuredClone({
    temperature: 0,
    topK: 40,
    topP: 0.9,
  })

export const axBaseAIDefaultCreativeConfig = (): AxModelConfig =>
  structuredClone({
    temperature: 0.4,
    topP: 0.7,
    frequencyPenalty: 0.2,
  })

// Default logger function that uses process.stdout.write
const defaultLogger: AxLoggerFunction = (
  message: string,
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  _options?: { tags?: string[] }
) => {
  process.stdout.write(message)
}

export class AxBaseAI<
  TModel,
  TEmbedModel,
  TChatRequest,
  TEmbedRequest,
  TChatResponse,
  TChatResponseDelta,
  TEmbedResponse,
> implements AxAIService<TModel, TEmbedModel>
{
  private debug = false

  private rt?: AxAIServiceOptions['rateLimiter']
  private fetch?: AxAIServiceOptions['fetch']
  private tracer?: AxAIServiceOptions['tracer']
  private timeout?: AxAIServiceOptions['timeout']
  private excludeContentFromTrace?: boolean
  private models?: AxAIInputModelList<TModel, TEmbedModel>
  private abortSignal?: AbortSignal
  private logger: AxLoggerFunction = defaultLogger

  private modelInfo: readonly AxModelInfo[]
  private modelUsage?: AxModelUsage
  private embedModelUsage?: AxModelUsage
  private defaults: AxBaseAIArgs<TModel, TEmbedModel>['defaults']
  private lastUsedModelConfig?: AxModelConfig
  private lastUsedChatModel?: TModel
  private lastUsedEmbedModel?: TEmbedModel

  protected apiURL: string
  protected name: string
  protected id: string
  protected headers: () => Promise<Record<string, string>>
  protected supportFor: AxAIFeatures | ((model: TModel) => AxAIFeatures)

  // Add private metrics tracking properties
  private metrics: AxAIServiceMetrics = {
    latency: {
      chat: {
        mean: 0,
        p95: 0,
        p99: 0,
        samples: [],
      },
      embed: {
        mean: 0,
        p95: 0,
        p99: 0,
        samples: [],
      },
    },
    errors: {
      chat: {
        count: 0,
        rate: 0,
        total: 0,
      },
      embed: {
        count: 0,
        rate: 0,
        total: 0,
      },
    },
  }

  constructor(
    private readonly aiImpl: Readonly<
      AxAIServiceImpl<
        TModel,
        TEmbedModel,
        TChatRequest,
        TEmbedRequest,
        TChatResponse,
        TChatResponseDelta,
        TEmbedResponse
      >
    >,
    {
      name,
      apiURL,
      headers,
      modelInfo,
      defaults,
      options = {},
      supportFor,
      models,
    }: Readonly<AxBaseAIArgs<TModel, TEmbedModel>>
  ) {
    this.name = name
    this.apiURL = apiURL
    this.headers = headers
    this.supportFor = supportFor
    this.tracer = options.tracer
    this.modelInfo = modelInfo
    this.models = models
    this.id = crypto.randomUUID()

    const model = this.getModel(defaults.model) ?? defaults.model
    const embedModel =
      this.getEmbedModel(defaults.embedModel) ?? defaults.embedModel

    this.defaults = { model, embedModel }

    if (
      !defaults.model ||
      typeof defaults.model !== 'string' ||
      defaults.model === ''
    ) {
      throw new Error('No model defined')
    }

    this.setOptions(options)

    if (models) {
      validateModels(models)
    }
  }

  public setName(name: string): void {
    this.name = name
  }

  public getId(): string {
    return this.id
  }

  public setAPIURL(apiURL: string): void {
    this.apiURL = apiURL
  }

  public setHeaders(headers: () => Promise<Record<string, string>>): void {
    this.headers = headers
  }

  setOptions(options: Readonly<AxAIServiceOptions>): void {
    this.debug = options.debug ?? false
    this.rt = options.rateLimiter
    this.fetch = options.fetch
    this.timeout = options.timeout
    this.tracer = options.tracer
    this.excludeContentFromTrace = options.excludeContentFromTrace
    this.abortSignal = options.abortSignal
    this.logger = options.logger ?? defaultLogger
  }

  getOptions(): Readonly<AxAIServiceOptions> {
    return {
      debug: this.debug,
      rateLimiter: this.rt,
      fetch: this.fetch,
      tracer: this.tracer,
      timeout: this.timeout,
      excludeContentFromTrace: this.excludeContentFromTrace,
      abortSignal: this.abortSignal,
      logger: this.logger,
    }
  }

  getLogger(): AxLoggerFunction {
    return this.logger
  }

  getModelList(): AxAIModelList | undefined {
    const models: AxAIModelList = []
    for (const model of this.models ?? []) {
      if (model.isInternal) {
        continue
      }

      if ('model' in model && model.model) {
        models.push({
          key: model.key,
          description: model.description,
          model: model.model as string,
        })
      }

      if ('embedModel' in model && model.embedModel) {
        models.push({
          key: model.key,
          description: model.description,
          embedModel: model.embedModel as string,
        })
      }
    }

    return models
  }

  getName(): string {
    return this.name
  }

  getFeatures(model?: TModel): AxAIFeatures {
    return typeof this.supportFor === 'function'
      ? this.supportFor(model ?? this.defaults.model)
      : this.supportFor
  }

  getLastUsedChatModel(): TModel | undefined {
    return this.lastUsedChatModel
  }

  getLastUsedEmbedModel(): TEmbedModel | undefined {
    return this.lastUsedEmbedModel
  }

  getLastUsedModelConfig(): AxModelConfig | undefined {
    return this.lastUsedModelConfig
  }

  // Method to calculate percentiles
  private calculatePercentile(
    samples: readonly number[],
    percentile: number
  ): number {
    if (samples.length === 0) return 0
    const sorted = [...samples].sort((a, b) => a - b)
    const index = Math.ceil((percentile / 100) * sorted.length) - 1
    return sorted[index] ?? 0
  }

  // Method to update latency metrics
  private updateLatencyMetrics(type: 'chat' | 'embed', duration: number): void {
    const metrics = this.metrics.latency[type]
    metrics.samples.push(duration)

    // Keep only last 1000 samples to prevent memory issues
    if (metrics.samples.length > 1000) {
      metrics.samples.shift()
    }

    // Update statistics
    metrics.mean =
      metrics.samples.reduce((a, b) => a + b, 0) / metrics.samples.length
    metrics.p95 = this.calculatePercentile(metrics.samples, 95)
    metrics.p99 = this.calculatePercentile(metrics.samples, 99)
  }

  // Method to update error metrics
  private updateErrorMetrics(type: 'chat' | 'embed', isError: boolean): void {
    const metrics = this.metrics.errors[type]
    metrics.total++
    if (isError) {
      metrics.count++
    }
    metrics.rate = metrics.count / metrics.total
  }

  // Public method to get metrics
  public getMetrics(): AxAIServiceMetrics {
    return structuredClone(this.metrics)
  }

  async chat(
    req: Readonly<AxChatRequest<TModel>>,
    options?: Readonly<
      AxAIPromptConfig & AxAIServiceActionOptions<TModel, TEmbedModel>
    >
  ): Promise<AxChatResponse | ReadableStream<AxChatResponse>> {
    const startTime = performance.now()
    let isError = false

    try {
      const result = await this._chat1(req, options)
      return result
    } catch (error) {
      isError = true
      throw error
    } finally {
      const duration = performance.now() - startTime
      this.updateLatencyMetrics('chat', duration)
      this.updateErrorMetrics('chat', isError)
    }
  }

  private async _chat1(
    req: Readonly<AxChatRequest<TModel>>,
    options?: Readonly<
      AxAIPromptConfig & AxAIServiceActionOptions<TModel, TEmbedModel>
    >
  ): Promise<AxChatResponse | ReadableStream<AxChatResponse>> {
    const model = this.getModel(req.model) ?? req.model ?? this.defaults.model

    const modelConfig = {
      ...this.aiImpl.getModelConfig(),
      ...req.modelConfig,
    }

    // Check for thinkingTokenBudget support
    if (
      options?.thinkingTokenBudget &&
      !this.getFeatures(model).hasThinkingBudget
    ) {
      throw new Error(
        `Model ${model as string} does not support thinkingTokenBudget.`
      )
    }

    // Check for showThoughts support
    if (options?.showThoughts && !this.getFeatures(model).hasShowThoughts) {
      throw new Error(`Model ${model as string} does not support showThoughts.`)
    }

    // stream is true by default unless explicitly set to false
    modelConfig.stream =
      (options?.stream !== undefined ? options.stream : modelConfig.stream) ??
      true

    const canStream = this.getFeatures(model).streaming
    if (!canStream) {
      modelConfig.stream = false
    }

    if (this.tracer) {
      return await this.tracer.startActiveSpan(
        'AI Chat Request',
        {
          kind: SpanKind.SERVER,
          attributes: {
            [axSpanAttributes.LLM_SYSTEM]: this.name,
            [axSpanAttributes.LLM_OPERATION_NAME]: 'chat',
            [axSpanAttributes.LLM_REQUEST_MODEL]: model as string,
            [axSpanAttributes.LLM_REQUEST_MAX_TOKENS]:
              modelConfig.maxTokens ?? 'Not set',
            [axSpanAttributes.LLM_REQUEST_TEMPERATURE]: modelConfig.temperature,
            [axSpanAttributes.LLM_REQUEST_TOP_P]: modelConfig.topP ?? 'Not set',
            [axSpanAttributes.LLM_REQUEST_TOP_K]: modelConfig.topK ?? 'Not set',
            [axSpanAttributes.LLM_REQUEST_FREQUENCY_PENALTY]:
              modelConfig.frequencyPenalty ?? 'Not set',
            [axSpanAttributes.LLM_REQUEST_PRESENCE_PENALTY]:
              modelConfig.presencePenalty ?? 'Not set',
            [axSpanAttributes.LLM_REQUEST_STOP_SEQUENCES]:
              modelConfig.stopSequences?.join(', ') ?? 'Not set',
            [axSpanAttributes.LLM_REQUEST_LLM_IS_STREAMING]:
              modelConfig.stream ?? 'Not set',
          },
        },
        options?.traceContext ?? context.active(),
        async (span) => {
          return await this._chat2(model, modelConfig, req, options, span)
        }
      )
    }
    return await this._chat2(model, modelConfig, req, options)
  }

  private cleanupFunctionSchema(
    fn: Readonly<NonNullable<AxChatRequest['functions']>[number]>
  ): NonNullable<AxChatRequest['functions']>[number] {
    const cleanFn = { ...fn }
    if (cleanFn.parameters) {
      const cleanParams = { ...cleanFn.parameters }

      // Remove empty required array
      if (
        Array.isArray(cleanParams.required) &&
        cleanParams.required.length === 0
      ) {
        // biome-ignore lint/performance/noDelete: <explanation>
        delete cleanParams.required
      }

      // Remove empty properties object
      if (
        cleanParams.properties &&
        Object.keys(cleanParams.properties).length === 0
      ) {
        // biome-ignore lint/performance/noDelete: <explanation>
        delete cleanParams.properties
      }

      // After cleaning, remove the entire parameters object if it's effectively empty
      // i.e., either no keys left or just { type: 'object' } remaining.
      if (
        Object.keys(cleanParams).length === 0 ||
        (Object.keys(cleanParams).length === 1 && cleanParams.type === 'object')
      ) {
        // biome-ignore lint/performance/noDelete: <explanation>
        delete cleanFn.parameters
      } else {
        cleanFn.parameters = cleanParams
      }
    }
    return cleanFn
  }

  private async _chat2(
    model: TModel,
    modelConfig: Readonly<AxModelConfig>,
    chatReq: Readonly<Omit<AxChatRequest<TModel>, 'modelConfig'>>,
    options?: Readonly<AxAIServiceActionOptions<TModel, TEmbedModel>>,
    span?: Span
  ): Promise<AxChatResponse | ReadableStream<AxChatResponse>> {
    if (!this.aiImpl.createChatReq) {
      throw new Error('generateChatReq not implemented')
    }

    const debug = options?.debug ?? this.debug

    let functions: NonNullable<AxChatRequest['functions']> | undefined

    if (chatReq.functions && chatReq.functions.length > 0) {
      functions = chatReq.functions.map((fn) => this.cleanupFunctionSchema(fn))
    }

    // Validate chat prompt for empty content
    validateChatPrompt(chatReq.chatPrompt)

    const req = {
      ...chatReq,
      model,
      functions,
      modelConfig,
    }

    // Store the last used model and config
    this.lastUsedChatModel = model
    this.lastUsedModelConfig = modelConfig

    const fn = async () => {
      const [apiConfig, reqValue] = this.aiImpl.createChatReq(
        req,
        options as AxAIPromptConfig
      )

      if (span?.isRecording()) {
        setChatRequestEvents(chatReq, span, this.excludeContentFromTrace)
      }

      const res = await apiCall(
        {
          name: apiConfig.name,
          url: this.apiURL,
          headers: await this.buildHeaders(apiConfig.headers),
          stream: modelConfig.stream,
          timeout: this.timeout,
          debug,
          fetch: this.fetch,
          span,
          abortSignal: options?.abortSignal ?? this.abortSignal,
        },
        reqValue
      )
      return res
    }

    if (debug) {
      logChatRequest(
        req.chatPrompt,
        options?.debugHideSystemPrompt,
        options?.logger ?? this.logger
      )
    }

    const rt = options?.rateLimiter ?? this.rt
    const rv = rt ? await rt(fn, { modelUsage: this.modelUsage }) : await fn()

    if (modelConfig.stream) {
      if (!this.aiImpl.createChatStreamResp) {
        throw new Error('generateChatResp not implemented')
      }

      const respFn = this.aiImpl.createChatStreamResp.bind(this)
      const wrappedRespFn =
        (state: object) => (resp: Readonly<TChatResponseDelta>) => {
          const res = respFn(resp, state)
          res.sessionId = options?.sessionId

          if (!res.modelUsage) {
            res.modelUsage = {
              ai: this.name,
              model: model as string,
              tokens: this.aiImpl.getTokenUsage(),
            }
          }
          this.modelUsage = res.modelUsage

          if (span?.isRecording()) {
            setChatResponseEvents(res, span, this.excludeContentFromTrace)
          }

          if (debug) {
            logResponse(res, options?.logger ?? this.logger)
          }
          return res
        }

      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      const doneCb = async (_values: readonly AxChatResponse[]) => {
        if (debug) {
          const logger = options?.logger ?? this.logger
          logger('', { tags: ['responseEnd'] })
        }
        if (span?.isRecording()) {
          span.end()
        }
      }

      const st = (rv as ReadableStream<TChatResponseDelta>).pipeThrough(
        new RespTransformStream<TChatResponseDelta, AxChatResponse>(
          wrappedRespFn({}),
          doneCb
        )
      )
      return st
    }

    if (!this.aiImpl.createChatResp) {
      throw new Error('generateChatResp not implemented')
    }
    const res = this.aiImpl.createChatResp(rv as TChatResponse)
    res.sessionId = options?.sessionId

    if (!res.modelUsage) {
      const tokenUsage = this.aiImpl.getTokenUsage()
      if (tokenUsage) {
        res.modelUsage = {
          ai: this.name,
          model: model as string,
          tokens: tokenUsage,
        }
      }
    }

    if (res.modelUsage) {
      this.modelUsage = res.modelUsage
    }

    if (span?.isRecording()) {
      setChatResponseEvents(res, span, this.excludeContentFromTrace)
      span.end()
    }

    if (debug) {
      logResponse(res, options?.logger ?? this.logger)
    }

    if (debug) {
      this.logger('', { tags: ['responseEnd'] })
    }

    return res
  }

  async embed(
    req: Readonly<AxEmbedRequest<TEmbedModel>>,
    options?: Readonly<AxAIServiceActionOptions<TModel, TEmbedModel>>
  ): Promise<AxEmbedResponse> {
    const startTime = performance.now()
    let isError = false

    try {
      return this._embed1(req, options)
    } catch (error) {
      isError = true
      throw error
    } finally {
      const duration = performance.now() - startTime
      this.updateLatencyMetrics('embed', duration)
      this.updateErrorMetrics('embed', isError)
    }
  }

  private async _embed1(
    req: Readonly<AxEmbedRequest<TEmbedModel>>,
    options?: Readonly<AxAIServiceActionOptions<TModel, TEmbedModel>>
  ): Promise<AxEmbedResponse> {
    const embedModel =
      this.getEmbedModel(req.embedModel) ??
      req.embedModel ??
      this.defaults.embedModel

    if (!embedModel) {
      throw new Error('No embed model defined')
    }

    if (this.tracer) {
      await this.tracer?.startActiveSpan(
        'AI Embed Request',
        {
          kind: SpanKind.SERVER,
          attributes: {
            [axSpanAttributes.LLM_SYSTEM]: this.name,
            [axSpanAttributes.LLM_OPERATION_NAME]: 'embeddings',
            [axSpanAttributes.LLM_REQUEST_MODEL]: embedModel as string,
          },
        },
        options?.traceContext ?? context.active(),
        async (span) => {
          try {
            return await this._embed2(embedModel, req, options, span)
          } finally {
            span.end()
          }
        }
      )
    }
    return this._embed2(embedModel, req, options)
  }

  private async _embed2(
    embedModel: TEmbedModel,
    embedReq: Readonly<AxEmbedRequest<TEmbedModel>>,
    options?: Readonly<AxAIServiceActionOptions<TModel, TEmbedModel>>,
    span?: Span
  ): Promise<AxEmbedResponse> {
    if (!this.aiImpl.createEmbedReq) {
      throw new Error('generateEmbedReq not implemented')
    }
    if (!this.aiImpl.createEmbedResp) {
      throw new Error('generateEmbedResp not implemented')
    }

    const debug = options?.debug ?? this.debug

    const req = {
      ...embedReq,
      embedModel,
    }

    // Store the last used embed model
    this.lastUsedEmbedModel = embedModel

    const fn = async () => {
      const [apiConfig, reqValue] = this.aiImpl.createEmbedReq!(req)

      const res = await apiCall(
        {
          name: apiConfig.name,
          url: this.apiURL,
          headers: await this.buildHeaders(apiConfig.headers),
          debug,
          fetch: this.fetch,
          timeout: this.timeout,
          span,
          abortSignal: options?.abortSignal ?? this.abortSignal,
        },
        reqValue
      )
      return res
    }

    const resValue = this.rt
      ? await this.rt(fn, { modelUsage: this.embedModelUsage })
      : await fn()
    const res = this.aiImpl.createEmbedResp!(resValue as TEmbedResponse)

    res.sessionId = options?.sessionId

    if (!res.modelUsage) {
      res.modelUsage = {
        ai: this.name,
        model: embedModel as string,
        tokens: this.aiImpl.getTokenUsage(),
      }
    }
    this.embedModelUsage = res.modelUsage

    if (span?.isRecording() && res.modelUsage?.tokens) {
      span.addEvent(axSpanEvents.GEN_AI_USAGE, {
        [axSpanAttributes.LLM_USAGE_INPUT_TOKENS]:
          res.modelUsage.tokens.promptTokens,
        [axSpanAttributes.LLM_USAGE_OUTPUT_TOKENS]:
          res.modelUsage.tokens.completionTokens ?? 0,
        [axSpanAttributes.LLM_USAGE_TOTAL_TOKENS]:
          res.modelUsage.tokens.totalTokens,
      })
    }

    span?.end()
    return res
  }

  private async buildHeaders(
    headers: Record<string, string> = {}
  ): Promise<Record<string, string>> {
    return { ...headers, ...(await this.headers()) }
  }

  private getModelByKey(
    modelName?: TModel | TEmbedModel
  ): AxAIInputModelList<TModel, TEmbedModel>[number] | undefined {
    if (!modelName) {
      return undefined
    }
    const item = this.models?.find((v) => v.key === modelName)
    return item
  }

  private getModel(modelName?: TModel): TModel | undefined {
    const item = this.getModelByKey(modelName)
    return item && 'model' in item ? item.model : undefined
  }

  private getEmbedModel(modelName?: TEmbedModel): TEmbedModel | undefined {
    const item = this.getModelByKey(modelName)
    return item && 'embedModel' in item ? item.embedModel : undefined
  }
}

export function setChatRequestEvents(
  req: Readonly<AxChatRequest<unknown>>,
  span: Span,
  excludeContentFromTrace?: boolean
): void {
  const userMessages: string[] = []

  if (
    req.chatPrompt &&
    Array.isArray(req.chatPrompt) &&
    req.chatPrompt.length > 0
  ) {
    for (const prompt of req.chatPrompt) {
      switch (prompt.role) {
        case 'system':
          if (prompt.content) {
            const eventData: { content?: string } = {}
            if (!excludeContentFromTrace) {
              eventData.content = prompt.content
            }
            span.addEvent(axSpanEvents.GEN_AI_SYSTEM_MESSAGE, eventData)
          }
          break
        case 'user':
          if (typeof prompt.content === 'string') {
            userMessages.push(prompt.content)
          } else if (Array.isArray(prompt.content)) {
            for (const part of prompt.content) {
              if (part.type === 'text') {
                userMessages.push(part.text)
              }
            }
          }
          break
        case 'assistant':
          const functionCalls = prompt.functionCalls?.map((call) => {
            return {
              id: call.id,
              type: call.type,
              function: call.function.name,
              arguments: call.function.params,
            }
          })

          if (functionCalls && functionCalls.length > 0) {
            const eventData: { content?: string; function_calls: string } = {
              function_calls: JSON.stringify(functionCalls, null, 2),
            }
            if (!excludeContentFromTrace && prompt.content) {
              eventData.content = prompt.content
            }
            span.addEvent(axSpanEvents.GEN_AI_ASSISTANT_MESSAGE, eventData)
          } else if (prompt.content) {
            const eventData: { content?: string } = {}
            if (!excludeContentFromTrace) {
              eventData.content = prompt.content
            }
            span.addEvent(axSpanEvents.GEN_AI_ASSISTANT_MESSAGE, eventData)
          }
          break

        case 'function':
          const eventData: { content?: string; id: string } = {
            id: prompt.functionId,
          }
          if (!excludeContentFromTrace) {
            eventData.content = prompt.result
          }
          span.addEvent(axSpanEvents.GEN_AI_TOOL_MESSAGE, eventData)
          break
      }
    }
  }

  // Always add user message event, even if empty
  const userEventData: { content?: string } = {}
  if (!excludeContentFromTrace) {
    userEventData.content = userMessages.join('\n')
  }
  span.addEvent(axSpanEvents.GEN_AI_USER_MESSAGE, userEventData)
}

export function setChatResponseEvents(
  res: Readonly<AxChatResponse>,
  span: Span,
  excludeContentFromTrace?: boolean
) {
  if (res.modelUsage?.tokens) {
    const thoughTokens = res.modelUsage.tokens.thoughtsTokens
      ? {
          [axSpanAttributes.LLM_USAGE_THOUGHTS_TOKENS]:
            res.modelUsage.tokens.thoughtsTokens,
        }
      : {}
    span.addEvent(axSpanEvents.GEN_AI_USAGE, {
      [axSpanAttributes.LLM_USAGE_INPUT_TOKENS]:
        res.modelUsage.tokens.promptTokens,
      [axSpanAttributes.LLM_USAGE_OUTPUT_TOKENS]:
        res.modelUsage.tokens.completionTokens ?? 0,
      [axSpanAttributes.LLM_USAGE_TOTAL_TOKENS]:
        res.modelUsage.tokens.totalTokens,
      ...thoughTokens,
    })
  }

  if (!res.results) {
    return
  }

  for (let index = 0; index < res.results.length; index++) {
    const result = res.results[index]
    if (!result) {
      continue
    }

    // Skip empty results that have no meaningful content to avoid empty GEN_AI_CHOICE events
    if (
      !result.content &&
      !result.thought &&
      !result.functionCalls?.length &&
      !result.finishReason
    ) {
      continue
    }

    const toolCalls = result.functionCalls?.map((call) => {
      return {
        id: call.id,
        type: call.type,
        function: call.function.name,
        arguments: call.function.params,
      }
    })

    let message: { content?: string; tool_calls?: unknown[] } = {}

    if (toolCalls && toolCalls.length > 0) {
      if (!excludeContentFromTrace) {
        message.content = result.content
      }
      message.tool_calls = toolCalls
    } else {
      if (!excludeContentFromTrace) {
        message.content = result.content ?? ''
      }
    }

    span.addEvent(axSpanEvents.GEN_AI_CHOICE, {
      finish_reason: result.finishReason,
      index,
      message: JSON.stringify(message, null, 2),
    })
  }
}

export function validateAxMessageArray<T>(values: T[]): void {
  // Validate AxMessage array items
  for (let i = 0; i < values.length; i++) {
    const message = values[i]
    if (!message || typeof message !== 'object') {
      throw new Error(
        `AxMessage array validation failed: Item at index ${i} is not a valid message object`
      )
    }
    if (
      'content' in message &&
      typeof message.content === 'string' &&
      message.content.trim() === ''
    ) {
      throw new Error(
        `AxMessage array validation failed: Item at index ${i} has empty content`
      )
    }
  }
}

function validateChatPrompt(
  chatPrompt: Readonly<AxChatRequest['chatPrompt']>
): void {
  // Validate chat prompt for empty content
  for (let i = 0; i < chatPrompt.length; i++) {
    const message = chatPrompt[i]
    if (
      message &&
      'content' in message &&
      typeof message.content === 'string' &&
      message.content.trim() === ''
    ) {
      throw new Error(
        `Chat prompt validation failed: Message at index ${i} has empty content`
      )
    }
  }
}

function validateModels<TModel, TEmbedModel>(
  models: Readonly<AxAIInputModelList<TModel, TEmbedModel>>
): void {
  // Validate duplicate keys in models.
  const keys = new Set<string>()
  for (const model of models) {
    if (keys.has(model.key)) {
      throw new Error(
        `Duplicate model key detected: "${model.key}". Each model key must be unique.`
      )
    }
    keys.add(model.key)
  }
}



================================================
FILE: src/ax/ai/debug.ts
================================================
import { ColorLog } from '../util/log.js'

import type {
  AxChatRequest,
  AxChatResponse,
  AxLoggerFunction,
  AxLoggerTag,
} from './types.js'

const colorLog = new ColorLog()

// Default output function that writes to stdout
const defaultOutput = (message: string): void => {
  process.stdout.write(message)
}

// Factory function to create a default logger with customizable output
export const createDefaultLogger = (
  output: (message: string) => void = defaultOutput
): AxLoggerFunction => {
  return (message: string, options?: { tags?: AxLoggerTag[] }) => {
    const tags = options?.tags ?? []
    let formattedMessage = message

    // Apply styling based on semantic tags
    if (tags.includes('error')) {
      formattedMessage = colorLog.red(formattedMessage)
    } else if (tags.includes('success') || tags.includes('responseContent')) {
      formattedMessage = colorLog.greenBright(formattedMessage)
    } else if (tags.includes('functionName')) {
      formattedMessage = colorLog.whiteBright(formattedMessage)
    } else if (
      tags.includes('functionArg') ||
      tags.includes('systemContent') ||
      tags.includes('assistantContent')
    ) {
      formattedMessage = colorLog.blueBright(formattedMessage)
    } else if (tags.includes('warning') || tags.includes('discovery')) {
      formattedMessage = colorLog.yellow(formattedMessage)
    }

    // Apply semantic spacing
    if (
      tags.includes('responseStart') ||
      tags.includes('systemStart') ||
      tags.includes('userStart')
    ) {
      formattedMessage = `\n${formattedMessage}`
    } else if (
      tags.includes('responseEnd') ||
      tags.includes('systemEnd') ||
      tags.includes('userEnd')
    ) {
      formattedMessage = `${formattedMessage}\n`
    } else if (tags.includes('assistantStart')) {
      formattedMessage = `\n${formattedMessage}\n`
    } else if (tags.includes('error')) {
      formattedMessage = `\n${formattedMessage}\n`
    } else if (tags.includes('functionEnd')) {
      formattedMessage = `${formattedMessage}\n`
    }

    output(formattedMessage)
  }
}

// Factory function to create a text-only logger (no colors) with customizable output
export const createDefaultTextLogger = (
  output: (message: string) => void = defaultOutput
): AxLoggerFunction => {
  return (message: string, options?: { tags?: AxLoggerTag[] }) => {
    const tags = options?.tags ?? []
    let formattedMessage = message

    // Apply semantic spacing only (no colors)
    if (
      tags.includes('responseStart') ||
      tags.includes('systemStart') ||
      tags.includes('userStart')
    ) {
      formattedMessage = `\n${formattedMessage}`
    } else if (
      tags.includes('responseEnd') ||
      tags.includes('systemEnd') ||
      tags.includes('userEnd')
    ) {
      formattedMessage = `${formattedMessage}\n`
    } else if (tags.includes('assistantStart')) {
      formattedMessage = `\n${formattedMessage}\n`
    } else if (tags.includes('error')) {
      formattedMessage = `\n${formattedMessage}\n`
    } else if (tags.includes('functionEnd')) {
      formattedMessage = `${formattedMessage}\n`
    }

    output(formattedMessage)
  }
}

// Default logger instance
const defaultLogger: AxLoggerFunction = createDefaultLogger()

const formatChatMessage = (
  msg: AxChatRequest['chatPrompt'][number],
  hideContent?: boolean,
  hideSystemPrompt?: boolean
) => {
  switch (msg.role) {
    case 'system':
      if (hideSystemPrompt) {
        return ''
      }
      return `\nSystem:\n${msg.content}`
    case 'function':
      return `\nFunction Result:\n${msg.result}`
    case 'user': {
      if (typeof msg.content === 'string') {
        return `\nUser:\n${msg.content}`
      }
      const items = msg.content.map((v) => {
        switch (v.type) {
          case 'text':
            return v.text
          case 'image':
            return `(Image, ${v.mimeType}) ${v.image.substring(0, 10)}`
          default:
            throw new Error('Invalid content type')
        }
      })
      return `\nUser:\n${items.join('\n')}`
    }
    case 'assistant': {
      if (msg.functionCalls) {
        const fns = msg.functionCalls?.map(({ function: fn }) => {
          const args =
            typeof fn.params !== 'string'
              ? JSON.stringify(fn.params, null, 2)
              : fn.params
          return `${fn.name}(${args})`
        })
        return `\nFunctions:\n${fns.join('\n')}`
      }
      return `\nAssistant:\n${hideContent ? '' : (msg.content ?? '<empty>')}`
    }
    default:
      throw new Error('Invalid role')
  }
}

export const logChatRequestMessage = (
  msg: AxChatRequest['chatPrompt'][number],
  hideSystemPrompt?: boolean,
  logger: AxLoggerFunction = defaultLogger
) => {
  const formattedMessage = formatChatMessage(msg, false, hideSystemPrompt)
  if (formattedMessage) {
    const tags: AxLoggerTag[] =
      msg.role === 'system'
        ? ['systemStart', 'systemContent']
        : msg.role === 'function'
          ? ['functionName']
          : msg.role === 'user'
            ? ['userStart', 'userContent']
            : []
    logger(formattedMessage, { tags })
  }
  logger('Assistant:', { tags: ['assistantStart'] })
}

export const logChatRequest = (
  chatPrompt: Readonly<AxChatRequest['chatPrompt']>,
  hideSystemPrompt?: boolean,
  logger: AxLoggerFunction = defaultLogger
) => {
  for (const msg of chatPrompt ?? []) {
    const formattedMessage = formatChatMessage(msg, false, hideSystemPrompt)
    if (formattedMessage) {
      const tags: AxLoggerTag[] =
        msg.role === 'system'
          ? ['systemContent']
          : msg.role === 'function'
            ? ['functionName']
            : msg.role === 'user'
              ? ['userContent']
              : []
      logger(formattedMessage, { tags })
    }
  }

  logger('Assistant:', { tags: ['assistantStart'] })
}

export const logResponseResult = (
  r: Readonly<AxChatResponse['results'][number]>,
  logger: AxLoggerFunction = defaultLogger
) => {
  if (r.content) {
    logger(r.content, { tags: ['responseContent'] })
  }

  if (r.functionCalls && r.functionCalls.length > 0) {
    for (const [i, f] of r.functionCalls.entries()) {
      if (f.function.name) {
        logger(`[${i + 1}] ${f.function.name}`, {
          tags: ['functionName'],
        })
      }
      if (f.function.params) {
        const params =
          typeof f.function.params === 'string'
            ? f.function.params
            : JSON.stringify(f.function.params, null, 2)
        logger(params, { tags: ['functionArg'] })
      }
    }
    // Add function end marker for the last function
    logger('', { tags: ['functionEnd'] })
  }
}

export const logResponse = (
  resp: Readonly<AxChatResponse>,
  logger: AxLoggerFunction = defaultLogger
) => {
  if (!resp.results) {
    return
  }
  for (const r of resp.results) {
    logResponseResult(r, logger)
  }
}

export const logResponseDelta = (
  delta: string,
  logger: AxLoggerFunction = defaultLogger
) => {
  logger(delta, { tags: ['responseContent'] })
}



================================================
FILE: src/ax/ai/logger.test.ts
================================================
import { describe, expect, it, vi } from 'vitest'

import { AxMockAIService } from './mock/api.js'

describe('Logger functionality', () => {
  it('should use custom logger in AI service', () => {
    const mockLogger = vi.fn()
    const ai = new AxMockAIService({
      options: {
        debug: true,
        logger: mockLogger,
      },
    })

    const logger = ai.getLogger()
    logger('test message')

    expect(mockLogger).toHaveBeenCalledWith('test message')
  })

  it('should use default logger when none provided', () => {
    const ai = new AxMockAIService()
    const logger = ai.getLogger()

    // Should not throw and should be a function
    expect(typeof logger).toBe('function')
  })

  it('should pass logger through options', () => {
    const mockLogger = vi.fn()
    const ai = new AxMockAIService()

    ai.setOptions({ logger: mockLogger })
    const logger = ai.getLogger()
    logger('test message')

    expect(mockLogger).toHaveBeenCalledWith('test message')
  })
})



================================================
FILE: src/ax/ai/multiservice.test.ts
================================================
import { describe, expect, it, vi } from 'vitest'

import { AxMultiServiceRouter } from './multiservice.js'
import type {
  AxAIService,
  AxAIServiceMetrics,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxEmbedRequest,
  AxEmbedResponse,
  AxLoggerFunction,
  AxModelConfig,
} from './types.js'

// Mock logger function for tests
const mockLogger: AxLoggerFunction = (message: string) => console.log(message)

//
// Create two dummy AI services.
//

const metrics: AxAIServiceMetrics = {
  latency: {
    chat: { mean: 10, p95: 10, p99: 10, samples: [] },
    embed: { mean: 10, p95: 10, p99: 10, samples: [] },
  },
  errors: {
    chat: { count: 1, rate: 0, total: 1 },
    embed: { count: 1, rate: 0, total: 1 },
  },
}

type AxAIServiceLastUsed = {
  chatModel?: string
  embedModel?: string
  modelConfig?: AxModelConfig
}

const testModelConfig: AxModelConfig = {
  maxTokens: 1000,
  temperature: 0.5,
  topP: 0.9,
  topK: 10,
  presencePenalty: 0.0,
  frequencyPenalty: 0.0,
}

const serviceALastUsed: AxAIServiceLastUsed = {
  modelConfig: testModelConfig,
}

const serviceA: AxAIService<string, string> = {
  getId: () => 'serviceA',
  getName: () => 'Service A',
  getFeatures: () => ({ functions: false, streaming: false }),
  getModelList: () => [
    {
      key: 'serviceA-modelA',
      model: 'ModelA',
      description: 'First service A model',
    },
    {
      key: 'serviceA-modelB',
      model: 'ModelB',
      description: 'Second service A model',
    },
  ],
  getMetrics: () => metrics,
  getLogger: () => (message: string) => console.log(message),
  getLastUsedChatModel: function (): string | undefined {
    return serviceALastUsed.chatModel
  },
  getLastUsedEmbedModel: function (): string | undefined {
    return serviceALastUsed.embedModel
  },
  getLastUsedModelConfig: function (): AxModelConfig | undefined {
    return undefined
  },
  chat: async (
    req: Readonly<AxChatRequest<string>>
  ): Promise<AxChatResponse> => {
    serviceALastUsed.chatModel = req.model
    return { results: [{ content: `model ${req.model} from Service A` }] }
  },
  embed: async (): Promise<AxEmbedResponse> => {
    serviceALastUsed.embedModel = 'test-model'
    return {
      embeddings: [[1, 2, 3]],
      modelUsage: {
        ai: 'test-ai',
        model: 'test-model',
        tokens: {
          promptTokens: 5,
          completionTokens: 5,
          totalTokens: 10,
        },
      },
    }
  },
  setOptions: () => {},
  getOptions: () => ({ optionFrom: 'A' }) as AxAIServiceOptions,
}

const serviceBLastUsed: AxAIServiceLastUsed = {
  modelConfig: testModelConfig,
}

const serviceB: AxAIService<string, string> = {
  getId: () => 'serviceB',
  getName: () => 'Service B',
  getFeatures: () => ({ functions: true, streaming: true }),
  getModelList: () => [
    {
      key: 'serviceB-modelA',
      model: 'ModelA',
      description: 'First service B model',
    },
    {
      key: 'serviceB-modelB',
      model: 'ModelB',
      description: 'Second service B model',
    },
  ],
  getLogger: () => (message: string) => console.log(message),
  getLastUsedChatModel: function (): string | undefined {
    return serviceBLastUsed.chatModel
  },
  getLastUsedEmbedModel: function (): string | undefined {
    return serviceBLastUsed.embedModel
  },
  getLastUsedModelConfig: function (): AxModelConfig | undefined {
    return serviceBLastUsed.modelConfig
  },
  getMetrics: () => metrics,
  chat: async (
    req: Readonly<AxChatRequest<string>>
  ): Promise<AxChatResponse> => {
    serviceBLastUsed.chatModel = req.model
    return { results: [{ content: `model ${req.model} from Service B` }] }
  },
  embed: async (): Promise<AxEmbedResponse> => {
    serviceBLastUsed.embedModel = 'test-model'
    return {
      embeddings: [[4, 5, 6]],
      modelUsage: {
        ai: 'test-ai',
        model: 'test-model',
        tokens: {
          promptTokens: 10,
          completionTokens: 10,
          totalTokens: 20,
        },
      },
    }
  },
  setOptions: () => {},
  getOptions: () => ({ optionFrom: 'B' }) as AxAIServiceOptions,
}

const serviceC: AxAIService<string, string> = {
  getId: () => 'serviceC',
  getName: () => 'Service C',
  getFeatures: () => ({ functions: false, streaming: false }),
  getModelList: () => [],
  getMetrics: () => metrics,
  getLogger: () => (message: string) => console.log(message),
  chat: async (
    req: Readonly<AxChatRequest<string>>
  ): Promise<AxChatResponse> => {
    return { results: [{ content: `model ${req.model} from Service C` }] }
  },
  embed: async (): Promise<AxEmbedResponse> => {
    return {
      embeddings: [[4, 5, 6]],
      modelUsage: {
        ai: 'test-ai',
        model: 'test-model',
        tokens: {
          promptTokens: 10,
          completionTokens: 10,
          totalTokens: 20,
        },
      },
    }
  },
  setOptions: () => {},
  getOptions: () => ({ optionFrom: 'C' }) as AxAIServiceOptions,
  getLastUsedChatModel: function (): string | undefined {
    return undefined
  },
  getLastUsedEmbedModel: function (): string | undefined {
    return undefined
  },
  getLastUsedModelConfig: function (): AxModelConfig | undefined {
    return undefined
  },
}

describe('AxMultiServiceRouter', () => {
  it('aggregates the model list from all services', () => {
    const router = new AxMultiServiceRouter([
      serviceA,
      serviceB,
      {
        key: 'serviceC',
        service: serviceC,
        description: 'Service C',
      },
    ])
    // Manually add model for key-based service after construction
    router['services'].set('serviceC', {
      service: serviceC,
      description: 'Service C',
      model: 'modelC',
    })

    const list = router.getModelList()
    expect(list).toHaveLength(5)
    expect(list?.map((m) => m.key)).toContain('serviceA-modelA')
    expect(list?.map((m) => m.key)).toContain('serviceA-modelB')
    expect(list?.map((m) => m.key)).toContain('serviceB-modelA')
    expect(list?.map((m) => m.key)).toContain('serviceB-modelB')
    expect(list?.map((m) => m.key)).toContain('serviceC')
  })

  it('delegates chat calls with the correct model parameter for key‐based and non‐key–based services', async () => {
    // Create a dummy key–based service.
    const dummyKeyServiceChat = vi.fn(
      async (req: Readonly<AxChatRequest<string>>) => {
        // Echo back the model value received for verification.
        return { results: [{ content: req.model }] }
      }
    )
    const dummyKeyServiceEmbed = vi.fn(
      async (req: Readonly<AxEmbedRequest>) => {
        return { embeddings: [[req.embedModel?.length ?? 0]] }
      }
    )
    const dummyKeyService = {
      getId: () => 'dummy-key-service',
      getName: () => 'Dummy Key Service',
      getFeatures: () => ({ functions: false, streaming: false }),
      getModelList: () => [],
      chat: dummyKeyServiceChat,
      embed: dummyKeyServiceEmbed,
      setOptions: () => {},
      getOptions: () => ({}),
      getLogger: () => mockLogger,
      getMetrics: () => metrics,
      getLastUsedChatModel: function (): string | undefined {
        return undefined
      },
      getLastUsedEmbedModel: function (): string | undefined {
        return undefined
      },
      getLastUsedModelConfig: function (): AxModelConfig | undefined {
        return undefined
      },
    }
    const keyBasedItem = {
      key: 'A',
      service: dummyKeyService,
      description: 'Key based service',
    }

    // Create a dummy non–key–based service.
    const dummyNonKeyServiceChat = vi.fn(
      async (req: Readonly<AxChatRequest<string>>) => {
        return { results: [{ content: req.model }] }
      }
    )
    const dummyNonKeyServiceEmbed = vi.fn(
      async (req: Readonly<AxEmbedRequest>) => {
        return { embeddings: [[req.embedModel?.length ?? 0]] }
      }
    )
    const dummyNonKeyService = {
      getId: () => 'dummy-non-key-service',
      getName: () => 'Dummy Non-Key Service',
      getFeatures: () => ({ functions: true, streaming: true }),
      getModelList: () => [
        { key: 'B', description: 'Non-key model', model: 'modelB' },
      ],
      chat: dummyNonKeyServiceChat,
      embed: dummyNonKeyServiceEmbed,
      setOptions: () => {},
      getOptions: () => ({}),
      getLogger: () => mockLogger,
      getMetrics: () => metrics,
      getLastUsedChatModel: function (): string | undefined {
        return 'modelB'
      },
      getLastUsedEmbedModel: function (): string | undefined {
        return undefined
      },
      getLastUsedModelConfig: function (): AxModelConfig | undefined {
        return {
          maxTokens: 1000,
          temperature: 0.5,
          topP: 0.9,
          topK: 10,
          presencePenalty: 0.0,
          frequencyPenalty: 0.0,
        }
      },
    }

    // Create a router that wraps both services.
    const router = new AxMultiServiceRouter([keyBasedItem, dummyNonKeyService])

    // Manually add model for key-based service after construction
    router['services'].set('A', {
      service: dummyKeyService,
      description: 'Key based service',
      model: 'A', // This is crucial - the model must be set to the key for the delegation to work
    })

    // For key-based service, the router uses the "useDefaultModel" flag so that the delegated
    // chat call passes the request's model (which here is the key "A").
    const chatReqA: AxChatRequest<string> = {
      model: 'A',
      chatPrompt: [{ role: 'user', content: 'Hello from A' }],
    }
    await router.chat(chatReqA)
    expect(dummyKeyServiceChat).toHaveBeenCalledTimes(1)

    const chatCallArgA = dummyKeyServiceChat.mock
      .calls[0]![0] as AxChatRequest<string>
    expect(chatCallArgA.model).toBe('A')

    // For non–key–based service, getModelList produced an entry with key "B".
    const chatReqB: AxChatRequest<string> = {
      model: 'B',
      chatPrompt: [{ role: 'user', content: 'Hello from B' }],
    }
    await router.chat(chatReqB)
    expect(dummyNonKeyServiceChat).toHaveBeenCalledTimes(1)

    const chatCallArgB = dummyNonKeyServiceChat.mock
      .calls[0]![0] as AxChatRequest<string>
    // For non–key–based services, the delegated "model" is also the key ("B").
    expect(chatCallArgB.model).toBe('B')
  })

  it('delegates embed calls with the correct embed model parameter for key‐based and non‐key–based services', async () => {
    // Create a dummy key-based service.
    const dummyKeyServiceEmbed = vi.fn(
      async (req: Readonly<AxEmbedRequest>) => {
        return { embeddings: [[req.embedModel?.length ?? 0]] }
      }
    )
    const dummyKeyService = {
      getId: () => 'dummy-key-service',
      getName: () => 'Dummy Key Service',
      getFeatures: () => ({ functions: false, streaming: false }),
      getModelList: () => [],
      chat: async () => {
        return { results: [{ content: 'dummy key service' }] }
      },
      embed: dummyKeyServiceEmbed,
      setOptions: () => {},
      getOptions: () => ({}),
      getLogger: () => mockLogger,
      getMetrics: () => metrics,
      getLastUsedChatModel: function (): string | undefined {
        return undefined
      },
      getLastUsedEmbedModel: function (): string | undefined {
        return undefined
      },
      getLastUsedModelConfig: function (): AxModelConfig | undefined {
        return undefined
      },
    }
    const keyBasedItem = {
      key: 'A',
      service: dummyKeyService,
      description: 'Key based service',
    }

    // Create a dummy non-key-based service.
    const dummyNonKeyServiceEmbed = vi.fn(
      async (req: Readonly<AxEmbedRequest>) => {
        return { embeddings: [[req.embedModel?.length ?? 0]] }
      }
    )
    const dummyNonKeyService = {
      getId: () => 'dummy-non-key-service',
      getName: () => 'Dummy Non-Key Service',
      getFeatures: () => ({ functions: true, streaming: true }),
      getModelList: () => [
        { key: 'B', description: 'Non-key model', model: 'modelB' },
      ],
      chat: async () => {
        return { results: [{ content: 'dummy non-key service' }] }
      },
      getLastUsedChatModel: function (): string | undefined {
        return 'modelB'
      },
      getLastUsedEmbedModel: function (): string | undefined {
        return undefined
      },
      getLastUsedModelConfig: function (): AxModelConfig | undefined {
        return {
          maxTokens: 1000,
          temperature: 0.5,
          topP: 0.9,
          topK: 10,
          presencePenalty: 0.0,
          frequencyPenalty: 0.0,
        }
      },
      getMetrics: () => metrics,
      embed: dummyNonKeyServiceEmbed,
      setOptions: () => {},
      getOptions: () => ({}),
      getLogger: () => mockLogger,
    }

    // Create a router containing both services.
    const router = new AxMultiServiceRouter([keyBasedItem, dummyNonKeyService])

    // Manually add model for key-based service after construction
    router['services'].set('A', {
      service: dummyKeyService,
      description: 'Key based service',
      model: 'A', // This is crucial - the model must be set to the key for the delegation to work
    })

    // For key-based service, when embed is requested with embedModel "A", the delegated
    // call passes "A" as the embed model.
    const embedReqA: AxEmbedRequest<string> = {
      embedModel: 'A',
      texts: ['Embed text A'],
    }
    await router.embed(embedReqA)
    expect(dummyKeyServiceEmbed).toHaveBeenCalledTimes(1)

    const embedCallArgA = dummyKeyServiceEmbed.mock
      .calls[0]![0] as AxEmbedRequest<string>
    expect(embedCallArgA.embedModel).toBe('A')

    // For non–key–based service (the model list provided an entry with key "B"),
    // when embed is called with embedModel "B", the resulting delegate call passes "B".
    const embedReqB: AxEmbedRequest<string> = {
      embedModel: 'B',
      texts: ['Embed text B'],
    }
    await router.embed(embedReqB)
    expect(dummyNonKeyServiceEmbed).toHaveBeenCalledTimes(1)

    const embedCallArgB = dummyNonKeyServiceEmbed.mock
      .calls[0]![0] as AxEmbedRequest<string>
    expect(embedCallArgB.embedModel).toBe('B')
  })

  it('delegates chat calls for non-key-based services (real services)', async () => {
    const router = new AxMultiServiceRouter([serviceA, serviceB])
    const chatRespA: AxChatResponse = (await router.chat({
      model: 'serviceA-modelA',
      chatPrompt: [{ role: 'user', content: 'Hello' }],
    })) as AxChatResponse
    expect(chatRespA.results[0]!.content!).toBe(
      'model serviceA-modelA from Service A'
    )
    const chatRespB: AxChatResponse = (await router.chat({
      model: 'serviceB-modelB',
      chatPrompt: [{ role: 'user', content: 'Hello' }],
    })) as AxChatResponse
    expect(chatRespB.results[0]!.content!).toBe(
      'model serviceB-modelB from Service B'
    )
  })

  it('delegates embed calls for non-key-based services (real services)', async () => {
    const router = new AxMultiServiceRouter([serviceA, serviceB])
    const embedRespA = await router.embed({
      embedModel: 'serviceA-modelA',
      texts: ['Hello'],
    })
    expect(embedRespA.embeddings).toEqual([[1, 2, 3]])
    const embedRespB = await router.embed({
      embedModel: 'serviceB-modelB',
      texts: ['Hello'],
    })
    expect(embedRespB.embeddings).toEqual([[4, 5, 6]])
  })

  it('aggregates the model list including embedModel entries', () => {
    const embedOnlyServiceLastUsed: AxAIServiceLastUsed = {
      modelConfig: testModelConfig,
    }
    const embedOnlyService: AxAIService<string, string> = {
      getId: () => 'embed-only-service',
      getName: () => 'Embed Only Service',
      getFeatures: () => ({ functions: false, streaming: false }),
      getModelList: () => [
        {
          key: 'embed-only',
          description: 'Embed only model',
          embedModel: 'modelE',
        },
      ],
      getMetrics: () => metrics,
      chat: async () => {
        throw new Error('chat should not be called')
      },
      embed: async (): Promise<AxEmbedResponse> => {
        embedOnlyServiceLastUsed.embedModel = 'test-model'
        return {
          embeddings: [[42]],
          modelUsage: {
            ai: 'test-ai',
            model: 'test-model',
            tokens: {
              promptTokens: 0,
              completionTokens: 0,
              totalTokens: 0,
            },
          },
        }
      },
      getLastUsedChatModel: function (): string | undefined {
        return undefined
      },
      getLastUsedEmbedModel: function (): string | undefined {
        return embedOnlyServiceLastUsed.embedModel
      },
      getLastUsedModelConfig: function (): AxModelConfig | undefined {
        return embedOnlyServiceLastUsed.modelConfig
      },
      setOptions: () => {},
      getOptions: () => ({}),
      getLogger: () => mockLogger,
    }
    const router2 = new AxMultiServiceRouter([embedOnlyService])
    const list = router2.getModelList()
    expect(list).toHaveLength(1)
    expect(list[0]).toHaveProperty('key', 'embed-only')
    expect(list[0]).toHaveProperty('embedModel', 'modelE')
    expect(list[0]).not.toHaveProperty('model')
  })

  it('delegates embedModel-only service embed calls stripping embedModel', async () => {
    const embedOnlyServiceLastUsed: AxAIServiceLastUsed = {
      modelConfig: testModelConfig,
    }
    const embedFn = vi.fn(async (req: Readonly<AxEmbedRequest>) => {
      embedOnlyServiceLastUsed.embedModel = req.embedModel
      return { embeddings: [[req.texts?.length ?? 0]] }
    })

    const embedOnlyService2 = {
      getId: () => 'embed-only-service',
      getName: () => 'Embed Only Service',
      getFeatures: () => ({ functions: false, streaming: false }),
      getModelList: () => [
        {
          key: 'embed-only',
          description: 'Embed only service',
          embedModel: 'modelE',
        },
      ],
      getLastUsedChatModel: function (): string | undefined {
        return undefined
      },
      getLastUsedEmbedModel: function (): string | undefined {
        return embedOnlyServiceLastUsed.embedModel
      },
      getLastUsedModelConfig: function (): AxModelConfig | undefined {
        return embedOnlyServiceLastUsed.modelConfig
      },
      getMetrics: () => metrics,
      chat: async () => {
        throw new Error('chat should not be called')
      },
      embed: embedFn,
      setOptions: () => {},
      getOptions: () => ({}),
      getLogger: () => mockLogger,
    }
    const router3 = new AxMultiServiceRouter([embedOnlyService2])
    const resp = await router3.embed({
      embedModel: 'embed-only',
      texts: ['a', 'b', 'c'],
    })
    expect(embedFn).toHaveBeenCalledTimes(1)
    const callArg = embedFn.mock.calls[0]![0] as AxEmbedRequest
    expect(callArg).not.toHaveProperty('embedModel')
    expect(callArg.texts!).toEqual(['a', 'b', 'c'])
    expect(resp.embeddings).toEqual([[3]])
  })
})



================================================
FILE: src/ax/ai/multiservice.ts
================================================
import type { ReadableStream } from 'stream/web'

import type {
  AxAIModelList,
  AxAIPromptConfig,
  AxAIService,
  AxAIServiceActionOptions,
  AxAIServiceMetrics,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxEmbedRequest,
  AxEmbedResponse,
  AxLoggerFunction,
  AxModelConfig,
} from './types.js'

type AxAIServiceListItem<TModel = unknown, TEmbedModel = unknown> = {
  key: string
  service: AxAIService<TModel, TEmbedModel>
  description: string
  isInternal?: boolean
}

export class AxMultiServiceRouter implements AxAIService<string, string> {
  private options?: AxAIServiceOptions
  private lastUsedService?: AxAIService<string, string>

  private services: Map<
    string,
    {
      isInternal?: boolean
      description: string
      model?: string
      embedModel?: string
      service: AxAIService<string, string>
    }
  > = new Map()
  /**
   * Constructs a new multi-service router.
   * It validates that each service provides a unique set of model keys,
   * then builds a lookup (map) for routing the chat/embed requests.
   */
  constructor(
    services: (
      | AxAIServiceListItem<string, string>
      | AxAIService<string, string>
    )[]
  ) {
    if (services.length === 0) {
      throw new Error('No AI services provided.')
    }

    // Determine input type based on first element (assuming homogeneous array)

    for (const [index, item] of services.entries()) {
      const isKeyBased = 'key' in item

      if (isKeyBased) {
        if (this.services.has(item.key)) {
          throw new Error(`Duplicate model key: ${item.key}`)
        }

        const { service, description, isInternal } = item

        this.services.set(item.key, {
          service: service as AxAIService<string, string>,
          description,
          isInternal,
        })
      } else {
        const modelList = item.getModelList() as AxAIModelList | undefined

        if (!modelList) {
          throw new Error(
            `Service ${index} \`${item.getName()}\` has no model list.`
          )
        }

        for (const v of modelList) {
          if (this.services.has(v.key)) {
            const otherService = this.services.get(v.key)?.service
            throw new Error(
              `Service ${index} \`${item.getName()}\` has duplicate model key: ${v.key} as service ${otherService?.getName()}`
            )
          } else {
            if ('model' in v && typeof v.model) {
              this.services.set(v.key, {
                description: v.description,
                service: item as AxAIService<string, string>,
                model: v.model,
              })
            } else if ('embedModel' in v && v.embedModel) {
              this.services.set(v.key, {
                description: v.description,
                service: item as AxAIService<string, string>,
                embedModel: v.embedModel,
              })
            } else {
              throw new Error(
                `Key ${v.key} in model list for service ${index} \`${item.getName()}\` is missing a model or embedModel property.`
              )
            }
          }
        }
      }
    }
  }
  getLastUsedChatModel(): string | undefined {
    return this.lastUsedService?.getLastUsedChatModel()
  }
  getLastUsedEmbedModel(): string | undefined {
    return this.lastUsedService?.getLastUsedEmbedModel()
  }
  getLastUsedModelConfig(): AxModelConfig | undefined {
    return this.lastUsedService?.getLastUsedModelConfig()
  }

  /**
   * Delegates the chat call to the service matching the provided model key.
   */
  async chat(
    req: Readonly<AxChatRequest<string>>,
    options?: Readonly<
      AxAIPromptConfig & AxAIServiceActionOptions<string, string>
    >
  ): Promise<AxChatResponse | ReadableStream<AxChatResponse>> {
    const modelKey = req.model
    if (!modelKey) {
      throw new Error('Model key must be specified for multi-service')
    }

    const item = this.services.get(modelKey)
    if (!item) {
      throw new Error(`No service found for model key: ${modelKey}`)
    }

    this.lastUsedService = item.service

    if (!item.model) {
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      const { model, ...reqWithoutModel } = req
      return await item.service.chat(reqWithoutModel, options)
    }

    return await item.service.chat({ model: modelKey, ...req }, options)
  }

  /**
   * Delegates the embed call to the service matching the provided embed model key.
   */
  async embed(
    req: Readonly<AxEmbedRequest<string>>,
    options?: Readonly<AxAIServiceActionOptions<string, string>>
  ): Promise<AxEmbedResponse> {
    const embedModelKey = req.embedModel
    if (!embedModelKey) {
      throw new Error('Embed model key must be specified for multi-service')
    }

    const item = this.services.get(embedModelKey)
    if (!item) {
      throw new Error(`No service found for embed model key: ${embedModelKey}`)
    }

    this.lastUsedService = item.service

    if (!item.model) {
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      const { embedModel, ...reqWithoutEmbedModel } = req
      return await item.service.embed(reqWithoutEmbedModel, options)
    }

    return await item.service.embed(
      { embedModel: embedModelKey, ...req },
      options
    )
  }

  /**
   * Returns a composite ID built from the IDs of the underlying services.
   */
  getId(): string {
    return (
      'MultiServiceRouter:' +
      Array.from(this.services.values())
        .map((s) => s.service.getId())
        .join(',')
    )
  }

  /**
   * Returns the name of this router.
   */
  getName(): string {
    return 'MultiServiceRouter'
  }

  /**
   * Aggregates all available models across the underlying services.
   */
  getModelList(): AxAIModelList {
    return Array.from(this.services)
      .filter(([, value]) => !value.isInternal)
      .map(([key, v]) => {
        if (v.model) {
          return { key, description: v.description, model: v.model }
        } else if (v.embedModel) {
          return { key, description: v.description, embedModel: v.embedModel }
        } else {
          throw new Error(`Service ${key} has no model or embedModel`)
        }
      })
  }

  /**
   * If a model key is provided, delegate to the corresponding service's features.
   * Otherwise, returns a default feature set.
   */
  getFeatures(model?: string): {
    functions: boolean
    streaming: boolean
    functionCot?: boolean
  } {
    if (model) {
      const service = this.services.get(model)
      if (service) {
        return service.service.getFeatures(model)
      }
    }
    return { functions: false, streaming: false }
  }

  /**
   * Returns aggregated metrics from the underlying service.
   * Uses the metrics from the last service that was used,
   * or falls back to the first service if none has been used.
   */
  getMetrics(): AxAIServiceMetrics {
    let serviceInstance = this.lastUsedService
    if (!serviceInstance) {
      const firstServiceEntry = this.services.values().next().value
      if (firstServiceEntry) {
        // Check if it's the service directly or the wrapped object
        serviceInstance =
          'service' in firstServiceEntry
            ? firstServiceEntry.service
            : firstServiceEntry
      }
    }

    if (!serviceInstance) {
      throw new Error('No service available to get metrics.')
    }
    return serviceInstance.getMetrics()
  }

  /**
   * Sets options on all underlying services.
   */
  setOptions(options: Readonly<AxAIServiceOptions>): void {
    for (const service of this.services.values()) {
      service.service.setOptions(options)
    }
    this.options = options
  }

  /**
   * Returns the options from the last used service,
   * or falls back to the first service if none has been used.
   */
  getOptions(): Readonly<AxAIServiceOptions> {
    return this.options ?? {}
  }

  /**
   * Returns the logger from the last used service,
   * or falls back to the first service if none has been used.
   */
  getLogger(): AxLoggerFunction {
    let serviceInstance = this.lastUsedService
    if (!serviceInstance) {
      const firstServiceEntry = this.services.values().next().value
      if (firstServiceEntry) {
        serviceInstance = firstServiceEntry.service
      }
    }

    if (!serviceInstance) {
      // Return a default logger if no service is available
      return (message: string) => {
        process.stdout.write(message)
      }
    }
    return serviceInstance.getLogger()
  }
}



================================================
FILE: src/ax/ai/types.ts
================================================
import type { ReadableStream } from 'node:stream/web'

import type { Context, Tracer } from '@opentelemetry/api'

import type { AxAPI } from '../util/apicall.js'

import type { AxAIFeatures } from './base.js'

export type AxAIInputModelList<TModel, TEmbedModel> = (AxAIModelListBase & {
  isInternal?: boolean
} & ({ model: TModel } | { embedModel: TEmbedModel }))[]

export type AxAIModelListBase = {
  key: string
  description: string
}

export type AxAIModelList = (AxAIModelListBase &
  ({ model: string } | { embedModel: string }))[]

export type AxModelInfo = {
  name: string
  currency?: string
  characterIsToken?: boolean
  promptTokenCostPer1M?: number
  completionTokenCostPer1M?: number
  aliases?: string[]
  hasThinkingBudget?: boolean
  hasShowThoughts?: boolean
  maxTokens?: number
}

export type AxTokenUsage = {
  promptTokens: number
  completionTokens: number
  totalTokens: number
  thoughtsTokens?: number
}

export type AxModelConfig = {
  maxTokens?: number
  temperature?: number
  topP?: number
  topK?: number
  presencePenalty?: number
  frequencyPenalty?: number
  stopSequences?: string[]
  endSequences?: string[]
  stream?: boolean
  n?: number
}

export type AxFunctionHandler = (
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  args?: any,
  extra?: Readonly<{
    sessionId?: string
    traceId?: string
    debug?: boolean
    ai?: AxAIService
  }>
) => unknown

export type AxFunctionJSONSchema = {
  type: string
  properties?: Record<
    string,
    AxFunctionJSONSchema & {
      enum?: string[]
      description: string
    }
  >
  required?: string[]
  items?: AxFunctionJSONSchema
}

export type AxFunction = {
  name: string
  description: string
  parameters?: AxFunctionJSONSchema
  func: AxFunctionHandler
}

export type AxChatResponseResult = {
  content?: string
  thought?: string
  name?: string
  id?: string
  functionCalls?: {
    id: string
    type: 'function'
    function: { name: string; params?: string | object }
  }[]
  finishReason?:
    | 'stop'
    | 'length'
    | 'function_call'
    | 'content_filter'
    | 'error'
}

export type AxModelUsage = {
  ai: string
  model: string
  tokens?: AxTokenUsage
}

export type AxChatResponse = {
  sessionId?: string
  remoteId?: string
  results: readonly AxChatResponseResult[]
  modelUsage?: AxModelUsage
}

export type AxEmbedResponse = {
  remoteId?: string
  sessionId?: string
  embeddings: readonly (readonly number[])[]
  modelUsage?: AxModelUsage
}

export type AxModelInfoWithProvider = AxModelInfo & { provider: string }

export type AxChatRequest<TModel = string> = {
  chatPrompt: (
    | { role: 'system'; content: string; cache?: boolean }
    | {
        role: 'user'
        name?: string
        content:
          | string
          | (
              | {
                  type: 'text'
                  text: string
                  cache?: boolean
                }
              | {
                  type: 'image'
                  mimeType: string
                  image: string
                  details?: 'high' | 'low' | 'auto'
                  cache?: boolean
                }
              | {
                  type: 'audio'
                  data: string
                  format?: 'wav'
                  cache?: boolean
                }
            )[]
      }
    | {
        role: 'assistant'
        content?: string
        name?: string
        functionCalls?: {
          id: string
          type: 'function'
          function: { name: string; params?: string | object }
        }[]
        cache?: boolean
      }
    | {
        role: 'function'
        result: string
        isError?: boolean
        functionId: string
        cache?: boolean
      }
  )[]
  functions?: Readonly<{
    name: string
    description: string
    parameters?: AxFunctionJSONSchema
  }>[]
  functionCall?:
    | 'none'
    | 'auto'
    | 'required'
    | { type: 'function'; function: { name: string } }
  modelConfig?: AxModelConfig
  model?: TModel
}

export interface AxAIServiceMetrics {
  latency: {
    chat: {
      mean: number
      p95: number
      p99: number
      samples: number[]
    }
    embed: {
      mean: number
      p95: number
      p99: number
      samples: number[]
    }
  }
  errors: {
    chat: {
      count: number
      rate: number
      total: number
    }
    embed: {
      count: number
      rate: number
      total: number
    }
  }
}

export type AxInternalChatRequest<TModel> = Omit<AxChatRequest, 'model'> &
  Required<Pick<AxChatRequest<TModel>, 'model'>>

export type AxEmbedRequest<TEmbedModel = string> = {
  texts?: readonly string[]
  embedModel?: TEmbedModel
}

export type AxInternalEmbedRequest<TEmbedModel> = Omit<
  AxEmbedRequest,
  'embedModel'
> &
  Required<Pick<AxEmbedRequest<TEmbedModel>, 'embedModel'>>

export type AxRateLimiterFunction = <T = unknown>(
  reqFunc: () => Promise<T | ReadableStream<T>>,
  info: Readonly<{ modelUsage?: AxModelUsage }>
) => Promise<T | ReadableStream<T>>

export type AxLoggerTag =
  | 'error'
  | 'warning'
  | 'success'
  | 'functionName'
  | 'functionArg'
  | 'functionEnd'
  | 'responseStart'
  | 'responseContent'
  | 'responseEnd'
  | 'requestStart'
  | 'requestContent'
  | 'requestEnd'
  | 'systemStart'
  | 'systemContent'
  | 'systemEnd'
  | 'userStart'
  | 'userContent'
  | 'userEnd'
  | 'assistantStart'
  | 'assistantContent'
  | 'assistantEnd'
  | 'discovery'

export type AxLoggerFunction = (
  message: string,
  options?: { tags?: AxLoggerTag[] }
) => void

export type AxAIPromptConfig = {
  stream?: boolean
  thinkingTokenBudget?:
    | 'minimal'
    | 'low'
    | 'medium'
    | 'high'
    | 'highest'
    | 'none'
  showThoughts?: boolean
}

export type AxAIServiceOptions = {
  debug?: boolean
  rateLimiter?: AxRateLimiterFunction
  fetch?: typeof fetch
  tracer?: Tracer
  timeout?: number
  excludeContentFromTrace?: boolean
  abortSignal?: AbortSignal
  logger?: AxLoggerFunction
}

export type AxAIServiceActionOptions<
  TModel = unknown,
  TEmbedModel = unknown,
> = {
  ai?: Readonly<AxAIService<TModel, TEmbedModel>>
  sessionId?: string
  traceId?: string
  timeout?: number
  rateLimiter?: AxRateLimiterFunction
  debug?: boolean
  debugHideSystemPrompt?: boolean
  traceContext?: Context
  abortSignal?: AbortSignal
  logger?: AxLoggerFunction
}

export interface AxAIService<TModel = unknown, TEmbedModel = unknown> {
  getId(): string
  getName(): string
  getFeatures(model?: TModel): AxAIFeatures
  getModelList(): AxAIModelList | undefined
  getMetrics(): AxAIServiceMetrics
  getLogger(): AxLoggerFunction

  getLastUsedChatModel(): TModel | undefined
  getLastUsedEmbedModel(): TEmbedModel | undefined
  getLastUsedModelConfig(): AxModelConfig | undefined

  chat(
    req: Readonly<AxChatRequest<TModel>>,
    options?: Readonly<
      AxAIPromptConfig & AxAIServiceActionOptions<TModel, TEmbedModel>
    >
  ): Promise<AxChatResponse | ReadableStream<AxChatResponse>>
  embed(
    req: Readonly<AxEmbedRequest<TEmbedModel>>,
    options?: Readonly<AxAIServiceActionOptions<TModel, TEmbedModel>>
  ): Promise<AxEmbedResponse>

  setOptions(options: Readonly<AxAIServiceOptions>): void
  getOptions(): Readonly<AxAIServiceOptions>
}

export interface AxAIServiceImpl<
  TModel,
  TEmbedModel,
  TChatRequest,
  TEmbedRequest,
  TChatResponse,
  TChatResponseDelta,
  TEmbedResponse,
> {
  createChatReq(
    req: Readonly<AxInternalChatRequest<TModel>>,
    config: Readonly<AxAIPromptConfig>
  ): [AxAPI, TChatRequest]

  createChatResp(resp: Readonly<TChatResponse>): AxChatResponse

  createChatStreamResp?(
    resp: Readonly<TChatResponseDelta>,
    state: object
  ): AxChatResponse

  createEmbedReq?(
    req: Readonly<AxInternalEmbedRequest<TEmbedModel>>
  ): [AxAPI, TEmbedRequest]

  createEmbedResp?(resp: Readonly<TEmbedResponse>): AxEmbedResponse

  getModelConfig(): AxModelConfig

  getTokenUsage(): AxTokenUsage | undefined
}



================================================
FILE: src/ax/ai/util.ts
================================================
/* eslint-disable @typescript-eslint/naming-convention */
import { createHash } from 'crypto'

import type { AxChatResponseResult, AxModelInfo } from './types.js'

export const findItemByNameOrAlias = (
  list: readonly AxModelInfo[],
  name: string
): AxModelInfo | undefined => {
  for (const item of list) {
    if (item.name === name || item.aliases?.includes(name)) {
      return item
    }
  }
  return undefined
}

export const uniqBy = <T>(
  array: readonly T[],
  uniqueField: (value: T) => unknown
): T[] => {
  const uniqueValues = new Map()

  array.forEach((value: T) => {
    const field = uniqueField(value)

    if (!uniqueValues.has(field)) {
      uniqueValues.set(field, value)
    }
  })

  return Array.from(uniqueValues.values())
}

const functionCallRe = /(\w+)\((.*)\)/s

export const parseFunction = (
  value: string
): { name: string; args?: string } | undefined => {
  let v: string[] | null

  // extract function calls
  if ((v = functionCallRe.exec(value)) !== null) {
    const name = v.at(1)?.trim()
    const args = v.at(2)?.trim()
    if (!name || name.length === 0) {
      throw new Error(`Invalid function format: ${value}`)
    }
    return { name, args }
  }
  return
}

export interface mergeFunctionsState {
  lastId?: string
}

export function mergeFunctionCalls(
  functionCalls: NonNullable<AxChatResponseResult['functionCalls']>,
  functionCallDeltas: Readonly<
    NonNullable<AxChatResponseResult['functionCalls']>
  >
) {
  for (const _fc of functionCallDeltas) {
    const fc = functionCalls.find((fc) => fc.id === _fc.id)

    if (fc) {
      if (
        typeof _fc.function.name == 'string' &&
        _fc.function.name.length > 0
      ) {
        fc.function.name += _fc.function.name
      }

      if (
        typeof _fc.function.params == 'string' &&
        _fc.function.params.length > 0
      ) {
        fc.function.params += _fc.function.params
      }

      if (typeof _fc.function.params == 'object') {
        fc.function.params = _fc.function.params
      }
    } else {
      functionCalls.push(_fc)
    }
  }
}

export const hashObject = (obj: object) => {
  const hash = createHash('sha256')
  hash.update(JSON.stringify(obj))
  return hash.digest('hex')
}



================================================
FILE: src/ax/ai/wrap.ts
================================================
import type { ReadableStream } from 'stream/web'

import { AxAIAnthropic, type AxAIAnthropicArgs } from './anthropic/api.js'
import type { AxAIAnthropicModel } from './anthropic/types.js'
import {
  AxAIAzureOpenAI,
  type AxAIAzureOpenAIArgs,
} from './azure-openai/api.js'
import { AxAICohere, type AxAICohereArgs } from './cohere/api.js'
import type { AxAICohereEmbedModel, AxAICohereModel } from './cohere/types.js'
import { AxAIDeepSeek, type AxAIDeepSeekArgs } from './deepseek/api.js'
import type { AxAIDeepSeekModel } from './deepseek/types.js'
import {
  AxAIGoogleGemini,
  type AxAIGoogleGeminiArgs,
} from './google-gemini/api.js'
import type {
  AxAIGoogleGeminiEmbedModel,
  AxAIGoogleGeminiModel,
} from './google-gemini/types.js'
import { AxAIGroq, type AxAIGroqArgs } from './groq/api.js'
import type { AxAIGroqModel } from './groq/types.js'
import { AxAIHuggingFace, type AxAIHuggingFaceArgs } from './huggingface/api.js'
import type { AxAIHuggingFaceModel } from './huggingface/types.js'
import { AxAIMistral, type AxAIMistralArgs } from './mistral/api.js'
import type { AxAIMistralModel } from './mistral/types.js'
import { AxAIOllama, type AxAIOllamaArgs } from './ollama/api.js'
import {
  AxAIOpenAI,
  type AxAIOpenAIArgs as AxAIOpenAIArgs,
} from './openai/api.js'
import type {
  AxAIOpenAIEmbedModel,
  AxAIOpenAIModel,
} from './openai/chat_types.js'
import {
  AxAIOpenAIResponses,
  type AxAIOpenAIResponsesArgs,
} from './openai/responses_api_base.js'
import { AxAIReka, type AxAIRekaArgs } from './reka/api.js'
import { AxAITogether, type AxAITogetherArgs } from './together/api.js'
import type {
  AxAIModelList,
  AxAIPromptConfig,
  AxAIService,
  AxAIServiceActionOptions,
  AxAIServiceMetrics,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxEmbedRequest,
  AxEmbedResponse,
  AxLoggerFunction,
} from './types.js'

export type AxAIArgs =
  | AxAIOpenAIArgs
  | AxAIOpenAIResponsesArgs
  | AxAIAzureOpenAIArgs
  | AxAITogetherArgs
  | AxAIAnthropicArgs
  | AxAIGroqArgs
  | AxAIGoogleGeminiArgs
  | AxAICohereArgs
  | AxAIHuggingFaceArgs
  | AxAIMistralArgs
  | AxAIDeepSeekArgs
  | AxAIOllamaArgs
  | AxAIRekaArgs

export type AxAIModels =
  | AxAIOpenAIModel
  | AxAIAnthropicModel
  | AxAIGroqModel
  | AxAIGoogleGeminiModel
  | AxAICohereModel
  | AxAIHuggingFaceModel
  | AxAIMistralModel
  | AxAIDeepSeekModel

export type AxAIEmbedModels =
  | AxAIOpenAIEmbedModel
  | AxAIGoogleGeminiEmbedModel
  | AxAICohereEmbedModel

export class AxAI implements AxAIService {
  private ai: AxAIService

  constructor(options: Readonly<AxAIArgs>) {
    switch (options.name) {
      case 'openai':
        this.ai = new AxAIOpenAI(options)
        break
      case 'openai-responses':
        this.ai = new AxAIOpenAIResponses(options)
        break
      case 'azure-openai':
        this.ai = new AxAIAzureOpenAI(options)
        break
      case 'huggingface':
        this.ai = new AxAIHuggingFace(options)
        break
      case 'groq':
        this.ai = new AxAIGroq(options)
        break
      case 'together':
        this.ai = new AxAITogether(options)
        break
      case 'cohere':
        this.ai = new AxAICohere(options)
        break
      case 'google-gemini':
        this.ai = new AxAIGoogleGemini(options)
        break
      case 'anthropic':
        this.ai = new AxAIAnthropic(options)
        break
      case 'mistral':
        this.ai = new AxAIMistral(options)
        break
      case 'deepseek':
        this.ai = new AxAIDeepSeek(options)
        break
      case 'ollama':
        this.ai = new AxAIOllama(options)
        break
      case 'reka':
        this.ai = new AxAIReka(options)
        break
      default:
        throw new Error(`Unknown AI`)
    }
  }

  getName(): string {
    return this.ai.getName()
  }

  getId(): string {
    return this.ai.getId()
  }

  getFeatures(model?: string): { functions: boolean; streaming: boolean } {
    return this.ai.getFeatures(model)
  }

  getModelList() {
    return this.ai.getModelList() as AxAIModelList | undefined
  }

  getLastUsedChatModel() {
    return this.ai.getLastUsedChatModel()
  }

  getLastUsedEmbedModel() {
    return this.ai.getLastUsedEmbedModel()
  }

  getLastUsedModelConfig() {
    return this.ai.getLastUsedModelConfig()
  }

  getMetrics(): AxAIServiceMetrics {
    return this.ai.getMetrics()
  }

  async chat(
    req: Readonly<AxChatRequest>,
    options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions>
  ): Promise<AxChatResponse | ReadableStream<AxChatResponse>> {
    return await this.ai.chat(req, options)
  }

  async embed(
    req: Readonly<AxEmbedRequest>,
    options?: Readonly<AxAIServiceActionOptions & AxAIServiceActionOptions>
  ): Promise<AxEmbedResponse> {
    return await this.ai.embed(req, options)
  }

  setOptions(options: Readonly<AxAIServiceOptions>): void {
    this.ai.setOptions(options)
  }

  getOptions(): Readonly<AxAIServiceOptions> {
    return this.ai.getOptions()
  }

  getLogger(): AxLoggerFunction {
    return this.ai.getLogger()
  }
}



================================================
FILE: src/ax/ai/anthropic/api.ts
================================================
import type { AxAPI } from '../../util/apicall.js'
import { AxBaseAI, axBaseAIDefaultConfig } from '../base.js'
import { GoogleVertexAuth } from '../google-vertex/auth.js'
import type {
  AxAIInputModelList,
  AxAIServiceImpl,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxChatResponseResult,
  AxInternalChatRequest,
  AxModelConfig,
  AxTokenUsage,
} from '../types.js'

import { axModelInfoAnthropic } from './info.js'
import {
  type AxAIAnthropicChatError,
  type AxAIAnthropicChatRequest,
  type AxAIAnthropicChatResponse,
  type AxAIAnthropicChatResponseDelta,
  type AxAIAnthropicConfig,
  type AxAIAnthropicContentBlockDeltaEvent,
  type AxAIAnthropicContentBlockStartEvent,
  type AxAIAnthropicErrorEvent,
  type AxAIAnthropicMessageDeltaEvent,
  type AxAIAnthropicMessageStartEvent,
  AxAIAnthropicModel,
  AxAIAnthropicVertexModel,
} from './types.js'

export const axAIAnthropicDefaultConfig = (): AxAIAnthropicConfig =>
  structuredClone({
    model: AxAIAnthropicModel.Claude37Sonnet,
    ...axBaseAIDefaultConfig(),
  })

export const axAIAnthropicVertexDefaultConfig = (): AxAIAnthropicConfig =>
  structuredClone({
    model: AxAIAnthropicVertexModel.Claude37Sonnet,
    ...axBaseAIDefaultConfig(),
  })

export interface AxAIAnthropicArgs {
  name: 'anthropic'
  apiKey?: string
  projectId?: string
  region?: string
  config?: Readonly<Partial<AxAIAnthropicConfig>>
  options?: Readonly<AxAIServiceOptions>
  models?: AxAIInputModelList<
    AxAIAnthropicModel | AxAIAnthropicVertexModel,
    undefined
  >
}

class AxAIAnthropicImpl
  implements
    AxAIServiceImpl<
      AxAIAnthropicModel | AxAIAnthropicVertexModel,
      unknown,
      AxAIAnthropicChatRequest,
      unknown,
      AxAIAnthropicChatResponse,
      AxAIAnthropicChatResponseDelta,
      unknown
    >
{
  private tokensUsed: AxTokenUsage | undefined

  constructor(
    private config: AxAIAnthropicConfig,
    private isVertex: boolean
  ) {}

  getTokenUsage(): AxTokenUsage | undefined {
    return this.tokensUsed
  }

  getModelConfig(): AxModelConfig {
    const { config } = this
    return {
      maxTokens: config.maxTokens ?? 4096,
      temperature: config.temperature,
      topP: config.topP,
      topK: config.topK,
      stream: config.stream,
      stopSequences: config.stopSequences,
      endSequences: config.endSequences,
      presencePenalty: config.presencePenalty,
      frequencyPenalty: config.frequencyPenalty,
      n: config.n,
    } as AxModelConfig
  }

  createChatReq = (
    req: Readonly<
      AxInternalChatRequest<AxAIAnthropicModel | AxAIAnthropicVertexModel>
    >
  ): [AxAPI, AxAIAnthropicChatRequest] => {
    const model = req.model
    const stream = req.modelConfig?.stream ?? this.config.stream

    let apiConfig
    if (this.isVertex) {
      apiConfig = {
        name: stream
          ? `/models/${model}:streamRawPredict?alt=sse`
          : `/models/${model}:rawPredict`,
      }
    } else {
      apiConfig = {
        name: '/messages',
      }
    }

    let toolsChoice

    if (req.functionCall && req.functions && req.functions.length > 0) {
      if (typeof req.functionCall === 'string') {
        switch (req.functionCall) {
          case 'auto':
            toolsChoice = { tool_choice: { type: 'auto' as const } }
            break
          case 'required':
            toolsChoice = { tool_choice: { type: 'any' as const } }
            break
          case 'none':
            throw new Error('functionCall none not supported')
        }
      } else if ('function' in req.functionCall) {
        toolsChoice = {
          tool_choice: {
            type: 'tool' as const,
            name: req.functionCall.function.name,
          },
        }
      } else {
        throw new Error('Invalid function call type, must be string or object')
      }
    }

    const system = req.chatPrompt
      .filter((msg) => msg.role === 'system')
      .map((msg) => ({
        type: 'text' as const,
        text: msg.content,
        ...(msg.cache ? { cache: { type: 'ephemeral' } } : {}),
      }))

    const otherMessages = req.chatPrompt.filter((msg) => msg.role !== 'system')

    const messages = createMessages(otherMessages)

    const tools: AxAIAnthropicChatRequest['tools'] = req.functions?.map(
      (v) => ({
        name: v.name,
        description: v.description,
        input_schema: v.parameters,
      })
    )

    const maxTokens = req.modelConfig?.maxTokens ?? this.config.maxTokens
    const stopSequences =
      req.modelConfig?.stopSequences ?? this.config.stopSequences
    const temperature = req.modelConfig?.temperature ?? this.config.temperature
    const topP = req.modelConfig?.topP ?? this.config.topP
    const topK = req.modelConfig?.topK ?? this.config.topK

    const reqValue: AxAIAnthropicChatRequest = {
      ...(this.isVertex
        ? { anthropic_version: 'vertex-2023-10-16' }
        : { model }),
      ...(maxTokens ? { max_tokens: maxTokens } : {}),
      ...(stopSequences && stopSequences.length > 0
        ? { stop_sequences: stopSequences }
        : {}),
      ...(temperature ? { temperature } : {}),
      ...(topP ? { top_p: topP } : {}),
      ...(topK ? { top_k: topK } : {}),
      ...toolsChoice,
      ...(tools && tools.length > 0 ? { tools } : {}),
      ...(stream ? { stream: true } : {}),
      ...(system ? { system } : {}),
      messages,
    }

    return [apiConfig, reqValue]
  }

  createChatResp = (
    resp: Readonly<AxAIAnthropicChatResponse | AxAIAnthropicChatError>
  ): AxChatResponse => {
    if (resp.type === 'error') {
      throw new Error(`Anthropic Chat API Error: ${resp.error.message}`)
    }

    const finishReason = mapFinishReason(resp.stop_reason)

    const results = resp.content.map((msg): AxChatResponseResult => {
      if (msg.type === 'tool_use') {
        return {
          id: msg.id,
          functionCalls: [
            {
              id: msg.id,
              type: 'function' as const,
              function: {
                name: msg.name,
                params: msg.input,
              },
            },
          ],
          finishReason,
        }
      }
      return {
        content: msg.type === 'text' ? msg.text : '',
        id: resp.id,
        finishReason,
      }
    })

    this.tokensUsed = {
      promptTokens: resp.usage.input_tokens,
      completionTokens: resp.usage.output_tokens,
      totalTokens: resp.usage.input_tokens + resp.usage.output_tokens,
    }

    return { results, remoteId: resp.id }
  }

  createChatStreamResp = (
    resp: Readonly<AxAIAnthropicChatResponseDelta>,
    state: object
  ): AxChatResponse => {
    if (!('type' in resp)) {
      throw new Error('Invalid Anthropic streaming event')
    }

    const sstate = state as {
      indexIdMap: Record<number, string>
    }

    if (!sstate.indexIdMap) {
      sstate.indexIdMap = {}
    }

    if (resp.type === 'error') {
      const { error } = resp as unknown as AxAIAnthropicErrorEvent
      throw new Error(error.message)
    }

    if (resp.type === 'message_start') {
      const { message } = resp as unknown as AxAIAnthropicMessageStartEvent
      const results = [{ content: '', id: message.id }]

      this.tokensUsed = {
        promptTokens: message.usage?.input_tokens ?? 0,
        completionTokens: message.usage?.output_tokens ?? 0,
        totalTokens:
          (message.usage?.input_tokens ?? 0) +
          (message.usage?.output_tokens ?? 0),
      }
      return { results }
    }

    if (resp.type === 'content_block_start') {
      const { content_block: contentBlock } =
        resp as unknown as AxAIAnthropicContentBlockStartEvent

      if (contentBlock.type === 'text') {
        return {
          results: [{ content: contentBlock.text }],
        }
      }
      if (contentBlock.type === 'tool_use') {
        if (
          typeof contentBlock.id === 'string' &&
          typeof resp.index === 'number' &&
          !sstate.indexIdMap[resp.index]
        ) {
          sstate.indexIdMap[resp.index] = contentBlock.id
          const functionCalls = [
            {
              id: contentBlock.id,
              type: 'function' as const,
              function: {
                name: contentBlock.name,
                params: '',
              },
            },
          ]
          return {
            results: [{ functionCalls }],
          }
        }
      }
    }

    if (resp.type === 'content_block_delta') {
      const { delta } = resp as unknown as AxAIAnthropicContentBlockDeltaEvent
      if (delta.type === 'text_delta') {
        return {
          results: [{ content: delta.text }],
        }
      }
      if (delta.type === 'input_json_delta') {
        const id = sstate.indexIdMap[resp.index]
        if (!id) {
          throw new Error('invalid streaming index no id found: ' + resp.index)
        }
        const functionCalls = [
          {
            id,
            type: 'function' as const,
            function: {
              name: '',
              params: delta.partial_json,
            },
          },
        ]
        return {
          results: [{ functionCalls }],
        }
      }
    }

    if (resp.type === 'message_delta') {
      const { delta, usage } = resp as unknown as AxAIAnthropicMessageDeltaEvent

      this.tokensUsed = {
        promptTokens: 0,
        completionTokens: usage.output_tokens,
        totalTokens: usage.output_tokens,
      }

      const results = [
        { content: '', finishReason: mapFinishReason(delta.stop_reason) },
      ]
      return { results }
    }

    return {
      results: [{ content: '' }],
    }
  }
}

export class AxAIAnthropic extends AxBaseAI<
  AxAIAnthropicModel | AxAIAnthropicVertexModel,
  unknown,
  AxAIAnthropicChatRequest,
  unknown,
  AxAIAnthropicChatResponse,
  AxAIAnthropicChatResponseDelta,
  unknown
> {
  constructor({
    apiKey,
    projectId,
    region,
    config,
    options,
    models,
  }: Readonly<Omit<AxAIAnthropicArgs, 'name'>>) {
    const isVertex = projectId !== undefined && region !== undefined

    let apiURL
    let headers

    if (isVertex) {
      apiURL = `https://${region}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${region}/publishers/anthropic/`
      if (apiKey) {
        headers = async () => ({ Authorization: `Bearer ${apiKey}` })
      } else {
        const vertexAuth = new GoogleVertexAuth()
        headers = async () => ({
          Authorization: `Bearer ${await vertexAuth.getAccessToken()}`,
        })
      }
    } else {
      if (!apiKey) {
        throw new Error('Anthropic API key not set')
      }
      apiURL = 'https://api.anthropic.com/v1'
      headers = async () => ({
        'anthropic-version': '2023-06-01',
        'anthropic-beta': 'prompt-caching-2024-07-31',
        'x-api-key': apiKey,
      })
    }

    const _config = {
      ...axAIAnthropicDefaultConfig(),
      ...config,
    }

    const aiImpl = new AxAIAnthropicImpl(_config, isVertex)

    super(aiImpl, {
      name: 'Anthropic',
      apiURL,
      headers,
      modelInfo: axModelInfoAnthropic,
      defaults: { model: _config.model },
      options,
      supportFor: { functions: true, streaming: true, functionCot: true },
      models,
    })
  }
}

type AnthropicMsg = AxAIAnthropicChatRequest['messages'][0]
type AnthropicMsgRoleUser = Extract<AnthropicMsg, { role: 'user' }>
type AnthropicMsgRoleUserToolResult = Extract<
  AnthropicMsgRoleUser['content'][0],
  { type: 'tool_result' }
>

function createMessages(
  chatPrompt: Readonly<AxChatRequest['chatPrompt']>
): AxAIAnthropicChatRequest['messages'] {
  const items: AxAIAnthropicChatRequest['messages'] = chatPrompt.map((msg) => {
    switch (msg.role) {
      case 'function':
        const content: AnthropicMsgRoleUserToolResult[] = [
          {
            type: 'tool_result' as const,
            content: msg.result,
            tool_use_id: msg.functionId,
            ...(msg.isError ? { is_error: true } : {}),
            ...(msg.cache ? { cache: { type: 'ephemeral' } } : {}),
          },
        ]

        return {
          role: 'user' as const,
          content,
        }
      case 'user': {
        if (typeof msg.content === 'string') {
          return {
            role: 'user' as const,
            content: msg.content,
          }
        }
        const content = msg.content.map((v) => {
          switch (v.type) {
            case 'text':
              return {
                type: 'text' as const,
                text: v.text,
                ...(v.cache ? { cache: { type: 'ephemeral' } } : {}),
              }
            case 'image':
              return {
                type: 'image' as const,
                source: {
                  type: 'base64' as const,
                  media_type: v.mimeType,
                  data: v.image,
                },
                ...(v.cache ? { cache: { type: 'ephemeral' } } : {}),
              }
            default:
              throw new Error('Invalid content type')
          }
        })
        return {
          role: 'user' as const,
          content,
        }
      }
      case 'assistant': {
        let content: Extract<
          AxAIAnthropicChatRequest['messages'][0],
          { role: 'assistant' }
        >['content'] = ''

        if (typeof msg.content === 'string') {
          content = msg.content
        }
        if (typeof msg.functionCalls !== 'undefined') {
          content = msg.functionCalls.map((v) => {
            let input
            if (typeof v.function.params === 'string') {
              input = JSON.parse(v.function.params)
            } else if (typeof v.function.params === 'object') {
              input = v.function.params
            }
            return {
              type: 'tool_use' as const,
              id: v.id,
              name: v.function.name,
              input,
              ...(msg.cache ? { cache: { type: 'ephemeral' } } : {}),
            }
          })
        }
        return {
          role: 'assistant' as const,
          content,
        }
      }
      default:
        throw new Error('Invalid role')
    }
  })

  return mergeAssistantMessages(items)
}

// Anthropic and some others need this in non-streaming mode
function mergeAssistantMessages(
  messages: Readonly<AxAIAnthropicChatRequest['messages']>
): AxAIAnthropicChatRequest['messages'] {
  const mergedMessages: AxAIAnthropicChatRequest['messages'] = []

  for (const [i, cur] of messages.entries()) {
    // Continue if not an assistant message or first message
    if (cur.role !== 'assistant') {
      mergedMessages.push(cur)
      continue
    }

    // Merge current message with the previous one if both are from the assistant
    if (i > 0 && messages.at(i - 1)?.role === 'assistant') {
      const lastMessage = mergedMessages.pop()

      mergedMessages.push({
        ...(lastMessage ? lastMessage : {}),
        ...cur,
      })
    } else {
      mergedMessages.push(cur)
    }
  }

  return mergedMessages
}

function mapFinishReason(
  stopReason?: AxAIAnthropicChatResponse['stop_reason'] | null
): AxChatResponse['results'][0]['finishReason'] | undefined {
  if (!stopReason) {
    return undefined
  }
  switch (stopReason) {
    case 'stop_sequence':
      return 'stop'
      break
    case 'max_tokens':
      return 'length'
      break
    case 'tool_use':
      return 'function_call'
      break
    case 'end_turn':
      return 'stop'
      break
    default:
      return 'stop'
  }
}



================================================
FILE: src/ax/ai/anthropic/info.ts
================================================
import type { AxModelInfo } from '../types.js'

import { AxAIAnthropicModel } from './types.js'

export const axModelInfoAnthropic: AxModelInfo[] = [
  // 4
  {
    name: AxAIAnthropicModel.Claude4Opus,
    currency: 'usd',
    promptTokenCostPer1M: 15.0,
    completionTokenCostPer1M: 75.0,
    maxTokens: 32000,
  },
  {
    name: AxAIAnthropicModel.Claude4Sonnet,
    currency: 'usd',
    promptTokenCostPer1M: 3.0,
    completionTokenCostPer1M: 15.0,
    maxTokens: 64000,
  },
  // 3.7
  {
    name: AxAIAnthropicModel.Claude37Sonnet,
    currency: 'usd',
    promptTokenCostPer1M: 3.0,
    completionTokenCostPer1M: 15.0,
    maxTokens: 64000,
  },
  // 3.5
  {
    name: AxAIAnthropicModel.Claude35Sonnet,
    currency: 'usd',
    promptTokenCostPer1M: 3.0,
    completionTokenCostPer1M: 15.0,
    maxTokens: 8192,
  },
  {
    name: AxAIAnthropicModel.Claude35Haiku,
    currency: 'usd',
    promptTokenCostPer1M: 0.8,
    completionTokenCostPer1M: 4.0,
    maxTokens: 8192,
  },
  // 3
  {
    name: AxAIAnthropicModel.Claude3Opus,
    currency: 'usd',
    promptTokenCostPer1M: 15.0,
    completionTokenCostPer1M: 75.0,
    maxTokens: 4096,
  },
  {
    name: AxAIAnthropicModel.Claude3Sonnet,
    currency: 'usd',
    promptTokenCostPer1M: 3.0,
    completionTokenCostPer1M: 15.0,
    maxTokens: 4096,
  },
  {
    name: AxAIAnthropicModel.Claude3Haiku,
    currency: 'usd',
    promptTokenCostPer1M: 0.25,
    completionTokenCostPer1M: 1.25,
    maxTokens: 4096,
  },
  // 2.1
  {
    name: AxAIAnthropicModel.Claude21,
    currency: 'usd',
    promptTokenCostPer1M: 8.0,
    completionTokenCostPer1M: 25,
    maxTokens: 4096,
  },
  {
    name: AxAIAnthropicModel.ClaudeInstant12,
    currency: 'usd',
    promptTokenCostPer1M: 0.8,
    completionTokenCostPer1M: 2.24,
    maxTokens: 4096,
  },
]



================================================
FILE: src/ax/ai/anthropic/types.ts
================================================
import type { AxModelConfig } from '../types.js'

export enum AxAIAnthropicModel {
  Claude4Opus = 'claude-opus-4-20250514',
  Claude4Sonnet = 'claude-sonnet-4-20250514',
  Claude37Sonnet = 'claude-3-7-sonnet-latest',

  Claude35Sonnet = 'claude-3-5-sonnet-latest',
  Claude35Haiku = 'claude-3-5-haiku-latest',

  Claude3Opus = 'claude-3-opus-latest',
  Claude3Sonnet = 'claude-3-sonnet-20240229',
  Claude3Haiku = 'claude-3-haiku-20240307',

  Claude21 = 'claude-2.1',
  ClaudeInstant12 = 'claude-instant-1.2',
}

export enum AxAIAnthropicVertexModel {
  Claude37Sonnet = 'claude-3-7-sonnet',
  Claude35Haiku = 'claude-3-5-haiku',
  Claude35Sonnet = 'claude-3-5-sonnet',
  Claude35SonnetV2 = 'claude-3-5-sonnet-v2',
  Claude3Haiku = 'claude-3-haiku',
  Claude3Opus = 'claude-3-opus',
}

export type AxAIAnthropicConfig = AxModelConfig & {
  model: AxAIAnthropicModel | AxAIAnthropicVertexModel
}

export type AxAIAnthropicChatRequestCacheParam = {
  cache_control?: { type: 'ephemeral' }
}

// Type for the request to create a message using Anthropic's Messages API
export type AxAIAnthropicChatRequest = {
  model?: string
  anthropic_version?: string
  messages: (
    | {
        role: 'user'
        content:
          | string
          | (
              | ({
                  type: 'text'
                  text: string
                } & AxAIAnthropicChatRequestCacheParam)
              | ({
                  type: 'image'
                  source: { type: 'base64'; media_type: string; data: string }
                } & AxAIAnthropicChatRequestCacheParam)
              | {
                  type: 'tool_result'
                  is_error?: boolean
                  tool_use_id: string
                  content:
                    | string
                    | (
                        | ({
                            type: 'text'
                            text: string
                          } & AxAIAnthropicChatRequestCacheParam)
                        | ({
                            type: 'image'
                            source: {
                              type: 'base64'
                              media_type: string
                              data: string
                            }
                          } & AxAIAnthropicChatRequestCacheParam)
                      )[]
                }
            )[]
      }
    | {
        role: 'assistant'
        content:
          | string
          | (
              | { type: 'text'; text: string }
              | { type: 'tool_use'; id: string; name: string; input: object }
            )[]
      }
  )[]
  tools?: ({
    name: string
    description: string
    input_schema?: object
  } & AxAIAnthropicChatRequestCacheParam)[]
  tool_choice?: { type: 'auto' | 'any' } | { type: 'tool'; name?: string }
  max_tokens?: number // Maximum number of tokens to generate
  // Optional metadata about the request
  stop_sequences?: string[] // Custom sequences that trigger the end of generation
  stream?: boolean // Whether to stream the response incrementally
  system?:
    | string
    | ({
        type: 'text'
        text: string
      } & AxAIAnthropicChatRequestCacheParam)[] // system prompt
  temperature?: number // Randomness of the response
  top_p?: number // Nucleus sampling probability
  top_k?: number // Sample from the top K options
  metadata?: {
    user_id: string
  }
}

export type AxAIAnthropicChatResponse = {
  id: string // Unique identifier for the response
  type: 'message' // Object type, always 'message' for this API
  role: 'assistant' // Conversational role of the generated message, always 'assistant'
  content: (
    | {
        type: 'text'
        text: string
      }
    | {
        id: string
        name: string
        type: 'tool_use'
        input?: string
      }
  )[]
  model: string
  stop_reason: 'end_turn' | 'max_tokens' | 'stop_sequence' | 'tool_use'
  stop_sequence?: string
  usage: {
    input_tokens: number
    output_tokens: number
  }
}

export type AxAIAnthropicChatError = {
  type: 'error'
  error: {
    type: 'authentication_error'
    message: string
  }
}

// Represents the start of a message with an empty content array
export interface AxAIAnthropicMessageStartEvent {
  type: 'message_start'
  message: {
    id: string
    type: 'message'
    role: 'assistant'
    content: []
    model: string
    stop_reason: null | string
    stop_sequence: null | string
    usage: {
      input_tokens: number
      output_tokens: number
    }
  }
}

// Indicates the start of a content block within a message
export interface AxAIAnthropicContentBlockStartEvent {
  index: number
  type: 'content_block_start'
  content_block:
    | {
        type: 'text'
        text: string
      }
    | {
        type: 'tool_use'
        id: string
        name: string
        input: object
      }
}

// Represents incremental updates to a content block
export interface AxAIAnthropicContentBlockDeltaEvent {
  index: number
  type: 'content_block_delta'
  delta:
    | {
        type: 'text_delta'
        text: string
      }
    | {
        type: 'input_json_delta'
        partial_json: string
      }
}

// Marks the end of a content block within a message
export interface AxAIAnthropicContentBlockStopEvent {
  type: 'content_block_stop'
  index: number
}

// Indicates top-level changes to the final message object
export interface AxAIAnthropicMessageDeltaEvent {
  type: 'message_delta'
  delta: {
    stop_reason: 'end_turn' | 'max_tokens' | 'stop_sequence' | null
    stop_sequence: string | null
  }
  usage: {
    output_tokens: number
  }
}

// Marks the end of a message
export interface AxAIAnthropicMessageStopEvent {
  type: 'message_stop'
}

// Represents a ping event, which can occur any number of times
export interface AxAIAnthropicPingEvent {
  type: 'ping'
}

// Represents an error event
export interface AxAIAnthropicErrorEvent {
  type: 'error'
  error: {
    type: 'overloaded_error'
    message: string
  }
}

// Union type for all possible event types in the stream
export type AxAIAnthropicChatResponseDelta =
  | AxAIAnthropicMessageStartEvent
  | AxAIAnthropicContentBlockStartEvent
  | AxAIAnthropicContentBlockDeltaEvent
  | AxAIAnthropicContentBlockStopEvent
  | AxAIAnthropicMessageDeltaEvent
  | AxAIAnthropicMessageStopEvent
  | AxAIAnthropicPingEvent
  | AxAIAnthropicErrorEvent



================================================
FILE: src/ax/ai/azure-openai/api.ts
================================================
import { getModelInfo } from '@ax-llm/ax/dsp/modelinfo.js'

import {
  type AxAIOpenAIArgs,
  AxAIOpenAIBase,
  axAIOpenAIBestConfig,
  axAIOpenAICreativeConfig,
  axAIOpenAIDefaultConfig,
  axAIOpenAIFastConfig,
} from '../openai/api.js'
import type {
  AxAIOpenAIConfig,
  AxAIOpenAIEmbedModel,
  AxAIOpenAIModel,
} from '../openai/chat_types.js'
import { axModelInfoOpenAI } from '../openai/info.js'

export const axAIAzureOpenAIDefaultConfig = axAIOpenAIDefaultConfig

export const axAIAzureOpenAICreativeConfig = axAIOpenAICreativeConfig

export const axAIAzureOpenAIFastConfig = axAIOpenAIFastConfig

export const axAIAzureOpenAIBestConfig = axAIOpenAIBestConfig

export type AxAIAzureOpenAIConfig = AxAIOpenAIConfig<
  AxAIOpenAIModel,
  AxAIOpenAIEmbedModel
>
export type AxAIAzureOpenAIArgs = AxAIOpenAIArgs<
  'azure-openai',
  AxAIOpenAIModel,
  AxAIOpenAIEmbedModel
> & {
  resourceName: string
  deploymentName: string
  version?: string
}

export class AxAIAzureOpenAI extends AxAIOpenAIBase<
  AxAIOpenAIModel,
  AxAIOpenAIEmbedModel
> {
  constructor({
    apiKey,
    resourceName,
    deploymentName,
    version = 'api-version=2024-02-15-preview',
    config,
    options,
    models,
    modelInfo,
  }: Readonly<Omit<AxAIAzureOpenAIArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('Azure OpenAPI API key not set')
    }
    if (!resourceName || resourceName === '') {
      throw new Error('Azure OpenAPI resource name not set')
    }
    if (!deploymentName || deploymentName === '') {
      throw new Error('Azure OpenAPI deployment id not set')
    }

    const _config = {
      ...axAIAzureOpenAIDefaultConfig(),
      ...config,
    }

    modelInfo = [...axModelInfoOpenAI, ...(modelInfo ?? [])]

    const supportFor = (model: AxAIOpenAIModel) => {
      const mi = getModelInfo<AxAIOpenAIModel, AxAIOpenAIEmbedModel>({
        model,
        modelInfo,
        models,
      })
      return {
        functions: true,
        streaming: true,
        hasThinkingBudget: mi?.hasThinkingBudget ?? false,
        hasShowThoughts: mi?.hasShowThoughts ?? false,
      }
    }

    super({
      apiKey,
      config: _config,
      options,
      models,
      modelInfo,
      supportFor,
    })

    const host = resourceName.includes('://')
      ? resourceName
      : `https://${resourceName}.openai.azure.com/`

    super.setName('Azure OpenAI')

    super.setAPIURL(
      new URL(
        `/openai/deployments/${deploymentName}?api-version=${version}`,
        host
      ).href
    )

    super.setHeaders(async () => ({ 'api-key': apiKey }))
  }
}



================================================
FILE: src/ax/ai/cohere/api.ts
================================================
import type { AxAPI } from '../../util/apicall.js'
import {
  AxBaseAI,
  axBaseAIDefaultConfig,
  axBaseAIDefaultCreativeConfig,
} from '../base.js'
import type {
  AxAIInputModelList,
  AxAIPromptConfig,
  AxAIServiceImpl,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxEmbedResponse,
  AxInternalChatRequest,
  AxInternalEmbedRequest,
  AxModelConfig,
  AxTokenUsage,
} from '../types.js'

import { axModelInfoCohere } from './info.js'
import {
  type AxAICohereChatRequest,
  type AxAICohereChatResponse,
  type AxAICohereChatResponseDelta,
  type AxAICohereConfig,
  AxAICohereEmbedModel,
  type AxAICohereEmbedRequest,
  type AxAICohereEmbedResponse,
  AxAICohereModel,
} from './types.js'

export const axAICohereDefaultConfig = (): AxAICohereConfig =>
  structuredClone({
    model: AxAICohereModel.CommandRPlus,
    embedModel: AxAICohereEmbedModel.EmbedEnglishV30,
    ...axBaseAIDefaultConfig(),
  })

export const axAICohereCreativeConfig = (): AxAICohereConfig =>
  structuredClone({
    model: AxAICohereModel.CommandR,
    embedModel: AxAICohereEmbedModel.EmbedEnglishV30,
    ...axBaseAIDefaultCreativeConfig(),
  })

export interface AxAICohereArgs {
  name: 'cohere'
  apiKey: string
  config?: Readonly<Partial<AxAICohereConfig>>
  options?: Readonly<AxAIServiceOptions>
  models?: AxAIInputModelList<AxAICohereModel, AxAICohereEmbedModel>
}

class AxAICohereImpl
  implements
    AxAIServiceImpl<
      AxAICohereModel,
      AxAICohereEmbedModel,
      AxAICohereChatRequest,
      AxAICohereEmbedRequest,
      AxAICohereChatResponse,
      AxAICohereChatResponseDelta,
      AxAICohereEmbedResponse
    >
{
  private tokensUsed: AxTokenUsage | undefined

  constructor(private config: AxAICohereConfig) {}

  getTokenUsage(): AxTokenUsage | undefined {
    return this.tokensUsed
  }

  getModelConfig(): AxModelConfig {
    const { config } = this
    return {
      maxTokens: config.maxTokens,
      temperature: config.temperature,
      topP: config.topP,
      topK: config.topK,
      frequencyPenalty: config.frequencyPenalty,
      presencePenalty: config.presencePenalty,
      endSequences: config.endSequences,
      stopSequences: config.stopSequences,
      stream: config.stream,
      n: config.n,
    } as AxModelConfig
  }

  createChatReq(
    req: Readonly<AxInternalChatRequest<AxAICohereModel>>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _config: Readonly<AxAIPromptConfig>
  ): [AxAPI, AxAICohereChatRequest] {
    const model = req.model

    const lastChatMsg = req.chatPrompt.at(-1)
    const restOfChat = req.chatPrompt.slice(0, -1)

    let message: AxAICohereChatRequest['message'] | undefined

    if (
      lastChatMsg &&
      lastChatMsg.role === 'user' &&
      typeof lastChatMsg.content === 'string'
    ) {
      message = lastChatMsg?.content
    }

    const chatHistory = createHistory(restOfChat)

    type PropValue = NonNullable<
      AxAICohereChatRequest['tools']
    >[0]['parameter_definitions'][0]

    const tools: AxAICohereChatRequest['tools'] = req.functions?.map((v) => {
      const props: Record<string, PropValue> = {}
      if (v.parameters?.properties) {
        for (const [key, value] of Object.entries(v.parameters.properties)) {
          props[key] = {
            description: value.description,
            type: value.type,
            required: v.parameters.required?.includes(key) ?? false,
          }
        }
      }

      return {
        name: v.name,
        description: v.description,
        parameter_definitions: props,
      }
    })

    type FnType = Extract<AxChatRequest['chatPrompt'][0], { role: 'function' }>

    const toolResults: AxAICohereChatRequest['tool_results'] = (
      req.chatPrompt as FnType[]
    )
      .filter((chat) => chat.role === 'function')
      .map((chat) => {
        const fn = tools?.find((t) => t.name === chat.functionId)
        if (!fn) {
          throw new Error('Function not found')
        }
        return {
          call: { name: fn.name, parameters: fn.parameter_definitions },
          outputs: [{ result: chat.result ?? '' }],
        }
      })

    const apiConfig = {
      name: '/chat',
    }

    const reqValue: AxAICohereChatRequest = {
      message,
      model,
      tools,
      ...(toolResults && !message ? { tool_results: toolResults } : {}),
      chat_history: chatHistory,
      max_tokens: req.modelConfig?.maxTokens ?? this.config.maxTokens,
      temperature: req.modelConfig?.temperature ?? this.config.temperature,
      k: req.modelConfig?.topK ?? this.config.topK,
      p: req.modelConfig?.topP ?? this.config.topP,
      frequency_penalty:
        req.modelConfig?.frequencyPenalty ?? this.config.frequencyPenalty,
      presence_penalty:
        req.modelConfig?.presencePenalty ?? this.config.presencePenalty,
      end_sequences: this.config.endSequences,
      stop_sequences:
        req.modelConfig?.stopSequences ?? this.config.stopSequences,
    }

    return [apiConfig, reqValue]
  }

  createEmbedReq = (
    req: Readonly<AxInternalEmbedRequest<AxAICohereEmbedModel>>
  ): [AxAPI, AxAICohereEmbedRequest] => {
    const model = req.embedModel

    if (!model) {
      throw new Error('Embed model not set')
    }

    if (!req.texts || req.texts.length === 0) {
      throw new Error('Embed texts is empty')
    }

    const apiConfig = {
      name: '/embed',
    }

    const reqValue = {
      model,
      texts: req.texts ?? [],
      input_type: 'classification',
      truncate: '',
    }

    return [apiConfig, reqValue]
  }

  createChatResp = (resp: Readonly<AxAICohereChatResponse>): AxChatResponse => {
    this.tokensUsed = resp.meta.billed_units
      ? {
          promptTokens: resp.meta.billed_units.input_tokens,
          completionTokens: resp.meta.billed_units.output_tokens,
          totalTokens:
            resp.meta.billed_units.input_tokens +
            resp.meta.billed_units.output_tokens,
        }
      : undefined

    let finishReason: AxChatResponse['results'][0]['finishReason']
    if ('finish_reason' in resp) {
      switch (resp.finish_reason) {
        case 'COMPLETE':
          finishReason = 'stop'
          break
        case 'MAX_TOKENS':
          finishReason = 'length'
          break
        case 'ERROR':
          throw new Error('Finish reason: ERROR')
        case 'ERROR_TOXIC':
          throw new Error('Finish reason: CONTENT_FILTER')
        default:
          finishReason = 'stop'
          break
      }
    }

    let functionCalls: AxChatResponse['results'][0]['functionCalls']

    if ('tool_calls' in resp) {
      functionCalls = resp.tool_calls?.map(
        (v): NonNullable<AxChatResponse['results'][0]['functionCalls']>[0] => {
          return {
            id: v.name,
            type: 'function' as const,
            function: { name: v.name, params: v.parameters },
          }
        }
      )
    }

    const results: AxChatResponse['results'] = [
      {
        id: resp.generation_id,
        content: resp.text,
        functionCalls,
        finishReason,
      },
    ]

    return { results, remoteId: resp.response_id }
  }

  createChatStreamResp = (
    resp: Readonly<AxAICohereChatResponseDelta>,
    state: object
  ): AxChatResponse => {
    const ss = state as {
      generation_id?: string
    }

    if (resp.event_type === 'stream-start') {
      ss.generation_id = resp.generation_id
    }

    this.tokensUsed = {
      promptTokens: 0,
      completionTokens: resp.meta.billed_units?.output_tokens ?? 0,
      totalTokens: resp.meta.billed_units?.output_tokens ?? 0,
    }

    const { results } = this.createChatResp(resp)
    const result = results[0]
    if (!result) {
      throw new Error('No result')
    }

    result.id = ss.generation_id ?? ''
    return { results }
  }

  createEmbedResp(resp: Readonly<AxAICohereEmbedResponse>): AxEmbedResponse {
    return {
      remoteId: resp.id,
      embeddings: resp.embeddings,
    }
  }
}

export class AxAICohere extends AxBaseAI<
  AxAICohereModel,
  AxAICohereEmbedModel,
  AxAICohereChatRequest,
  AxAICohereEmbedRequest,
  AxAICohereChatResponse,
  AxAICohereChatResponseDelta,
  AxAICohereEmbedResponse
> {
  constructor({
    apiKey,
    config,
    options,
    models,
  }: Readonly<Omit<AxAICohereArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('Cohere API key not set')
    }
    const _config = {
      ...axAICohereDefaultConfig(),
      ...config,
    }

    const aiImpl = new AxAICohereImpl(_config)

    super(aiImpl, {
      name: 'Cohere',
      apiURL: 'https://api.cohere.ai/v1',
      headers: async () => ({ Authorization: `Bearer ${apiKey}` }),
      modelInfo: axModelInfoCohere,
      defaults: { model: _config.model },
      supportFor: { functions: true, streaming: true },
      options,
      models,
    })
  }
}
function createHistory(
  chatPrompt: Readonly<AxChatRequest['chatPrompt']>
): AxAICohereChatRequest['chat_history'] {
  return chatPrompt.map((chat) => {
    let message: string = ''

    if (
      chat.role === 'system' ||
      chat.role === 'assistant' ||
      chat.role === 'user'
    ) {
      if (typeof chat.content === 'string') {
        message = chat.content
      } else {
        throw new Error('Multi-modal content not supported')
      }
    }

    switch (chat.role) {
      case 'user':
        return { role: 'USER' as const, message }
      case 'system':
        return { role: 'SYSTEM' as const, message }
      case 'assistant': {
        const toolCalls = createToolCall(chat.functionCalls)
        return {
          role: 'CHATBOT' as const,
          message,
          tool_calls: toolCalls,
        }
      }
      case 'function': {
        const functionCalls = chatPrompt
          .map((v) => {
            if (v.role === 'assistant') {
              return v.functionCalls?.find((f) => f.id === chat.functionId)
            }
            return undefined
          })
          .filter((v) => v !== undefined)

        const call = createToolCall(functionCalls)?.at(0)

        if (!call) {
          throw new Error('Function call not found')
        }

        const outputs = [{ result: chat.result }]
        return {
          role: 'TOOL' as const,
          tool_results: [
            {
              call,
              outputs,
            },
          ],
        }
      }
      default:
        throw new Error('Unknown role')
    }
  })
}
function createToolCall(
  functionCalls: Readonly<
    Extract<
      AxChatRequest['chatPrompt'][0],
      { role: 'assistant' }
    >['functionCalls']
  >
) {
  return functionCalls?.map((v) => {
    const parameters =
      typeof v.function.params === 'string'
        ? JSON.parse(v.function.params)
        : v.function.params
    return { name: v.function.name, parameters }
  })
}



================================================
FILE: src/ax/ai/cohere/info.ts
================================================
import type { AxModelInfo } from '../types.js'

import { AxAICohereEmbedModel, AxAICohereModel } from './types.js'

export const axModelInfoCohere: AxModelInfo[] = [
  {
    name: AxAICohereModel.CommandRPlus,
    currency: 'usd',
    promptTokenCostPer1M: 3.0,
    completionTokenCostPer1M: 15,
  },
  {
    name: AxAICohereModel.CommandR,
    currency: 'usd',
    promptTokenCostPer1M: 0.5,
    completionTokenCostPer1M: 1.5,
  },
  {
    name: AxAICohereModel.Command,
    currency: 'usd',
    promptTokenCostPer1M: 0.5,
    completionTokenCostPer1M: 1.5,
  },
  {
    name: AxAICohereModel.CommandLight,
    currency: 'usd',
    promptTokenCostPer1M: 0.3,
    completionTokenCostPer1M: 0.6,
  },
  {
    name: AxAICohereEmbedModel.EmbedEnglishLightV30,
    currency: 'usd',
    promptTokenCostPer1M: 0.1,
    completionTokenCostPer1M: 0.1,
  },
  {
    name: AxAICohereEmbedModel.EmbedEnglishV30,
    currency: 'usd',
    promptTokenCostPer1M: 0.1,
    completionTokenCostPer1M: 0.1,
  },
  {
    name: AxAICohereEmbedModel.EmbedMultiLingualV30,
    currency: 'usd',
    promptTokenCostPer1M: 0.1,
    completionTokenCostPer1M: 0.1,
  },
  {
    name: AxAICohereEmbedModel.EmbedMultiLingualLightV30,
    currency: 'usd',
    promptTokenCostPer1M: 0.1,
    completionTokenCostPer1M: 0.1,
  },
]



================================================
FILE: src/ax/ai/cohere/types.ts
================================================
import type { AxModelConfig } from '../types.js'

/**
 * Cohere: Models for text generation
 */
export enum AxAICohereModel {
  CommandRPlus = 'command-r-plus',
  CommandR = 'command-r',
  Command = 'command',
  CommandLight = 'command-light',
}

/**
 * Cohere: Models for use in embeddings
 */
export enum AxAICohereEmbedModel {
  EmbedEnglishV30 = 'embed-english-v3.0',
  EmbedEnglishLightV30 = 'embed-english-light-v3.0',
  EmbedMultiLingualV30 = 'embed-multilingual-v3.0',
  EmbedMultiLingualLightV30 = 'embed-multilingual-light-v3.0',
}

/**
 * Cohere: Model options for text generation
 */
export type AxAICohereConfig = AxModelConfig & {
  model: AxAICohereModel
  embedModel?: AxAICohereEmbedModel
}

export type AxAICohereChatResponseToolCalls = {
  name: string
  parameters?: object
}[]

export type AxAICohereChatRequestToolResults = {
  call: AxAICohereChatResponseToolCalls[0]
  outputs: object[]
}[]

export type AxAICohereChatRequest = {
  message?: string
  preamble?: string
  chat_history: (
    | {
        role: 'CHATBOT'
        message: string
        tool_calls?: AxAICohereChatResponseToolCalls
      }
    | {
        role: 'SYSTEM'
        message: string
      }
    | {
        role: 'USER'
        message: string
      }
    | {
        role: 'TOOL'
        message?: string
        tool_results: AxAICohereChatRequestToolResults
      }
  )[]

  model: AxAICohereModel
  max_tokens?: number
  temperature?: number
  k?: number
  p?: number
  frequency_penalty?: number
  presence_penalty?: number
  end_sequences?: readonly string[]
  stop_sequences?: string[]
  tools?: {
    name: string
    description: string
    parameter_definitions: Record<
      string,
      {
        description: string
        type: string
        required: boolean
      }
    >
  }[]
  tool_results?: AxAICohereChatRequestToolResults
}

export type AxAICohereChatResponse = {
  response_id: string
  meta: {
    billed_units: {
      input_tokens: number
      output_tokens: number
    }
  }
  generation_id: string
  text: string
  finish_reason:
    | 'COMPLETE'
    | 'ERROR'
    | 'ERROR_TOXIC'
    | 'ERROR_LIMIT'
    | 'USER_CANCEL'
    | 'MAX_TOKENS'
  tool_calls: AxAICohereChatResponseToolCalls
}

export type AxAICohereChatResponseDelta = AxAICohereChatResponse & {
  event_type:
    | 'stream-start'
    | 'text-generation'
    | 'tool-calls-generation'
    | 'stream-end'
}

export type AxAICohereEmbedRequest = {
  texts: readonly string[]
  model: AxAICohereEmbedModel
  truncate: string
}

export type AxAICohereEmbedResponse = {
  id: string
  texts: string[]
  model: AxAICohereEmbedModel
  embeddings: number[][]
}



================================================
FILE: src/ax/ai/deepseek/api.ts
================================================
import {
  axBaseAIDefaultConfig,
  axBaseAIDefaultCreativeConfig,
} from '../base.js'
import { type AxAIOpenAIArgs, AxAIOpenAIBase } from '../openai/api.js'
import type { AxAIOpenAIConfig } from '../openai/chat_types.js'

import { axModelInfoDeepSeek } from './info.js'
import { AxAIDeepSeekModel } from './types.js'

type DeepSeekConfig = AxAIOpenAIConfig<AxAIDeepSeekModel, undefined>

export const axAIDeepSeekDefaultConfig = (): DeepSeekConfig =>
  structuredClone({
    model: AxAIDeepSeekModel.DeepSeekChat,
    ...axBaseAIDefaultConfig(),
  })

export const axAIDeepSeekCodeConfig = (): DeepSeekConfig =>
  structuredClone({
    model: AxAIDeepSeekModel.DeepSeekCoder,
    ...axBaseAIDefaultCreativeConfig(),
  })

export type AxAIDeepSeekArgs = AxAIOpenAIArgs<
  'deepseek',
  AxAIDeepSeekModel,
  undefined
>

export class AxAIDeepSeek extends AxAIOpenAIBase<AxAIDeepSeekModel, undefined> {
  constructor({
    apiKey,
    config,
    options,
    models,
    modelInfo,
  }: Readonly<Omit<AxAIDeepSeekArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('DeepSeek API key not set')
    }
    const _config = {
      ...axAIDeepSeekDefaultConfig(),
      ...config,
    }

    modelInfo = [...axModelInfoDeepSeek, ...(modelInfo ?? [])]

    super({
      apiKey,
      config: _config,
      options,
      apiURL: 'https://api.deepseek.com',
      modelInfo,
      supportFor: {
        functions: true,
        streaming: true,
        hasThinkingBudget: false,
        hasShowThoughts: false,
      },
      models,
    })

    super.setName('DeepSeek')
  }
}



================================================
FILE: src/ax/ai/deepseek/info.ts
================================================
import type { AxModelInfo } from '../types.js'

import { AxAIDeepSeekModel } from './types.js'

export const axModelInfoDeepSeek: AxModelInfo[] = [
  {
    name: AxAIDeepSeekModel.DeepSeekChat,
    currency: 'USD',
    promptTokenCostPer1M: 0.27,
    completionTokenCostPer1M: 1.1,
  },
  {
    name: AxAIDeepSeekModel.DeepSeekReasoner,
    currency: 'USD',
    promptTokenCostPer1M: 0.55,
    completionTokenCostPer1M: 2.19,
  },
]



================================================
FILE: src/ax/ai/deepseek/types.ts
================================================
/**
 * DeepSeek: Models for text generation
 */
export enum AxAIDeepSeekModel {
  DeepSeekChat = 'deepseek-chat',
  DeepSeekCoder = 'deepseek-coder',
  DeepSeekReasoner = 'deepseek-reasoner',
}



================================================
FILE: src/ax/ai/google-gemini/api.ts
================================================
import { getModelInfo } from '@ax-llm/ax/dsp/modelinfo.js'

import type { AxAPI } from '../../util/apicall.js'
import {
  AxBaseAI,
  axBaseAIDefaultConfig,
  axBaseAIDefaultCreativeConfig,
} from '../base.js'
import { GoogleVertexAuth } from '../google-vertex/auth.js'
import type {
  AxAIInputModelList,
  AxAIPromptConfig,
  AxAIServiceImpl,
  AxAIServiceOptions,
  AxChatResponse,
  AxChatResponseResult,
  AxEmbedResponse,
  AxInternalChatRequest,
  AxInternalEmbedRequest,
  AxModelConfig,
  AxModelInfo,
  AxTokenUsage,
} from '../types.js'

import { axModelInfoGoogleGemini } from './info.js'
import {
  type AxAIGoogleGeminiBatchEmbedRequest,
  type AxAIGoogleGeminiBatchEmbedResponse,
  type AxAIGoogleGeminiChatRequest,
  type AxAIGoogleGeminiChatResponse,
  type AxAIGoogleGeminiChatResponseDelta,
  type AxAIGoogleGeminiConfig,
  type AxAIGoogleGeminiContent,
  type AxAIGoogleGeminiContentPart,
  AxAIGoogleGeminiEmbedModel,
  type AxAIGoogleGeminiGenerationConfig,
  AxAIGoogleGeminiModel,
  AxAIGoogleGeminiSafetyCategory,
  type AxAIGoogleGeminiSafetySettings,
  AxAIGoogleGeminiSafetyThreshold,
  type AxAIGoogleVertexBatchEmbedRequest,
  type AxAIGoogleVertexBatchEmbedResponse,
} from './types.js'

const safetySettings: AxAIGoogleGeminiSafetySettings = [
  {
    category: AxAIGoogleGeminiSafetyCategory.HarmCategoryHarassment,
    threshold: AxAIGoogleGeminiSafetyThreshold.BlockNone,
  },
  {
    category: AxAIGoogleGeminiSafetyCategory.HarmCategoryHateSpeech,
    threshold: AxAIGoogleGeminiSafetyThreshold.BlockNone,
  },
  {
    category: AxAIGoogleGeminiSafetyCategory.HarmCategorySexuallyExplicit,
    threshold: AxAIGoogleGeminiSafetyThreshold.BlockNone,
  },
  {
    category: AxAIGoogleGeminiSafetyCategory.HarmCategoryDangerousContent,
    threshold: AxAIGoogleGeminiSafetyThreshold.BlockNone,
  },
]

/**
 * AxAIGoogleGemini: Default Model options for text generation
 */
export const axAIGoogleGeminiDefaultConfig = (): AxAIGoogleGeminiConfig =>
  structuredClone<AxAIGoogleGeminiConfig>({
    model: AxAIGoogleGeminiModel.Gemini25Flash,
    embedModel: AxAIGoogleGeminiEmbedModel.TextEmbedding005,
    safetySettings,
    thinkingTokenBudgetLevels: {
      minimal: 200,
      low: 800,
      medium: 5000,
      high: 10000,
      highest: 24500,
    },
    ...axBaseAIDefaultConfig(),
  })

export const axAIGoogleGeminiDefaultCreativeConfig =
  (): AxAIGoogleGeminiConfig =>
    structuredClone<AxAIGoogleGeminiConfig>({
      model: AxAIGoogleGeminiModel.Gemini20Flash,
      embedModel: AxAIGoogleGeminiEmbedModel.TextEmbedding005,
      safetySettings,
      thinkingTokenBudgetLevels: {
        minimal: 200,
        low: 800,
        medium: 5000,
        high: 10000,
        highest: 24500,
      },
      ...axBaseAIDefaultCreativeConfig(),
    })

export interface AxAIGoogleGeminiOptionsTools {
  codeExecution?: boolean
  googleSearchRetrieval?: {
    mode?: 'MODE_DYNAMIC'
    dynamicThreshold?: number
  }
  googleSearch?: boolean
  urlContext?: boolean
}

export interface AxAIGoogleGeminiArgs {
  name: 'google-gemini'
  apiKey?: string
  projectId?: string
  region?: string
  endpointId?: string
  config?: Readonly<Partial<AxAIGoogleGeminiConfig>>
  options?: Readonly<AxAIServiceOptions & AxAIGoogleGeminiOptionsTools>
  models?: AxAIInputModelList<AxAIGoogleGeminiModel, AxAIGoogleGeminiEmbedModel>
  modelInfo?: AxModelInfo[]
}

class AxAIGoogleGeminiImpl
  implements
    AxAIServiceImpl<
      AxAIGoogleGeminiModel,
      AxAIGoogleGeminiEmbedModel,
      AxAIGoogleGeminiChatRequest,
      AxAIGoogleGeminiBatchEmbedRequest | AxAIGoogleVertexBatchEmbedRequest,
      AxAIGoogleGeminiChatResponse,
      AxAIGoogleGeminiChatResponseDelta,
      AxAIGoogleGeminiBatchEmbedResponse | AxAIGoogleVertexBatchEmbedResponse
    >
{
  private tokensUsed: AxTokenUsage | undefined

  constructor(
    private config: AxAIGoogleGeminiConfig,
    private isVertex: boolean,
    private endpointId?: string,
    private apiKey?: string,
    private options?: AxAIGoogleGeminiArgs['options']
  ) {
    if (!this.isVertex && this.config.autoTruncate) {
      throw new Error('Auto truncate is not supported for GoogleGemini')
    }
  }

  getTokenUsage(): AxTokenUsage | undefined {
    return this.tokensUsed
  }

  getModelConfig(): AxModelConfig {
    const { config } = this
    return {
      maxTokens: config.maxTokens,
      temperature: config.temperature,
      topP: config.topP,
      topK: config.topK,
      presencePenalty: config.presencePenalty,
      frequencyPenalty: config.frequencyPenalty,
      stopSequences: config.stopSequences,
      endSequences: config.endSequences,
      stream: config.stream,
      n: config.n,
    } as AxModelConfig
  }

  createChatReq = (
    req: Readonly<AxInternalChatRequest<AxAIGoogleGeminiModel>>,
    config: Readonly<AxAIPromptConfig>
  ): [AxAPI, AxAIGoogleGeminiChatRequest] => {
    const model = req.model
    const stream = req.modelConfig?.stream ?? this.config.stream

    if (!req.chatPrompt || req.chatPrompt.length === 0) {
      throw new Error('Chat prompt is empty')
    }

    let apiConfig
    if (this.endpointId) {
      apiConfig = {
        name: stream
          ? `/${this.endpointId}:streamGenerateContent?alt=sse`
          : `/${this.endpointId}:generateContent`,
      }
    } else {
      apiConfig = {
        name: stream
          ? `/models/${model}:streamGenerateContent?alt=sse`
          : `/models/${model}:generateContent`,
      }
    }

    if (!this.isVertex) {
      const pf = stream ? '&' : '?'
      apiConfig.name += `${pf}key=${this.apiKey}`
    }

    const systemPrompts = req.chatPrompt
      .filter((p) => p.role === 'system')
      .map((p) => p.content)

    const systemInstruction =
      systemPrompts.length > 0
        ? {
            role: 'user' as const,
            parts: [{ text: systemPrompts.join(' ') }],
          }
        : undefined

    const contents: AxAIGoogleGeminiContent[] = req.chatPrompt
      .filter((p) => p.role !== 'system')
      .map((msg, i) => {
        switch (msg.role) {
          case 'user': {
            const parts: AxAIGoogleGeminiContentPart[] = Array.isArray(
              msg.content
            )
              ? msg.content.map((c, i) => {
                  switch (c.type) {
                    case 'text':
                      return { text: c.text }
                    case 'image':
                      return {
                        inlineData: { mimeType: c.mimeType, data: c.image },
                      }
                    default:
                      throw new Error(
                        `Chat prompt content type not supported (index: ${i})`
                      )
                  }
                })
              : [{ text: msg.content }]
            return {
              role: 'user' as const,
              parts,
            }
          }

          case 'assistant': {
            let parts: AxAIGoogleGeminiContentPart[] = []

            if (msg.functionCalls) {
              parts = msg.functionCalls.map((f) => {
                const args =
                  typeof f.function.params === 'string'
                    ? JSON.parse(f.function.params)
                    : f.function.params
                return {
                  functionCall: {
                    name: f.function.name,
                    args: args,
                  },
                }
              })

              if (!parts) {
                throw new Error('Function call is empty')
              }

              return {
                role: 'model' as const,
                parts,
              }
            }

            if (!msg.content) {
              throw new Error('Assistant content is empty')
            }

            parts = [{ text: msg.content }]
            return {
              role: 'model' as const,
              parts,
            }
          }

          case 'function': {
            if (!('functionId' in msg)) {
              throw new Error(`Chat prompt functionId is empty (index: ${i})`)
            }
            const parts: AxAIGoogleGeminiContentPart[] = [
              {
                functionResponse: {
                  name: msg.functionId,
                  response: { result: msg.result },
                },
              },
            ]

            return {
              role: 'user' as const,
              parts,
            }
          }

          default:
            throw new Error(
              `Invalid role: ${JSON.stringify(msg)} (index: ${i})`
            )
        }
      })

    let tools: AxAIGoogleGeminiChatRequest['tools'] | undefined = []

    if (req.functions && req.functions.length > 0) {
      tools.push({ function_declarations: req.functions })
    }

    if (this.options?.codeExecution) {
      tools.push({ code_execution: {} })
    }

    if (this.options?.googleSearchRetrieval) {
      tools.push({
        google_search_retrieval: {
          dynamic_retrieval_config: this.options.googleSearchRetrieval,
        },
      })
    }

    if (this.options?.googleSearch) {
      tools.push({ google_search: {} })
    }

    if (this.options?.urlContext) {
      tools.push({ url_context: {} })
    }

    if (tools.length === 0) {
      tools = undefined
    }

    let toolConfig

    if (req.functionCall) {
      if (req.functionCall === 'none') {
        toolConfig = { function_calling_config: { mode: 'NONE' as const } }
      } else if (req.functionCall === 'auto') {
        toolConfig = { function_calling_config: { mode: 'AUTO' as const } }
      } else if (req.functionCall === 'required') {
        toolConfig = {
          function_calling_config: { mode: 'ANY' as const },
        }
      } else {
        const allowedFunctionNames = req.functionCall.function?.name
          ? {
              allowedFunctionNames: [req.functionCall.function.name],
            }
          : {}
        toolConfig = {
          function_calling_config: { mode: 'ANY' as const },
          ...allowedFunctionNames,
        }
      }
    } else if (tools && tools.length > 0) {
      toolConfig = { function_calling_config: { mode: 'AUTO' as const } }
    }

    const thinkingConfig: AxAIGoogleGeminiGenerationConfig['thinkingConfig'] =
      {}

    if (this.config.thinking?.includeThoughts) {
      thinkingConfig.includeThoughts = true
    }

    if (this.config.thinking?.thinkingTokenBudget) {
      thinkingConfig.thinkingBudget = this.config.thinking.thinkingTokenBudget
    }

    // Then, override based on prompt-specific config
    if (config?.thinkingTokenBudget) {
      //The thinkingBudget must be an integer in the range 0 to 24576
      const levels = this.config.thinkingTokenBudgetLevels

      switch (config.thinkingTokenBudget) {
        case 'none':
          thinkingConfig.thinkingBudget = 0 // Explicitly set to 0
          thinkingConfig.includeThoughts = false // When thinkingTokenBudget is 'none', disable showThoughts
          break
        case 'minimal':
          thinkingConfig.thinkingBudget = levels?.minimal ?? 200
          break
        case 'low':
          thinkingConfig.thinkingBudget = levels?.low ?? 800
          break
        case 'medium':
          thinkingConfig.thinkingBudget = levels?.medium ?? 5000
          break
        case 'high':
          thinkingConfig.thinkingBudget = levels?.high ?? 10000
          break
        case 'highest':
          thinkingConfig.thinkingBudget = levels?.highest ?? 24500
          break
      }
    }

    if (config?.showThoughts !== undefined) {
      // Only override includeThoughts if thinkingTokenBudget is not 'none'
      if (config?.thinkingTokenBudget !== 'none') {
        thinkingConfig.includeThoughts = config.showThoughts
      }
    }

    const generationConfig: AxAIGoogleGeminiGenerationConfig = {
      maxOutputTokens: req.modelConfig?.maxTokens ?? this.config.maxTokens,
      temperature: req.modelConfig?.temperature ?? this.config.temperature,
      topP: req.modelConfig?.topP ?? this.config.topP,
      topK: req.modelConfig?.topK ?? this.config.topK,
      frequencyPenalty:
        req.modelConfig?.frequencyPenalty ?? this.config.frequencyPenalty,
      candidateCount: 1,
      stopSequences:
        req.modelConfig?.stopSequences ?? this.config.stopSequences,
      responseMimeType: 'text/plain',

      ...(Object.keys(thinkingConfig).length > 0 ? { thinkingConfig } : {}),
    }

    const safetySettings = this.config.safetySettings

    const reqValue: AxAIGoogleGeminiChatRequest = {
      contents,
      tools,
      toolConfig,
      systemInstruction,
      generationConfig,
      safetySettings,
    }

    return [apiConfig, reqValue]
  }

  createEmbedReq = (
    req: Readonly<AxInternalEmbedRequest<AxAIGoogleGeminiEmbedModel>>
  ): [
    AxAPI,
    AxAIGoogleGeminiBatchEmbedRequest | AxAIGoogleVertexBatchEmbedRequest,
  ] => {
    const model = req.embedModel

    if (!model) {
      throw new Error('Embed model not set')
    }

    if (!req.texts || req.texts.length === 0) {
      throw new Error('Embed texts is empty')
    }

    let apiConfig
    let reqValue:
      | AxAIGoogleGeminiBatchEmbedRequest
      | AxAIGoogleVertexBatchEmbedRequest

    if (this.isVertex) {
      if (this.endpointId) {
        apiConfig = {
          name: `/${this.endpointId}:predict`,
        }
      } else {
        apiConfig = {
          name: `/models/${model}:predict`,
        }
      }

      reqValue = {
        instances: req.texts.map((text) => ({
          content: text,
          ...(this.config.embedType && { taskType: this.config.embedType }),
        })),
        parameters: {
          autoTruncate: this.config.autoTruncate,
          outputDimensionality: this.config.dimensions,
        },
      }
    } else {
      apiConfig = {
        name: `/models/${model}:batchEmbedContents?key=${this.apiKey}`,
      }

      reqValue = {
        requests: req.texts.map((text) => ({
          model: 'models/' + model,
          content: { parts: [{ text }] },
          outputDimensionality: this.config.dimensions,
          ...(this.config.embedType && { taskType: this.config.embedType }),
        })),
      }
    }

    return [apiConfig, reqValue]
  }

  createChatResp = (
    resp: Readonly<AxAIGoogleGeminiChatResponse>
  ): AxChatResponse => {
    const results: AxChatResponseResult[] = resp.candidates?.map(
      (candidate) => {
        const result: AxChatResponseResult = {}

        switch (candidate.finishReason) {
          case 'MAX_TOKENS':
            result.finishReason = 'length'
            break
          case 'STOP':
            result.finishReason = 'stop'
            break
          case 'SAFETY':
            throw new Error('Finish reason: SAFETY')
          case 'RECITATION':
            throw new Error('Finish reason: RECITATION')
          case 'MALFORMED_FUNCTION_CALL':
            throw new Error('Finish reason: MALFORMED_FUNCTION_CALL')
        }

        if (!candidate.content || !candidate.content.parts) {
          return result
        }

        for (const part of candidate.content.parts) {
          if ('text' in part) {
            if ('thought' in part && part.thought) {
              result.thought = part.text
            } else {
              result.content = part.text
            }
            continue
          }

          if ('functionCall' in part) {
            result.functionCalls = [
              {
                id: part.functionCall.name,
                type: 'function',
                function: {
                  name: part.functionCall.name,
                  params: part.functionCall.args,
                },
              },
            ]
          }
        }
        return result
      }
    )

    if (resp.usageMetadata) {
      this.tokensUsed = {
        totalTokens: resp.usageMetadata.totalTokenCount,
        promptTokens: resp.usageMetadata.promptTokenCount,
        completionTokens: resp.usageMetadata.candidatesTokenCount,
        thoughtsTokens: resp.usageMetadata.thoughtsTokenCount,
      }
    }
    return { results }
  }

  createChatStreamResp = (
    resp: Readonly<AxAIGoogleGeminiChatResponseDelta>
  ): AxChatResponse => {
    return this.createChatResp(resp)
  }

  createEmbedResp = (
    resp: Readonly<
      AxAIGoogleGeminiBatchEmbedResponse | AxAIGoogleVertexBatchEmbedResponse
    >
  ): AxEmbedResponse => {
    let embeddings: number[][]
    if (this.isVertex) {
      embeddings = (resp as AxAIGoogleVertexBatchEmbedResponse).predictions.map(
        (prediction) => prediction.embeddings.values
      )
    } else {
      embeddings = (resp as AxAIGoogleGeminiBatchEmbedResponse).embeddings.map(
        (embedding) => embedding.values
      )
    }

    return {
      embeddings,
    }
  }
}

/**
 * AxAIGoogleGemini: AI Service
 */
export class AxAIGoogleGemini extends AxBaseAI<
  AxAIGoogleGeminiModel,
  AxAIGoogleGeminiEmbedModel,
  AxAIGoogleGeminiChatRequest,
  AxAIGoogleGeminiBatchEmbedRequest | AxAIGoogleVertexBatchEmbedRequest,
  AxAIGoogleGeminiChatResponse,
  AxAIGoogleGeminiChatResponseDelta,
  AxAIGoogleGeminiBatchEmbedResponse | AxAIGoogleVertexBatchEmbedResponse
> {
  constructor({
    apiKey,
    projectId,
    region,
    endpointId,
    config,
    options,
    models,
    modelInfo,
  }: Readonly<Omit<AxAIGoogleGeminiArgs, 'name'>>) {
    const isVertex = projectId !== undefined && region !== undefined

    let apiURL
    let headers

    if (isVertex) {
      let path
      if (endpointId) {
        path = 'endpoints'
      } else {
        path = 'publishers/google'
      }

      apiURL = `https://${region}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${region}/${path}`
      if (apiKey) {
        headers = async () => ({ Authorization: `Bearer ${apiKey}` })
      } else {
        const vertexAuth = new GoogleVertexAuth()
        headers = async () => ({
          Authorization: `Bearer ${await vertexAuth.getAccessToken()}`,
        })
      }
    } else {
      if (!apiKey) {
        throw new Error('GoogleGemini AI API key not set')
      }
      apiURL = 'https://generativelanguage.googleapis.com/v1beta'
      headers = async () => ({})
    }

    const _config = {
      ...axAIGoogleGeminiDefaultConfig(),
      ...config,
    }

    const aiImpl = new AxAIGoogleGeminiImpl(
      _config,
      isVertex,
      endpointId,
      apiKey,
      options
    )

    modelInfo = [...axModelInfoGoogleGemini, ...(modelInfo ?? [])]

    const supportFor = (model: AxAIGoogleGeminiModel) => {
      const mi = getModelInfo<
        AxAIGoogleGeminiModel,
        AxAIGoogleGeminiEmbedModel
      >({
        model,
        modelInfo,
        models,
      })
      return {
        functions: true,
        streaming: true,
        hasThinkingBudget: mi?.hasThinkingBudget ?? false,
        hasShowThoughts: mi?.hasShowThoughts ?? false,
        functionCot: false,
      }
    }

    super(aiImpl, {
      name: 'GoogleGeminiAI',
      apiURL,
      headers,
      modelInfo,
      defaults: {
        model: _config.model as AxAIGoogleGeminiModel,
        embedModel: _config.embedModel as AxAIGoogleGeminiEmbedModel,
      },
      options,
      supportFor,
      models,
    })
  }
}



================================================
FILE: src/ax/ai/google-gemini/info.ts
================================================
import type { AxModelInfo } from '../types.js'

import { AxAIGoogleGeminiModel } from './types.js'

/**
 * AxAIGoogleGemini: Model information
 */
export const axModelInfoGoogleGemini: AxModelInfo[] = [
  {
    name: AxAIGoogleGeminiModel.Gemini25Pro,
    currency: 'usd',
    characterIsToken: false,
    promptTokenCostPer1M: 2.5,
    completionTokenCostPer1M: 15.0,
    hasThinkingBudget: true,
    hasShowThoughts: true,
  },
  {
    name: AxAIGoogleGeminiModel.Gemini25Flash,
    currency: 'usd',
    characterIsToken: false,
    promptTokenCostPer1M: 15.0,
    completionTokenCostPer1M: 3.5,
    hasThinkingBudget: true,
    hasShowThoughts: true,
  },
  {
    name: AxAIGoogleGeminiModel.Gemini25FlashLite,
    currency: 'usd',
    characterIsToken: false,
    promptTokenCostPer1M: 0.1,
    completionTokenCostPer1M: 0.4,
    hasThinkingBudget: true,
    hasShowThoughts: true,
  },
  {
    name: AxAIGoogleGeminiModel.Gemini20Flash,
    currency: 'usd',
    characterIsToken: false,
    promptTokenCostPer1M: 0.01,
    completionTokenCostPer1M: 0.4,
  },

  {
    name: AxAIGoogleGeminiModel.Gemini20FlashLite,
    currency: 'usd',
    characterIsToken: false,
    promptTokenCostPer1M: 0.0,
    completionTokenCostPer1M: 0.0,
  },
  {
    name: AxAIGoogleGeminiModel.Gemini15Flash,
    currency: 'usd',
    characterIsToken: false,
    promptTokenCostPer1M: 0.075,
    completionTokenCostPer1M: 0.3,
  },
  {
    name: AxAIGoogleGeminiModel.Gemini15Flash8B,
    currency: 'usd',
    characterIsToken: false,
    promptTokenCostPer1M: 0.0375,
    completionTokenCostPer1M: 0.15,
  },
  {
    name: AxAIGoogleGeminiModel.Gemini15Pro,
    currency: 'usd',
    characterIsToken: false,
    promptTokenCostPer1M: 1.25,
    completionTokenCostPer1M: 5.0,
  },
  {
    name: AxAIGoogleGeminiModel.Gemini1Pro,
    currency: 'usd',
    characterIsToken: false,
    promptTokenCostPer1M: 0.5,
    completionTokenCostPer1M: 1.5,
  },
]



================================================
FILE: src/ax/ai/google-gemini/types.ts
================================================
import type { AxModelConfig } from '../types.js'

export enum AxAIGoogleGeminiModel {
  Gemini25Pro = 'gemini-2.5-pro',
  Gemini25Flash = 'gemini-2.5-flash',
  Gemini25FlashLite = 'gemini-2.5-flash-lite-preview-06-17',
  Gemini20Flash = 'gemini-2.0-flash',
  Gemini20FlashLite = 'gemini-2.0-flash-lite-preview-02-05',
  Gemini1Pro = 'gemini-1.0-pro',
  Gemini15Flash = 'gemini-1.5-flash',
  Gemini15Flash002 = 'gemini-1.5-flash-002',
  Gemini15Flash8B = 'gemini-1.5-flash-8b',
  Gemini15Pro = 'gemini-1.5-pro',
}

export enum AxAIGoogleGeminiEmbedModel {
  GeminiEmbedding = 'gemini-embedding-exp',
  TextEmbeddingLarge = 'text-embedding-large-exp-03-07',
  TextEmbedding004 = 'text-embedding-004',
  TextEmbedding005 = 'text-embedding-005',
}

export enum AxAIGoogleGeminiSafetyCategory {
  HarmCategoryHarassment = 'HARM_CATEGORY_HARASSMENT',
  HarmCategoryHateSpeech = 'HARM_CATEGORY_HATE_SPEECH',
  HarmCategorySexuallyExplicit = 'HARM_CATEGORY_SEXUALLY_EXPLICIT',
  HarmCategoryDangerousContent = 'HARM_CATEGORY_DANGEROUS_CONTENT',
}

export enum AxAIGoogleGeminiSafetyThreshold {
  BlockNone = 'BLOCK_NONE',
  BlockOnlyHigh = 'BLOCK_ONLY_HIGH',
  BlockMediumAndAbove = 'BLOCK_MEDIUM_AND_ABOVE',
  BlockLowAndAbove = 'BLOCK_LOW_AND_ABOVE',
  BlockDefault = 'HARM_BLOCK_THRESHOLD_UNSPECIFIED',
}

export enum AxAIGoogleGeminiEmbedTypes {
  SemanticSimilarity = 'SEMANTIC_SIMILARITY',
  Classification = 'CLASSIFICATION',
  Clustering = 'CLUSTERING',
  RetrievalDocument = 'RETRIEVAL_DOCUMENT',
  RetrievalQuery = 'RETRIEVAL_QUERY',
  QuestionAnswering = 'QUESTION_ANSWERING',
  FactVerification = 'FACT_VERIFICATION',
  CodeRetrievalQuery = 'CODE_RETRIEVAL_QUERY',
}

export type AxAIGoogleGeminiContent = {
  role: 'user' | 'model'
  parts: AxAIGoogleGeminiContentPart[]
}

// Part type with common fields intersected with a union of data fields
export type AxAIGoogleGeminiContentPart = {
  thought?: boolean
  metadata?: { videoMetadata: object }
} & (
  | { text: string }
  | {
      inlineData: {
        mimeType: string
        data: string
      }
    }
  | {
      functionCall: {
        name: string
        args: object
      }
    }
  | {
      functionResponse: {
        name: string
        response: object
      }
    }
  | {
      fileData: {
        mimeType: string
        fileUri: string
      }
    }
  | { executableCode: object }
  | { codeExecutionResult: object }
)

export type AxAIGoogleGeminiToolFunctionDeclaration = {
  name: string
  description?: string
  parameters?: object
}

export type AxAIGoogleGeminiToolGoogleSearchRetrieval = {
  dynamic_retrieval_config: {
    mode?: 'MODE_DYNAMIC'
    dynamic_threshold?: number
  }
}

export type AxAIGoogleGeminiTool = {
  function_declarations?: AxAIGoogleGeminiToolFunctionDeclaration[]
  code_execution?: object
  google_search_retrieval?: AxAIGoogleGeminiToolGoogleSearchRetrieval
  google_search?: object
  url_context?: object
}

export type AxAIGoogleGeminiToolConfig = {
  function_calling_config: {
    mode: 'ANY' | 'NONE' | 'AUTO'
    allowed_function_names?: string[]
  }
}

export type AxAIGoogleGeminiGenerationConfig = {
  temperature?: number
  topP?: number
  topK?: number
  frequencyPenalty?: number
  candidateCount?: number
  maxOutputTokens?: number
  stopSequences?: readonly string[]
  responseMimeType?: string
  thinkingConfig?: {
    thinkingBudget?: number
    includeThoughts?: boolean
  }
}

export type AxAIGoogleGeminiSafetySettings = {
  category: AxAIGoogleGeminiSafetyCategory
  threshold: AxAIGoogleGeminiSafetyThreshold
}[]

export type AxAIGoogleGeminiChatRequest = {
  contents: AxAIGoogleGeminiContent[]
  tools?: AxAIGoogleGeminiTool[]
  toolConfig?: AxAIGoogleGeminiToolConfig
  systemInstruction?: AxAIGoogleGeminiContent
  generationConfig: AxAIGoogleGeminiGenerationConfig
  safetySettings?: AxAIGoogleGeminiSafetySettings
}

export type AxAIGoogleGeminiChatResponse = {
  candidates: {
    content: AxAIGoogleGeminiContent

    finishReason:
      | 'STOP'
      | 'MAX_TOKENS'
      | 'SAFETY'
      | 'RECITATION'
      | 'OTHER'
      | 'MALFORMED_FUNCTION_CALL'
    citationMetadata: {
      citations: {
        startIndex: number
        endIndex: number
        uri: string
        title: string
        license: string
        publicationDate: {
          year: number
          month: number
          day: number
        }
      }[]
    }
  }[]
  usageMetadata: {
    promptTokenCount: number
    candidatesTokenCount: number
    totalTokenCount: number
    thoughtsTokenCount: number
  }
}

export type AxAIGoogleGeminiChatResponseDelta = AxAIGoogleGeminiChatResponse

export type AxAIGoogleGeminiThinkingConfig = {
  thinkingTokenBudget?: number
  includeThoughts?: boolean
}

export type AxAIGoogleGeminiThinkingTokenBudgetLevels = {
  minimal?: number
  low?: number
  medium?: number
  high?: number
  highest?: number
}

/**
 * AxAIGoogleGeminiConfig: Configuration options for Google Gemini API
 */
export type AxAIGoogleGeminiConfig = AxModelConfig & {
  model: AxAIGoogleGeminiModel
  embedModel?: AxAIGoogleGeminiEmbedModel
  safetySettings?: AxAIGoogleGeminiSafetySettings
  embedType?: AxAIGoogleGeminiEmbedTypes
  dimensions?: number
  autoTruncate?: boolean
  thinking?: AxAIGoogleGeminiThinkingConfig
  thinkingTokenBudgetLevels?: AxAIGoogleGeminiThinkingTokenBudgetLevels
  urlContext?: string
}

/**
 * AxAIGoogleGeminiEmbedRequest: Structure for making an embedding request to the Google Gemini API.
 */
export type AxAIGoogleGeminiBatchEmbedRequest = {
  requests: {
    model: string
    content: {
      parts: { text: string }[]
    }
  }[]
}

/**
 * AxAIGoogleGeminiEmbedResponse: Structure for handling responses from the Google Gemini API embedding requests.
 */
export type AxAIGoogleGeminiBatchEmbedResponse = {
  embeddings: {
    values: number[]
  }[]
}

/**
 * AxAIGoogleVertexBatchEmbedRequest: Structure for making an embedding request to the Google Vertex API.
 */
export type AxAIGoogleVertexBatchEmbedRequest = {
  instances: {
    content: string
    task_type?: AxAIGoogleGeminiEmbedTypes
  }[]
  parameters: {
    autoTruncate?: boolean
    outputDimensionality?: number
  }
}

/**
 * AxAIGoogleVertexBatchEmbedResponse: Structure for handling responses from the Google Vertex API embedding requests.
 */
export type AxAIGoogleVertexBatchEmbedResponse = {
  predictions: {
    embeddings: {
      values: number[]
    }
  }[]
}



================================================
FILE: src/ax/ai/google-vertex/auth.ts
================================================
import { GoogleAuth } from 'google-auth-library'
import type {
  GoogleAuthOptions,
  JSONClient,
} from 'google-auth-library/build/src/auth/googleauth.js'

/**
 * This class is used to authenticate with the Google Vertex AI API.
 */
export class GoogleVertexAuth {
  private auth: GoogleAuth
  private client?: JSONClient

  constructor(config: GoogleAuthOptions = {}) {
    this.auth = new GoogleAuth({
      scopes: ['https://www.googleapis.com/auth/cloud-platform'],
      ...config,
    })
  }

  async getAuthenticatedClient() {
    if (!this.client) {
      this.client = (await this.auth.getClient()) as JSONClient
    }
    return this.client
  }

  async getAccessToken() {
    const client = await this.getAuthenticatedClient()
    const response = await client.getAccessToken()
    if (!response.token) {
      throw new Error('Failed to obtain access token')
    }
    return response.token
  }
}



================================================
FILE: src/ax/ai/groq/api.ts
================================================
import { AxRateLimiterTokenUsage } from '../../util/rate-limit.js'
import { axBaseAIDefaultConfig } from '../base.js'
import { type AxAIOpenAIArgs, AxAIOpenAIBase } from '../openai/api.js'
import type { AxAIOpenAIConfig } from '../openai/chat_types.js'
import type {
  AxAIServiceOptions,
  AxModelInfo,
  AxRateLimiterFunction,
} from '../types.js'

import { axModelInfoGroq } from './info.js'
import { AxAIGroqModel } from './types.js'

type AxAIGroqAIConfig = AxAIOpenAIConfig<AxAIGroqModel, undefined>

const axAIGroqDefaultConfig = (): AxAIGroqAIConfig =>
  structuredClone({
    model: AxAIGroqModel.Llama33_70B,
    ...axBaseAIDefaultConfig(),
  })

export type AxAIGroqArgs = AxAIOpenAIArgs<'groq', AxAIGroqModel, undefined> & {
  options?: Readonly<AxAIServiceOptions> & { tokensPerMinute?: number }
  modelInfo?: AxModelInfo[]
}

export class AxAIGroq extends AxAIOpenAIBase<AxAIGroqModel, undefined> {
  constructor({
    apiKey,
    config,
    options,
    models,
    modelInfo,
  }: Readonly<Omit<AxAIGroqArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('Groq API key not set')
    }
    const _config = {
      ...axAIGroqDefaultConfig(),
      ...config,
    }

    const _options = {
      ...options,
      streamingUsage: false,
    }

    modelInfo = [...axModelInfoGroq, ...(modelInfo ?? [])]

    const supportFor = {
      functions: true,
      streaming: true,
      hasThinkingBudget: false,
      hasShowThoughts: false,
    }

    super({
      apiKey,
      config: _config,
      options: _options,
      modelInfo,
      apiURL: 'https://api.groq.com/openai/v1',
      models,
      supportFor,
    })

    super.setName('Groq')
    this.setOptions(_options)
  }

  override setOptions = (options: Readonly<AxAIServiceOptions>) => {
    const rateLimiter = this.newRateLimiter(options)
    super.setOptions({ ...options, rateLimiter })
  }

  private newRateLimiter = (options: Readonly<AxAIGroqArgs['options']>) => {
    if (options?.rateLimiter) {
      return options.rateLimiter
    }

    const tokensPerMin = options?.tokensPerMinute ?? 4800
    const rt = new AxRateLimiterTokenUsage(tokensPerMin, tokensPerMin / 60, {
      debug: options?.debug,
    })

    const rtFunc: AxRateLimiterFunction = async (func, info) => {
      const totalTokens = info.modelUsage?.tokens?.totalTokens || 0
      await rt.acquire(totalTokens)
      return await func()
    }

    return rtFunc
  }
}



================================================
FILE: src/ax/ai/groq/info.ts
================================================
import type { AxModelInfo } from '../types.js'

import { AxAIGroqModel } from './types.js'

/**
 * AxAIGroq: Model information
 */
export const axModelInfoGroq: AxModelInfo[] = [
  {
    name: AxAIGroqModel.Gemma2_9B,
    currency: 'usd',
    characterIsToken: true,
    promptTokenCostPer1M: 0.2,
    completionTokenCostPer1M: 0.2,
  },
  {
    name: AxAIGroqModel.Llama33_70B,
    currency: 'usd',
    characterIsToken: true,
    promptTokenCostPer1M: 0.59,
    completionTokenCostPer1M: 0.79,
  },
  {
    name: AxAIGroqModel.Llama3_8B,
    currency: 'usd',
    characterIsToken: true,
    promptTokenCostPer1M: 0.05,
    completionTokenCostPer1M: 0.08,
  },
  {
    name: AxAIGroqModel.Mixtral_8x7B,
    currency: 'usd',
    characterIsToken: true,
    promptTokenCostPer1M: 0.24,
    completionTokenCostPer1M: 0.24,
  },
]



================================================
FILE: src/ax/ai/groq/types.ts
================================================
export enum AxAIGroqModel {
  Llama3_8B = 'llama3-8b-8192',
  Llama33_70B = 'llama-3.3-70b-versatile',
  Mixtral_8x7B = 'mixtral-8x7b-32768',
  Gemma2_9B = 'gemma2-9b-it',
}



================================================
FILE: src/ax/ai/huggingface/api.ts
================================================
import type { AxAPI } from '../../util/apicall.js'
import {
  AxBaseAI,
  axBaseAIDefaultConfig,
  axBaseAIDefaultCreativeConfig,
} from '../base.js'
import type {
  AxAIInputModelList,
  AxAIPromptConfig,
  AxAIServiceImpl,
  AxAIServiceOptions,
  AxChatResponse,
  AxInternalChatRequest,
  AxModelConfig,
  AxTokenUsage,
} from '../types.js'

import { axModelInfoHuggingFace } from './info.js'
import {
  type AxAIHuggingFaceConfig,
  AxAIHuggingFaceModel,
  type AxAIHuggingFaceRequest,
  type AxAIHuggingFaceResponse,
} from './types.js'

export const axAIHuggingFaceDefaultConfig = (): AxAIHuggingFaceConfig =>
  structuredClone({
    model: AxAIHuggingFaceModel.MetaLlama270BChatHF,
    ...axBaseAIDefaultConfig(),
  })

export const axAIHuggingFaceCreativeConfig = (): AxAIHuggingFaceConfig =>
  structuredClone({
    model: AxAIHuggingFaceModel.MetaLlama270BChatHF,
    ...axBaseAIDefaultCreativeConfig(),
  })

export interface AxAIHuggingFaceArgs {
  name: 'huggingface'
  apiKey: string
  config?: Readonly<Partial<AxAIHuggingFaceConfig>>
  options?: Readonly<AxAIServiceOptions>
  models?: AxAIInputModelList<AxAIHuggingFaceModel, undefined>
}

class AxAIHuggingFaceImpl
  implements
    AxAIServiceImpl<
      AxAIHuggingFaceModel,
      unknown,
      AxAIHuggingFaceRequest,
      unknown,
      AxAIHuggingFaceResponse,
      unknown,
      unknown
    >
{
  private tokensUsed: AxTokenUsage | undefined

  constructor(private config: AxAIHuggingFaceConfig) {}

  getTokenUsage(): AxTokenUsage | undefined {
    return this.tokensUsed
  }

  getModelConfig(): AxModelConfig {
    const { config } = this
    return {
      maxTokens: config.maxTokens,
      temperature: config.temperature,
      topP: config.topP,
      topK: config.topK,
      n: config.n,
      presencePenalty: config.presencePenalty,
    } as AxModelConfig
  }

  createChatReq = (
    req: Readonly<AxInternalChatRequest<AxAIHuggingFaceModel>>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _config: Readonly<AxAIPromptConfig>
  ): [AxAPI, AxAIHuggingFaceRequest] => {
    const model = req.model

    const functionsList = req.functions
      ? `Functions:\n${JSON.stringify(req.functions, null, 2)}\n`
      : ''

    const prompt = req.chatPrompt
      ?.map((msg) => {
        switch (msg.role) {
          case 'user':
            return `User: ${msg.content}`
          case 'system':
            return `System: ${msg.content}`
          case 'function':
            return `Function Result: ${msg.result}`
          case 'assistant': {
            const fc = msg.functionCalls
              ?.map((fc) => {
                const args =
                  typeof fc.function.params === 'string'
                    ? fc.function.params
                    : JSON.stringify(fc.function.params)

                return `${fc.function.name}(${args})`
              })
              .join('\n')
            if (fc) {
              return `Assistant: ${msg.content}\n Functions:\n${fc}`
            }
            return `Assistant: ${msg.content}`
          }
          default:
            throw new Error(`Unknown role`)
        }

        //return `${msg.role}: ${msg.content}`;
      })
      .join('\n')

    const inputs = `${functionsList} ${prompt}`.trim()

    const apiConfig = {
      name: '/models',
    }

    const reqValue: AxAIHuggingFaceRequest = {
      model,
      inputs,
      parameters: {
        max_new_tokens: req.modelConfig?.maxTokens ?? this.config.maxTokens,
        repetition_penalty:
          req.modelConfig?.presencePenalty ?? this.config.presencePenalty,
        temperature: req.modelConfig?.temperature ?? this.config.temperature,
        top_p: req.modelConfig?.topP ?? this.config.topP,
        top_k: req.modelConfig?.topK ?? this.config.topK,
        return_full_text: this.config.returnFullText,
        num_return_sequences: this.config.n,
        do_sample: this.config.doSample,
        max_time: this.config.maxTime,
      },
      options: {
        use_cache: this.config.useCache,
        wait_for_model: this.config.waitForModel,
      },
    }

    return [apiConfig, reqValue]
  }

  createChatResp = (
    resp: Readonly<AxAIHuggingFaceResponse>
  ): AxChatResponse => {
    return {
      results: [
        {
          content: resp.generated_text,
        },
      ],
    }
  }
}

export class AxAIHuggingFace extends AxBaseAI<
  AxAIHuggingFaceModel,
  unknown,
  AxAIHuggingFaceRequest,
  unknown,
  AxAIHuggingFaceResponse,
  unknown,
  unknown
> {
  constructor({
    apiKey,
    config,
    options,
    models,
  }: Readonly<Omit<AxAIHuggingFaceArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('HuggingFace API key not set')
    }
    const _config = {
      ...axAIHuggingFaceDefaultConfig(),
      ...config,
    }

    const aiImpl = new AxAIHuggingFaceImpl(_config)

    super(aiImpl, {
      name: 'HuggingFace',
      apiURL: 'https://api-inference.huggingface.co',
      headers: async () => ({ Authorization: `Bearer ${apiKey}` }),
      modelInfo: axModelInfoHuggingFace,
      defaults: { model: _config.model },
      options,
      supportFor: { functions: false, streaming: false },
      models,
    })
  }
}



================================================
FILE: src/ax/ai/huggingface/info.ts
================================================
import type { AxModelInfo } from '../types.js'

/**
 * HuggingFace: Model information
 */
export const axModelInfoHuggingFace: AxModelInfo[] = []



================================================
FILE: src/ax/ai/huggingface/types.ts
================================================
import type { AxModelConfig } from '../types.js'

export enum AxAIHuggingFaceModel {
  MetaLlama270BChatHF = 'meta-llama/Llama-2-70b-chat-hf',
}

export type AxAIHuggingFaceConfig = AxModelConfig & {
  model: AxAIHuggingFaceModel
  returnFullText?: boolean
  doSample?: boolean
  maxTime?: number
  useCache?: boolean
  waitForModel?: boolean
}

export type AxAIHuggingFaceRequest = {
  model: AxAIHuggingFaceModel
  inputs: string
  parameters: {
    max_new_tokens?: number
    repetition_penalty?: number
    temperature?: number
    top_p?: number
    top_k?: number
    return_full_text?: boolean
    num_return_sequences?: number
    do_sample?: boolean
    max_time?: number
  }
  options?: {
    use_cache?: boolean
    wait_for_model?: boolean
  }
}

export type AxAIHuggingFaceResponse = {
  generated_text: string
}



================================================
FILE: src/ax/ai/mistral/api.ts
================================================
import { axBaseAIDefaultConfig } from '../base.js'
import { type AxAIOpenAIArgs, AxAIOpenAIBase } from '../openai/api.js'
import type {
  AxAIOpenAIChatRequest,
  AxAIOpenAIConfig,
} from '../openai/chat_types.js'
import type { AxAIServiceOptions, AxModelInfo } from '../types.js'

import { axModelInfoMistral } from './info.js'
import { AxAIMistralEmbedModels, AxAIMistralModel } from './types.js'

type AxAIMistralConfig = AxAIOpenAIConfig<
  AxAIMistralModel,
  AxAIMistralEmbedModels
>

export const axAIMistralDefaultConfig = (): AxAIMistralConfig =>
  structuredClone({
    model: AxAIMistralModel.MistralSmall,
    ...axBaseAIDefaultConfig(),
    topP: 1,
  })

export const axAIMistralBestConfig = (): AxAIMistralConfig =>
  structuredClone({
    ...axAIMistralDefaultConfig(),
    model: AxAIMistralModel.MistralLarge,
  })

export type AxAIMistralChatRequest = Omit<
  AxAIOpenAIChatRequest<AxAIMistralModel>,
  'max_completion_tokens' | 'stream_options' | 'messages'
> & {
  max_tokens?: number
  messages: (
    | { role: 'system'; content: string }
    | {
        role: 'user'
        content:
          | string
          | (
              | {
                  type: 'text'
                  text: string
                }
              | {
                  type: 'image_url'
                  image_url: string
                }
            )[]
        name?: string
      }
    | {
        role: 'assistant'
        content: string
        name?: string
        tool_calls?: {
          type: 'function'
          function: {
            name: string
            // eslint-disable-next-line functional/functional-parameters
            arguments?: string
          }
        }[]
      }
    | { role: 'tool'; content: string; tool_call_id: string }
  )[]
}

export type AxAIMistralArgs = AxAIOpenAIArgs<
  'mistral',
  AxAIMistralModel,
  AxAIMistralEmbedModels
> & {
  options?: Readonly<AxAIServiceOptions> & { tokensPerMinute?: number }
  modelInfo?: AxModelInfo[]
}

export class AxAIMistral extends AxAIOpenAIBase<
  AxAIMistralModel,
  AxAIMistralEmbedModels
> {
  constructor({
    apiKey,
    config,
    options,
    models,
    modelInfo,
  }: Readonly<Omit<AxAIMistralArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('Mistral API key not set')
    }
    const _config = {
      ...axAIMistralDefaultConfig(),
      ...config,
    }

    modelInfo = [...axModelInfoMistral, ...(modelInfo ?? [])]

    const supportFor = {
      functions: true,
      streaming: true,
      hasThinkingBudget: false,
      hasShowThoughts: false,
    }

    // Chat request updater to add Grok's search parameters
    const chatReqUpdater = (
      req: Readonly<AxAIOpenAIChatRequest<AxAIMistralModel>>
    ): AxAIMistralChatRequest => {
      // eslint-disable-next-line @typescript-eslint/naming-convention, @typescript-eslint/no-unused-vars
      const { max_completion_tokens, stream_options, messages, ...result } =
        req as AxAIOpenAIChatRequest<AxAIMistralModel> & {
          stream_options?: unknown
        }

      return {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        ...(result as any),
        messages: this.updateMessages(messages),
        max_tokens: max_completion_tokens,
      }
    }

    super({
      apiKey,
      config: _config,
      options,
      apiURL: 'https://api.mistral.ai/v1',
      modelInfo,
      models,
      supportFor,
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      chatReqUpdater: chatReqUpdater as any,
    })

    super.setName('Mistral')
  }

  private updateMessages(
    messages: AxAIOpenAIChatRequest<AxAIMistralModel>['messages']
  ) {
    const messagesUpdated: AxAIOpenAIChatRequest<AxAIMistralModel>['messages'] =
      []

    if (!Array.isArray(messages)) {
      return messages
    }

    for (const message of messages) {
      if (message.role === 'user' && Array.isArray(message.content)) {
        const contentUpdated = message.content.map((item) => {
          if (
            typeof item === 'object' &&
            item !== null &&
            'image_url' in item
          ) {
            return {
              type: 'image_url' as const,
              image_url: { url: item.image_url?.url },
            }
          }
          return item
        })
        messagesUpdated.push({ ...message, content: contentUpdated })
      } else {
        messagesUpdated.push(message)
      }
    }

    return messagesUpdated
  }
}



================================================
FILE: src/ax/ai/mistral/info.ts
================================================
// cspell:ignore mistral, mixtral, codestral, nemo

import type { AxModelInfo } from '../types.js'

import { AxAIMistralModel } from './types.js'

export const axModelInfoMistral: AxModelInfo[] = [
  {
    name: AxAIMistralModel.Mistral7B,
    currency: 'USD',
    promptTokenCostPer1M: 0.25,
    completionTokenCostPer1M: 0.25,
  },
  {
    name: AxAIMistralModel.Mistral8x7B,
    currency: 'USD',
    promptTokenCostPer1M: 0.7,
    completionTokenCostPer1M: 0.7,
  },
  {
    name: AxAIMistralModel.MistralNemo,
    currency: 'USD',
    promptTokenCostPer1M: 0.15,
    completionTokenCostPer1M: 0.15,
  },
  {
    name: AxAIMistralModel.MistralSmall,
    currency: 'USD',
    promptTokenCostPer1M: 0.2,
    completionTokenCostPer1M: 0.6,
  },
  {
    name: AxAIMistralModel.MistralLarge,
    currency: 'USD',
    promptTokenCostPer1M: 2,
    completionTokenCostPer1M: 6,
  },
  {
    name: AxAIMistralModel.Codestral,
    currency: 'USD',
    promptTokenCostPer1M: 0.2,
    completionTokenCostPer1M: 0.6,
  },
  {
    name: AxAIMistralModel.OpenCodestralMamba,
    currency: 'USD',
    promptTokenCostPer1M: 0.25,
    completionTokenCostPer1M: 0.25,
  },
  {
    name: AxAIMistralModel.OpenMistralNemo,
    currency: 'USD',
    promptTokenCostPer1M: 0.3,
    completionTokenCostPer1M: 0.3,
  },
]



================================================
FILE: src/ax/ai/mistral/types.ts
================================================
// cspell:ignore mistral, mixtral, codestral, nemo

export enum AxAIMistralModel {
  Mistral7B = 'open-mistral-7b',
  Mistral8x7B = 'open-mixtral-8x7b',
  MistralSmall = 'mistral-small-latest',
  MistralNemo = 'mistral-nemo-latest',
  MistralLarge = 'mistral-large-latest',
  Codestral = 'codestral-latest',
  OpenCodestralMamba = 'open-codestral-mamba',
  OpenMistralNemo = 'open-mistral-nemo-latest',
}

export enum AxAIMistralEmbedModels {
  MistralEmbed = 'mistral-embed',
}



================================================
FILE: src/ax/ai/mock/api.ts
================================================
import crypto from 'crypto'
import type { ReadableStream } from 'stream/web'

import type {
  AxAIModelList,
  AxAIPromptConfig,
  AxAIService,
  AxAIServiceActionOptions,
  AxAIServiceMetrics,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxEmbedRequest,
  AxEmbedResponse,
  AxLoggerFunction,
  AxModelConfig,
  AxModelInfoWithProvider,
} from '../types.js'

export type AxMockAIServiceConfig = {
  name?: string
  id?: string
  modelInfo?: Partial<AxModelInfoWithProvider>
  embedModelInfo?: AxModelInfoWithProvider
  features?: { functions?: boolean; streaming?: boolean }
  models?: AxAIModelList
  options?: AxAIServiceOptions
  chatResponse?:
    | AxChatResponse
    | ReadableStream<AxChatResponse>
    | (() => Promise<AxChatResponse | ReadableStream<AxChatResponse>>)
    | ((
        req: Readonly<AxChatRequest<unknown>>,
        options?: Readonly<
          AxAIPromptConfig & AxAIServiceActionOptions<unknown, unknown>
        >
      ) => Promise<AxChatResponse | ReadableStream<AxChatResponse>>)

  embedResponse?:
    | AxEmbedResponse
    | ((
        req: Readonly<AxEmbedRequest>
      ) => AxEmbedResponse | Promise<AxEmbedResponse>)
  shouldError?: boolean
  errorMessage?: string
  latencyMs?: number
}

export class AxMockAIService implements AxAIService {
  private metrics: AxAIServiceMetrics = {
    latency: {
      chat: { mean: 0, p95: 0, p99: 0, samples: [] },
      embed: { mean: 0, p95: 0, p99: 0, samples: [] },
    },
    errors: {
      chat: { count: 0, rate: 0, total: 0 },
      embed: { count: 0, rate: 0, total: 0 },
    },
  }

  constructor(private readonly config: AxMockAIServiceConfig = {}) {
    this.config.id = this.config.id ?? crypto.randomUUID()
  }
  getLastUsedChatModel(): unknown {
    return this.config.modelInfo?.name ?? 'mock-model'
  }
  getLastUsedEmbedModel(): unknown {
    return this.config.embedModelInfo?.name ?? 'mock-embed-model'
  }
  getLastUsedModelConfig(): AxModelConfig | undefined {
    return this.config.modelInfo
      ? {
          maxTokens: this.config.modelInfo.maxTokens,
          temperature: 0.7, // Default temperature
          stream: this.config.features?.streaming ?? false,
        }
      : undefined
  }

  getName(): string {
    return this.config.name ?? 'mock-ai-service'
  }

  getId(): string {
    return this.config.id ?? 'mock-ai-service-id'
  }

  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  getFeatures(_model?: string): { functions: boolean; streaming: boolean } {
    return {
      functions: this.config.features?.functions ?? false,
      streaming: this.config.features?.streaming ?? false,
    }
  }

  getModelList(): AxAIModelList | undefined {
    return this.config.models
  }

  getMetrics(): AxAIServiceMetrics {
    return this.metrics
  }

  async chat(
    req: Readonly<AxChatRequest<unknown>>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    options?: Readonly<
      AxAIPromptConfig & AxAIServiceActionOptions<unknown, unknown>
    >
  ) {
    if (this.config.latencyMs) {
      await new Promise((resolve) => setTimeout(resolve, this.config.latencyMs))
    }

    if (this.config.shouldError) {
      throw new Error(this.config.errorMessage ?? 'Mock chat error')
    }

    this.updateMetrics('chat')

    if (typeof this.config.chatResponse === 'function') {
      return await this.config.chatResponse(req)
    }

    return (
      this.config.chatResponse ?? {
        results: [
          {
            content: 'Mock response',
            finishReason: 'stop',
          },
        ],
        modelUsage: {
          ai: this.getName(),
          model: 'mock-model',
          tokens: {
            promptTokens: 10,
            completionTokens: 5,
            totalTokens: 15,
          },
        },
      }
    )
  }

  async embed(
    req: Readonly<AxEmbedRequest>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options?: Readonly<AxAIServiceActionOptions>
  ): Promise<AxEmbedResponse> {
    if (this.config.latencyMs) {
      await new Promise((resolve) => setTimeout(resolve, this.config.latencyMs))
    }

    if (this.config.shouldError) {
      throw new Error(this.config.errorMessage ?? 'Mock embed error')
    }

    this.updateMetrics('embed')

    if (typeof this.config.embedResponse === 'function') {
      return this.config.embedResponse(req)
    }

    return (
      this.config.embedResponse ?? {
        embeddings: [[0.1, 0.2, 0.3]],
        modelUsage: {
          ai: this.getName(),
          model: 'mock-model',
          tokens: {
            promptTokens: 5,
            completionTokens: 0,
            totalTokens: 5,
          },
        },
      }
    )
  }

  setOptions(options: Readonly<AxAIServiceOptions>): void {
    this.config.options = options
  }

  getOptions(): Readonly<AxAIServiceOptions> {
    return this.config.options ?? {}
  }

  getLogger(): AxLoggerFunction {
    return (
      this.config.options?.logger ??
      ((message: string) => {
        process.stdout.write(message)
      })
    )
  }

  private updateMetrics(type: 'chat' | 'embed'): void {
    const latency = this.config.latencyMs ?? 0
    this.metrics.latency[type].samples.push(latency)
    const samples = this.metrics.latency[type].samples

    // Update mean
    this.metrics.latency[type].mean =
      samples.reduce((a, b) => a + b, 0) / samples.length

    // Calculate percentiles only if we have enough samples
    if (samples.length > 0) {
      const sortedSamples = [...samples].sort((a, b) => a - b)

      // For p95, we need at least 20 samples for meaningful calculation (1/0.05)
      const p95Index = Math.max(0, Math.floor(sortedSamples.length * 0.95) - 1)
      this.metrics.latency[type].p95 = sortedSamples[p95Index] ?? latency

      // For p99, we need at least 100 samples for meaningful calculation (1/0.01)
      const p99Index = Math.max(0, Math.floor(sortedSamples.length * 0.99) - 1)
      this.metrics.latency[type].p99 = sortedSamples[p99Index] ?? latency
    }

    if (this.config.shouldError) {
      this.metrics.errors[type].count++
      this.metrics.errors[type].total++

      // Calculate error rate against total requests, not just samples
      const totalRequests = this.metrics.latency[type].samples.length
      this.metrics.errors[type].rate =
        totalRequests > 0 ? this.metrics.errors[type].count / totalRequests : 0
    }
  }
}

// Example usage:
/*
const mockService = new MockAIService({
  name: 'test-service',
  modelInfo: {
    name: 'test-model',
    provider: 'test-provider',
    promptTokenCostPer1M: 200,
    completionTokenCostPer1M: 150,
  },
  features: {
    functions: true,
    streaming: true,
  },
  chatResponse: async (req) => ({
    results: [
      {
        content: `Processed request with ${req.chatPrompt.length} messages`,
        finishReason: 'stop',
      },
    ],
    modelUsage: {
      promptTokens: 20,
      completionTokens: 10,
      totalTokens: 30,
    },
  }),
  latencyMs: 100,
})
*/



================================================
FILE: src/ax/ai/ollama/api.ts
================================================
import {
  axBaseAIDefaultConfig,
  axBaseAIDefaultCreativeConfig,
} from '../base.js'
import { type AxAIOpenAIArgs, AxAIOpenAIBase } from '../openai/api.js'
import type { AxAIOpenAIConfig } from '../openai/chat_types.js'

export type AxAIOllamaAIConfig = AxAIOpenAIConfig<string, string>

export const axAIOllamaDefaultConfig = (): AxAIOllamaAIConfig =>
  structuredClone({
    ...axBaseAIDefaultConfig(),
    model: 'nous-hermes2',
    embedModel: 'all-minilm',
  })

export const axAIOllamaDefaultCreativeConfig = (): AxAIOllamaAIConfig =>
  structuredClone({
    ...axBaseAIDefaultCreativeConfig(),
    model: 'nous-hermes2',
    embedModel: 'all-minilm',
  })

export type AxAIOllamaArgs = AxAIOpenAIArgs<'ollama', string, string> & {
  model?: string
  embedModel?: string
  url?: string
}

/**
 * OllamaAI: AI Service
 */
export class AxAIOllama extends AxAIOpenAIBase<string, string> {
  constructor({
    apiKey = 'not-set',
    url = 'http://localhost:11434/v1',
    config,
    options,
    models,
  }: Readonly<Omit<AxAIOllamaArgs, 'name'>>) {
    const _config = {
      ...axAIOllamaDefaultConfig(),
      ...config,
    }
    super({
      apiKey,
      options,
      config: _config,
      apiURL: url,
      models,
      modelInfo: [],
      supportFor: {
        functions: true,
        streaming: true,
        hasThinkingBudget: false,
        hasShowThoughts: false,
      },
    })

    super.setName('Ollama')
  }
}



================================================
FILE: src/ax/ai/openai/api.ts
================================================
import { getModelInfo } from '@ax-llm/ax/dsp/modelinfo.js'

import type { AxAPI } from '../../util/apicall.js'
import {
  type AxAIFeatures,
  AxBaseAI,
  axBaseAIDefaultConfig,
  axBaseAIDefaultCreativeConfig,
} from '../base.js'
import type {
  AxAIInputModelList,
  AxAIPromptConfig,
  AxAIServiceImpl,
  AxAIServiceOptions,
  AxChatResponse,
  AxChatResponseResult,
  AxEmbedResponse,
  AxInternalChatRequest,
  AxInternalEmbedRequest,
  AxModelConfig,
  AxModelInfo,
  AxTokenUsage,
} from '../types.js'

import {
  type AxAIOpenAIChatRequest,
  type AxAIOpenAIChatResponse,
  type AxAIOpenAIChatResponseDelta,
  type AxAIOpenAIConfig,
  AxAIOpenAIEmbedModel,
  type AxAIOpenAIEmbedRequest,
  type AxAIOpenAIEmbedResponse,
  AxAIOpenAIModel,
} from './chat_types.js'
import { axModelInfoOpenAI } from './info.js'

export const axAIOpenAIDefaultConfig = (): AxAIOpenAIConfig<
  AxAIOpenAIModel,
  AxAIOpenAIEmbedModel
> =>
  structuredClone({
    model: AxAIOpenAIModel.GPT41,
    embedModel: AxAIOpenAIEmbedModel.TextEmbedding3Small,
    ...axBaseAIDefaultConfig(),
  })

export const axAIOpenAIBestConfig = (): AxAIOpenAIConfig<
  AxAIOpenAIModel,
  AxAIOpenAIEmbedModel
> =>
  structuredClone({
    ...axAIOpenAIDefaultConfig(),
    model: AxAIOpenAIModel.GPT41,
  })

export const axAIOpenAICreativeConfig = (): AxAIOpenAIConfig<
  AxAIOpenAIModel,
  AxAIOpenAIEmbedModel
> =>
  structuredClone({
    model: AxAIOpenAIModel.GPT41,
    embedModel: AxAIOpenAIEmbedModel.TextEmbedding3Small,
    ...axBaseAIDefaultCreativeConfig(),
  })

export const axAIOpenAIFastConfig = (): AxAIOpenAIConfig<
  AxAIOpenAIModel,
  AxAIOpenAIEmbedModel
> => ({
  ...axAIOpenAIDefaultConfig(),
  model: AxAIOpenAIModel.GPT41Mini,
})

export interface AxAIOpenAIArgs<
  TName = 'openai',
  TModel = AxAIOpenAIModel,
  TEmbedModel = AxAIOpenAIEmbedModel,
  TChatReq extends
    AxAIOpenAIChatRequest<TModel> = AxAIOpenAIChatRequest<TModel>,
> extends Omit<
    AxAIOpenAIBaseArgs<TModel, TEmbedModel, TChatReq>,
    'config' | 'supportFor' | 'modelInfo'
  > {
  name: TName
  modelInfo?: AxModelInfo[]
  config?: Partial<AxAIOpenAIBaseArgs<TModel, TEmbedModel, TChatReq>['config']>
}

type ChatReqUpdater<TModel, TChatReq extends AxAIOpenAIChatRequest<TModel>> = (
  req: Readonly<TChatReq>
) => TChatReq

export interface AxAIOpenAIBaseArgs<
  TModel,
  TEmbedModel,
  TChatReq extends AxAIOpenAIChatRequest<TModel>,
> {
  apiKey: string
  apiURL?: string
  config: Readonly<AxAIOpenAIConfig<TModel, TEmbedModel>>
  options?: Readonly<AxAIServiceOptions & { streamingUsage?: boolean }>
  modelInfo: Readonly<AxModelInfo[]>
  models?: AxAIInputModelList<TModel, TEmbedModel>
  chatReqUpdater?: ChatReqUpdater<TModel, TChatReq>
  supportFor: AxAIFeatures | ((model: TModel) => AxAIFeatures)
}

class AxAIOpenAIImpl<
  TModel,
  TEmbedModel,
  TChatReq extends AxAIOpenAIChatRequest<TModel>,
> implements
    AxAIServiceImpl<
      TModel,
      TEmbedModel,
      AxAIOpenAIChatRequest<TModel>,
      AxAIOpenAIEmbedRequest<TEmbedModel>,
      AxAIOpenAIChatResponse,
      AxAIOpenAIChatResponseDelta,
      AxAIOpenAIEmbedResponse
    >
{
  private tokensUsed: AxTokenUsage | undefined

  constructor(
    private readonly config: Readonly<AxAIOpenAIConfig<TModel, TEmbedModel>>,
    private streamingUsage: boolean,
    private readonly chatReqUpdater?: ChatReqUpdater<TModel, TChatReq>
  ) {}

  getTokenUsage(): AxTokenUsage | undefined {
    return this.tokensUsed
  }

  getModelConfig(): AxModelConfig {
    const { config } = this

    return {
      maxTokens: config.maxTokens,
      temperature: config.temperature,
      presencePenalty: config.presencePenalty,
      frequencyPenalty: config.frequencyPenalty,
      stopSequences: config.stopSequences,
      endSequences: config.endSequences,
      topP: config.topP,
      n: config.n,
      stream: config.stream,
    }
  }

  createChatReq(
    req: Readonly<AxInternalChatRequest<TModel>>,

    config: Readonly<AxAIPromptConfig>
  ): [AxAPI, AxAIOpenAIChatRequest<TModel>] {
    const model = req.model

    if (!req.chatPrompt || req.chatPrompt.length === 0) {
      throw new Error('Chat prompt is empty')
    }

    const apiConfig = {
      name: '/chat/completions',
    }

    const tools = req.functions?.map((v) => ({
      type: 'function' as const,
      function: {
        name: v.name,
        description: v.description,
        parameters: v.parameters,
      },
    }))

    const toolsChoice =
      !req.functionCall && req.functions && req.functions.length > 0
        ? 'auto'
        : req.functionCall

    const messages = createMessages(req)

    const frequencyPenalty =
      req.modelConfig?.frequencyPenalty ?? this.config.frequencyPenalty

    const stream = req.modelConfig?.stream ?? this.config.stream

    const store = this.config.store

    let reqValue: AxAIOpenAIChatRequest<TModel> = {
      model,
      messages,
      response_format: this.config?.responseFormat
        ? { type: this.config.responseFormat }
        : undefined,
      tools,
      tool_choice: toolsChoice,
      max_completion_tokens:
        req.modelConfig?.maxTokens ?? this.config.maxTokens,
      temperature: req.modelConfig?.temperature ?? this.config.temperature,
      top_p: req.modelConfig?.topP ?? this.config.topP ?? 1,
      n: req.modelConfig?.n ?? this.config.n,
      stop: req.modelConfig?.stopSequences ?? this.config.stop,
      presence_penalty:
        req.modelConfig?.presencePenalty ?? this.config.presencePenalty,
      logit_bias: this.config.logitBias,
      ...(frequencyPenalty ? { frequency_penalty: frequencyPenalty } : {}),
      ...(stream && this.streamingUsage
        ? { stream: true, stream_options: { include_usage: true } }
        : {}),
      ...(store ? { store: store } : {}),
      ...(this.config.serviceTier
        ? { service_tier: this.config.serviceTier }
        : {}),
      ...(this.config.user ? { user: this.config.user } : {}),
    }

    if (this.config.reasoningEffort) {
      reqValue.reasoning_effort = this.config.reasoningEffort
    }

    if (this.config.webSearchOptions) {
      reqValue.web_search_options = {
        ...(this.config.webSearchOptions.searchContextSize && {
          search_context_size: this.config.webSearchOptions.searchContextSize,
        }),
        ...(this.config.webSearchOptions.userLocation && {
          user_location: {
            approximate: {
              type: 'approximate',
              ...(this.config.webSearchOptions.userLocation.approximate
                .city && {
                city: this.config.webSearchOptions.userLocation.approximate
                  .city,
              }),
              ...(this.config.webSearchOptions.userLocation.approximate
                .country && {
                country:
                  this.config.webSearchOptions.userLocation.approximate.country,
              }),
              ...(this.config.webSearchOptions.userLocation.approximate
                .region && {
                region:
                  this.config.webSearchOptions.userLocation.approximate.region,
              }),
              ...(this.config.webSearchOptions.userLocation.approximate
                .timezone && {
                timezone:
                  this.config.webSearchOptions.userLocation.approximate
                    .timezone,
              }),
            },
          },
        }),
      }
    }

    // Then, override based on prompt-specific config
    if (config?.thinkingTokenBudget) {
      switch (config.thinkingTokenBudget) {
        case 'none':
          reqValue.reasoning_effort = undefined // Explicitly set to undefined
          break
        case 'minimal':
          reqValue.reasoning_effort = 'low'
          break
        case 'low':
          reqValue.reasoning_effort = 'medium'
          break
        case 'medium':
          reqValue.reasoning_effort = 'high'
          break
        case 'high':
          reqValue.reasoning_effort = 'high'
          break
        case 'highest':
          reqValue.reasoning_effort = 'high'
          break
      }
    }

    if (this.chatReqUpdater) {
      reqValue = this.chatReqUpdater(reqValue as TChatReq)
    }

    return [apiConfig, reqValue]
  }

  createEmbedReq(
    req: Readonly<AxInternalEmbedRequest<TEmbedModel>>
  ): [AxAPI, AxAIOpenAIEmbedRequest<TEmbedModel>] {
    const model = req.embedModel

    if (!model) {
      throw new Error('Embed model not set')
    }

    if (!req.texts || req.texts.length === 0) {
      throw new Error('Embed texts is empty')
    }

    const apiConfig = {
      name: '/embeddings',
    }

    const reqValue = {
      model: model,
      input: req.texts,
      dimensions: this.config.dimensions,
    }

    return [apiConfig, reqValue]
  }

  createChatResp(resp: Readonly<AxAIOpenAIChatResponse>): AxChatResponse {
    const { id, usage, choices, error } = resp

    if (error) {
      throw error
    }

    this.tokensUsed = usage
      ? {
          promptTokens: usage.prompt_tokens,
          completionTokens: usage.completion_tokens,
          totalTokens: usage.total_tokens,
        }
      : undefined

    const results = choices.map((choice) => {
      const finishReason = mapFinishReason(choice.finish_reason)

      const functionCalls = choice.message.tool_calls?.map(
        ({ id, function: { arguments: params, name } }) => ({
          id: id,
          type: 'function' as const,
          function: { name, params },
        })
      )

      return {
        id: `${choice.index}`,
        content: choice.message.content,
        thought: choice.message.reasoning_content,
        functionCalls,
        finishReason,
      }
    })

    return {
      results,
      remoteId: id,
    }
  }

  createChatStreamResp(
    resp: Readonly<AxAIOpenAIChatResponseDelta>,
    state: object
  ): AxChatResponse {
    const { id, usage, choices } = resp

    this.tokensUsed = usage
      ? {
          promptTokens: usage.prompt_tokens,
          completionTokens: usage.completion_tokens,
          totalTokens: usage.total_tokens,
        }
      : undefined

    const sstate = state as {
      indexIdMap: Record<number, string>
    }

    if (!sstate.indexIdMap) {
      sstate.indexIdMap = {}
    }

    const results = choices.map(
      ({
        delta: {
          content,
          role,
          tool_calls: toolCalls,
          reasoning_content: thought,
        },
        finish_reason: oaiFinishReason,
      }) => {
        const finishReason = mapFinishReason(oaiFinishReason)

        const functionCalls = toolCalls
          ?.map(({ id: _id, index, function: { name, arguments: params } }) => {
            if (
              typeof _id === 'string' &&
              typeof index === 'number' &&
              !sstate.indexIdMap[index]
            ) {
              sstate.indexIdMap[index] = _id
            }

            const id = sstate.indexIdMap[index]
            if (!id) {
              return null
            }

            return {
              id,
              type: 'function' as const,
              function: { name, params },
            }
          })
          .filter((v) => v !== null)

        return {
          content,
          role,
          thought,
          functionCalls,
          finishReason,
          id,
        }
      }
    )

    return { results }
  }

  createEmbedResp(resp: Readonly<AxAIOpenAIEmbedResponse>): AxEmbedResponse {
    const { data, usage } = resp

    this.tokensUsed = usage
      ? {
          promptTokens: usage.prompt_tokens,
          completionTokens: usage.completion_tokens,
          totalTokens: usage.total_tokens,
        }
      : undefined

    return { embeddings: data.map((v) => v.embedding) }
  }
}

const mapFinishReason = (
  finishReason: AxAIOpenAIChatResponse['choices'][0]['finish_reason']
): AxChatResponseResult['finishReason'] => {
  switch (finishReason) {
    case 'stop':
      return 'stop' as const
    case 'length':
      return 'length' as const
    case 'content_filter':
      return 'error' as const
    case 'tool_calls':
      return 'function_call' as const
  }
}

function createMessages<TModel>(
  req: Readonly<AxInternalChatRequest<TModel>>
): AxAIOpenAIChatRequest<TModel>['messages'] {
  type UserContent = Extract<
    AxAIOpenAIChatRequest<TModel>['messages'][number],
    { role: 'user' }
  >['content']

  return req.chatPrompt.map((msg) => {
    switch (msg.role) {
      case 'system':
        return { role: 'system' as const, content: msg.content }

      case 'user':
        const content: UserContent = Array.isArray(msg.content)
          ? msg.content.map((c) => {
              switch (c.type) {
                case 'text':
                  return { type: 'text' as const, text: c.text }
                case 'image': {
                  const url = `data:${c.mimeType};base64,` + c.image
                  return {
                    type: 'image_url' as const,
                    image_url: { url, details: c.details ?? 'auto' },
                  }
                }
                case 'audio': {
                  const data = c.data
                  return {
                    type: 'input_audio' as const,
                    input_audio: { data, format: c.format ?? 'wav' },
                  }
                }
                default:
                  throw new Error('Invalid content type')
              }
            })
          : msg.content
        return {
          role: 'user' as const,
          ...(msg.name ? { name: msg.name } : {}),
          content,
        }

      case 'assistant':
        const toolCalls = msg.functionCalls?.map((v) => ({
          id: v.id,
          type: 'function' as const,
          function: {
            name: v.function.name,
            arguments:
              typeof v.function.params === 'object'
                ? JSON.stringify(v.function.params)
                : v.function.params,
          },
        }))

        if (toolCalls && toolCalls.length > 0) {
          return {
            role: 'assistant' as const,
            ...(msg.content ? { content: msg.content } : {}),
            name: msg.name,
            tool_calls: toolCalls,
          }
        }

        if (!msg.content) {
          throw new Error(
            'Assistant content is required when no tool calls are provided'
          )
        }

        return {
          role: 'assistant' as const,
          content: msg.content,
          ...(msg.name ? { name: msg.name } : {}),
        }

      case 'function':
        return {
          role: 'tool' as const,
          content: msg.result,
          tool_call_id: msg.functionId,
        }
      default:
        throw new Error('Invalid role')
    }
  })
}

export class AxAIOpenAIBase<
  TModel,
  TEmbedModel,
  TChatReq extends
    AxAIOpenAIChatRequest<TModel> = AxAIOpenAIChatRequest<TModel>,
> extends AxBaseAI<
  TModel,
  TEmbedModel,
  AxAIOpenAIChatRequest<TModel>,
  AxAIOpenAIEmbedRequest<TEmbedModel>,
  AxAIOpenAIChatResponse,
  AxAIOpenAIChatResponseDelta,
  AxAIOpenAIEmbedResponse
> {
  constructor({
    apiKey,
    config,
    options,
    apiURL,
    modelInfo,
    models,
    chatReqUpdater,
    supportFor,
  }: Readonly<
    Omit<AxAIOpenAIBaseArgs<TModel, TEmbedModel, TChatReq>, 'name'>
  >) {
    if (!apiKey || apiKey === '') {
      throw new Error('OpenAI API key not set')
    }

    const aiImpl = new AxAIOpenAIImpl<TModel, TEmbedModel, TChatReq>(
      config,
      options?.streamingUsage ?? true,
      chatReqUpdater
    )

    super(aiImpl, {
      name: 'OpenAI',
      apiURL: apiURL ? apiURL : 'https://api.openai.com/v1',
      headers: async () => ({ Authorization: `Bearer ${apiKey}` }),
      modelInfo,
      defaults: {
        model: config.model,
        embedModel: config.embedModel,
      },
      options,
      supportFor,
      models,
    })
  }
}

export class AxAIOpenAI extends AxAIOpenAIBase<
  AxAIOpenAIModel,
  AxAIOpenAIEmbedModel
> {
  constructor({
    apiKey,
    config,
    options,
    models,
    modelInfo,
  }: Readonly<Omit<AxAIOpenAIArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('OpenAI API key not set')
    }

    modelInfo = [...axModelInfoOpenAI, ...(modelInfo ?? [])]

    const supportFor = (model: AxAIOpenAIModel) => {
      const mi = getModelInfo<AxAIOpenAIModel, AxAIOpenAIEmbedModel>({
        model,
        modelInfo,
        models,
      })
      return {
        functions: true,
        streaming: true,
        hasThinkingBudget: mi?.hasThinkingBudget ?? false,
        hasShowThoughts: mi?.hasShowThoughts ?? false,
      }
    }

    super({
      apiKey,
      config: {
        ...axAIOpenAIDefaultConfig(),
        ...config,
      },
      options,
      modelInfo,
      models,
      supportFor,
    })

    super.setName('OpenAI')
  }
}



================================================
FILE: src/ax/ai/openai/chat_types.ts
================================================
import type { AxModelConfig } from '../types.js'

export enum AxAIOpenAIModel {
  O1 = 'o1',
  O1Mini = 'o1-mini',
  GPT4 = 'gpt-4',
  GPT41 = 'gpt-4.1',
  GPT41Mini = 'gpt-4.1-mini',
  GPT4O = 'gpt-4o',
  GPT4OMini = 'gpt-4o-mini',
  GPT4ChatGPT4O = 'chatgpt-4o-latest',
  GPT4Turbo = 'gpt-4-turbo',
  GPT35Turbo = 'gpt-3.5-turbo',
  GPT35TurboInstruct = 'gpt-3.5-turbo-instruct',
  GPT35TextDavinci002 = 'text-davinci-002',
  GPT3TextBabbage002 = 'text-babbage-002',
  GPT3TextAda001 = 'text-ada-001',
}

export enum AxAIOpenAIEmbedModel {
  TextEmbeddingAda002 = 'text-embedding-ada-002',
  TextEmbedding3Small = 'text-embedding-3-small',
  TextEmbedding3Large = 'text-embedding-3-large',
}

export type AxAIOpenAIConfig<TModel, TEmbedModel> = Omit<
  AxModelConfig,
  'topK'
> & {
  model: TModel
  embedModel?: TEmbedModel
  user?: string
  responseFormat?: 'json_object'
  bestOf?: number
  logitBias?: Map<string, number>
  suffix?: string | null
  stop?: string[]
  logprobs?: number
  echo?: boolean
  dimensions?: number
  reasoningEffort?: 'low' | 'medium' | 'high'
  store?: boolean
  serviceTier?: 'auto' | 'default' | 'flex'
  webSearchOptions?: {
    searchContextSize?: 'low' | 'medium' | 'high'
    userLocation?: {
      approximate: {
        type: 'approximate'
        city?: string
        country?: string
        region?: string
        timezone?: string
      }
    } | null
  }
}

export type AxAIOpenAILogprob = {
  tokens: string[]
  token_logprobs: number[]
  top_logprobs: Map<string, number>
  text_offset: number[]
}

export type AxAIOpenAIUsage = {
  prompt_tokens: number
  completion_tokens: number
  total_tokens: number
}

export interface AxAIOpenAIResponseDelta<T> {
  id: string
  object: string
  created: number
  model: string
  choices: {
    index: number
    delta: T
    finish_reason: 'stop' | 'length' | 'content_filter' | 'tool_calls'
  }[]
  usage?: AxAIOpenAIUsage
  system_fingerprint: string
}

export type AxAIOpenAIChatRequest<TModel> = {
  model: TModel
  reasoning_effort?: 'low' | 'medium' | 'high'
  store?: boolean
  messages: (
    | { role: 'system'; content: string }
    | {
        role: 'user'
        content:
          | string
          | (
              | {
                  type: string
                  text: string
                }
              | {
                  type: 'image_url'
                  image_url: { url: string; details?: 'high' | 'low' | 'auto' }
                }
              | {
                  type: 'input_audio'
                  input_audio: { data: string; format?: 'wav' }
                }
              | {
                  type: 'file'
                  file: {
                    file_data: string
                    filename: string
                  }
                }
            )[]
        name?: string
      }
    | {
        role: 'assistant'
        content:
          | string
          | {
              type: string
              text: string
            }
        name?: string
      }
    | {
        role: 'assistant'
        content?:
          | string
          | {
              type: string
              text: string
            }
        name?: string
        tool_calls: {
          type: 'function'
          function: {
            name: string
            // eslint-disable-next-line functional/functional-parameters
            arguments?: string
          }
        }[]
      }
    | { role: 'tool'; content: string; tool_call_id: string }
  )[]
  tools?: {
    type: 'function'
    function: {
      name: string
      description: string
      parameters?: object
    }
  }[]
  tool_choice?:
    | 'none'
    | 'auto'
    | 'required'
    | { type: 'function'; function: { name: string } }
  response_format?: { type: string }
  max_completion_tokens?: number
  temperature?: number
  top_p?: number
  n?: number
  stream?: boolean
  stop?: readonly string[]
  presence_penalty?: number
  frequency_penalty?: number
  logit_bias?: Map<string, number>
  user?: string
  organization?: string
  web_search_options?: {
    search_context_size?: 'low' | 'medium' | 'high'
    user_location?: {
      approximate: {
        type: 'approximate'
        city?: string
        country?: string
        region?: string
        timezone?: string
      }
    } | null
  }
}

export type AxAIOpenAIChatResponse = {
  id: string
  object: 'chat.completion'
  created: number
  model: string
  choices: {
    index: number
    message: {
      role: string
      content: string
      reasoning_content?: string
      tool_calls?: {
        id: string
        type: 'function'
        // eslint-disable-next-line functional/functional-parameters
        function: { name: string; arguments: string }
      }[]
    }
    finish_reason: 'stop' | 'length' | 'content_filter' | 'tool_calls'
  }[]
  usage?: AxAIOpenAIUsage
  error?: {
    message: string
    type: string
    param: string
    code: number
  }
  system_fingerprint: string
}

export type AxAIOpenAIChatResponseDelta = AxAIOpenAIResponseDelta<{
  content: string
  reasoning_content?: string
  role?: string
  tool_calls?: (NonNullable<
    AxAIOpenAIChatResponse['choices'][0]['message']['tool_calls']
  >[0] & {
    index: number
  })[]
}>

export type AxAIOpenAIEmbedRequest<TEmbedModel> = {
  input: readonly string[]
  model: TEmbedModel
  dimensions?: number
  user?: string
}

export type AxAIOpenAIEmbedResponse = {
  model: string
  data: {
    embedding: readonly number[]
    index: number
  }[]
  usage: AxAIOpenAIUsage
}



================================================
FILE: src/ax/ai/openai/info.ts
================================================
import type { AxModelInfo } from '../types.js'

import { AxAIOpenAIEmbedModel, AxAIOpenAIModel } from './chat_types.js'
import { AxAIOpenAIResponsesModel } from './responses_types.js'

/**
 * OpenAI: Model information
 */
export const axModelInfoOpenAI: AxModelInfo[] = [
  {
    name: AxAIOpenAIModel.O1,
    currency: 'usd',
    promptTokenCostPer1M: 15,
    completionTokenCostPer1M: 60,
    hasThinkingBudget: true,
  },
  {
    name: AxAIOpenAIModel.O1Mini,
    currency: 'usd',
    promptTokenCostPer1M: 1.1,
    completionTokenCostPer1M: 14.4,
    hasThinkingBudget: true,
  },
  {
    name: AxAIOpenAIModel.GPT4,
    currency: 'usd',
    promptTokenCostPer1M: 30,
    completionTokenCostPer1M: 60,
  },
  {
    name: AxAIOpenAIModel.GPT41,
    currency: 'usd',
    promptTokenCostPer1M: 2,
    completionTokenCostPer1M: 8,
  },
  {
    name: AxAIOpenAIModel.GPT41Mini,
    currency: 'usd',
    promptTokenCostPer1M: 0.4,
    completionTokenCostPer1M: 1.6,
  },
  {
    name: AxAIOpenAIModel.GPT4O,
    currency: 'usd',
    promptTokenCostPer1M: 5,
    completionTokenCostPer1M: 15,
  },
  {
    name: AxAIOpenAIModel.GPT4OMini,
    currency: 'usd',
    promptTokenCostPer1M: 0.15,
    completionTokenCostPer1M: 0.6,
  },
  {
    name: AxAIOpenAIModel.GPT4ChatGPT4O,
    currency: 'usd',
    promptTokenCostPer1M: 5,
    completionTokenCostPer1M: 15,
  },
  {
    name: AxAIOpenAIModel.GPT4Turbo,
    currency: 'usd',
    promptTokenCostPer1M: 10,
    completionTokenCostPer1M: 30,
  },
  {
    name: AxAIOpenAIModel.GPT35Turbo,
    currency: 'usd',
    promptTokenCostPer1M: 0.5,
    completionTokenCostPer1M: 1.5,
  },
  // Responses API only models
  {
    name: AxAIOpenAIResponsesModel.O3,
    currency: 'usd',
    promptTokenCostPer1M: 15,
    completionTokenCostPer1M: 60,
    hasThinkingBudget: true,
    hasShowThoughts: true,
  },
  {
    name: AxAIOpenAIResponsesModel.O3Mini,
    currency: 'usd',
    promptTokenCostPer1M: 1.1,
    completionTokenCostPer1M: 4.4,
    hasThinkingBudget: true,
    hasShowThoughts: true,
  },
  {
    name: AxAIOpenAIResponsesModel.O4Mini,
    currency: 'usd',
    promptTokenCostPer1M: 1.1,
    completionTokenCostPer1M: 4.4,
    hasThinkingBudget: true,
    hasShowThoughts: true,
  },
  // Embedding models
  {
    name: AxAIOpenAIEmbedModel.TextEmbeddingAda002,
    currency: 'usd',
    promptTokenCostPer1M: 0.1,
    completionTokenCostPer1M: 0.1,
  },
  {
    name: AxAIOpenAIEmbedModel.TextEmbedding3Small,
    currency: 'usd',
    promptTokenCostPer1M: 0.02,
    completionTokenCostPer1M: 0.02,
  },
  {
    name: AxAIOpenAIEmbedModel.TextEmbedding3Large,
    currency: 'usd',
    promptTokenCostPer1M: 0.13,
    completionTokenCostPer1M: 0.13,
  },
]



================================================
FILE: src/ax/ai/openai/responses_api.ts
================================================
import type {
  AxAIOpenAIEmbedRequest,
  AxAIOpenAIEmbedResponse,
  AxAPI,
} from '@ax-llm/ax/index.js'

import type {
  AxAIPromptConfig,
  AxAIServiceImpl,
  AxChatRequest,
  AxChatResponse,
  AxChatResponseResult,
  AxInternalChatRequest,
  AxInternalEmbedRequest,
  AxModelConfig,
  AxTokenUsage,
} from '../types.js'

import type {
  AxAIOpenAIResponsesCodeInterpreterToolCall,
  AxAIOpenAIResponsesComputerToolCall,
  AxAIOpenAIResponsesConfig,
  AxAIOpenAIResponsesDefineFunctionTool,
  AxAIOpenAIResponsesFileSearchToolCall,
  AxAIOpenAIResponsesImageGenerationToolCall,
  AxAIOpenAIResponsesInputContentPart,
  AxAIOpenAIResponsesInputItem,
  AxAIOpenAIResponsesInputMessageItem,
  AxAIOpenAIResponsesLocalShellToolCall,
  AxAIOpenAIResponsesMCPToolCall,
  AxAIOpenAIResponsesOutputRefusalContentPart,
  AxAIOpenAIResponsesOutputTextContentPart,
  AxAIOpenAIResponsesReasoningItem,
  AxAIOpenAIResponsesRequest,
  AxAIOpenAIResponsesResponse,
  AxAIOpenAIResponsesResponseDelta,
  AxAIOpenAIResponsesStreamEvent,
  AxAIOpenAIResponsesToolDefinition,
  AxAIOpenAIResponsesWebSearchToolCall,
  Mutable,
  RequestFunctionDefinition,
  ResponsesReqUpdater,
  UserMessageContentItem,
} from './responses_types.js'

export class AxAIOpenAIResponsesImpl<
  TModel,
  TEmbedModel, // Kept for interface compatibility, but not used by this impl.
  TResponsesReq extends AxAIOpenAIResponsesRequest<TModel>,
> implements
    AxAIServiceImpl<
      TModel,
      TEmbedModel,
      Readonly<AxAIOpenAIResponsesRequest<TModel>>, // ChatReq (now ResponsesReq)
      Readonly<AxAIOpenAIEmbedRequest<TEmbedModel>>, // EmbedReq
      Readonly<AxAIOpenAIResponsesResponse>, // ChatResp (now ResponsesResp)
      Readonly<AxAIOpenAIResponsesResponseDelta>, // ChatRespDelta (now ResponsesRespDelta)
      Readonly<AxAIOpenAIEmbedResponse> // EmbedResp
    >
{
  private tokensUsed: AxTokenUsage | undefined

  constructor(
    private readonly config: Readonly<
      AxAIOpenAIResponsesConfig<TModel, TEmbedModel>
    >,
    private readonly streamingUsage: boolean, // If /v1/responses supports include_usage for streams
    private readonly responsesReqUpdater?: ResponsesReqUpdater<
      TModel,
      TResponsesReq
    >
  ) {}

  getTokenUsage(): Readonly<AxTokenUsage> | undefined {
    return this.tokensUsed
  }

  getModelConfig(): Readonly<AxModelConfig> {
    const { config } = this
    return {
      maxTokens: config.maxTokens, // maps to max_output_tokens
      temperature: config.temperature,
      // presencePenalty, frequencyPenalty are not direct params in /v1/responses
      stopSequences: config.stopSequences, // /v1/responses uses 'truncation' or relies on item structure
      topP: config.topP,
      // n: config.n, // Not a direct parameter in /v1/responses
      stream: config.stream,
    }
  }

  private mapInternalContentToResponsesInput(
    content: ReadonlyArray<UserMessageContentItem> // Expects an array of content items, string case handled by caller
  ): ReadonlyArray<AxAIOpenAIResponsesInputContentPart> {
    const mappedParts: Mutable<AxAIOpenAIResponsesInputContentPart>[] =
      content.map((part: UserMessageContentItem) => {
        // AxUserMessageContentItem ensures part is one of {type: text}, {type: image}, {type: audio}
        if (part.type === 'text') {
          return { type: 'text', text: part.text }
        } else if (part.type === 'image') {
          const url = `data:${part.mimeType};base64,` + part.image
          return {
            type: 'image_url',
            image_url: { url, details: part.details ?? 'auto' },
          }
        } else if (part.type === 'audio') {
          return {
            type: 'input_audio',
            input_audio: { data: part.data, format: part.format ?? 'wav' },
          }
        }
        // This should be exhaustive given AxUserMessageContentItem's definition
        const _exhaustiveCheck: never = part
        throw new Error(
          `Unsupported content part: ${JSON.stringify(_exhaustiveCheck)}`
        )
      })
    return mappedParts as ReadonlyArray<AxAIOpenAIResponsesInputContentPart>
  }

  private createResponsesReqInternalInput(
    chatPrompt: ReadonlyArray<AxChatRequest<TModel>['chatPrompt'][number]>,
    excludeSystemMessages: boolean = false // New parameter
  ): ReadonlyArray<AxAIOpenAIResponsesInputItem> {
    // Map from AxChatPromptItemType roles to AxAIOpenAI /v1/responses API roles:
    // - 'system' -> 'system' (may be skipped if excludeSystemMessages is true)
    // - 'user' -> 'user'
    // - 'assistant' -> 'assistant'
    // - 'function' -> Special handling for function call outputs (different structure)
    //
    // Note: AxAIOpenAI's /v1/responses API also supports a 'developer' role that isn't
    // currently mapped from our AxChatPromptItemType structure.

    const items: Mutable<AxAIOpenAIResponsesInputItem>[] = []
    for (const msg of chatPrompt) {
      if (excludeSystemMessages && msg.role === 'system') {
        continue // Skip system messages if they are handled by top-level 'instructions'
      }

      let mappedContent:
        | string
        | ReadonlyArray<AxAIOpenAIResponsesInputContentPart>
      // Type guard for content based on role
      if (
        msg.role === 'system' ||
        msg.role === 'user' ||
        (msg.role === 'assistant' && msg.content)
      ) {
        if (typeof msg.content === 'string') {
          mappedContent = msg.content
        } else if (Array.isArray(msg.content)) {
          // Only for user role typically
          mappedContent = this.mapInternalContentToResponsesInput(
            msg.content as ReadonlyArray<UserMessageContentItem>
          )
        } else {
          // Handle cases where content might be undefined for assistant, or unexpected type
          if (msg.role === 'assistant' && !msg.content && msg.functionCalls) {
            // This is fine, assistant message can be just functionCalls
          } else {
            throw new Error(`Invalid content type for role ${msg.role}`)
          }
          mappedContent = '' // Default or skip
        }
      } else if (msg.role === 'function') {
        // Function role does not have 'content' in the same way, it has 'result'
        mappedContent = '' // Placeholder, not directly used for content field in function_call_output
      } else {
        mappedContent = '' // Default for roles that might not have content or are handled differently
      }

      switch (msg.role) {
        case 'system': // Will be skipped if excludeSystemMessages is true
          items.push({
            type: 'message',
            role: 'system',
            content: mappedContent as string,
          })
          break
        case 'user':
          items.push({
            type: 'message',
            role: 'user',
            content: mappedContent,
            name: msg.name,
          })
          break
        case 'assistant':
          if (msg.content || msg.functionCalls) {
            // Assistant can have content, functionCalls, or both
            const assistantMessage: Mutable<AxAIOpenAIResponsesInputMessageItem> =
              {
                type: 'message',
                role: 'assistant',
                content: '',
              } // Start with empty content
            if (msg.content) {
              assistantMessage.content = mappedContent
            }
            if (msg.name) {
              assistantMessage.name = msg.name
            }
            // If only function calls, content might remain empty or not be applicable in the same way for AxAIOpenAI item
            // AxAIOpenAI /v1/responses expects assistant messages with tool calls to be structured carefully.
            // For now, pushing the textual content if present. Tool calls are separate items.
            if (msg.content)
              items.push(
                assistantMessage as AxAIOpenAIResponsesInputMessageItem
              )

            if (msg.functionCalls) {
              for (const call of msg.functionCalls) {
                items.push({
                  type: 'function_call',
                  call_id: call.id,
                  name: call.function.name,
                  arguments:
                    typeof call.function.params === 'object'
                      ? JSON.stringify(call.function.params)
                      : call.function.params || '',
                })
              }
            }
          }
          break
        case 'function': // This is a tool result
          items.push({
            type: 'function_call_output',
            call_id: msg.functionId!,
            output: msg.result!,
          })
          break
        default:
          // Fix for any type
          const invalidRole = (msg as { role: string }).role
          throw new Error(`Invalid role in chat prompt: ${invalidRole}`)
      }
    }
    return items as ReadonlyArray<AxAIOpenAIResponsesInputItem>
  }

  createChatReq(
    req: Readonly<AxInternalChatRequest<TModel>>,
    config: Readonly<AxAIPromptConfig>
  ): [Readonly<AxAPI>, Readonly<AxAIOpenAIResponsesRequest<TModel>>] {
    const model = req.model
    const apiConfig: Readonly<AxAPI> = { name: '/responses' }

    let instructionsFromPrompt: string | null = null
    let systemMessageFoundAndUsed = false
    if (req.chatPrompt) {
      for (const item of req.chatPrompt) {
        if (item.role === 'system' && typeof item.content === 'string') {
          instructionsFromPrompt = item.content
          systemMessageFoundAndUsed = true
          break
        }
      }
    }

    const finalInstructions =
      instructionsFromPrompt ?? this.config.systemPrompt ?? null

    const tools: ReadonlyArray<AxAIOpenAIResponsesToolDefinition> | undefined =
      req.functions?.map(
        (
          v: Readonly<RequestFunctionDefinition>
        ): AxAIOpenAIResponsesDefineFunctionTool => ({
          type: 'function' as const,
          name: v.name,
          description: v.description,
          parameters: v.parameters ?? {},
        })
      )

    // Set include field based on showThoughts option, but override if thinkingTokenBudget is 'none'
    const includeFields: (
      | 'file_search_call.results'
      | 'message.input_image.image_url'
      | 'computer_call_output.output.image_url'
      | 'reasoning.encrypted_content'
      | 'code_interpreter_call.outputs'
    )[] = []
    const shouldShowThoughts =
      config?.thinkingTokenBudget === 'none' ? false : config?.showThoughts
    if (shouldShowThoughts) {
      includeFields.push('reasoning.encrypted_content')
    }

    let mutableReq: Mutable<AxAIOpenAIResponsesRequest<TModel>> = {
      model,
      input: '', // Will be set below
      instructions: finalInstructions,
      tools: tools?.length ? tools : undefined,
      tool_choice:
        req.functionCall === 'none' ||
        req.functionCall === 'auto' ||
        req.functionCall === 'required'
          ? req.functionCall
          : typeof req.functionCall === 'object' && req.functionCall.function
            ? { type: 'function', name: req.functionCall.function.name }
            : undefined,
      max_output_tokens:
        req.modelConfig?.maxTokens ?? this.config.maxTokens ?? undefined,
      temperature:
        req.modelConfig?.temperature ?? this.config.temperature ?? undefined,
      top_p: req.modelConfig?.topP ?? this.config.topP ?? undefined,
      stream: req.modelConfig?.stream ?? this.config.stream ?? false, // Sourced from modelConfig or global config
      // Optional fields from AxAIOpenAIResponsesRequest that need to be in Mutable for initialization
      background: undefined,
      include: includeFields.length > 0 ? includeFields : undefined,
      metadata: undefined,
      parallel_tool_calls: this.config.parallelToolCalls,
      previous_response_id: undefined,
      reasoning: undefined,
      service_tier: this.config.serviceTier,
      store: this.config.store,
      text: undefined,
      truncation: undefined,
      user: this.config.user,
      seed: this.config.seed,
    }

    // Populate from this.config if properties exist on AxAIOpenAIConfig
    if (this.config.user) mutableReq.user = this.config.user
    if (this.config.parallelToolCalls !== undefined)
      mutableReq.parallel_tool_calls = this.config.parallelToolCalls
    if (this.config.responseFormat)
      mutableReq.text = {
        format: {
          type: this.config.responseFormat as
            | 'text'
            | 'json_object'
            | 'json_schema',
        },
      }
    if (this.config.seed) mutableReq.seed = this.config.seed
    // TODO: Check AxAIOpenAIConfig for other fields like store, background, include, metadata, service_tier, truncation

    const inputItems = req.chatPrompt
      ? this.createResponsesReqInternalInput(
          req.chatPrompt,
          systemMessageFoundAndUsed
        )
      : []

    if (inputItems.length > 0) {
      mutableReq.input = inputItems
    } else if (
      req.chatPrompt &&
      req.chatPrompt.length === 1 &&
      req.chatPrompt[0]?.role === 'user' &&
      req.chatPrompt[0]?.content &&
      typeof req.chatPrompt[0].content === 'string' &&
      !finalInstructions
    ) {
      // Fallback to simple string input if only one user message and no instructions
      mutableReq.input = req.chatPrompt[0].content
    } else if (inputItems.length === 0 && !finalInstructions) {
      throw new Error('Responses API request must have input or instructions.')
    }

    let currentReasoning = mutableReq.reasoning ?? {}
    if (this.config.reasoningEffort) {
      currentReasoning = {
        ...currentReasoning,
        effort: this.config.reasoningEffort,
      }
    }

    // Handle thinkingTokenBudget config parameter
    if (config?.thinkingTokenBudget) {
      switch (config.thinkingTokenBudget) {
        case 'none':
          // When thinkingTokenBudget is 'none', remove reasoning entirely
          currentReasoning = {}
          break
        case 'minimal':
          currentReasoning = {
            ...currentReasoning,
            effort: 'low',
          }
          break
        case 'low':
          currentReasoning = {
            ...currentReasoning,
            effort: 'medium',
          }
          break
        case 'medium':
        case 'high':
        case 'highest':
          currentReasoning = {
            ...currentReasoning,
            effort: 'high',
          }
          break
      }
    }

    if (Object.keys(currentReasoning).length > 0 && currentReasoning.effort) {
      mutableReq.reasoning = currentReasoning
    } else {
      delete mutableReq.reasoning // Ensure reasoning is not sent if empty or only has non-effort keys by mistake
    }

    let finalReqToProcess: Readonly<AxAIOpenAIResponsesRequest<TModel>> =
      mutableReq as Readonly<AxAIOpenAIResponsesRequest<TModel>>

    if (this.responsesReqUpdater) {
      finalReqToProcess = this.responsesReqUpdater(
        finalReqToProcess as Readonly<TResponsesReq>
      )
    }

    return [apiConfig, finalReqToProcess]
  }

  // Create Chat Response from /v1/responses (non-streaming)
  createChatResp(
    resp: Readonly<AxAIOpenAIResponsesResponse>
  ): Readonly<AxChatResponse> {
    const { id, output, usage } = resp

    if (usage) {
      this.tokensUsed = {
        promptTokens: usage.prompt_tokens,
        completionTokens: usage.completion_tokens,
        totalTokens: usage.total_tokens,
      }
    }

    let currentResult: Partial<AxChatResponseResult> = {}

    for (const item of output ?? []) {
      switch (item.type) {
        case 'message':
          currentResult.id = item.id
          currentResult.content = contentToText(item.content)
          currentResult.finishReason =
            item.status === 'completed' ? 'stop' : 'content_filter'
          break

        case 'reasoning':
          currentResult.id = item.id
          // Use encrypted_content if available (when showThoughts is enabled), otherwise use summary
          if (item.encrypted_content) {
            currentResult.thought = item.encrypted_content
          } else {
            currentResult.thought = item.summary
              .map((s: string | object) =>
                typeof s === 'object' ? JSON.stringify(s) : s
              )
              .join('\n')
          }
          break

        case 'file_search_call':
          currentResult.id = item.id
          currentResult.functionCalls = [
            {
              id: item.id,
              type: 'function' as const,
              function: {
                name: 'file_search',
                params: {
                  queries: item.queries,
                  results: item.results,
                },
              },
            },
          ]
          currentResult.finishReason = 'function_call'
          break
        case 'web_search_call':
          currentResult.id = item.id
          currentResult.functionCalls = [
            {
              id: item.id,
              type: 'function' as const,
              function: {
                name: 'web_search',
                params: {
                  queries: item.queries,
                },
              },
            },
          ]
          currentResult.finishReason = 'function_call'
          break
        case 'computer_call':
          currentResult.id = item.id
          currentResult.functionCalls = [
            {
              id: item.id,
              type: 'function' as const,
              function: {
                name: 'computer_use',
                params: {
                  action: item.action,
                },
              },
            },
          ]
          currentResult.finishReason = 'function_call'
          break
        case 'code_interpreter_call':
          currentResult.id = item.id
          currentResult.functionCalls = [
            {
              id: item.id,
              type: 'function' as const,
              function: {
                name: 'code_interpreter',
                params: {
                  code: item.code,
                  results: item.results,
                },
              },
            },
          ]
          currentResult.finishReason = 'function_call'
          break
        case 'image_generation_call':
          currentResult.id = item.id
          currentResult.functionCalls = [
            {
              id: item.id,
              type: 'function' as const,
              function: {
                name: 'image_generation',
                params: {
                  result: item.result,
                },
              },
            },
          ]
          currentResult.finishReason = 'function_call'
          break
        case 'local_shell_call':
          currentResult.id = item.id
          currentResult.functionCalls = [
            {
              id: item.id,
              type: 'function' as const,
              function: {
                name: 'local_shell',
                params: {
                  action: item.action,
                },
              },
            },
          ]
          currentResult.finishReason = 'function_call'
          break
        case 'mcp_call':
          currentResult.id = item.id
          currentResult.functionCalls = [
            {
              id: item.id,
              type: 'function' as const,
              function: {
                name: 'mcp',
                params: {
                  name: item.name,
                  args: item.args,
                  serverLabel: item.server_label,
                  output: item.output,
                  error: item.error,
                },
              },
            },
          ]
          currentResult.finishReason = 'function_call'
          break
        case 'function_call':
          currentResult.id = item.id
          currentResult.functionCalls = [
            {
              id: item.id,
              type: 'function' as const,
              function: {
                name: item.name,
                params: item.arguments,
              },
            },
          ]
          currentResult.finishReason = 'function_call'
          break
      }
    }

    return {
      results: [currentResult],
      remoteId: id,
    }
  }

  // Create Chat Stream Response from /v1/responses stream events
  createChatStreamResp(
    streamEvent: Readonly<AxAIOpenAIResponsesResponseDelta>
  ): Readonly<AxChatResponse> {
    // Handle new streaming event format
    const event = streamEvent as AxAIOpenAIResponsesStreamEvent

    // Create a basic result structure
    const baseResult: AxChatResponseResult = {
      id: '',
      content: '',
      finishReason: 'stop',
    }

    let remoteId: string | undefined

    switch (event.type) {
      case 'response.created':
      case 'response.in_progress':
      case 'response.queued':
        // Response lifecycle events - return empty content with metadata
        remoteId = event.response.id
        baseResult.id = event.response.id + '_res_0'
        break

      case 'response.output_item.added':
        // New output item added
        switch (event.item.type) {
          case 'message':
            baseResult.id = event.item.id
            baseResult.content = contentToText(event.item.content)
            break
          case 'function_call':
            baseResult.id = event.item.id
            baseResult.functionCalls = [
              {
                id: event.item.id,
                type: 'function' as const,
                function: {
                  name: event.item.name,
                  params: event.item.arguments,
                },
              },
            ]
            break
          case 'file_search_call':
            {
              const fileSearchItem =
                event.item as AxAIOpenAIResponsesFileSearchToolCall
              baseResult.id = event.item.id
              baseResult.functionCalls = [
                {
                  id: fileSearchItem.id,
                  type: 'function' as const,
                  function: {
                    name: 'file_search',
                    params: {
                      queries: fileSearchItem.queries || [],
                      results: fileSearchItem.results?.map((r) => ({
                        fileId: r.file_id,
                        filename: r.filename,
                        score: r.score,
                        text: r.text,
                        attributes: r.attributes,
                      })),
                    },
                  },
                },
              ]
            }
            break
          case 'web_search_call':
            {
              const webSearchItem =
                event.item as AxAIOpenAIResponsesWebSearchToolCall
              baseResult.id = event.item.id
              baseResult.functionCalls = [
                {
                  id: webSearchItem.id,
                  type: 'function' as const,
                  function: {
                    name: 'web_search',
                    params: {
                      queries: webSearchItem.queries || [],
                    },
                  },
                },
              ]
            }
            break
          case 'computer_call':
            {
              const computerItem =
                event.item as AxAIOpenAIResponsesComputerToolCall
              baseResult.id = event.item.id
              baseResult.functionCalls = [
                {
                  id: computerItem.id,
                  type: 'function' as const,
                  function: {
                    name: 'computer_use',
                    params: {
                      action: computerItem.action || {},
                    },
                  },
                },
              ]
            }
            break
          case 'code_interpreter_call':
            {
              const codeItem =
                event.item as AxAIOpenAIResponsesCodeInterpreterToolCall
              baseResult.id = event.item.id
              baseResult.functionCalls = [
                {
                  id: codeItem.id,
                  type: 'function' as const,
                  function: {
                    name: 'code_interpreter',
                    params: {
                      code: codeItem.code || '',
                      results: codeItem.results,
                    },
                  },
                },
              ]
            }
            break
          case 'image_generation_call':
            {
              const imageItem =
                event.item as AxAIOpenAIResponsesImageGenerationToolCall
              baseResult.id = event.item.id
              baseResult.functionCalls = [
                {
                  id: imageItem.id,
                  type: 'function' as const,
                  function: {
                    name: 'image_generation',
                    params: {
                      result: imageItem.result,
                    },
                  },
                },
              ]
            }
            break
          case 'local_shell_call':
            {
              const shellItem =
                event.item as AxAIOpenAIResponsesLocalShellToolCall
              baseResult.id = event.item.id
              baseResult.functionCalls = [
                {
                  id: shellItem.id,
                  type: 'function' as const,
                  function: {
                    name: 'local_shell',
                    params: {
                      action: shellItem.action || {},
                    },
                  },
                },
              ]
            }
            break
          case 'mcp_call':
            {
              const mcpItem = event.item as AxAIOpenAIResponsesMCPToolCall
              baseResult.id = event.item.id
              baseResult.functionCalls = [
                {
                  id: mcpItem.id,
                  type: 'function' as const,
                  function: {
                    name: 'mcp',
                    params: {
                      name: mcpItem.name || '',
                      args: mcpItem.args || '',
                      serverLabel: mcpItem.server_label || '',
                      output: mcpItem.output,
                      error: mcpItem.error,
                    },
                  },
                },
              ]
            }
            break
          case 'reasoning':
            {
              const reasoningItem =
                event.item as AxAIOpenAIResponsesReasoningItem
              baseResult.id = event.item.id
              // Use encrypted_content if available (when showThoughts is enabled), otherwise use summary
              if (reasoningItem.encrypted_content) {
                baseResult.thought = reasoningItem.encrypted_content
              } else if (reasoningItem.summary) {
                baseResult.thought = reasoningItem.summary
                  .map((s: string | object) =>
                    typeof s === 'object' ? JSON.stringify(s) : s
                  )
                  .join('\n')
              }
            }
            break
        }
        break

      case 'response.content_part.added':
        // Content part added - return the initial text if any
        baseResult.id = event.item_id
        baseResult.content = contentToText([event.part])
        break

      case 'response.output_text.delta':
        // Text delta - return just the delta content
        baseResult.id = event.item_id
        baseResult.content = event.delta
        break

      case 'response.output_text.done':
        break

      case 'response.function_call_arguments.delta':
        // Function call arguments delta - return delta with empty name
        baseResult.id = event.item_id
        baseResult.functionCalls = [
          {
            id: event.item_id,
            type: 'function' as const,
            function: {
              name: '',
              params: event.delta,
            },
          },
        ]
        break

      case 'response.function_call_arguments.done':
        // Function call arguments done - don't return function calls here
        // The mergeFunctionCalls will handle combining name and arguments
        // baseResult.id = event.item_id
        // baseResult.finishReason = 'function_call'
        break

      case 'response.reasoning_summary_text.delta':
        // Reasoning summary delta
        baseResult.id = event.item_id
        baseResult.thought = event.delta
        break

      case 'response.reasoning_summary_text.done':
        // Reasoning summary done
        baseResult.id = event.item_id
        baseResult.thought = event.text
        break

      // File search tool events
      case 'response.file_search_call.in_progress':
      case 'response.file_search_call.searching':
        baseResult.id = event.item_id
        baseResult.finishReason = 'function_call'
        break

      case 'response.file_search_call.completed':
        baseResult.id = event.item_id
        baseResult.finishReason = 'function_call'
        break

      // Web search tool events
      case 'response.web_search_call.in_progress':
      case 'response.web_search_call.searching':
        baseResult.id = event.item_id
        baseResult.finishReason = 'function_call'
        break

      case 'response.web_search_call.completed':
        baseResult.id = event.item_id
        baseResult.finishReason = 'function_call'
        break

      // Image generation tool events
      case 'response.image_generation_call.in_progress':
      case 'response.image_generation_call.generating':
        baseResult.id = event.item_id
        baseResult.finishReason = 'function_call'
        break

      case 'response.image_generation_call.completed':
        baseResult.id = event.item_id
        baseResult.finishReason = 'function_call'
        break

      case 'response.image_generation_call.partial_image':
        baseResult.id = event.item_id
        baseResult.finishReason = 'function_call'
        // Could potentially add partial image data to content or a special field
        break

      // MCP tool events
      case 'response.mcp_call.in_progress':
        baseResult.id = event.item_id
        baseResult.finishReason = 'function_call'
        break

      case 'response.mcp_call.arguments.delta':
        baseResult.id = event.item_id
        baseResult.functionCalls = [
          {
            id: event.item_id,
            type: 'function' as const,
            function: {
              name: '',
              params: event.delta,
            },
          },
        ]
        break

      case 'response.mcp_call.arguments.done':
        baseResult.id = event.item_id
        baseResult.functionCalls = [
          {
            id: event.item_id,
            type: 'function' as const,
            function: {
              name: '',
              params: event.arguments,
            },
          },
        ]
        break

      case 'response.mcp_call.completed':
      case 'response.mcp_call.failed':
        // These events don't have item_id, use a generic ID
        baseResult.id = 'mcp_call_event'
        baseResult.finishReason = 'function_call'
        break

      case 'response.mcp_list_tools.in_progress':
      case 'response.mcp_list_tools.completed':
      case 'response.mcp_list_tools.failed':
        // MCP list tools events don't have item_id
        baseResult.id = 'mcp_list_tools_event'
        baseResult.finishReason = 'function_call'
        break

      case 'response.output_item.done':
        // Item completion

        switch (event.item.type) {
          case 'message':
            baseResult.id = event.item.id
            baseResult.finishReason =
              event.item.status === 'completed' ? 'stop' : 'error'
            break
          case 'function_call':
          case 'file_search_call':
          case 'web_search_call':
          case 'computer_call':
          case 'code_interpreter_call':
          case 'image_generation_call':
          case 'local_shell_call':
          case 'mcp_call':
            // Tool calls completed - finishReason indicates function execution needed
            baseResult.id = event.item.id
            baseResult.finishReason = 'function_call'
            break
          case 'reasoning':
            // Reasoning completed
            baseResult.id = event.item.id
            baseResult.finishReason = 'stop'
            break
        }
        break

      case 'response.completed':
        // Response completion - handle usage
        if (event.response.usage) {
          this.tokensUsed = {
            promptTokens: event.response.usage.prompt_tokens,
            completionTokens: event.response.usage.completion_tokens,
            totalTokens: event.response.usage.total_tokens,
          }
        }
        remoteId = event.response.id
        baseResult.id = event.response.id + '_completed'
        baseResult.finishReason = 'stop'
        break

      case 'response.failed':
        // Response failure
        remoteId = event.response.id
        baseResult.id = event.response.id + '_failed'
        baseResult.finishReason = 'error'
        break

      case 'response.incomplete':
        // Response incomplete
        remoteId = event.response.id
        baseResult.id = event.response.id + '_incomplete'
        baseResult.finishReason = 'length'
        break

      case 'error':
        // Error event
        baseResult.id = 'error'
        baseResult.content = `Error: ${event.message}`
        baseResult.finishReason = 'error'
        break

      default:
        // For unhandled events, return empty result
        baseResult.id = 'unknown'
        break
    }

    return {
      results: [baseResult],
      remoteId,
    } as Readonly<AxChatResponse>
  }

  createEmbedReq(
    req: Readonly<AxInternalEmbedRequest<TEmbedModel>>
  ): [AxAPI, AxAIOpenAIEmbedRequest<TEmbedModel>] {
    const model = req.embedModel

    if (!model) {
      throw new Error('Embed model not set')
    }

    if (!req.texts || req.texts.length === 0) {
      throw new Error('Embed texts is empty')
    }

    const apiConfig = {
      name: '/embeddings',
    }

    const reqValue = {
      model: model,
      input: req.texts,
      dimensions: this.config.dimensions,
    }

    return [apiConfig, reqValue]
  }
}

const contentToText = (
  content: ReadonlyArray<
    | AxAIOpenAIResponsesOutputTextContentPart
    | AxAIOpenAIResponsesOutputRefusalContentPart
  >
): string => {
  return [
    ...content.filter((c) => c.type === 'output_text').map((c) => c.text),
    ...content.filter((c) => c.type === 'refusal').map((c) => c.refusal),
  ].join('\n')
}



================================================
FILE: src/ax/ai/openai/responses_api_base.ts
================================================
import { getModelInfo } from '@ax-llm/ax/dsp/modelinfo.js'
import { type AxAIOpenAIResponsesConfig } from '@ax-llm/ax/index.js'

import { AxBaseAI } from '../base.js'
import type { AxAIFeatures } from '../base.js'
import type {
  AxAIInputModelList,
  AxAIServiceOptions,
  AxModelInfo,
} from '../types.js'

import type {
  AxAIOpenAIEmbedRequest,
  AxAIOpenAIEmbedResponse,
} from './chat_types.js'
import { AxAIOpenAIEmbedModel } from './chat_types.js'
import { axModelInfoOpenAI } from './info.js'
import { AxAIOpenAIResponsesImpl } from './responses_api.js'
import type {
  AxAIOpenAIResponsesRequest,
  AxAIOpenAIResponsesResponse,
  AxAIOpenAIResponsesResponseDelta,
} from './responses_types.js'
import { AxAIOpenAIResponsesModel } from './responses_types.js'

// Helper functions to create default configurations
export const axAIOpenAIResponsesDefaultConfig = (): AxAIOpenAIResponsesConfig<
  AxAIOpenAIResponsesModel,
  AxAIOpenAIEmbedModel
> => ({
  model: AxAIOpenAIResponsesModel.GPT4O,
  embedModel: AxAIOpenAIEmbedModel.TextEmbeddingAda002,
  temperature: 0.7,
  topP: 1,
  stream: true,
  //   reasoningEffort: 'medium',
})

export const axAIOpenAIResponsesBestConfig = (): AxAIOpenAIResponsesConfig<
  AxAIOpenAIResponsesModel,
  AxAIOpenAIEmbedModel
> => ({
  ...axAIOpenAIResponsesDefaultConfig(),
  model: AxAIOpenAIResponsesModel.GPT4O,
  temperature: 0.5,
})

export const axAIOpenAIResponsesCreativeConfig = (): AxAIOpenAIResponsesConfig<
  AxAIOpenAIResponsesModel,
  AxAIOpenAIEmbedModel
> => ({
  ...axAIOpenAIResponsesDefaultConfig(),
  model: AxAIOpenAIResponsesModel.GPT4O,
  temperature: 0.9,
})

// Arguments for AxAIOpenAIResponsesBase constructor
interface AxAIOpenAIResponsesBaseArgs<
  TModel,
  TEmbedModel,
  TResponsesReq extends AxAIOpenAIResponsesRequest<TModel>,
> {
  apiKey: string
  config: AxAIOpenAIResponsesConfig<TModel, TEmbedModel>
  options?: {
    streamingUsage?: boolean
  } & AxAIServiceOptions
  apiURL?: string
  modelInfo?: ReadonlyArray<AxModelInfo>
  models?: AxAIInputModelList<TModel, TEmbedModel>
  responsesReqUpdater?: (
    req: Readonly<TResponsesReq>
  ) => Readonly<TResponsesReq>
  supportFor?: AxAIFeatures | ((model: TModel) => AxAIFeatures)
}

/**
 * Base class for OpenAI AI services using the /v1/responses API endpoint
 */
export class AxAIOpenAIResponsesBase<
  TModel,
  TEmbedModel,
  TResponsesReq extends AxAIOpenAIResponsesRequest<TModel>,
> extends AxBaseAI<
  TModel,
  TEmbedModel,
  AxAIOpenAIResponsesRequest<TModel>,
  AxAIOpenAIEmbedRequest<TEmbedModel>,
  AxAIOpenAIResponsesResponse,
  AxAIOpenAIResponsesResponseDelta,
  AxAIOpenAIEmbedResponse
> {
  constructor({
    apiKey,
    config,
    options,
    apiURL,
    modelInfo = [],
    models,
    responsesReqUpdater,
    supportFor = { functions: true, streaming: true },
  }: Readonly<
    AxAIOpenAIResponsesBaseArgs<TModel, TEmbedModel, TResponsesReq>
  >) {
    if (!apiKey || apiKey === '') {
      throw new Error('OpenAI API key not set')
    }

    const aiImpl = new AxAIOpenAIResponsesImpl<
      TModel,
      TEmbedModel,
      TResponsesReq
    >(config, options?.streamingUsage ?? true, responsesReqUpdater)

    // Convert models to the expected format if needed
    const formattedModels = models as
      | AxAIInputModelList<TModel, TEmbedModel>
      | undefined

    super(aiImpl, {
      name: 'OpenAI',
      apiURL: apiURL ? apiURL : 'https://api.openai.com/v1',
      headers: async () => ({ Authorization: `Bearer ${apiKey}` }),
      modelInfo,
      defaults: {
        model: config.model,
        embedModel: config.embedModel,
      },
      options,
      supportFor,
      models: formattedModels,
    })
  }
}

/**
 * Ready-to-use implementation of the OpenAI Responses API client
 * This class uses OpenAI's /v1/responses API endpoint which supports text, image, and audio inputs
 */

export interface AxAIOpenAIResponsesArgs<
  TName = 'openai-responses',
  TModel = AxAIOpenAIResponsesModel,
  TEmbedModel = AxAIOpenAIEmbedModel,
  TChatReq extends
    AxAIOpenAIResponsesRequest<TModel> = AxAIOpenAIResponsesRequest<TModel>,
> extends Omit<
    AxAIOpenAIResponsesBaseArgs<TModel, TEmbedModel, TChatReq>,
    'config' | 'supportFor' | 'modelInfo'
  > {
  name: TName
  modelInfo?: AxModelInfo[]
  config?: Partial<
    AxAIOpenAIResponsesBaseArgs<TModel, TEmbedModel, TChatReq>['config']
  >
}

export class AxAIOpenAIResponses extends AxAIOpenAIResponsesBase<
  AxAIOpenAIResponsesModel,
  AxAIOpenAIEmbedModel,
  AxAIOpenAIResponsesRequest<AxAIOpenAIResponsesModel>
> {
  constructor({
    apiKey,
    config,
    options,
    models,
    modelInfo,
  }: Readonly<Omit<AxAIOpenAIResponsesArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('OpenAI API key not set')
    }

    // Use the original OpenAI model info since it contains both chat and embed models
    modelInfo = [...axModelInfoOpenAI, ...(modelInfo ?? [])]

    const supportFor = (model: AxAIOpenAIResponsesModel) => {
      const mi = getModelInfo<AxAIOpenAIResponsesModel, AxAIOpenAIEmbedModel>({
        model,
        modelInfo,
        models,
      })
      return {
        functions: true,
        streaming: true,
        hasThinkingBudget: mi?.hasThinkingBudget ?? false,
        hasShowThoughts: mi?.hasShowThoughts ?? false,
      }
    }

    super({
      apiKey,
      config: {
        ...axAIOpenAIResponsesDefaultConfig(),
        ...config,
      },
      options,
      modelInfo,
      models,
      supportFor,
    })
  }
}



================================================
FILE: src/ax/ai/openai/responses_types.ts
================================================
import type {
  AxChatRequest,
  AxChatResponseResult,
  AxModelConfig,
} from '../types.js'

// Extended model enum for the responses API that includes models only available on responses API
export enum AxAIOpenAIResponsesModel {
  // All chat API models
  O1 = 'o1',
  O1Mini = 'o1-mini',
  GPT4 = 'gpt-4',
  GPT41 = 'gpt-4.1',
  GPT41Mini = 'gpt-4.1-mini',
  GPT4O = 'gpt-4o',
  GPT4OMini = 'gpt-4o-mini',
  GPT4ChatGPT4O = 'chatgpt-4o-latest',
  GPT4Turbo = 'gpt-4-turbo',
  GPT35Turbo = 'gpt-3.5-turbo',
  GPT35TurboInstruct = 'gpt-3.5-turbo-instruct',
  GPT35TextDavinci002 = 'text-davinci-002',
  GPT3TextBabbage002 = 'text-babbage-002',
  GPT3TextAda001 = 'text-ada-001',
  // Responses API only models
  O3 = 'o3',
  O3Mini = 'o3-mini',
  O4Mini = 'o4-mini',
}

// Define content part types directly based on AxChatRequest structure
export interface TextContentPart {
  type: 'text'
  text: string
  cache?: boolean
}

export interface ImageContentPart {
  type: 'image'
  mimeType: string
  image: string
  details?: 'high' | 'low' | 'auto'
  cache?: boolean
}

export interface AudioContentPart {
  type: 'audio'
  data: string
  format?: 'wav'
  cache?: boolean
}

// Union of all content part types
export type UserMessageContentItem =
  | TextContentPart
  | ImageContentPart
  | AudioContentPart

// export type  for function calls as defined in AxChatResponseResult
export type FunctionCallType = NonNullable<
  AxChatResponseResult['functionCalls']
>[number]

// export type  for the items in req.functions
export type RequestFunctionDefinition = NonNullable<
  AxChatRequest['functions']
>[number]

// --- AxAIOpenAI /v1/responses Specific Request Types ---

// Content parts for input messages
export interface AxAIOpenAIResponsesInputTextContentPart {
  readonly type: 'text'
  text: string // Made mutable for stream aggregation
}

export interface AxAIOpenAIResponsesInputImageUrlContentPart {
  readonly type: 'image_url'
  readonly image_url: {
    readonly url: string
    readonly details?: 'low' | 'high' | 'auto'
  }
}

export interface AxAIOpenAIResponsesInputAudioContentPart {
  readonly type: 'input_audio' // This is an assumption based on compatibility needs
  readonly input_audio: {
    readonly data: string // base64 encoded audio
    readonly format?: string // e.g., 'wav', 'mp3'
  }
}

export type AxAIOpenAIResponsesInputContentPart =
  | AxAIOpenAIResponsesInputTextContentPart
  | AxAIOpenAIResponsesInputImageUrlContentPart
  | AxAIOpenAIResponsesInputAudioContentPart

// Input Item: Message
export interface AxAIOpenAIResponsesInputMessageItem {
  readonly type: 'message'
  readonly role: 'system' | 'user' | 'assistant' | 'developer'
  readonly content: string | ReadonlyArray<AxAIOpenAIResponsesInputContentPart>
  readonly name?: string // Optional name for user/assistant messages
  // status?: 'in_progress' | 'completed' | 'incomplete' // Typically for response items
}

// Input Item: Function Call (representing a past call by the model)
export interface AxAIOpenAIResponsesInputFunctionCallItem {
  readonly type: 'function_call'
  readonly id?: string // Optional unique ID of this item in the context
  readonly call_id: string // The ID that links this call to its output
  readonly name: string
  // eslint-disable-next-line functional/functional-parameters
  readonly arguments: string // JSON string of arguments
  // status?: string // Typically for response items
}

// Input Item: Function Call Output (representing the result of a past call)
export interface AxAIOpenAIResponsesInputFunctionCallOutputItem {
  readonly type: 'function_call_output'
  readonly id?: string // Optional unique ID of this item in the context
  readonly call_id: string
  readonly output: string // JSON string of the output
  // status?: string // Typically for response items
}

// Union of all possible input items
// Add other item types here as needed (e.g., FileSearch, WebSearch, Reasoning items)
export type AxAIOpenAIResponsesInputItem =
  | string // Simple text input
  | AxAIOpenAIResponsesInputMessageItem
  | AxAIOpenAIResponsesInputFunctionCallItem
  | AxAIOpenAIResponsesInputFunctionCallOutputItem

// Tool Definitions
export interface AxAIOpenAIResponsesDefineFunctionTool {
  readonly type: 'function'
  readonly name: string
  readonly description?: string
  readonly parameters: object // JSON schema
  readonly strict?: boolean // Default true
}

// Add other tool definitions (FileSearch, WebSearch, etc.)
// export interface AxAIOpenAIResponsesDefineFileSearchTool { type: 'file_search'; vector_store_ids: string[]; ... }
// export interface AxAIOpenAIResponsesDefineWebSearchTool { type: 'web_search_preview'; ... }

export type AxAIOpenAIResponsesToolDefinition =
  AxAIOpenAIResponsesDefineFunctionTool // | AxAIOpenAIResponsesDefineFileSearchTool | ...

// Tool Choice
export type AxAIOpenAIResponsesToolChoice =
  | 'none'
  | 'auto'
  | 'required'
  | { readonly type: 'function'; readonly name: string }
  | { readonly type: 'file_search' } // And other hosted tools
// | { type: 'web_search_preview' }
// | { type: 'code_interpreter' }

// Main Request for /v1/responses
export interface AxAIOpenAIResponsesRequest<TModel = AxAIOpenAIResponsesModel> {
  readonly input: string | ReadonlyArray<AxAIOpenAIResponsesInputItem>
  readonly model: TModel
  readonly background?: boolean | null
  readonly include?: ReadonlyArray<
    | 'file_search_call.results'
    | 'message.input_image.image_url'
    | 'computer_call_output.output.image_url'
    | 'reasoning.encrypted_content'
    | 'code_interpreter_call.outputs'
  > | null
  readonly instructions?: string | null // Maps to system prompt
  readonly max_output_tokens?: number | null
  readonly metadata?: Readonly<Record<string, string>> | null
  readonly parallel_tool_calls?: boolean | null
  readonly previous_response_id?: string | null
  readonly reasoning?: {
    readonly effort?: 'low' | 'medium' | 'high' | null
    readonly summary?: 'auto' | 'concise' | 'detailed' | null // 'generate_summary' is deprecated
  } | null
  readonly service_tier?: 'auto' | 'default' | 'flex' | null
  readonly store?: boolean | null // Whether to store for later retrieval
  readonly stream?: boolean | null
  readonly temperature?: number | null
  readonly text?: {
    readonly format?:
      | { readonly type: 'text' }
      | { readonly type: 'json_object' } // Older JSON mode
      | { readonly type: 'json_schema'; readonly json_schema?: object } // Structured Outputs
      | null
  } | null
  readonly tool_choice?: AxAIOpenAIResponsesToolChoice | null
  readonly tools?: ReadonlyArray<AxAIOpenAIResponsesToolDefinition> | null
  readonly top_p?: number | null
  readonly truncation?: 'auto' | 'disabled' | null // How to handle context window overflow
  readonly user?: string | null // User identifier for tracking/moderation
  readonly seed?: number | null // Added seed from later in the code
}

// --- AxAIOpenAI /v1/responses Specific Response Types ---

// Output Item: Message (from assistant)
export interface AxAIOpenAIResponsesOutputMessageItem {
  type: 'message' // Mutable during construction
  id: string // Mutable during construction
  role: 'assistant' // Mutable during construction
  content: ReadonlyArray<
    | AxAIOpenAIResponsesOutputTextContentPart
    | AxAIOpenAIResponsesOutputRefusalContentPart
  >
  status: 'in_progress' | 'completed' | 'incomplete' // Mutable during construction
}

// Output Item: Function Call (emitted by the model)
export interface AxAIOpenAIResponsesFunctionCallItem {
  type: 'function_call' // Mutable during construction
  id: string // Mutable during construction
  call_id: string // Mutable during construction
  name: string // Mutable during construction
  // eslint-disable-next-line functional/functional-parameters
  arguments: string // Mutable during construction (appendable)
  status?: 'in_progress' | 'completed' | 'incomplete' | 'searching' | 'failed' // Mutable
}

// Output Item: Reasoning (if requested and supported)
export interface AxAIOpenAIResponsesReasoningItem {
  readonly type: 'reasoning' // Typically not built incrementally in the same way by client
  readonly id: string
  readonly summary: ReadonlyArray<string | object>
  readonly encrypted_content?: string | null
  readonly status?: 'in_progress' | 'completed' | 'incomplete'
}

// Add this new export interface for output_text parts
export interface AxAIOpenAIResponsesOutputTextContentPart {
  readonly type: 'output_text'
  readonly text: string
  readonly annotations?: ReadonlyArray<unknown>
}

export interface AxAIOpenAIResponsesOutputRefusalContentPart {
  readonly type: 'refusal'
  readonly refusal: string
}

// Add export interface for reasoning summary parts
export interface AxAIOpenAIResponsesReasoningSummaryPart {
  readonly type: 'summary_text'
  readonly text: string
}

// Update the union of all possible output items
export type AxAIOpenAIResponsesOutputItem =
  | AxAIOpenAIResponsesOutputMessageItem
  | AxAIOpenAIResponsesFunctionCallItem
  | AxAIOpenAIResponsesReasoningItem
  | AxAIOpenAIResponsesFileSearchToolCall
  | AxAIOpenAIResponsesWebSearchToolCall
  | AxAIOpenAIResponsesComputerToolCall
  | AxAIOpenAIResponsesCodeInterpreterToolCall
  | AxAIOpenAIResponsesImageGenerationToolCall
  | AxAIOpenAIResponsesLocalShellToolCall
  | AxAIOpenAIResponsesMCPToolCall

// Main Response from /v1/responses (non-streaming)
export interface AxAIOpenAIResponsesResponse {
  readonly id: string // Response ID
  readonly object: string // e.g., "response"
  readonly created: number // Timestamp
  readonly model: string // Model ID used
  readonly output: ReadonlyArray<AxAIOpenAIResponsesOutputItem>
  readonly usage?: {
    readonly prompt_tokens: number
    readonly completion_tokens: number // Or output_tokens / generated_tokens
    readonly total_tokens: number
    // reasoning_tokens?: number // if applicable and included
  } | null
}

// --- Streaming Event Types for /v1/responses ---

// Base streaming event interface
export interface AxAIOpenAIResponsesStreamEventBase {
  readonly type: string
  readonly sequence_number: number
}

// Response lifecycle events
export interface AxAIOpenAIResponsesResponseCreatedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.created'
  readonly response: Readonly<AxAIOpenAIResponsesResponse>
}

export interface AxAIOpenAIResponsesResponseInProgressEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.in_progress'
  readonly response: Readonly<AxAIOpenAIResponsesResponse>
}

export interface AxAIOpenAIResponsesResponseCompletedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.completed'
  readonly response: Readonly<AxAIOpenAIResponsesResponse>
}

export interface AxAIOpenAIResponsesResponseFailedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.failed'
  readonly response: Readonly<AxAIOpenAIResponsesResponse>
}

export interface AxAIOpenAIResponsesResponseIncompleteEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.incomplete'
  readonly response: Readonly<AxAIOpenAIResponsesResponse>
}

export interface AxAIOpenAIResponsesResponseQueuedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.queued'
  readonly response: Readonly<AxAIOpenAIResponsesResponse>
}

// Output item events
export interface AxAIOpenAIResponsesOutputItemAddedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.output_item.added'
  readonly output_index: number
  readonly item: Readonly<AxAIOpenAIResponsesOutputItem>
}

export interface AxAIOpenAIResponsesOutputItemDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.output_item.done'
  readonly output_index: number
  readonly item: Readonly<AxAIOpenAIResponsesOutputItem>
}

// Content part events
export interface AxAIOpenAIResponsesContentPartAddedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.content_part.added'
  readonly item_id: string
  readonly output_index: number
  readonly content_index: number
  readonly part: Readonly<
    | AxAIOpenAIResponsesOutputTextContentPart
    | AxAIOpenAIResponsesOutputRefusalContentPart
  >
}

export interface AxAIOpenAIResponsesContentPartDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.content_part.done'
  readonly item_id: string
  readonly output_index: number
  readonly content_index: number
  readonly part: Readonly<
    | AxAIOpenAIResponsesOutputTextContentPart
    | AxAIOpenAIResponsesOutputRefusalContentPart
  >
}

// Text delta events
export interface AxAIOpenAIResponsesOutputTextDeltaEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.output_text.delta'
  readonly item_id: string
  readonly output_index: number
  readonly content_index: number
  readonly delta: string
}

export interface AxAIOpenAIResponsesOutputTextDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.output_text.done'
  readonly item_id: string
  readonly output_index: number
  readonly content_index: number
  readonly text: string
}

// Refusal events
export interface AxAIOpenAIResponsesRefusalDeltaEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.refusal.delta'
  readonly item_id: string
  readonly output_index: number
  readonly content_index: number
  readonly delta: string
}

export interface AxAIOpenAIResponsesRefusalDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.refusal.done'
  readonly item_id: string
  readonly output_index: number
  readonly content_index: number
  readonly refusal: string
}

// Function call events
export interface AxAIOpenAIResponsesFunctionCallArgumentsDeltaEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.function_call_arguments.delta'
  readonly item_id: string
  readonly output_index: number
  readonly delta: string
}

export interface AxAIOpenAIResponsesFunctionCallArgumentsDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.function_call_arguments.done'
  readonly item_id: string
  readonly output_index: number
  // eslint-disable-next-line functional/functional-parameters
  readonly arguments: string
}

// File search events
export interface AxAIOpenAIResponsesFileSearchCallInProgressEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.file_search_call.in_progress'
  readonly item_id: string
  readonly output_index: number
}

export interface AxAIOpenAIResponsesFileSearchCallSearchingEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.file_search_call.searching'
  readonly item_id: string
  readonly output_index: number
}

export interface AxAIOpenAIResponsesFileSearchCallCompletedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.file_search_call.completed'
  readonly item_id: string
  readonly output_index: number
}

// Web search events
export interface AxAIOpenAIResponsesWebSearchCallInProgressEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.web_search_call.in_progress'
  readonly item_id: string
  readonly output_index: number
}

export interface AxAIOpenAIResponsesWebSearchCallSearchingEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.web_search_call.searching'
  readonly item_id: string
  readonly output_index: number
}

export interface AxAIOpenAIResponsesWebSearchCallCompletedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.web_search_call.completed'
  readonly item_id: string
  readonly output_index: number
}

// Reasoning events
export interface AxAIOpenAIResponsesReasoningDeltaEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.reasoning.delta'
  readonly item_id: string
  readonly output_index: number
  readonly content_index: number
  readonly delta: object
}

export interface AxAIOpenAIResponsesReasoningDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.reasoning.done'
  readonly item_id: string
  readonly output_index: number
  readonly content_index: number
  readonly text: string
}

// Reasoning summary events
export interface AxAIOpenAIResponsesReasoningSummaryPartAddedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.reasoning_summary_part.added'
  readonly item_id: string
  readonly output_index: number
  readonly summary_index: number
  readonly part: Readonly<AxAIOpenAIResponsesReasoningSummaryPart>
}

export interface AxAIOpenAIResponsesReasoningSummaryPartDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.reasoning_summary_part.done'
  readonly item_id: string
  readonly output_index: number
  readonly summary_index: number
  readonly part: Readonly<AxAIOpenAIResponsesReasoningSummaryPart>
}

export interface AxAIOpenAIResponsesReasoningSummaryTextDeltaEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.reasoning_summary_text.delta'
  readonly item_id: string
  readonly output_index: number
  readonly summary_index: number
  readonly delta: string
}

export interface AxAIOpenAIResponsesReasoningSummaryTextDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.reasoning_summary_text.done'
  readonly item_id: string
  readonly output_index: number
  readonly summary_index: number
  readonly text: string
}

export interface AxAIOpenAIResponsesReasoningSummaryDeltaEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.reasoning_summary.delta'
  readonly item_id: string
  readonly output_index: number
  readonly summary_index: number
  readonly delta: object
}

export interface AxAIOpenAIResponsesReasoningSummaryDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.reasoning_summary.done'
  readonly item_id: string
  readonly output_index: number
  readonly summary_index: number
  readonly text: string
}

// Image generation events
export interface AxAIOpenAIResponsesImageGenerationCallInProgressEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.image_generation_call.in_progress'
  readonly item_id: string
  readonly output_index: number
}

export interface AxAIOpenAIResponsesImageGenerationCallGeneratingEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.image_generation_call.generating'
  readonly item_id: string
  readonly output_index: number
}

export interface AxAIOpenAIResponsesImageGenerationCallCompletedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.image_generation_call.completed'
  readonly item_id: string
  readonly output_index: number
}

export interface AxAIOpenAIResponsesImageGenerationCallPartialImageEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.image_generation_call.partial_image'
  readonly item_id: string
  readonly output_index: number
  readonly partial_image_index: number
  readonly partial_image_b64: string
}

// MCP events
export interface AxAIOpenAIResponsesMCPCallInProgressEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.mcp_call.in_progress'
  readonly item_id: string
  readonly output_index: number
}

export interface AxAIOpenAIResponsesMCPCallArgumentsDeltaEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.mcp_call.arguments.delta'
  readonly item_id: string
  readonly output_index: number
  readonly delta: object
}

export interface AxAIOpenAIResponsesMCPCallArgumentsDoneEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.mcp_call.arguments.done'
  readonly item_id: string
  readonly output_index: number
  // eslint-disable-next-line functional/functional-parameters
  readonly arguments: object
}

export interface AxAIOpenAIResponsesMCPCallCompletedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.mcp_call.completed'
}

export interface AxAIOpenAIResponsesMCPCallFailedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.mcp_call.failed'
}

export interface AxAIOpenAIResponsesMCPListToolsInProgressEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.mcp_list_tools.in_progress'
}

export interface AxAIOpenAIResponsesMCPListToolsCompletedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.mcp_list_tools.completed'
}

export interface AxAIOpenAIResponsesMCPListToolsFailedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.mcp_list_tools.failed'
}

// Annotation events
export interface AxAIOpenAIResponsesOutputTextAnnotationAddedEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'response.output_text_annotation.added'
  readonly item_id: string
  readonly output_index: number
  readonly content_index: number
  readonly annotation_index: number
  readonly annotation: object
}

// Error event
export interface AxAIOpenAIResponsesErrorEvent
  extends AxAIOpenAIResponsesStreamEventBase {
  readonly type: 'error'
  readonly code: string | null
  readonly message: string
  readonly param: string | null
}

// Union of all streaming events
export type AxAIOpenAIResponsesStreamEvent =
  | AxAIOpenAIResponsesResponseCreatedEvent
  | AxAIOpenAIResponsesResponseInProgressEvent
  | AxAIOpenAIResponsesResponseCompletedEvent
  | AxAIOpenAIResponsesResponseFailedEvent
  | AxAIOpenAIResponsesResponseIncompleteEvent
  | AxAIOpenAIResponsesResponseQueuedEvent
  | AxAIOpenAIResponsesOutputItemAddedEvent
  | AxAIOpenAIResponsesOutputItemDoneEvent
  | AxAIOpenAIResponsesContentPartAddedEvent
  | AxAIOpenAIResponsesContentPartDoneEvent
  | AxAIOpenAIResponsesOutputTextDeltaEvent
  | AxAIOpenAIResponsesOutputTextDoneEvent
  | AxAIOpenAIResponsesRefusalDeltaEvent
  | AxAIOpenAIResponsesRefusalDoneEvent
  | AxAIOpenAIResponsesFunctionCallArgumentsDeltaEvent
  | AxAIOpenAIResponsesFunctionCallArgumentsDoneEvent
  | AxAIOpenAIResponsesFileSearchCallInProgressEvent
  | AxAIOpenAIResponsesFileSearchCallSearchingEvent
  | AxAIOpenAIResponsesFileSearchCallCompletedEvent
  | AxAIOpenAIResponsesWebSearchCallInProgressEvent
  | AxAIOpenAIResponsesWebSearchCallSearchingEvent
  | AxAIOpenAIResponsesWebSearchCallCompletedEvent
  | AxAIOpenAIResponsesReasoningDeltaEvent
  | AxAIOpenAIResponsesReasoningDoneEvent
  | AxAIOpenAIResponsesReasoningSummaryPartAddedEvent
  | AxAIOpenAIResponsesReasoningSummaryPartDoneEvent
  | AxAIOpenAIResponsesReasoningSummaryTextDeltaEvent
  | AxAIOpenAIResponsesReasoningSummaryTextDoneEvent
  | AxAIOpenAIResponsesReasoningSummaryDeltaEvent
  | AxAIOpenAIResponsesReasoningSummaryDoneEvent
  | AxAIOpenAIResponsesImageGenerationCallInProgressEvent
  | AxAIOpenAIResponsesImageGenerationCallGeneratingEvent
  | AxAIOpenAIResponsesImageGenerationCallCompletedEvent
  | AxAIOpenAIResponsesImageGenerationCallPartialImageEvent
  | AxAIOpenAIResponsesMCPCallInProgressEvent
  | AxAIOpenAIResponsesMCPCallArgumentsDeltaEvent
  | AxAIOpenAIResponsesMCPCallArgumentsDoneEvent
  | AxAIOpenAIResponsesMCPCallCompletedEvent
  | AxAIOpenAIResponsesMCPCallFailedEvent
  | AxAIOpenAIResponsesMCPListToolsInProgressEvent
  | AxAIOpenAIResponsesMCPListToolsCompletedEvent
  | AxAIOpenAIResponsesMCPListToolsFailedEvent
  | AxAIOpenAIResponsesOutputTextAnnotationAddedEvent
  | AxAIOpenAIResponsesErrorEvent

// Legacy delta export interface for backward compatibility - now maps to the new streaming events
export interface AxAIOpenAIResponsesResponseDelta {
  readonly id?: string // Overall response ID, appears in first event usually
  readonly model?: string // Model ID, might appear in first event
  readonly event?: string // e.g., 'response.delta', 'response.item_delta', 'response.done'

  // If event is 'response.delta' or 'response.item_delta'
  readonly delta?: {
    // For message content delta
    readonly content?: string // If item is a message part
    // For tool call argument delta
    // eslint-disable-next-line functional/functional-parameters
    readonly arguments?: string // If item is a function_call part
    // Other potential delta fields based on item type
  }

  // If event is 'response.item_created', 'response.item_delta', 'response.item_completed'
  readonly item_index?: number // Index of the item in the `items` array
  readonly item?: Partial<Readonly<AxAIOpenAIResponsesOutputItem>> // The item being streamed or its delta

  // If event is 'response.done'
  readonly response?: Readonly<AxAIOpenAIResponsesResponse> // The final full response object (often without items if streamed separately)
  readonly usage?: {
    readonly prompt_tokens: number
    readonly completion_tokens: number
    readonly total_tokens: number
    // reasoning_tokens?: number
  } | null // Usage often comes in the 'response.done' event or with stream_options
}

// export type  for the function that updates the request before sending
export type ResponsesReqUpdater<
  TModel,
  TResponsesReq extends AxAIOpenAIResponsesRequest<TModel>,
> = (req: Readonly<TResponsesReq>) => Readonly<TResponsesReq>

// Utility export type  to make properties of T mutable
export type Mutable<T> = { -readonly [P in keyof T]: T[P] }

export type AxAIOpenAIResponsesConfig<TModel, TEmbedModel> = Omit<
  AxModelConfig,
  'topK'
> & {
  model: TModel
  embedModel?: TEmbedModel
  user?: string
  bestOf?: number
  logitBias?: Map<string, number>
  suffix?: string | null
  stop?: string[]
  logprobs?: number
  echo?: boolean
  dimensions?: number
  reasoningEffort?: 'low' | 'medium' | 'high'
  store?: boolean
  systemPrompt?: string
  parallelToolCalls?: boolean
  seed?: number
  responseFormat?: 'text' | 'json_object' | 'json_schema'
  serviceTier?: 'auto' | 'default' | 'flex'
}

// ToolCall response types
export interface AxAIOpenAIResponsesToolCallBase {
  id: string
  type: string
  status?: string
}

export interface AxAIOpenAIResponsesFileSearchToolCall
  extends AxAIOpenAIResponsesToolCallBase {
  type: 'file_search_call'
  queries: string[]
  results?: {
    file_id: string
    filename: string
    score: number
    text: string
    attributes?: Record<string, string | boolean | number>
  }[]
}

export interface AxAIOpenAIResponsesWebSearchToolCall
  extends AxAIOpenAIResponsesToolCallBase {
  type: 'web_search_call'
  queries: string[]
}

export interface AxAIOpenAIResponsesComputerToolCall
  extends AxAIOpenAIResponsesToolCallBase {
  type: 'computer_call'
  action: object
}

export interface AxAIOpenAIResponsesCodeInterpreterToolCall
  extends AxAIOpenAIResponsesToolCallBase {
  type: 'code_interpreter_call'
  code: string
  results?: unknown[]
}

export interface AxAIOpenAIResponsesImageGenerationToolCall
  extends AxAIOpenAIResponsesToolCallBase {
  type: 'image_generation_call'
  result?: string
}

export interface AxAIOpenAIResponsesLocalShellToolCall
  extends AxAIOpenAIResponsesToolCallBase {
  type: 'local_shell_call'
  action: object
}

export interface AxAIOpenAIResponsesMCPToolCall
  extends AxAIOpenAIResponsesToolCallBase {
  type: 'mcp_call'
  name: string
  args: string
  server_label: string
  output?: string
  error?: string
}

export type AxAIOpenAIResponsesToolCall =
  | AxAIOpenAIResponsesFunctionCallItem
  | AxAIOpenAIResponsesFileSearchToolCall
  | AxAIOpenAIResponsesWebSearchToolCall
  | AxAIOpenAIResponsesComputerToolCall
  | AxAIOpenAIResponsesCodeInterpreterToolCall
  | AxAIOpenAIResponsesImageGenerationToolCall
  | AxAIOpenAIResponsesLocalShellToolCall
  | AxAIOpenAIResponsesMCPToolCall



================================================
FILE: src/ax/ai/reka/api.ts
================================================
import type { AxAPI } from '../../util/apicall.js'
import {
  AxBaseAI,
  axBaseAIDefaultConfig,
  axBaseAIDefaultCreativeConfig,
} from '../base.js'
import type {
  AxAIInputModelList,
  AxAIPromptConfig,
  AxAIServiceImpl,
  AxAIServiceOptions,
  AxChatRequest,
  AxChatResponse,
  AxChatResponseResult,
  AxInternalChatRequest,
  AxModelConfig,
  AxModelInfo,
  AxTokenUsage,
} from '../types.js'

import { axModelInfoReka } from './info.js'
import {
  type AxAIRekaChatRequest,
  type AxAIRekaChatResponse,
  type AxAIRekaChatResponseDelta,
  type AxAIRekaConfig,
  AxAIRekaModel,
} from './types.js'

export const axAIRekaDefaultConfig = (): AxAIRekaConfig =>
  structuredClone({
    model: AxAIRekaModel.RekaCore,
    ...axBaseAIDefaultConfig(),
  })

export const axAIRekaBestConfig = (): AxAIRekaConfig =>
  structuredClone({
    ...axAIRekaDefaultConfig(),
    model: AxAIRekaModel.RekaCore,
  })

export const axAIRekaCreativeConfig = (): AxAIRekaConfig =>
  structuredClone({
    model: AxAIRekaModel.RekaCore,
    ...axBaseAIDefaultCreativeConfig(),
  })

export const axAIRekaFastConfig = (): AxAIRekaConfig => ({
  ...axAIRekaDefaultConfig(),
  model: AxAIRekaModel.RekaFlash,
})

export interface AxAIRekaArgs {
  name: 'reka'
  apiKey: string
  apiURL?: string
  config?: Readonly<Partial<AxAIRekaConfig>>
  options?: Readonly<AxAIServiceOptions & { streamingUsage?: boolean }>
  modelInfo?: Readonly<AxModelInfo[]>
  models?: AxAIInputModelList<AxAIRekaModel, undefined>
}

class AxAIRekaImpl
  implements
    AxAIServiceImpl<
      AxAIRekaModel,
      undefined,
      AxAIRekaChatRequest,
      unknown,
      AxAIRekaChatResponse,
      AxAIRekaChatResponseDelta,
      unknown
    >
{
  private tokensUsed: AxTokenUsage | undefined

  constructor(private config: AxAIRekaConfig) {}

  getTokenUsage(): AxTokenUsage | undefined {
    return this.tokensUsed
  }

  getModelConfig(): AxModelConfig {
    const { config } = this
    return {
      maxTokens: config.maxTokens,
      temperature: config.temperature,
      presencePenalty: config.presencePenalty,
      frequencyPenalty: config.frequencyPenalty,
      stopSequences: config.stopSequences,
      topP: config.topP,
      n: config.n,
      stream: config.stream,
    }
  }

  createChatReq = (
    req: Readonly<AxInternalChatRequest<AxAIRekaModel>>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _config: Readonly<AxAIPromptConfig>
  ): [AxAPI, AxAIRekaChatRequest] => {
    const model = req.model

    if (!req.chatPrompt || req.chatPrompt.length === 0) {
      throw new Error('Chat prompt is empty')
    }

    const apiConfig = {
      name: '/chat/completions',
    }

    const messages = createMessages(req)

    const frequencyPenalty =
      req.modelConfig?.frequencyPenalty ?? this.config.frequencyPenalty

    const stream = req.modelConfig?.stream ?? this.config.stream

    const reqValue: AxAIRekaChatRequest = {
      model,
      messages,
      max_tokens: req.modelConfig?.maxTokens ?? this.config.maxTokens,
      temperature: req.modelConfig?.temperature ?? this.config.temperature,
      top_k: req.modelConfig?.n ?? this.config.n,
      top_p: req.modelConfig?.topP ?? this.config.topP ?? 1,
      stop: req.modelConfig?.stopSequences ?? this.config.stop,
      presence_penalty:
        req.modelConfig?.presencePenalty ?? this.config.presencePenalty,
      ...(frequencyPenalty ? { frequency_penalty: frequencyPenalty } : {}),
      ...(stream ? { stream: true } : {}),
    }

    return [apiConfig, reqValue]
  }

  createChatResp = (resp: Readonly<AxAIRekaChatResponse>): AxChatResponse => {
    const { id, usage, responses } = resp

    this.tokensUsed = usage
      ? {
          promptTokens: usage.input_tokens,
          completionTokens: usage.output_tokens,
          totalTokens: usage.input_tokens + usage.output_tokens,
        }
      : undefined

    const results = responses.map((res) => {
      const finishReason = mapFinishReason(res.finish_reason)
      let content
      if (typeof res.message.content === 'string') {
        content = res.message.content
      } else {
        content = res.message.content.text
      }

      return {
        id: `${id}`,
        content,
        finishReason,
      }
    })

    return { results, remoteId: id }
  }

  createChatStreamResp = (
    resp: Readonly<AxAIRekaChatResponseDelta>
  ): AxChatResponse => {
    const { id, usage, responses } = resp

    this.tokensUsed = usage
      ? {
          promptTokens: usage.input_tokens,
          completionTokens: usage.output_tokens,
          totalTokens: usage.input_tokens + usage.output_tokens,
        }
      : undefined

    const results = responses.map((res) => {
      const finishReason = mapFinishReason(res.finish_reason)
      let content
      if (typeof res.chunk.content === 'string') {
        content = res.chunk.content
      } else {
        content = res.chunk.content.text
      }

      return {
        id: `${id}`,
        content,
        finishReason,
      }
    })

    return { results }
  }
}

const mapFinishReason = (
  finishReason: AxAIRekaChatResponse['responses'][0]['finish_reason']
): AxChatResponseResult['finishReason'] => {
  switch (finishReason) {
    case 'stop':
      return 'stop' as const
    case 'context':
      return 'length' as const
    case 'length':
      return 'length' as const
  }
}

function createMessages(
  req: Readonly<AxChatRequest>
): AxAIRekaChatRequest['messages'] {
  return req.chatPrompt.map((msg) => {
    switch (msg.role) {
      case 'system':
        return { role: 'user' as const, content: msg.content }

      case 'user':
        if (Array.isArray(msg.content)) {
          return {
            role: 'user' as const,
            content: msg.content.map((c) => {
              switch (c.type) {
                case 'text':
                  return { type: 'text' as const, text: c.text }
                case 'image': {
                  throw new Error('Image type not supported')
                }
                default:
                  throw new Error('Invalid content type')
              }
            }),
          }
        }
        return { role: 'user' as const, content: msg.content }

      case 'assistant':
        if (Array.isArray(msg.content)) {
          return {
            role: 'assistant' as const,
            content: msg.content.map((c) => {
              switch (c.type) {
                case 'text':
                  return { type: 'text' as const, text: c.text }
                case 'image': {
                  throw new Error('Image type not supported')
                }
                default:
                  throw new Error('Invalid content type')
              }
            }),
          }
        }
        if (!msg.content) {
          throw new Error('Assistant content is empty')
        }
        return { role: 'user' as const, content: msg.content }
      default:
        throw new Error('Invalid role')
    }
  })
}

export class AxAIReka extends AxBaseAI<
  AxAIRekaModel,
  undefined,
  AxAIRekaChatRequest,
  unknown,
  AxAIRekaChatResponse,
  AxAIRekaChatResponseDelta,
  unknown
> {
  constructor({
    apiKey,
    config,
    options,
    apiURL,
    modelInfo = axModelInfoReka,
    models,
  }: Readonly<Omit<AxAIRekaArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('Reka API key not set')
    }
    const _config = {
      ...axAIRekaDefaultConfig(),
      ...config,
    }

    const aiImpl = new AxAIRekaImpl(_config)

    super(aiImpl, {
      name: 'Reka',
      apiURL: apiURL ? apiURL : 'https://api.reka.ai/v1/chat',
      headers: async () => ({ 'X-Api-Key': apiKey }),
      modelInfo,
      defaults: {
        model: _config.model,
      },
      options,
      supportFor: { functions: true, streaming: true },
      models,
    })
  }
}



================================================
FILE: src/ax/ai/reka/info.ts
================================================
import type { AxModelInfo } from '../types.js'

import { AxAIRekaModel } from './types.js'
/**
 * OpenAI: Model information
 */
export const axModelInfoReka: AxModelInfo[] = [
  {
    name: AxAIRekaModel.RekaCore,
    currency: 'usd',
    promptTokenCostPer1M: 3,
    completionTokenCostPer1M: 15,
  },
  {
    name: AxAIRekaModel.RekaFlash,
    currency: 'usd',
    promptTokenCostPer1M: 0.8,
    completionTokenCostPer1M: 2,
  },
  {
    name: AxAIRekaModel.RekaEdge,
    currency: 'usd',
    promptTokenCostPer1M: 0.4,
    completionTokenCostPer1M: 1,
  },
]



================================================
FILE: src/ax/ai/reka/types.ts
================================================
import type { AxModelConfig } from '../types.js'

export enum AxAIRekaModel {
  RekaCore = 'reka-core',
  RekaFlash = 'reka-flash',
  RekaEdge = 'reka-edge',
}

export type AxAIRekaConfig = Omit<AxModelConfig, 'topK'> & {
  model: AxAIRekaModel
  stop?: readonly string[]
  useSearchEngine?: boolean
}

export type AxAIRekaUsage = {
  input_tokens: number
  output_tokens: number
}

export type AxAIRekaChatRequest = {
  model: string
  messages: (
    | {
        role: 'user'
        content:
          | string
          | {
              type: 'text'
              text: string
            }[]
      }
    | {
        role: 'assistant'
        content:
          | string
          | {
              type: 'text'
              text: string
            }[]
      }
  )[]
  usage?: AxAIRekaUsage
  response_format?: { type: string }
  max_tokens?: number
  temperature?: number
  top_p?: number
  top_k?: number
  stream?: boolean
  stop?: readonly string[]
  presence_penalty?: number
  frequency_penalty?: number
  use_search_engine?: boolean
}

export type AxAIRekaChatResponse = {
  id: string
  model: string
  responses: {
    message: {
      content:
        | string
        | {
            type: 'text'
            text: string
          }
    }
    finish_reason: 'stop' | 'length' | 'context'
  }[]
  usage?: AxAIRekaUsage
}

export type AxAIRekaChatResponseDelta = {
  id: string
  model: string
  responses: {
    chunk: AxAIRekaChatResponse['responses'][0]['message']
    finish_reason: AxAIRekaChatResponse['responses'][0]['finish_reason']
  }[]
  usage?: AxAIRekaUsage
}



================================================
FILE: src/ax/ai/together/api.ts
================================================
import { axBaseAIDefaultConfig } from '../base.js'
import { type AxAIOpenAIArgs, AxAIOpenAIBase } from '../openai/api.js'
import type { AxAIOpenAIConfig } from '../openai/chat_types.js'

import { axModelInfoTogether } from './info.js'

type TogetherAIConfig = AxAIOpenAIConfig<string, unknown>

export const axAITogetherDefaultConfig = (): TogetherAIConfig =>
  structuredClone({
    // cspell:disable-next-line
    model: 'mistralai/Mixtral-8x7B-Instruct-v0.1',
    ...axBaseAIDefaultConfig(),
  })

export type AxAITogetherArgs = AxAIOpenAIArgs<'together', string, unknown>

export class AxAITogether extends AxAIOpenAIBase<string, unknown> {
  constructor({
    apiKey,
    config,
    options,
    models,
    modelInfo,
  }: Readonly<Omit<AxAITogetherArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('Together API key not set')
    }
    const _config = {
      ...axAITogetherDefaultConfig(),
      ...config,
    }

    modelInfo = [...axModelInfoTogether, ...(modelInfo ?? [])]

    const supportFor = {
      functions: true,
      streaming: true,
      hasThinkingBudget: false,
      hasShowThoughts: false,
    }

    super({
      apiKey,
      config: _config,
      options,
      apiURL: 'https://api.together.xyz/v1',
      modelInfo,
      models,
      supportFor,
    })

    super.setName('Together')
  }
}



================================================
FILE: src/ax/ai/together/info.ts
================================================
import type { AxModelInfo } from '../types.js'

export const axModelInfoTogether: AxModelInfo[] = []



================================================
FILE: src/ax/ai/x-grok/api.ts
================================================
import { getModelInfo } from '@ax-llm/ax/dsp/modelinfo.js'

import { axBaseAIDefaultConfig } from '../base.js'
import { type AxAIOpenAIArgs, AxAIOpenAIBase } from '../openai/api.js'
import type {
  AxAIOpenAIChatRequest,
  AxAIOpenAIConfig,
} from '../openai/chat_types.js'
import type { AxAIServiceOptions, AxModelInfo } from '../types.js'

import { axModelInfoGrok } from './info.js'
import { AxAIGrokEmbedModels, AxAIGrokModel } from './types.js'

export const axAIGrokDefaultConfig = (): AxAIOpenAIConfig<
  AxAIGrokModel,
  AxAIGrokEmbedModels
> =>
  structuredClone({
    model: AxAIGrokModel.Grok3Mini,
    ...axBaseAIDefaultConfig(),
  })

export const axAIGrokBestConfig = (): AxAIOpenAIConfig<
  AxAIGrokModel,
  AxAIGrokEmbedModels
> =>
  structuredClone({
    ...axAIGrokDefaultConfig(),
    model: AxAIGrokModel.Grok3,
  })

export interface AxAIGrokSearchSource {
  type: 'web' | 'x' | 'news' | 'rss'
  country?: string // ISO alpha-2 code for web and news
  excludedWebsites?: string[] // Max 5 websites for web and news
  allowedWebsites?: string[] // Max 5 websites for web only
  safeSearch?: boolean // For web and news, default true
  xHandles?: string[] // For X source
  links?: string[] // For RSS source, max 1 link
}

export interface AxAIGrokOptionsTools {
  searchParameters?: {
    mode?: 'auto' | 'on' | 'off'
    returnCitations?: boolean
    fromDate?: string // ISO8601 format YYYY-MM-DD
    toDate?: string // ISO8601 format YYYY-MM-DD
    maxSearchResults?: number // Default 20
    sources?: AxAIGrokSearchSource[]
  }
}

export type AxAIGrokChatRequest = AxAIOpenAIChatRequest<AxAIGrokModel> & {
  search_parameters?: {
    mode?: 'auto' | 'on' | 'off'
    return_citations?: boolean
    from_date?: string
    to_date?: string
    max_search_results?: number
    sources?: AxAIGrokSearchSource[]
  }
}

export type AxAIGrokArgs = AxAIOpenAIArgs<
  'grok',
  AxAIGrokModel,
  AxAIGrokEmbedModels,
  AxAIGrokChatRequest
> & {
  options?: Readonly<AxAIServiceOptions & AxAIGrokOptionsTools> & {
    tokensPerMinute?: number
  }
  modelInfo?: AxModelInfo[]
}

export class AxAIGrok extends AxAIOpenAIBase<
  AxAIGrokModel,
  AxAIGrokEmbedModels,
  AxAIGrokChatRequest
> {
  constructor({
    apiKey,
    config,
    options,
    models,
    modelInfo,
  }: Readonly<Omit<AxAIGrokArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('Grok API key not set')
    }

    const _config = {
      ...axAIGrokDefaultConfig(),
      ...config,
    }

    modelInfo = [...axModelInfoGrok, ...(modelInfo ?? [])]

    const supportFor = (model: AxAIGrokModel) => {
      const mi = getModelInfo<AxAIGrokModel, AxAIGrokEmbedModels>({
        model,
        modelInfo,
        models,
      })
      return {
        functions: true,
        streaming: true,
        hasThinkingBudget: mi?.hasThinkingBudget ?? false,
        hasShowThoughts: mi?.hasShowThoughts ?? false,
      }
    }

    // Chat request updater to add Grok's search parameters
    const chatReqUpdater = (req: AxAIGrokChatRequest): AxAIGrokChatRequest => {
      if (options?.searchParameters) {
        const searchParams = options.searchParameters
        return {
          ...req,
          search_parameters: {
            mode: searchParams.mode,
            return_citations: searchParams.returnCitations,
            from_date: searchParams.fromDate,
            to_date: searchParams.toDate,
            max_search_results: searchParams.maxSearchResults,
            sources: searchParams.sources?.map((source) => ({
              type: source.type,
              country: source.country,
              excluded_websites: source.excludedWebsites,
              allowed_websites: source.allowedWebsites,
              safe_search: source.safeSearch,
              x_handles: source.xHandles,
              links: source.links,
            })),
          },
        }
      }
      return req
    }

    super({
      apiKey,
      config: _config,
      options,
      apiURL: 'https://api.x.ai/v1',
      modelInfo,
      models,
      supportFor,
      chatReqUpdater,
    })

    super.setName('Grok')
  }
}



================================================
FILE: src/ax/ai/x-grok/info.ts
================================================
// cspell:ignore grok

import type { AxModelInfo } from '../types.js'

import { AxAIGrokModel } from './types.js'

export const axModelInfoGrok: AxModelInfo[] = [
  {
    name: AxAIGrokModel.Grok3,
    currency: 'USD',
    promptTokenCostPer1M: 3.0,
    completionTokenCostPer1M: 15.0,
  },
  {
    name: AxAIGrokModel.Grok3Mini,
    currency: 'USD',
    promptTokenCostPer1M: 0.3,
    completionTokenCostPer1M: 0.5,
    hasThinkingBudget: true,
  },
  {
    name: AxAIGrokModel.Grok3Fast,
    currency: 'USD',
    promptTokenCostPer1M: 5.0,
    completionTokenCostPer1M: 25.0,
  },
  {
    name: AxAIGrokModel.Grok3MiniFast,
    currency: 'USD',
    promptTokenCostPer1M: 0.6,
    completionTokenCostPer1M: 4.0,
    hasThinkingBudget: true,
  },
]



================================================
FILE: src/ax/ai/x-grok/types.ts
================================================
// cspell:ignore grok

export enum AxAIGrokModel {
  Grok3 = 'grok-3',
  Grok3Mini = 'grok-3-mini',
  Grok3Fast = 'grok-3-fast',
  Grok3MiniFast = 'grok-3-mini-fast',
}

export enum AxAIGrokEmbedModels {
  GrokEmbedSmall = 'grok-embed-small', // Placeholder, update if actual models are known
}



================================================
FILE: src/ax/db/base.ts
================================================
import { type Span, SpanKind, type Tracer } from '@opentelemetry/api'

import { axSpanAttributes } from '../trace/trace.js'

import type {
  AxDBQueryRequest,
  AxDBQueryResponse,
  AxDBService,
  AxDBUpsertRequest,
  AxDBUpsertResponse,
} from './types.js'

export interface AxDBBaseArgs {
  fetch?: typeof fetch
  tracer?: Tracer
}

export interface AxDBBaseOpOptions {
  span?: Span
}

export class AxDBBase implements AxDBService {
  protected name: string
  protected fetch?: typeof fetch
  private tracer?: Tracer

  _upsert?: (
    req: Readonly<AxDBUpsertRequest>,
    update?: boolean,
    options?: Readonly<AxDBBaseOpOptions>
  ) => Promise<AxDBUpsertResponse>

  _batchUpsert?: (
    batchReq: Readonly<AxDBUpsertRequest[]>,
    update?: boolean,
    options?: Readonly<AxDBBaseOpOptions>
  ) => Promise<AxDBUpsertResponse>

  _query?: (
    req: Readonly<AxDBQueryRequest>,
    options?: Readonly<AxDBBaseOpOptions>
  ) => Promise<AxDBQueryResponse>

  constructor({
    name,
    fetch,
    tracer,
  }: Readonly<AxDBBaseArgs & { name: string }>) {
    this.name = name
    this.fetch = fetch
    this.tracer = tracer
  }

  async upsert(
    req: Readonly<AxDBUpsertRequest>,
    update?: boolean
  ): Promise<AxDBUpsertResponse> {
    if (!this._upsert) {
      throw new Error('upsert() not implemented')
    }

    if (!this.tracer) {
      return await this._upsert(req, update)
    }

    return await this.tracer.startActiveSpan(
      'DB Upsert Request',
      {
        kind: SpanKind.SERVER,
        attributes: {
          [axSpanAttributes.DB_SYSTEM]: this.name,
          [axSpanAttributes.DB_OPERATION_NAME]: 'upsert',
          [axSpanAttributes.DB_TABLE]: req.table,
          [axSpanAttributes.DB_NAMESPACE]: req.namespace,
          [axSpanAttributes.DB_OPERATION_NAME]: update ? 'update' : 'insert',
        },
      },
      async (span) => {
        try {
          return await this._upsert!(req, update, { span })
        } finally {
          span.end()
        }
      }
    )
  }

  async batchUpsert(
    req: Readonly<AxDBUpsertRequest[]>,
    update?: boolean
  ): Promise<AxDBUpsertResponse> {
    if (!this._batchUpsert) {
      throw new Error('batchUpsert() not implemented')
    }
    if (req.length == 0) {
      throw new Error('Batch request is empty')
    }
    if (!req[0]) {
      throw new Error('Batch request is invalid first element is undefined')
    }

    if (!this.tracer) {
      return await this._batchUpsert(req, update)
    }

    return await this.tracer.startActiveSpan(
      'DB Batch Upsert Request',
      {
        kind: SpanKind.SERVER,
        attributes: {
          [axSpanAttributes.DB_SYSTEM]: this.name,
          [axSpanAttributes.DB_OPERATION_NAME]: 'upsert',
          [axSpanAttributes.DB_TABLE]: req[0].table,
          [axSpanAttributes.DB_NAMESPACE]: req[0].namespace,
          [axSpanAttributes.DB_OPERATION_NAME]: update ? 'update' : 'insert',
        },
      },
      async (span) => {
        try {
          return await this._batchUpsert!(req, update, { span })
        } finally {
          span.end()
        }
      }
    )
  }

  async query(req: Readonly<AxDBQueryRequest>): Promise<AxDBQueryResponse> {
    if (!this._query) {
      throw new Error('query() not implemented')
    }
    if (!this.tracer) {
      return await this._query(req)
    }

    return await this.tracer.startActiveSpan(
      'DB Query Request',
      {
        kind: SpanKind.SERVER,
        attributes: {
          [axSpanAttributes.DB_SYSTEM]: this.name,
          [axSpanAttributes.DB_OPERATION_NAME]: 'upsert',
          [axSpanAttributes.DB_TABLE]: req.table,
          [axSpanAttributes.DB_NAMESPACE]: req.namespace,
          [axSpanAttributes.DB_OPERATION_NAME]: 'query',
        },
      },
      async (span) => {
        try {
          return await this._query!(req, { span })
        } finally {
          span.end()
        }
      }
    )
  }
}



================================================
FILE: src/ax/db/cloudflare.ts
================================================
import { apiCall } from '../util/apicall.js'

import { AxDBBase, type AxDBBaseArgs, type AxDBBaseOpOptions } from './base.js'
import type {
  AxDBQueryRequest,
  AxDBQueryResponse,
  AxDBUpsertRequest,
  AxDBUpsertResponse,
} from './types.js'

const baseURL = 'https://api.cloudflare.com/client/v4/accounts/'

export type AxDBCloudflareOpOptions = AxDBBaseOpOptions

type AxCloudflareUpsertResponse = {
  success: boolean
  errors?: { message: string }[]
  result: { ids: string[] }
}

type AxCloudflareQueryResponse = {
  success: boolean
  errors?: { message: string }[]
  result: {
    matches: {
      id: string
      score: number
      values: number[]
      metadata: object
    }[]
  }
}

export interface AxDBCloudflareArgs extends AxDBBaseArgs {
  name: 'cloudflare'
  apiKey: string
  accountId: string
  fetch?: typeof fetch
}

/**
 * Cloudflare: DB Service
 */
export class AxDBCloudflare extends AxDBBase {
  private apiKey: string
  private accountId: string

  constructor({
    apiKey,
    accountId,
    fetch,
    tracer,
  }: Readonly<Omit<AxDBCloudflareArgs, 'name'>>) {
    if (!apiKey || !accountId) {
      throw new Error('Cloudflare credentials not set')
    }
    super({ name: 'Cloudflare', fetch, tracer })
    this.apiKey = apiKey
    this.accountId = accountId
  }

  override _upsert = async (
    req: Readonly<AxDBUpsertRequest>,
    _update?: boolean,
    options?: Readonly<AxDBCloudflareOpOptions>
  ): Promise<AxDBUpsertResponse> => {
    const res = (await apiCall(
      {
        url: new URL(
          `${this.accountId}/vectorize/indexes/${req.table}/upsert`,
          baseURL
        ),
        headers: {
          'X-Auth-Key': this.apiKey,
        },
        fetch: this.fetch,
        span: options?.span,
      },
      {
        id: req.id,
        values: req.values,
        namespace: req.namespace,
        metadata: req.metadata,
      }
    )) as AxCloudflareUpsertResponse

    if (res.errors) {
      throw new Error(
        `Cloudflare upsert failed: ${res.errors.map(({ message }) => message).join(', ')}`
      )
    }

    return {
      ids: res.result.ids,
    }
  }

  override batchUpsert = async (
    batchReq: Readonly<AxDBUpsertRequest[]>,
    update?: boolean,
    options?: Readonly<AxDBCloudflareOpOptions>
  ): Promise<AxDBUpsertResponse> => {
    if (update) {
      throw new Error('Weaviate does not support batch update')
    }
    if (batchReq.length < 1) {
      throw new Error('Batch request is empty')
    }
    if (!batchReq[0] || !batchReq[0].table) {
      throw new Error('Table name is empty')
    }
    const table = batchReq[0].table

    const res = (await apiCall(
      {
        url: new URL(
          `${this.accountId}/vectorize/indexes/${table}/upsert`,
          baseURL
        ),
        headers: {
          'X-Auth-Key': this.apiKey,
        },
        fetch: this.fetch,
        span: options?.span,
      },
      batchReq.map((req) => ({
        id: req.id,
        values: req.values,
        namespace: req.namespace,
        metadata: req.metadata,
      }))
    )) as AxCloudflareUpsertResponse

    if (res.errors) {
      throw new Error(
        `Cloudflare batch upsert failed: ${res.errors
          .map(({ message }) => message)
          .join(', ')}`
      )
    }

    return {
      ids: res.result.ids,
    }
  }

  override query = async (
    req: Readonly<AxDBQueryRequest>,
    options?: Readonly<AxDBCloudflareOpOptions>
  ): Promise<AxDBQueryResponse> => {
    const res = (await apiCall(
      {
        url: new URL(
          `${this.accountId}/vectorize/indexes/${req.table}/query`,
          baseURL
        ),
        headers: {
          'X-Auth-Key': this.apiKey,
        },
        fetch: this.fetch,
        span: options?.span,
      },
      {
        vector: req.values,
        topK: req.limit || 10,
        returnValues: true,
      }
    )) as AxCloudflareQueryResponse

    if (res.errors) {
      throw new Error(
        `Cloudflare query failed: ${res.errors.map(({ message }) => message).join(', ')}`
      )
    }

    const matches = res.result.matches.map(
      ({ id, score, values, metadata }) => ({
        id,
        score,
        values,
        metadata,
      })
    )
    return { matches } as AxDBQueryResponse
  }
}



================================================
FILE: src/ax/db/memory.ts
================================================
import { AxDBBase, type AxDBBaseArgs, type AxDBBaseOpOptions } from './base.js'
import type {
  AxDBQueryRequest,
  AxDBQueryResponse,
  AxDBUpsertRequest,
  AxDBUpsertResponse,
} from './types.js'

export type AxDBMemoryOpOptions = AxDBBaseOpOptions

export interface AxDBMemoryArgs extends AxDBBaseArgs {
  name: 'memory'
}

export type AxDBState = Record<string, Record<string, AxDBUpsertRequest>>

/**
 * MemoryDB: DB Service
 */
export class AxDBMemory extends AxDBBase {
  private state: AxDBState

  constructor({ tracer }: Readonly<Omit<AxDBMemoryArgs, 'name'>> = {}) {
    super({ name: 'Memory', tracer })
    this.state = {}
  }

  override _upsert = async (
    req: Readonly<AxDBUpsertRequest>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _update?: boolean,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options?: Readonly<AxDBMemoryOpOptions>
  ): Promise<AxDBUpsertResponse> => {
    if (!this.state[req.table]) {
      this.state[req.table] = {
        [req.id]: req,
      }
    } else {
      const obj = this.state[req.table]
      if (!obj) {
        throw new Error('Table not found: ' + req.table)
      }
      obj[req.id] = req
    }

    return { ids: [req.id] }
  }

  override _batchUpsert = async (
    batchReq: Readonly<AxDBUpsertRequest[]>,
    update?: boolean,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options?: Readonly<AxDBMemoryOpOptions>
  ): Promise<AxDBUpsertResponse> => {
    const ids: string[] = []
    for (const req of batchReq) {
      const res = await this.upsert(req, update)
      ids.push(...res.ids)
    }

    return { ids }
  }

  override _query = async (
    req: Readonly<AxDBQueryRequest>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options?: Readonly<AxDBMemoryOpOptions>
  ): Promise<AxDBQueryResponse> => {
    const table = this.state[req.table]
    if (!table) {
      return { matches: [] }
    }

    const matches: AxDBQueryResponse['matches'] = []

    Object.entries(table).forEach(([id, data]) => {
      if (req.values && data.values) {
        const score = distance(req.values, data.values)
        matches.push({ id: id, score: score, metadata: data.metadata })
      }
    })

    matches.sort((a, b) => a.score - b.score)
    if (req.limit) {
      matches.length = req.limit
    }

    return { matches }
  }

  public getDB = () => {
    return structuredClone(this.state)
  }

  public setDB = (state: AxDBState) => {
    this.state = structuredClone(state)
  }

  public clearDB = () => {
    this.state = {}
  }
}

const distance = (a: readonly number[], b: readonly number[]): number => {
  if (a.length !== b.length) {
    throw new Error('Vectors must be of the same length.')
  }

  let dotProduct = 0
  let normA = 0
  let normB = 0
  let zeroVectorA = true
  let zeroVectorB = true

  const vectorA = new Float64Array(a)
  const vectorB = new Float64Array(b)

  for (let i = 0; i < vectorA.length; i++) {
    dotProduct += vectorA[i]! * vectorB[i]!
    normA += vectorA[i]! * vectorA[i]!
    normB += vectorB[i]! * vectorB[i]!
    if (vectorA[i] !== 0) zeroVectorA = false
    if (vectorB[i] !== 0) zeroVectorB = false
  }

  if (zeroVectorA || zeroVectorB) {
    return 1 // Return maximum distance if one vector is zero
  }

  const sqrtNormA = Math.sqrt(normA)
  const sqrtNormB = Math.sqrt(normB)
  const similarity = dotProduct / (sqrtNormA * sqrtNormB)
  return 1 - similarity // Returning distance as 1 - cosine similarity.
}



================================================
FILE: src/ax/db/pinecone.ts
================================================
import { apiCall } from '../util/apicall.js'

import { AxDBBase, type AxDBBaseArgs, type AxDBBaseOpOptions } from './base.js'
import type {
  AxDBQueryRequest,
  AxDBQueryResponse,
  AxDBUpsertRequest,
  AxDBUpsertResponse,
} from './types.js'

export type AxDBPineconeOpOptions = AxDBBaseOpOptions

type AxPineconeQueryRequest = {
  namespace?: string
  topK: number
  filter?: Record<string, string>
  includeValues: boolean
  includeMetadata: boolean
  vector: readonly number[]
  id?: string
}

type AxPineconeQueryResponse = {
  matches: {
    id: string
    score: number
    values: number[]
    metadata?: Record<string, string>
  }[]
}

const createPineconeQueryRequest = (
  req: Readonly<AxDBQueryRequest>
): AxPineconeQueryRequest => {
  const pineconeQueryRequest: AxPineconeQueryRequest = {
    namespace: req.namespace,
    topK: req.limit || 10,
    filter: {},
    includeValues: true,
    includeMetadata: true,
    vector: req.values ?? [],
    id: req.id,
  }

  return pineconeQueryRequest
}

export interface AxDBPineconeArgs extends AxDBBaseArgs {
  name: 'pinecone'
  apiKey: string
  host: string
  fetch?: typeof fetch
}

/**
 * Pinecone: DB Service
 */
export class AxDBPinecone extends AxDBBase {
  private apiKey: string
  private apiURL: string

  constructor({
    apiKey,
    host,
    fetch,
    tracer,
  }: Readonly<Omit<AxDBPineconeArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('Pinecone API key not set')
    }
    super({ name: 'Pinecone', fetch, tracer })
    this.apiKey = apiKey
    this.apiURL = host
  }

  override _upsert = async (
    req: Readonly<AxDBUpsertRequest>,
    update?: boolean,
    options?: Readonly<AxDBPineconeOpOptions>
  ): Promise<AxDBUpsertResponse> => {
    await this._batchUpsert([req], update, options)
    return { ids: [req.id] }
  }

  override _batchUpsert = async (
    batchReq: Readonly<AxDBUpsertRequest[]>,
    _update?: boolean,
    options?: Readonly<AxDBPineconeOpOptions>
  ): Promise<AxDBUpsertResponse> => {
    if (batchReq.length === 0) {
      throw new Error('Batch request is empty')
    }
    await apiCall(
      {
        url: this.apiURL,
        headers: { Authorization: `Bearer ${this.apiKey}` },
        name: '/vectors/upsert',
        fetch: this.fetch,
        span: options?.span,
      },
      batchReq.map(({ id, values = [], metadata }) => ({
        id,
        values,
        metadata,
      }))
    )

    return { ids: batchReq.map(({ id }) => id) }
  }

  override query = async (
    req: Readonly<AxDBQueryRequest>,
    options?: Readonly<AxDBPineconeOpOptions>
  ): Promise<AxDBQueryResponse> => {
    if (req.text) {
      throw new Error('Pinecone does not support text')
    }

    const res = (await apiCall(
      {
        url: this.apiURL,
        headers: { Authorization: `Bearer ${this.apiKey}` },
        name: '/query',
        fetch: this.fetch,
        span: options?.span,
      },
      createPineconeQueryRequest(req)
    )) as AxPineconeQueryResponse

    const matches = res.matches.map(({ id, score, values, metadata }) => ({
      id,
      score,
      metadata,
      values,
    }))

    return { matches }
  }
}



================================================
FILE: src/ax/db/types.ts
================================================
// For upsert

export type AxDBUpsertRequest = {
  id: string
  text?: string
  values?: readonly number[]
  metadata?: Record<string, string>
  table: string
  namespace?: string
}

export type AxDBUpsertResponse = {
  ids: string[]
}

// For query
export type AxDBQueryRequest = {
  id?: string
  text?: string
  values?: readonly number[]
  table: string
  columns?: string[]
  limit?: number
  namespace?: string
}

export type AxDBQueryResponse = {
  matches: {
    id: string
    score: number
    metadata?: Record<string, string>
    table?: string
  }[]
}

export interface AxDBService extends AxDBQueryService {
  upsert(
    req: Readonly<AxDBUpsertRequest>,
    update?: boolean
  ): Promise<AxDBUpsertResponse>

  batchUpsert(
    batchReq: Readonly<AxDBUpsertRequest[]>,
    update?: boolean
  ): Promise<AxDBUpsertResponse>
}

export interface AxDBQueryService {
  query(req: Readonly<AxDBQueryRequest>): Promise<AxDBQueryResponse>
}



================================================
FILE: src/ax/db/weaviate.ts
================================================
import { apiCall } from '../util/apicall.js'

import { AxDBBase, type AxDBBaseArgs, type AxDBBaseOpOptions } from './base.js'
import type {
  AxDBQueryRequest,
  AxDBQueryResponse,
  AxDBUpsertRequest,
  AxDBUpsertResponse,
} from './types.js'

export type AxDBWeaviateOpOptions = AxDBBaseOpOptions

type AxWeaviateUpsertResponse = {
  id: string
  result?: { errors?: { error: { message: string }[] } }
}

type AxWeaviateQueryResponse = {
  errors?: { location: string; message: string; path: string }[]
  data: {
    Get: {
      [key: string]: {
        [key: string]: unknown
      }[]
    }
  }
}

export interface AxDBWeaviateArgs extends AxDBBaseArgs {
  name: 'weaviate'
  apiKey: string
  host: string
  fetch?: typeof fetch
}

/**
 * Weaviate: DB Service
 */
export class AxDBWeaviate extends AxDBBase {
  private apiKey: string
  private apiURL: string

  constructor({
    apiKey,
    host,
    fetch,
    tracer,
  }: Readonly<Omit<AxDBWeaviateArgs, 'name'>>) {
    if (!apiKey || apiKey === '') {
      throw new Error('Weaviate API key not set')
    }
    super({ name: 'Weaviate', fetch, tracer })
    this.apiKey = apiKey
    this.apiURL = host
  }

  override _upsert = async (
    req: Readonly<AxDBUpsertRequest>,
    update?: boolean,
    options?: Readonly<AxDBWeaviateOpOptions>
  ): Promise<AxDBUpsertResponse> => {
    const res = (await apiCall(
      {
        url: this.apiURL,
        headers: { Authorization: `Bearer ${this.apiKey}` },
        name: `/v1/objects/${req.table}/${req.id}`,
        put: update ? true : false,
        fetch: this.fetch,
        span: options?.span,
      },
      {
        id: req.id,
        class: req.table,
        tenant: req.namespace,
        vector: req.values,
        properties: req.metadata ?? {},
      }
    )) as AxWeaviateUpsertResponse

    if (res?.result?.errors) {
      throw new Error(
        `Weaviate upsert failed: ${res.result.errors.error
          .map(({ message }) => message)
          .join(', ')}`
      )
    }

    return {
      ids: [res.id],
    }
  }

  override _batchUpsert = async (
    batchReq: Readonly<AxDBUpsertRequest[]>,
    update?: boolean,
    options?: Readonly<AxDBWeaviateOpOptions>
  ): Promise<AxDBUpsertResponse> => {
    if (update) {
      throw new Error('Weaviate does not support batch update')
    }
    if (batchReq.length === 0) {
      throw new Error('Batch request is empty')
    }
    const objects = batchReq.map((req) => ({
      id: req.id,
      class: req.table,
      tenant: req.namespace,
      vector: req.values,
      properties: req.metadata ?? {},
    }))

    const res = (await apiCall(
      {
        url: this.apiURL,
        headers: { Authorization: `Bearer ${this.apiKey}` },
        name: '/v1/batch/objects',
        fetch: this.fetch,
        span: options?.span,
      },
      { objects }
    )) as AxWeaviateUpsertResponse[]

    if (res?.some(({ result }) => result?.errors)) {
      throw new Error(
        `Weaviate batch upsert failed: ${res
          .map(({ result }) =>
            result?.errors?.error.map(({ message }) => message).join(', ')
          )
          .join(', ')}`
      )
    }

    return {
      ids: res.map(({ id }) => id),
    }
  }

  override _query = async (
    req: Readonly<AxDBQueryRequest>,
    options?: Readonly<AxDBWeaviateOpOptions>
  ): Promise<AxDBQueryResponse> => {
    let filter = ''

    if (req.columns && req.columns.length === 0) {
      throw new Error('Weaviate requires at least one column')
    }

    if (req.values) {
      filter = `nearVector: {
            vector: [${req.values.join(',')}],
        }`
    } else if (req.text) {
      filter = `nearText: {
            concepts: ['${req.text}'],
        }`
    } else {
      throw new Error('Weaviate requires either text or values')
    }

    const res = (await apiCall(
      {
        url: this.apiURL,
        headers: { Authorization: `Bearer ${this.apiKey}` },
        name: '/v1/graphql',
        fetch: this.fetch,
        span: options?.span,
      },
      {
        query: `{
          Get {
            ${req.table} (
              limit: ${req.limit || 10},
              ${filter}
            ) {
                ${req.columns?.join('\n')}
            }
          }
        }`,
      }
    )) as AxWeaviateQueryResponse

    if (res.errors) {
      throw new Error(
        `Weaviate query failed: ${res.errors
          .map(({ message }) => message)
          .join(', ')}`
      )
    }

    const resMatches = res.data.Get[req.table]

    if (!resMatches) {
      return { matches: [] }
    }

    const matches = resMatches.map((match) => {
      return {
        id: match['id'] as string,
        score: 1,
        metadata: match,
      }
    })
    return { matches } as AxDBQueryResponse
  }
}



================================================
FILE: src/ax/db/wrap.ts
================================================
import { AxDBCloudflare, type AxDBCloudflareArgs } from './cloudflare.js'
import { AxDBMemory, type AxDBMemoryArgs } from './memory.js'
import { AxDBPinecone, type AxDBPineconeArgs } from './pinecone.js'
import type {
  AxDBQueryRequest,
  AxDBQueryResponse,
  AxDBService,
  AxDBUpsertRequest,
  AxDBUpsertResponse,
} from './types.js'
import { AxDBWeaviate, type AxDBWeaviateArgs } from './weaviate.js'

export type AxDBArgs =
  | AxDBCloudflareArgs
  | AxDBPineconeArgs
  | AxDBWeaviateArgs
  | AxDBMemoryArgs

export class AxDB implements AxDBService {
  private db: AxDBService
  constructor(args: Readonly<AxDBArgs>) {
    switch (args.name) {
      case 'weaviate':
        this.db = new AxDBWeaviate(args)
        break
      case 'pinecone':
        this.db = new AxDBPinecone(args)
        break
      case 'cloudflare':
        this.db = new AxDBCloudflare(args)
        break
      case 'memory':
        this.db = new AxDBMemory(args)
        break
      default:
        throw new Error(`Unknown DB`)
    }
  }
  async upsert(
    req: Readonly<AxDBUpsertRequest>,
    update?: boolean
  ): Promise<AxDBUpsertResponse> {
    return await this.db.upsert(req, update)
  }

  async batchUpsert(
    batchReq: Readonly<AxDBUpsertRequest[]>,
    update?: boolean
  ): Promise<AxDBUpsertResponse> {
    return await this.db.batchUpsert(batchReq, update)
  }

  async query(req: Readonly<AxDBQueryRequest>): Promise<AxDBQueryResponse> {
    return await this.db.query(req)
  }
}



================================================
FILE: src/ax/docs/manager.ts
================================================
import { type AxAIService } from '../ai/types.js'
import { type AxDBQueryResponse, type AxDBService } from '../db/types.js'
import { type AxProgram } from '../dsp/program.js'

export type AxRewriteIn = { query: string }
export type AxRewriteOut = { rewrittenQuery: string }

export type AxRerankerIn = { query: string; items: string[] }
export type AxRerankerOut = { rankedItems: string[] }

export interface AxDBLoaderOptions {
  chunker?: (text: string) => string[]
  rewriter?: AxProgram<AxRewriteIn, AxRewriteOut>
  reranker?: AxProgram<AxRerankerIn, AxRerankerOut>
}

export interface AxDBManagerArgs {
  ai: AxAIService
  db: AxDBService
  config?: AxDBLoaderOptions
}

export interface AxDBMatch {
  score: number
  text: string
}

const table = '_internal'

export class AxDBManager {
  private ai: AxAIService
  private db: AxDBService
  private chunker: (text: string) => string[]
  private rewriter?: AxProgram<AxRewriteIn, AxRewriteOut>
  private reranker?: AxProgram<AxRerankerIn, AxRerankerOut>

  constructor({ ai, db, config }: Readonly<AxDBManagerArgs>) {
    this.ai = ai
    this.db = db
    this.chunker = config?.chunker ?? this.defaultChunker
    this.reranker = config?.reranker
    this.rewriter = config?.rewriter
  }

  private defaultChunker = (text: string): string[] => {
    // Default chunking by paragraphs
    return text.split(/\n\n+/)
  }

  insert = async (
    text: Readonly<string | string[]>,
    options?: Readonly<{
      batchSize?: number
      maxWordsPerChunk?: number
      minWordsPerChunk?: number
      abortSignal?: AbortSignal
    }>
  ): Promise<void> => {
    try {
      const chunkerInput = Array.isArray(text)
        ? text.join('\n\n')
        : (text as string)

      // Chunk the text using the specified or default chunking function
      const initialChunks = this.chunker(chunkerInput).filter(
        (chunk) => chunk.length > 0
      )

      const maxWordsPerChunk = options?.maxWordsPerChunk
      const minWordsPerChunk = options?.minWordsPerChunk

      const chunks = processChunks({
        initialChunks,
        minWordsPerChunk,
        maxWordsPerChunk,
      })

      const bs = options?.batchSize ?? 10

      // Process chunks in batches of 10
      for (let i = 0; i < chunks.length; i += bs) {
        const batch = chunks.slice(i, i + bs)

        // Get embeddings for the whole batch from the AI service in one call
        const ret = await this.ai.embed(
          { texts: batch },
          {
            abortSignal: options?.abortSignal,
          }
        )

        // Prepare batch for bulk upsert
        const embeddings = ret.embeddings
          .map((embedding, index) => ({
            id: `chunk_${Date.now() + index}`, // Unique ID for each chunk, adjusted by index
            table,
            values: embedding,
            metadata: { text: batch[index] ?? '' },
          }))
          .filter(
            (v) => v.metadata?.['text'] && v.metadata?.['text'].length > 0
          )

        // Batch upsert embeddings
        await this.db.batchUpsert(embeddings)
      }
    } catch (error) {
      throw new Error(`Error processing text: ${error}`)
    }
  }

  query = async (
    query: Readonly<string | string[] | number | number[]>,
    {
      topPercent,
      abortSignal,
    }:
      | Readonly<{ topPercent?: number; abortSignal?: AbortSignal }>
      | undefined = {}
  ): Promise<AxDBMatch[][]> => {
    const texts = Array.isArray(query) ? query : [query]

    if (typeof texts[0] === 'string' && this.rewriter) {
      for (const [i, text] of texts.entries()) {
        const { rewrittenQuery } = await this.rewriter.forward(this.ai, {
          query: text,
        })
        texts[i] = rewrittenQuery
      }
    }

    let queries: Promise<AxDBQueryResponse>[]

    if (typeof texts[0] === 'string') {
      const embedResults = await this.ai.embed(
        { texts },
        {
          abortSignal,
        }
      )
      queries = embedResults.embeddings.map((values) =>
        this.db.query({ table, values })
      )
    } else {
      queries = texts.map((values) => this.db.query({ table, values }))
    }

    const queryResults = await Promise.all(queries)
    const res: AxDBMatch[][] = []

    for (const { matches } of queryResults) {
      const m = matches
        .filter((v) => v.metadata?.['text'] && v.metadata?.['text'].length > 0)
        .map(({ score, metadata }) => ({
          score,
          text: metadata?.['text'] ?? '',
        }))

      const tp = topPercent && topPercent > 1 ? topPercent / 100 : topPercent
      const resultItems = tp ? getTopInPercent(m, tp) : m

      if (this.reranker) {
        const { rankedItems } = await this.reranker.forward(this.ai, {
          query: texts[0] as string,
          items: resultItems.map((item) => item.text),
        })

        const items = rankedItems
          .map((item) => resultItems.find((r) => r.text === item))
          .filter((v) => v !== undefined) as AxDBMatch[]

        res.push(items)
      } else {
        res.push(resultItems)
      }
    }

    return res
  }
}

const processChunks = ({
  initialChunks,
  maxWordsPerChunk = 350,
  minWordsPerChunk = 250,
}: Readonly<{
  initialChunks: readonly string[]
  maxWordsPerChunk?: number
  minWordsPerChunk?: number
}>): string[] => {
  const chunks: string[] = []

  let currentChunk = ''
  let currentWordCount = 0

  initialChunks.forEach((chunk) => {
    const words = chunk.split(/\s+/) // Split the chunk into words
    const wordCount = words.length // Count words in the current chunk

    if (currentWordCount + wordCount <= maxWordsPerChunk) {
      // Add to the current chunk if within the max size limit
      currentChunk += chunk + '\n\n'
      currentWordCount += wordCount
    } else if (
      currentWordCount > 0 &&
      currentWordCount + wordCount <= maxWordsPerChunk * 1.5
    ) {
      // If the total word count exceeds the limit but is less than 150% of the maxWordsPerChunk
      currentChunk += chunk + '\n\n'
      currentWordCount += wordCount
    } else {
      // If the current chunk is not empty and adding the new chunk exceeds the adjusted limit
      if (currentWordCount > minWordsPerChunk) {
        chunks.push(currentChunk.trim())
        currentChunk = ''
        currentWordCount = 0
      }
      // Handle the case where the chunk itself is larger than the limit
      if (wordCount > maxWordsPerChunk) {
        const remainingWords = words
        while (remainingWords.length > maxWordsPerChunk * 1.5) {
          const slice = remainingWords.splice(0, maxWordsPerChunk)
          chunks.push(slice.join(' '))
        }
        // Add the last portion if it fits the condition of being within 150% of maxWordsPerChunk
        if (remainingWords.length > 0) {
          currentChunk += remainingWords.join(' ') + '\n\n'
          currentWordCount += remainingWords.length
        }
      } else {
        // If the new chunk is smaller than the maximum words per chunk
        currentChunk = chunk + '\n\n'
        currentWordCount = wordCount
      }
    }
  })

  // Push the last chunk if it exists and meets the minimum words condition
  if (currentWordCount > minWordsPerChunk || chunks.length === 0) {
    chunks.push(currentChunk.trim())
  }
  return chunks
}

const getTopInPercent = (
  entries: readonly AxDBMatch[],
  percent: number = 0.1
): AxDBMatch[] => {
  // Sort entries by score in ascending order
  const sortedEntries = [...entries].sort((a, b) => a.score - b.score)

  // Calculate the number of entries to take (top 10%)
  const topTenPercentCount = Math.ceil(sortedEntries.length * percent)

  // Return the top 10% of entries
  return sortedEntries.slice(0, topTenPercentCount)
}



================================================
FILE: src/ax/docs/reranker.ts
================================================
import type { AxAIService } from '../ai/types.js'
import { AxGen } from '../dsp/generate.js'
import type { AxProgramForwardOptions } from '../dsp/program.js'
import { AxStringUtil } from '../dsp/strutil.js'

import { type AxRerankerIn, type AxRerankerOut } from './manager.js'

export class AxDefaultResultReranker extends AxGen<
  AxRerankerIn,
  AxRerankerOut
> {
  constructor(options?: Readonly<AxProgramForwardOptions>) {
    const signature = `"You are a re-ranker assistant tasked with evaluating a set of content items in relation to a specific question. Your role involves critically analyzing each content item to determine its relevance to the question and re-ranking them accordingly. This process includes assigning a relevance score from 0 to 10 to each content item based on how well it answers the question, its coverage of the topic, and the reliability of its information. This re-ranked list should start with the content item that is most relevant to the question and end with the least relevant. Output only the list."
    query: string, items: string[] -> rankedItems: string[] "list of id, 5-words Rationale, relevance score"`

    super(signature, options)
  }

  public override forward = async (
    ai: Readonly<AxAIService>,
    input: Readonly<AxRerankerIn>,
    options?: Readonly<AxProgramForwardOptions>
  ): Promise<AxRerankerOut> => {
    const { rankedItems } = await super.forward(ai, input, options)

    const sortedIndexes: number[] = rankedItems.map((item) => {
      const { id: index } = AxStringUtil.extractIdAndText(item)
      return index
    })

    // Ensure all elements are strings and filter out null or undefined
    const sortedItems = input.items
      .map((_, index) => {
        const originalIndex = sortedIndexes[index]
        return originalIndex !== undefined
          ? input.items[originalIndex]
          : undefined
      })
      .filter((item): item is string => item !== undefined)

    return { rankedItems: sortedItems }
  }
}



================================================
FILE: src/ax/docs/rewriter.ts
================================================
import { AxGen } from '../dsp/generate.js'
import type { AxProgramForwardOptions } from '../dsp/program.js'

import { type AxRewriteIn, type AxRewriteOut } from './manager.js'

export class AxDefaultQueryRewriter extends AxGen<AxRewriteIn, AxRewriteOut> {
  constructor(options?: Readonly<AxProgramForwardOptions>) {
    const signature = `"You are a query rewriter assistant tasked with rewriting a given query to improve its clarity, specificity, and relevance. Your role involves analyzing the query to identify any ambiguities, generalizations, or irrelevant information and then rephrasing it to make it more focused and precise. The rewritten query should be concise, easy to understand, and directly related to the original query. Output only the rewritten query."
    query: string -> rewrittenQuery: string`

    super(signature, options)
  }
}

export class AxRewriter extends AxGen<AxRewriteIn, AxRewriteOut> {
  constructor(options?: Readonly<AxProgramForwardOptions>) {
    super(
      '"Rewrite a given text to be clear and concise" original -> rewritten "improved text"',
      options
    )
  }
}



================================================
FILE: src/ax/docs/tika.ts
================================================
import { createReadStream } from 'node:fs'

export interface AxApacheTikaArgs {
  url?: string | URL
  fetch?: typeof fetch
}

export interface AxApacheTikaConvertOptions {
  format?: 'text' | 'html'
}

export class AxApacheTika {
  private tikaUrl: URL
  private fetch?: typeof fetch

  constructor(args?: Readonly<AxApacheTikaArgs>) {
    const _args = args ?? { url: 'http://localhost:9998/' }
    this.tikaUrl = new URL('/tika', _args.url)
    this.fetch = _args.fetch
  }

  private async _convert(
    file: string | Blob,
    options?: Readonly<AxApacheTikaConvertOptions>
  ): Promise<string> {
    const fileData =
      typeof file === 'string' ? createReadStream(file) : file.stream()

    if (!fileData) {
      throw new Error('Failed to read file data')
    }

    const acceptValue = options?.format === 'html' ? 'text/html' : 'text/plain'

    try {
      const res = await (this.fetch ?? fetch)(this.tikaUrl, {
        body: fileData,
        headers: { Accept: acceptValue },
        duplex: 'half',
        method: 'PUT',
      })

      if (!res.ok) {
        throw new Error(`Failed to upload file: ${res.statusText}`)
      }

      const text = await res.text()
      return text
    } catch (error) {
      throw new Error(`Error converting file: ${error}`)
    }
  }

  public async convert(
    files: Readonly<string[] | Blob[]>,
    options?: Readonly<{ batchSize?: number; format?: 'html' | 'text' }>
  ): Promise<string[]> {
    const results: string[] = []
    const bs = options?.batchSize ?? 10

    for (let i = 0; i < files.length; i += bs) {
      const batch = files.slice(i, i + bs)
      const uploadPromises = batch.map((files) =>
        this._convert(files, { format: options?.format })
      )
      const batchResults = await Promise.all(uploadPromises)
      results.push(...batchResults)
    }

    return results
  }
}
export default AxApacheTika



================================================
FILE: src/ax/dsp/asserts.ts
================================================
import type { extractionState } from './extract.js'

export interface AxAssertion {
  fn(
    values: Record<string, unknown>
  ): Promise<boolean | undefined> | boolean | undefined
  message?: string
}

export interface AxStreamingAssertion {
  fieldName: string
  fn(content: string, done?: boolean): boolean | undefined
  message?: string
}

export class AxAssertionError extends Error {
  constructor({
    message,
  }: Readonly<{
    message: string
  }>) {
    super(message)
    this.name = this.constructor.name
  }

  public getFixingInstructions = () => {
    const extraFields = []
    const message = this.message.trim()

    extraFields.push({
      name: 'error',
      title: 'Follow these instructions',
      description: message + (message.endsWith('.') ? '' : '.'),
    })

    return extraFields
  }

  override toString(): string {
    return `${this.name}: ${this.message}`
  }

  [Symbol.for('nodejs.util.inspect.custom')](
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _depth: number,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options: Record<string, unknown>
  ) {
    return this.toString()
  }
}

export const assertAssertions = async (
  asserts: readonly AxAssertion[],
  values: Record<string, unknown>
) => {
  for (const assert of asserts) {
    const { fn, message } = assert

    const res = await fn(values)
    if (res === undefined) {
      continue
    }

    if (!res) {
      if (!message) {
        throw new Error(`Assertion Failed: No message provided for assertion`)
      }
      throw new AxAssertionError({ message })
    }
  }
}

export const assertStreamingAssertions = async (
  asserts: readonly AxStreamingAssertion[],
  xstate: Readonly<extractionState>,
  content: string,
  final: boolean = false
) => {
  if (
    !xstate.currField ||
    xstate.s === -1 ||
    !asserts ||
    asserts.length === 0
  ) {
    return
  }

  const fieldAsserts = asserts.filter(
    (a) => a.fieldName === xstate.currField?.name
  )

  if (fieldAsserts.length === 0) {
    return
  }

  const currValue = content.substring(xstate.s)

  for (const assert of fieldAsserts) {
    const { message, fn } = assert

    const res = await fn(currValue, final)
    if (res === undefined) {
      continue
    }

    if (!res && message) {
      throw new AxAssertionError({ message })
    }
  }
}



================================================
FILE: src/ax/dsp/classifier.ts
================================================
import type { AxAIService } from '../ai/types.js'
import { AxDBMemory, type AxDBState } from '../db/memory.js'
import { ColorLog } from '../util/log.js'

const colorLog = new ColorLog()

export interface AxSimpleClassifierForwardOptions {
  cutoff?: number
  abortSignal?: AbortSignal
}

export class AxSimpleClassifierClass {
  private readonly name: string
  private readonly context: readonly string[]

  constructor(name: string, context: readonly string[]) {
    this.name = name
    this.context = context
  }

  public getName(): string {
    return this.name
  }

  public getContext(): readonly string[] {
    return this.context
  }
}

export class AxSimpleClassifier {
  private readonly ai: AxAIService

  private db: AxDBMemory
  private debug?: boolean

  public constructor(ai: AxAIService) {
    this.db = new AxDBMemory()
    this.ai = ai
  }

  public getState(): AxDBState | undefined {
    return this.db.getDB()
  }

  public setState(state: AxDBState) {
    this.db.setDB(state)
  }

  public setClasses = async (
    classes: readonly AxSimpleClassifierClass[],
    options?: Readonly<{ abortSignal?: AbortSignal }>
  ): Promise<void> => {
    for (const c of classes) {
      const ret = await this.ai.embed(
        { texts: c.getContext() },
        {
          abortSignal: options?.abortSignal,
        }
      )
      await this.db.upsert({
        id: c.getName(),
        table: 'classes',
        values: ret.embeddings[0],
      })
    }
  }

  public async forward(
    text: string,
    options?: Readonly<AxSimpleClassifierForwardOptions>
  ): Promise<string> {
    const { embeddings } = await this.ai.embed(
      { texts: [text] },
      {
        abortSignal: options?.abortSignal,
      }
    )

    const matches = await this.db.query({
      table: 'classes',
      values: embeddings[0],
    })

    let m = matches.matches
    if (typeof options?.cutoff === 'number') {
      const { cutoff } = options
      m = m.filter((m) => m.score <= cutoff)
    }

    if (this.debug) {
      console.log(
        colorLog.whiteBright(`query: ${text}`) +
          '\n' +
          colorLog.greenBright(
            JSON.stringify(m.map((m) => `${m.id}, ${m.score}`))
          )
      )
    }

    const matchedClass = m.at(0)
    if (!matchedClass) {
      return ''
    }

    return matchedClass.id
  }

  public setOptions(options: Readonly<{ debug?: boolean }>): void {
    if (typeof options.debug === 'boolean') {
      this.debug = options.debug
    }
  }
}



================================================
FILE: src/ax/dsp/datetime.test.ts
================================================
import { describe, expect, it } from 'vitest'

import { parseLLMFriendlyDate, parseLLMFriendlyDateTime } from './datetime.js'
import type { AxField } from './sig.js'

const field: AxField = {
  name: 'date',
  type: { name: 'date', isArray: false },
}

describe('datetime parsing', () => {
  it('should parse datetime with timezone abbreviation', () => {
    const dt = parseLLMFriendlyDateTime(field, '2022-01-01 12:00 EST')
    expect(dt?.toUTCString()).toBe('Sat, 01 Jan 2022 17:00:00 GMT')
  })

  it('should parse datetime with seconds and timezone abbreviation', () => {
    const dt = parseLLMFriendlyDateTime(field, '2022-01-01 12:00:10 EST')
    expect(dt?.toUTCString()).toBe('Sat, 01 Jan 2022 17:00:10 GMT')
  })

  it('should parse datetime with full timezone', () => {
    const dt = parseLLMFriendlyDateTime(
      field,
      '2022-01-01 12:00 America/New_York'
    )
    expect(dt?.toUTCString()).toBe('Sat, 01 Jan 2022 17:00:00 GMT')
  })

  it('should parse datetime with another full timezone', () => {
    const dt = parseLLMFriendlyDateTime(
      field,
      '2022-01-01 12:00 America/Los_Angeles'
    )
    expect(dt?.toUTCString()).toBe('Sat, 01 Jan 2022 20:00:00 GMT')
  })

  it('should parse datetime across DST boundary', () => {
    const summerDt = parseLLMFriendlyDateTime(field, '2022-07-01 12:00 EST')
    const winterDt = parseLLMFriendlyDateTime(field, '2022-01-01 12:00 EST')
    expect(summerDt?.getUTCHours()).toBe(winterDt?.getUTCHours())
  })

  it('should throw error for invalid datetime value', () => {
    expect(() => parseLLMFriendlyDateTime(field, '2022-01-01 12:00')).toThrow()
  })

  it('should throw error for invalid timezone', () => {
    expect(() =>
      parseLLMFriendlyDateTime(field, '2022-01-01 12:00 INVALID')
    ).toThrow()
  })
})

describe('date parsing', () => {
  it('should parse valid date', () => {
    const dt = parseLLMFriendlyDate(field, '2022-01-01')
    expect(dt?.toUTCString()).toBe('Sat, 01 Jan 2022 00:00:00 GMT')
  })

  it('should parse date with leading zeros', () => {
    const dt = parseLLMFriendlyDate(field, '2022-02-05')
    expect(dt?.toUTCString()).toBe('Sat, 05 Feb 2022 00:00:00 GMT')
  })

  it('should parse date at year boundary', () => {
    const dt = parseLLMFriendlyDate(field, '2022-12-31')
    expect(dt?.toUTCString()).toBe('Sat, 31 Dec 2022 00:00:00 GMT')
  })

  it('should parse date in leap year', () => {
    const dt = parseLLMFriendlyDate(field, '2024-02-29')
    expect(dt?.toUTCString()).toBe('Thu, 29 Feb 2024 00:00:00 GMT')
  })

  it('should throw error for invalid date value', () => {
    expect(() => parseLLMFriendlyDate(field, '2022-01-32')).toThrow()
  })

  it('should throw error for invalid month', () => {
    expect(() => parseLLMFriendlyDate(field, '2022-13-01')).toThrow()
  })

  it('should throw error for invalid format', () => {
    expect(() => parseLLMFriendlyDate(field, '01-01-2022')).toThrow()
  })
})



================================================
FILE: src/ax/dsp/datetime.ts
================================================
import moment from 'moment-timezone'

import type { AxField } from './sig.js'
import { ValidationError } from './validate.js'

export function parseLLMFriendlyDate(
  field: Readonly<AxField>,
  dateStr: string,
  required: boolean = false
) {
  try {
    return _parseLLMFriendlyDate(dateStr)
  } catch (err) {
    if (field.isOptional && !required) {
      return
    }
    const message = (err as Error).message
    throw new ValidationError({ fields: [field], message, value: dateStr })
  }
}

function _parseLLMFriendlyDate(dateStr: string) {
  // Validate the date string format
  if (!moment(dateStr, 'YYYY-MM-DD', true).isValid()) {
    throw new Error(
      'Invalid date format. Please provide the date in "YYYY-MM-DD" format.'
    )
  }

  // Parse the date and create a UTC moment object at midnight
  const date = moment.utc(dateStr, 'YYYY-MM-DD').startOf('day')

  return date.toDate()
}

export function parseLLMFriendlyDateTime(
  field: Readonly<AxField>,
  dateStr: string,
  required: boolean = false
) {
  try {
    return _parseLLMFriendlyDateTime(dateStr)
  } catch (err) {
    if (field.isOptional && !required) {
      return
    }
    const message = (err as Error).message
    throw new ValidationError({ fields: [field], message, value: dateStr })
  }
}

function _parseLLMFriendlyDateTime(dateTimeStr: string) {
  // Validate the date and time string format
  const dateTimeRegex = /^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}(?::\d{2})?) (.+)$/
  const match = dateTimeStr.match(dateTimeRegex)
  if (!match) {
    throw new Error(
      'Invalid date and time format. Please provide the date and time in "YYYY-MM-DD HH:mm" or "YYYY-MM-DD HH:mm:ss" format, followed by the timezone.'
    )
  }

  const [, dateTime, timeZone] = match

  if (!dateTime || !timeZone) {
    throw new Error(
      'Invalid date and time format. Please provide the date and time in "YYYY-MM-DD HH:mm" or "YYYY-MM-DD HH:mm:ss" format, followed by the timezone.'
    )
  }

  // Try to parse the timezone
  const zone = moment.tz.zone(timeZone)

  // If still not found, throw an error
  if (!zone) {
    throw new Error(
      `Unrecognized time zone ${timeZone}. Please provide a valid time zone name, abbreviation, or offset. For example, "America/New_York", or "EST".`
    )
  }

  // Parse the date and time in the specified time zone
  const date = moment.tz(
    dateTime,
    ['YYYY-MM-DD HH:mm', 'YYYY-MM-DD HH:mm:ss'],
    zone.name
  )

  // Check if the date and time are valid
  if (!date.isValid()) {
    throw new Error(
      'Invalid date and time values. Please ensure all components are correct.'
    )
  }

  // Convert to UTC
  return date.utc().toDate()
}

export const formatDateWithTimezone = (date: Readonly<Date>) => {
  const momentDate = moment(date).utc()
  return momentDate.format(`YYYY-MM-DD HH:mm:ss UTC`)
}



================================================
FILE: src/ax/dsp/eval.ts
================================================
import { stopwords } from './stopwords.js'

/**
 * Filters out tokens based on a set of exclusion tokens.
 *
 * @param tokens The array of tokens to filter.
 * @param exclusions A set containing tokens to exclude.
 * @returns An array of filtered tokens.
 */
function filterTokens(
  tokens: readonly string[],
  exclusions: ReadonlySet<string>
): string[] {
  return tokens.filter((token) => !exclusions.has(token))
}

/**
 * Counts the occurrences of each token in an array of tokens.
 *
 * This function supports the preprocessing step for NLP tasks like text similarity
 * and classification by transforming text into a bag-of-words model, facilitating
 * the comparison of different texts based on their content.
 *
 * @param tokens An array of string tokens.
 * @returns A Counter object mapping each token to its count.
 */
function countTokens(tokens: readonly string[]): Record<string, number> {
  const counter: Record<string, number> = {}
  for (const token of tokens) {
    counter[token] = (counter[token] || 0) + 1
  }
  return counter
}

/**
 * Normalizes text by lowercasing, removing punctuation, and squashing multiple spaces.
 *
 * This normalization is crucial in NLP for reducing the complexity of the text data,
 * minimizing the variance between words that should be considered the same for analysis
 * purposes (e.g., "Dog!" and "dog" are treated as the same word).
 *
 * @param s A string to be normalized.
 * @returns A normalized string.
 */
function normalizeText(s: string): string {
  s = s.normalize('NFD')
  s = s.replace(/\b(a|an|the)\b/g, ' ')
  s = s.split(/\s+/).join(' ')
  s = s.replace(/[!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~]/g, '')
  return s.toLowerCase()
}

/**
 * Calculates the Exact Match (EM) score between a prediction and ground truth.
 *
 * The EM score is a strict metric used in machine learning to assess if the predicted
 * answer matches the ground truth exactly, commonly used in tasks like question answering.
 *
 * @param prediction The predicted text.
 * @param groundTruth The actual correct text.
 * @returns A number (1.0 for exact match, 0.0 otherwise).
 */
function emScore(prediction: string, groundTruth: string): number {
  return normalizeText(prediction) === normalizeText(groundTruth) ? 1.0 : 0.0
}

/**
 * Calculates the F1 score between a prediction and ground truth.
 *
 * The F1 score is a harmonic mean of precision and recall, widely used in NLP to measure
 * a model's accuracy in considering both false positives and false negatives, offering a
 * balance for evaluating classification models.
 *
 * @param prediction The predicted text.
 * @param groundTruth The actual correct text.
 * @returns The F1 score as a number.
 */
function f1Score(prediction: string, groundTruth: string): number {
  const predictionTokens = normalizeText(prediction).split(' ')
  const groundTruthTokens = normalizeText(groundTruth).split(' ')

  // Calculate the intersection of common tokens between prediction and ground truth
  const predictionCounts = countTokens(predictionTokens)
  const groundTruthCounts = countTokens(groundTruthTokens)

  let numSame = 0
  for (const token in predictionCounts) {
    const v1 = predictionCounts[token] ?? 0
    const v2 = groundTruthCounts[token] ?? 0
    numSame += Math.min(v1, v2)
  }
  if (numSame === 0) {
    return 0
  }

  const precision = numSame / predictionTokens.length
  const recall = numSame / groundTruthTokens.length
  return (2 * precision * recall) / (precision + recall)
}

/**
 * Calculates a novel F1 score, taking into account a history of interaction and excluding stopwords.
 *
 * This metric extends the F1 score by considering contextual relevance and filtering out common words
 * that might skew the assessment of the prediction's quality, especially in conversational models or
 * when historical context is relevant.
 *
 * @param history The historical context or preceding interactions.
 * @param prediction The predicted text.
 * @param groundTruth The actual correct text.
 * @param returnRecall Optionally return the recall score instead of F1.
 * @returns The novel F1 or recall score as a number.
 */
function novelF1ScoreOptimized(
  history: string,
  prediction: string,
  groundTruth: string,
  returnRecall: boolean = false
): number {
  // Normalize and split the input texts into tokens
  const historyTokens = normalizeText(history).split(' ')
  let predictionTokens = normalizeText(prediction).split(' ')
  let groundTruthTokens = normalizeText(groundTruth).split(' ')

  // Combine stopwords and history tokens for exclusion
  const exclusions = new Set([...stopwords, ...historyTokens])

  // Filter prediction and ground truth tokens against the exclusions
  predictionTokens = filterTokens(predictionTokens, exclusions)
  groundTruthTokens = filterTokens(groundTruthTokens, exclusions)

  // Proceed with calculating common tokens, precision, recall, and F1 score as previously outlined

  // Placeholder for the calculation logic
  const numSame = 0 // This should be calculated as before
  const precision = numSame / predictionTokens.length
  const recall = numSame / groundTruthTokens.length
  const f1 = (2 * precision * recall) / (precision + recall)

  return returnRecall ? recall : f1
}

export const AxEvalUtil = {
  emScore,
  f1Score,
  novelF1ScoreOptimized,
}



================================================
FILE: src/ax/dsp/evaluate.ts
================================================
import type { AxAIService } from '../ai/types.js'

import type { AxExample, AxMetricFn } from './optimizer.js'
import type { AxProgram } from './program.js'
import type { AxGenIn, AxGenOut } from './types.js'
import { updateProgressBar } from './util.js'

export type AxEvaluateArgs<IN extends AxGenIn, OUT extends AxGenOut> = {
  ai: AxAIService
  program: Readonly<AxProgram<IN, OUT>>
  examples: Readonly<AxExample[]>
}

export class AxTestPrompt<
  IN extends AxGenIn = AxGenIn,
  OUT extends AxGenOut = AxGenOut,
> {
  private ai: AxAIService
  private program: Readonly<AxProgram<IN, OUT>>
  private examples: Readonly<AxExample[]>

  constructor({
    ai,
    program,
    examples = [],
  }: Readonly<AxEvaluateArgs<IN, OUT>>) {
    if (examples.length == 0) {
      throw new Error('No examples found')
    }
    this.ai = ai
    this.program = program
    this.examples = examples
  }

  public async run(metricFn: AxMetricFn) {
    const st = new Date().getTime()
    const total = this.examples.length
    let sumOfScores = 0

    for (let i = 0; i < total; i++) {
      const ex = this.examples[i]
      if (!ex) {
        throw new Error('Invalid example')
      }

      const res = await this.program.forward(this.ai, ex as IN)
      const score = await metricFn({ prediction: res, example: ex })
      sumOfScores += score

      const et = new Date().getTime() - st
      // Assuming updateProgressBar's 3rd argument is a count/value that represents progress.
      // If it specifically needs a 'success count', this might need adjustment.
      // For now, using sumOfScores, but it might represent total score, not #successes.
      // If AxMetricFn is always 0 or 1, sumOfScores is equivalent to successCount.
      updateProgressBar(i, total, sumOfScores, et, 'Testing Prompt', 30)
    }

    const averageScore = total > 0 ? sumOfScores / total : 0
    console.log(
      '\nPerformance: ',
      sumOfScores,
      '/',
      total,
      'Average Score: ',
      averageScore,
      '\n'
    )
  }
}



================================================
FILE: src/ax/dsp/extract.test.ts
================================================
import { describe, expect, test } from 'vitest'

import {
  type extractionState,
  extractValues,
  streamingExtractFinalValue,
  streamingExtractValues,
} from './extract.js'
import { AxSignature } from './sig.js'

// Helper function to create a clean initial state
const createInitialState = (): extractionState => ({
  currField: undefined,
  extractedFields: [],
  streamedIndex: {},
  s: -1,
})

describe('extractValues', () => {
  test('extracts single output field', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer')
    const values: Record<string, unknown> = {}
    const content = 'Model Answer:This is the output content!'

    extractValues(sig, values, content)

    expect(values).toEqual({ modelAnswer: 'This is the output content!' })
  })

  test('extracts multiple output fields', () => {
    const sig = new AxSignature(
      'userQuestion1, userQuestion2 -> modelAnswer1, modelAnswer2'
    )
    const values: Record<string, unknown> = {}
    const content = `Model Answer 1: First output content
Model Answer 2: Second\noutput\ncontent`

    extractValues(sig, values, content)

    expect(values).toEqual({
      modelAnswer1: 'First output content',
      modelAnswer2: 'Second\noutput\ncontent',
    })
  })

  test('preserves existing values', () => {
    const sig = new AxSignature(
      'userQuestion1, userQuestion2 -> modelAnswer1, modelAnswer2'
    )
    const values: Record<string, unknown> = {
      modelAnswer1: 'existing content',
    }
    const content = 'Model Answer 2: New content'

    extractValues(sig, values, content)

    expect(values).toEqual({
      modelAnswer1: 'existing content',
      modelAnswer2: 'New content',
    })
  })

  test('handles multiline output content', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1, modelAnswer2')
    const values: Record<string, unknown> = {}
    const content = `Model Answer 1: This is a multi-line
output content for field 1
Model Answer 2:And this is the
multi-line content for field 2`

    extractValues(sig, values, content)

    expect(values).toEqual({
      modelAnswer1: 'This is a multi-line\noutput content for field 1',
      modelAnswer2: 'And this is the\nmulti-line content for field 2',
    })
  })

  test('handles array output JSON', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1:string[]')
    const values: Record<string, unknown> = {}
    const content = 'Model Answer 1: ["test", "test2"]'

    extractValues(sig, values, content)

    expect(values).toEqual({ modelAnswer1: ['test', 'test2'] })
  })

  test('handles array output markdown', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1:string[]')
    const values: Record<string, unknown> = {}
    const content = `Model Answer 1:
  - test
  - test2`

    extractValues(sig, values, content)

    expect(values).toEqual({ modelAnswer1: ['test', 'test2'] })
  })

  // New test cases
  test('handles nested JSON objects', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1:json')
    const values: Record<string, unknown> = {}
    const content = 'Model Answer 1: {"name": "test", "values": [1, 2, 3]}'

    extractValues(sig, values, content)

    expect(values).toEqual({
      modelAnswer1: {
        name: 'test',
        values: [1, 2, 3],
      },
    })
  })

  test('handles boolean values', () => {
    const sig = new AxSignature(
      'userQuestion -> modelAnswer1:boolean, modelAnswer2:boolean'
    )
    const values: Record<string, unknown> = {}
    const content = `Model Answer 1: true
Model Answer 2: false`

    extractValues(sig, values, content)

    expect(values).toEqual({
      modelAnswer1: true,
      modelAnswer2: false,
    })
  })
})

describe('streamingExtractValues', () => {
  test('handles streaming output fields', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1, modelAnswer2')
    const values: Record<string, unknown> = {}
    const state = createInitialState()

    // First chunk
    let content = 'Model Answer 1: First '
    streamingExtractValues(sig, values, state, content)
    content += 'output content\n'
    streamingExtractValues(sig, values, state, content)
    content += 'Model Answer 2: Second '
    streamingExtractValues(sig, values, state, content)
    content += 'output content'
    streamingExtractFinalValue(sig, values, state, content)

    expect(values).toEqual({
      modelAnswer1: 'First output content',
      modelAnswer2: 'Second output content',
    })
  })

  test('handles partial output label', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1')
    const values: Record<string, unknown> = {}
    const state = createInitialState()

    // Split in middle of "Output" label
    let content = 'Mod'
    streamingExtractValues(sig, values, state, content)
    content += 'el Answer 1: Content here'
    streamingExtractValues(sig, values, state, content)
    streamingExtractFinalValue(sig, values, state, content)

    expect(values).toEqual({
      modelAnswer1: 'Content here',
    })
  })

  test('handles incremental content with multiple fields', () => {
    const sig = new AxSignature(
      'userQuestion -> modelAnswer1, modelAnswer2, modelAnswer3'
    )
    const values: Record<string, unknown> = {}
    const state = createInitialState()

    // Send content in chunks
    const chunks = [
      'Model Answer 1: First',
      ' content here\n',
      'Model Answer 2: Sec',
      'ond content\n',
      'Model Answer 3: Third content',
    ]

    let content = ''

    for (const chunk of chunks) {
      content += chunk
      streamingExtractValues(sig, values, state, content)
    }
    streamingExtractFinalValue(sig, values, state, content)

    expect(values).toEqual({
      modelAnswer1: 'First content here',
      modelAnswer2: 'Second content',
      modelAnswer3: 'Third content',
    })
  })

  // New test case
  test('handles streaming JSON array content', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1:string[]')
    const values: Record<string, unknown> = {}
    const state = createInitialState()

    let content = 'Model Answer 1: ["first"'
    streamingExtractValues(sig, values, state, content)
    content += ', "second", '
    streamingExtractValues(sig, values, state, content)
    content += '"third"]'
    streamingExtractFinalValue(sig, values, state, content)

    expect(values).toEqual({
      modelAnswer1: ['first', 'second', 'third'],
    })
  })
})

describe('error handling', () => {
  test('handles empty and whitespace content', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1?, modelAnswer2?')
    const values: Record<string, unknown> = {}
    const content = `Model Answer 1: 
Model Answer 2:    
Model Answer:`

    extractValues(sig, values, content)

    expect(values).toEqual({
      modelAnswer1: undefined,
      modelAnswer2: 'Model Answer:',
    })
  })

  test('handles malformed content', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1, modelAnswer2')
    const values: Record<string, unknown> = {}
    const malformedContent = 'Some random content without output prefix'

    extractValues(sig, values, malformedContent)

    expect(values).toEqual({})
  })

  // New test cases
  test('throws validation error for invalid markdown list', () => {
    const sig = new AxSignature('userQuestion -> modelAnswer1:string[]')
    const values: Record<string, unknown> = {}
    const content = `Model Answer 1:
    - test
    invalid format
    - test2`

    expect(() => extractValues(sig, values, content)).toThrow(
      'Invalid Array: Could not parse markdown list'
    )
  })

  test('handles missing optional fields', () => {
    const sig = new AxSignature(
      'userQuestion -> modelAnswer1, modelAnswer2?:string'
    )
    const values: Record<string, unknown> = {}
    const content = 'Model Answer 1: Only field one is present'

    extractValues(sig, values, content)

    expect(values).toEqual({
      modelAnswer1: 'Only field one is present',
    })
  })
})



================================================
FILE: src/ax/dsp/extract.ts
================================================
/* eslint-disable @typescript-eslint/naming-convention */

import { parseLLMFriendlyDate, parseLLMFriendlyDateTime } from './datetime.js'
import type { AxField, AxSignature } from './sig.js'
import { matchesContent, parseMarkdownList } from './util.js'
import { ValidationError } from './validate.js'

export const extractValues = (
  sig: Readonly<AxSignature>,
  values: Record<string, unknown>,
  content: string
) => {
  const xstate = { extractedFields: [], streamedIndex: {}, s: -1 }
  streamingExtractValues(sig, values, xstate, content)
  streamingExtractFinalValue(sig, values, xstate, content)

  // Filter out internal fields
  for (const field of sig.getOutputFields()) {
    if (field.isInternal) {
      delete values[field.name]
    }
  }
}

export interface extractionState {
  prevFields?: { field: AxField; s: number; e: number }[]
  currField?: AxField
  currFieldIndex?: number
  extractedFields: AxField[]
  streamedIndex: Record<string, number>
  s: number
  inBlock?: boolean
}

// Helper function to check for missing required fields
const checkMissingRequiredFields = (
  xstate: Readonly<extractionState>,
  values: Record<string, unknown>,
  currentIndex: number
) => {
  const missingFields: AxField[] = []

  // Check all fields up to the current index
  for (let i = 0; i < currentIndex; i++) {
    const field = xstate.extractedFields[i]
    if (field && !field.isOptional && values[field.name] === undefined) {
      missingFields.push(field)
    }
  }

  if (missingFields.length > 0) {
    throw new ValidationError({
      message: `Required ${missingFields.length === 1 ? 'field' : 'fields'} not found`,
      fields: missingFields,
    })
  }
}

export const streamingExtractValues = (
  sig: Readonly<AxSignature>,
  values: Record<string, unknown>,
  // eslint-disable-next-line functional/prefer-immutable-types
  xstate: extractionState,
  content: string,
  streamingValidation: boolean = false
) => {
  const fields = sig.getOutputFields()

  for (const [index, field] of fields.entries()) {
    if (field.name in values) {
      continue
    }

    const isFirst = xstate.extractedFields.length === 0
    const prefix = (isFirst ? '' : '\n') + field.title + ':'
    let e = matchesContent(content, prefix, xstate.s)

    switch (e) {
      case -1:
        if (streamingValidation && values.length == 0 && !field.isOptional) {
          throw new ValidationError({
            message: 'Required field not found',
            fields: [field],
          })
        }
        continue // Field is not found, continue to the next field
      case -2:
        return true // Partial match at end, skip and gather more content
      case -3:
        return true // String is only whitespace, skip and gather more content
      case -4:
        xstate.inBlock = true
        return true // String is only backticks, skip and gather more content
    }
    // We found the next field!!!

    let prefixLen = prefix.length

    // Lets wrap up the last field which is still the current field
    if (xstate.currField) {
      const val = content.substring(xstate.s, e).trim()
      const parsedValue = validateAndParseFieldValue(xstate.currField, val)
      if (parsedValue !== undefined) {
        values[xstate.currField.name] = parsedValue
      }
      if (xstate.prevFields) {
        xstate.prevFields?.push({ field: xstate.currField, s: xstate.s, e })
      } else {
        xstate.prevFields = [{ field: xstate.currField, s: xstate.s, e }]
      }
    }

    checkMissingRequiredFields(xstate, values, index)

    // Lets update the state for the new current field

    xstate.s = e + prefixLen
    xstate.currField = field
    xstate.currFieldIndex = index

    if (!xstate.extractedFields.includes(field)) {
      xstate.extractedFields.push(field)
    }

    if (xstate.streamedIndex[field.name] === undefined) {
      xstate.streamedIndex[field.name] = 0
    }
  }
}

export const streamingExtractFinalValue = (
  sig: Readonly<AxSignature>,
  values: Record<string, unknown>,
  // eslint-disable-next-line functional/prefer-immutable-types
  xstate: extractionState,
  content: string
) => {
  if (xstate.currField) {
    let val = content.substring(xstate.s).trim()

    const parsedValue = validateAndParseFieldValue(xstate.currField, val)
    if (parsedValue !== undefined) {
      values[xstate.currField.name] = parsedValue
    }
  }
  const sigFields = sig.getOutputFields()

  // Check all previous required fields before processing current field
  checkMissingRequiredFields(xstate, values, sigFields.length)
}

const convertValueToType = (
  field: Readonly<AxField>,
  val: string,
  required: boolean = false
) => {
  switch (field.type?.name) {
    case 'code':
      return extractBlock(val)

    case 'string':
      return val

    case 'number': {
      const v = Number(val)
      if (Number.isNaN(v)) {
        if (field.isOptional && !required) {
          return
        }
        throw new Error('Invalid number')
      }
      return v
    }

    case 'boolean': {
      if (typeof val === 'boolean') {
        return val
      }
      const v = val.toLowerCase()
      if (v === 'true') {
        return true
      } else if (v === 'false') {
        return false
      } else {
        if (field.isOptional && !required) {
          return
        }
        throw new Error('Invalid boolean')
      }
    }
    case 'date':
      return parseLLMFriendlyDate(field, val, required)

    case 'datetime':
      return parseLLMFriendlyDateTime(field, val, required)

    case 'class':
      const className = val
      if (field.type.options && !field.type.options.includes(className)) {
        if (field.isOptional) {
          return
        }
        throw new Error(
          `Invalid class '${val}', expected one of the following: ${field.type.options.join(', ')}`
        )
      }
      return className as string

    default:
      return val as string // Unknown type
  }
}

export function* yieldDelta<OUT>(
  content: string,
  field: Readonly<AxField>,
  s: number,
  e: number,
  // eslint-disable-next-line functional/prefer-immutable-types
  xstate: extractionState
) {
  const { name: fieldName, isInternal } = field
  const { isArray: fieldIsArray, name: fieldTypeName } = field.type ?? {}

  if (
    isInternal ||
    fieldIsArray ||
    (fieldTypeName && fieldTypeName !== 'string' && fieldTypeName !== 'code')
  ) {
    return
  }

  const pos = xstate.streamedIndex[fieldName] ?? 0
  const isFirstChunk = pos === 0

  const d1 = content.substring(s + pos, e)
  if (d1.length === 0) {
    return
  }

  // Remove trailing whitespace, tabs, and newlines
  let d2 = d1.replace(/\s+$/, '')

  // If this field is a "code" type, remove trailing backticks
  if (xstate.currField?.type?.name === 'code') {
    d2 = d2.replace(/\s*```\s*$/, '')
  }

  // Only trim start for the first chunk
  let d3 = isFirstChunk ? d2.trimStart() : d2

  if (xstate.currField?.type?.name === 'code') {
    // Remove any leading triple-backtick fences (with optional language specifier)
    d3 = d3.replace(/^[ ]*```[a-zA-Z0-9]*\n\s*/, '')
  }

  if (d3.length > 0) {
    yield { [fieldName]: d3 } as Partial<OUT>
    xstate.streamedIndex[fieldName] = pos + d2.length
  }
}

// export function getStreamingDelta(
//   values: Record<string, unknown>,
//   // eslint-disable-next-line functional/prefer-immutable-types
//   xstate: extractionState
// ) {
//   return processStreamingDelta(values, xstate)
// }

export function* streamValues<OUT>(
  sig: Readonly<AxSignature>,
  content: string,
  values: Readonly<Record<string, OUT>>,
  // eslint-disable-next-line functional/prefer-immutable-types
  xstate: extractionState
) {
  for (const prevField of xstate.prevFields ?? []) {
    const { field, s, e } = prevField
    yield* yieldDelta<OUT>(content, field, s, e, xstate)
  }
  xstate.prevFields = undefined

  if (!xstate.currField || xstate.currField.isInternal) {
    return
  }

  yield* yieldDelta<OUT>(
    content,
    xstate.currField,
    xstate.s,
    content.length,
    xstate
  )

  const outputFields = sig.getOutputFields()

  for (const key of Object.keys(values)) {
    const field = outputFields.find((f) => f.name === key)
    if (!field || field.isInternal) {
      continue
    }

    const value = values[key]

    if (Array.isArray(value)) {
      const s = xstate.streamedIndex?.[key] ?? 0
      const v = value.slice(s)
      if (v && v.length > 0) {
        yield { [key]: v } as Partial<OUT>
        xstate.streamedIndex[key] = s + v.length
      }
      continue
    }

    if (!xstate.streamedIndex[key]) {
      yield { [key]: value } as Partial<OUT>
      xstate.streamedIndex[key] = 1
    }
  }
}

function validateAndParseFieldValue(
  field: Readonly<AxField>,
  fieldValue: string | undefined
): unknown {
  if (
    !fieldValue ||
    fieldValue === '' ||
    /^(null|undefined)\s*$/i.test(fieldValue)
  ) {
    if (field.isOptional) {
      return
    }
    throw new ValidationError({
      message: 'Required field is missing',
      fields: [field],
      value: fieldValue,
    })
  }

  let value: unknown | undefined

  if (field.type?.name === 'json') {
    try {
      const text = extractBlock(fieldValue)
      value = JSON.parse(text)
      return value
    } catch (e) {
      throw new ValidationError({
        message: 'Invalid JSON: ' + (e as Error).message,
        fields: [field],
        value: fieldValue,
      })
    }
  }

  if (field.type?.isArray) {
    try {
      try {
        value = JSON.parse(fieldValue)
      } catch {
        // If JSON parsing fails, try markdown parsing
        value = parseMarkdownList(fieldValue)
      }
      if (!Array.isArray(value)) {
        throw new Error('Expected an array')
      }
    } catch (e) {
      throw new ValidationError({
        message: 'Invalid Array: ' + (e as Error).message,
        fields: [field],
        value: fieldValue,
      })
    }
  }

  try {
    if (Array.isArray(value)) {
      for (const [index, item] of value.entries()) {
        if (item !== undefined) {
          const v = typeof item === 'string' ? item.trim() : item
          value[index] = convertValueToType(field, v, true)
        }
      }
    } else {
      value = convertValueToType(field, fieldValue)
    }
  } catch (e) {
    throw new ValidationError({
      message: (e as Error).message,
      fields: [field],
      value: fieldValue,
    })
  }

  if (typeof value === 'string' && value === '') {
    return undefined
  }

  return value
}

export const extractBlock = (input: string): string => {
  const markdownBlockPattern = /```([A-Za-z]*)\n([\s\S]*?)\n```/g
  const match = markdownBlockPattern.exec(input)
  if (!match) {
    return input
  }
  if (match.length === 3) {
    return match[2] as string
  }
  if (match.length === 2) {
    return match[1] as string
  }
  return input
}



================================================
FILE: src/ax/dsp/fieldProcessor.test.ts
================================================
import { describe, expect, it } from 'vitest'

import { AxMemory } from '../mem/memory.js'

import {
  processFieldProcessors,
  processStreamingFieldProcessors,
} from './fieldProcessor.js'
import type { AxFieldValue, AxGenOut } from './types.js'

describe('Field Processor Functions', () => {
  it('processFieldProcessors should execute the processor and update memory', async () => {
    // Dummy synchronous processor: converts the value to uppercase.
    const dummyProcessor = {
      field: {
        name: 'testField',
        title: 'testField',
        type: { name: 'string' as const, isArray: false },
      },
      process: async (value: AxFieldValue) => {
        if (typeof value === 'string') {
          return value.toUpperCase()
        }
        return value
      },
    }

    const values: AxGenOut = { testField: 'hello world' }
    const mem = new AxMemory()
    const sessionId = 'session-sync'

    await processFieldProcessors([dummyProcessor], values, mem, sessionId)

    // The processor no longer updates the 'values' object directly.
    // Instead, we check that memory has been updated.
    const history = mem.history(sessionId)
    expect(history.length).toBe(1)

    // The message text is generated by addToMemory and will include the processed string.
    // We use toContain() to check that "HELLO WORLD" appears.
    const { chat, tags } = mem.getLast(sessionId) as {
      chat: { role: string; content: { type: string; text: string }[] }
      tags?: string[]
    }
    expect(tags).toContain('processor')
    expect(chat?.role).toBe('user')
    expect(chat?.content[0]?.text).toContain('HELLO WORLD')
  })

  it('processStreamingFieldProcessors should execute the processor and update memory without yielding any values', async () => {
    // Dummy streaming processor: appends a suffix.
    const dummyStreamingProcessor = {
      field: {
        name: 'streamField',
        title: 'streamField',
        type: { name: 'string' as const, isArray: false },
      },
      process: async (value: unknown) => {
        if (typeof value === 'string') {
          return value + ' updated'
        }
        return value
      },
    }

    const values: AxGenOut = { streamField: 'original' }
    const mem = new AxMemory()
    const sessionId = 'session-stream'
    // Create an extraction state with the current field set and start index 0.
    const xstate = {
      currField: dummyStreamingProcessor.field,
      s: 0,
      extractedFields: [],
      streamedIndex: {},
    }

    // Provide an initial content string.
    await processStreamingFieldProcessors(
      [dummyStreamingProcessor],
      'original',
      xstate,
      mem,
      values,
      sessionId,
      false
    )

    // Check that an assistant message is added into the session's history.
    const history = mem.history(sessionId)
    expect(history.length).toBe(1)

    const { chat, tags } = mem.getLast(sessionId) as {
      chat: { role: string; content: { type: string; text: string }[] }
      tags?: string[]
    }
    expect(tags).toContain('processor')
    expect(chat.role).toBe('user')
    expect(chat.content?.[0]?.text).toContain('original updated')
  })
})



================================================
FILE: src/ax/dsp/fieldProcessor.ts
================================================
import type { AxAIMemory } from '../mem/types.js'

import type { extractionState } from './extract.js'
import type { AxField } from './sig.js'
import type { AxFieldValue, AxGenOut } from './types.js'

export type AxFieldProcessorProcess = (
  value: AxFieldValue,
  context?: Readonly<{
    values?: AxGenOut
    sessionId?: string
    done?: boolean
  }>
) => unknown | Promise<unknown>

export type AxStreamingFieldProcessorProcess = (
  value: string,
  context?: Readonly<{
    values?: AxGenOut
    sessionId?: string
    done?: boolean
  }>
) => unknown | Promise<unknown>
export interface AxFieldProcessor {
  field: Readonly<AxField>

  /**
   * Process the field value and return a new value (or undefined if no update is needed).
   * The returned value may be merged back into memory.
   * @param value - The current field value.
   * @param context - Additional context (e.g. memory and session id).
   */
  process: AxFieldProcessorProcess | AxStreamingFieldProcessorProcess
}

/**
 * For synchronous responses: iterates over registered field processors,
 * passing in the current values. If a processor returns a new value,
 * that value is merged into memory with a special role ('processor').
 */
export async function processFieldProcessors(
  fieldProcessors: AxFieldProcessor[],
  values: AxGenOut,
  mem: AxAIMemory,
  sessionId?: string
) {
  for (const processor of fieldProcessors) {
    if (values[processor.field.name] === undefined) {
      continue
    }

    const processFn = processor.process as AxFieldProcessorProcess
    const result = await processFn(values[processor.field.name], {
      sessionId,
      values,
      done: true,
    })
    addToMemory(processor.field, mem, result, sessionId)
  }
}

/**
 * For streaming responses: processes each streaming field processor
 * and yields delta updates if they return new values.
 */
export async function processStreamingFieldProcessors(
  fieldProcessors: AxFieldProcessor[],
  content: string,
  xstate: Readonly<extractionState>,
  mem: AxAIMemory,
  values: AxGenOut,
  sessionId: string | undefined,
  done: boolean = false
): Promise<void> {
  for (const processor of fieldProcessors) {
    if (xstate.currField?.name !== processor.field.name) {
      continue
    }

    let value = content.substring(xstate.s)

    if (xstate.currField?.type?.name === 'code') {
      // remove markdown block
      value = value.replace(/^[ ]*```[a-zA-Z0-9]*\n\s*/, '')
      value = value.replace(/\s*```\s*$/, '')
    }
    const processFn = processor.process as AxStreamingFieldProcessorProcess
    const result = await processFn(value, {
      sessionId,
      values,
      done,
    })

    addToMemory(xstate.currField, mem, result, sessionId)
  }
}

const addToMemory = (
  field: Readonly<AxField>,
  mem: AxAIMemory,
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  result: any | any[],
  sessionId?: string
) => {
  if (
    result === undefined ||
    (typeof result === 'string' &&
      (result === '' || /^(null|undefined)\s*$/i.test(result)))
  ) {
    return
  }

  let resultText = JSON.stringify(
    result,
    (key, value) => (typeof value === 'bigint' ? Number(value) : value),
    2
  )

  const text = getFieldProcessingMessage(field, resultText)
  mem.add({ role: 'user', content: [{ type: 'text', text }] }, sessionId)
  mem.addTag(`processor`, sessionId)
}

function getFieldProcessingMessage(
  field: Readonly<AxField>,
  resultText: string
) {
  const isCodeField = field.type?.name === 'code'
  const fieldTitle = field.title

  if (isCodeField) {
    return `Code in the field "${fieldTitle}" was executed. The code execution produced the following output: ${resultText}`
  } else {
    return `The field "${fieldTitle}" was processed. The field contents were transformed into the following output: ${resultText}`
  }
}



================================================
FILE: src/ax/dsp/functions.ts
================================================
import type {
  AxAIService,
  AxAIServiceActionOptions,
  AxChatRequest,
  AxChatResponseResult,
  AxFunction,
} from '../ai/types.js'
import type { AxMemory } from '../mem/memory.js'

import { validateJSONSchema } from './jsonschema.js'

export class AxFunctionError extends Error {
  constructor(
    private fields: {
      field: string
      message: string
    }[]
  ) {
    super()
    this.name = this.constructor.name
  }

  getFields = () => this.fields

  override toString(): string {
    return [
      `${this.name}: Function validation error`,
      ...this.fields.map((field) => `  - ${field.field}: ${field.message}`),
    ].join('\n')
  }

  [Symbol.for('nodejs.util.inspect.custom')](
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _depth: number,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options: Record<string, unknown>
  ) {
    return this.toString()
  }
}

type FunctionFieldErrors = ConstructorParameters<typeof AxFunctionError>[0]

export class FunctionError extends Error {
  constructor(
    private readonly fields: FunctionFieldErrors,
    private readonly func: Readonly<AxFunction>,
    private readonly funcId?: string
  ) {
    super()
  }

  getFunctionId = () => this.funcId

  private getFieldDescription(fieldName: string): string {
    if (!this.func.parameters?.properties?.[fieldName]) {
      return ''
    }

    const fieldSchema = this.func.parameters.properties[fieldName]
    let description = fieldSchema.description

    if (fieldSchema.enum?.length) {
      description += ` Allowed values are: ${fieldSchema.enum.join(', ')}`
    }

    return description
  }

  public getFixingInstructions = () => {
    const bulletPoints = this.fields.map((fieldError) => {
      const schemaDescription = this.getFieldDescription(fieldError.field) || ''
      return `- \`${fieldError.field}\` - ${fieldError.message} (${schemaDescription}).`
    })

    return `Errors In Function Arguments: Fix the following invalid arguments to '${this.func.name}'\n${bulletPoints.join('\n')}`
  }

  override toString(): string {
    return [
      `${this.name}: Function execution error in '${this.func.name}'`,
      ...this.fields.map((field) => {
        const description = this.getFieldDescription(field.field)
        return `  - ${field.field}: ${field.message}${description ? ` (${description})` : ''}`
      }),
      this.funcId ? `  Function ID: ${this.funcId}` : '',
    ].join('\n')
  }

  [Symbol.for('nodejs.util.inspect.custom')](
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _depth: number,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options: Record<string, unknown>
  ) {
    return this.toString()
  }
}

export type AxChatResponseFunctionCall = {
  id: string
  name: string
  args: string
}

export class AxFunctionProcessor {
  private funcList: Readonly<AxFunction[]> = []

  constructor(funcList: Readonly<AxFunction[]>) {
    this.funcList = funcList
  }

  private executeFunction = async (
    fnSpec: Readonly<AxFunction>,
    func: Readonly<AxChatResponseFunctionCall>,
    options?: Readonly<AxAIServiceActionOptions>
  ) => {
    let args: unknown

    if (typeof func.args === 'string' && func.args.length > 0) {
      args = JSON.parse(func.args)
    } else {
      args = func.args
    }

    const opt = options
      ? {
          sessionId: options.sessionId,
          traceId: options.traceId,
          ai: options.ai,
        }
      : undefined

    if (!fnSpec.parameters) {
      const res =
        fnSpec.func.length === 1 ? await fnSpec.func(opt) : await fnSpec.func()

      return typeof res === 'string' ? res : JSON.stringify(res, null, 2)
    }

    const res =
      fnSpec.func.length === 2
        ? await fnSpec.func(args, opt)
        : await fnSpec.func(args)

    return typeof res === 'string' ? res : JSON.stringify(res, null, 2)
  }

  public execute = async (
    func: Readonly<AxChatResponseFunctionCall>,
    options?: Readonly<AxAIServiceActionOptions>
  ) => {
    const fnSpec = this.funcList.find(
      (v) => v.name.localeCompare(func.name) === 0
    )
    if (!fnSpec) {
      throw new Error(`Function not found: ${func.name}`)
    }
    if (!fnSpec.func) {
      throw new Error(`No handler for function: ${func.name}`)
    }

    // execute value function calls
    try {
      return await this.executeFunction(fnSpec, func, options)
    } catch (e) {
      if (e instanceof AxFunctionError) {
        throw new FunctionError(e.getFields(), fnSpec, func.id)
      }
      throw e
    }
  }
}

export type AxInputFunctionType = (
  | AxFunction
  | {
      toFunction: () => AxFunction | AxFunction[]
    }
)[]

export const parseFunctions = (
  newFuncs: Readonly<AxInputFunctionType>,
  existingFuncs?: readonly AxFunction[]
): AxFunction[] => {
  if (newFuncs.length === 0) {
    return [...(existingFuncs ?? [])]
  }

  // biome-ignore lint/complexity/useFlatMap: cannot use flatMap here
  const functions = newFuncs
    .map((f) => {
      if ('toFunction' in f) {
        return f.toFunction()
      }
      return f
    })
    .flat()

  for (const fn of functions.filter((v) => v.parameters)) {
    if (fn.parameters) {
      validateJSONSchema(fn.parameters)
    }
  }

  return [...(existingFuncs ?? []), ...functions]
}

type FunctionPromise =
  | undefined
  | Promise<Extract<AxChatRequest['chatPrompt'][number], { role: 'function' }>>

export const processFunctions = async (
  ai: Readonly<AxAIService>,
  functionList: Readonly<AxFunction[]>,
  functionCalls: readonly AxChatResponseFunctionCall[],
  mem: Readonly<AxMemory>,
  sessionId?: string,
  traceId?: string,
  span?: import('@opentelemetry/api').Span,
  excludeContentFromTelemetry?: boolean
) => {
  const funcProc = new AxFunctionProcessor(functionList)
  const functionsExecuted = new Set<string>()

  // Map each function call to a promise that resolves to the function result or null
  const promises = functionCalls.map((func) => {
    if (!func.id) {
      throw new Error(`Function ${func.name} did not return an ID`)
    }

    const promise: FunctionPromise = funcProc
      .execute(func, { sessionId, traceId, ai })
      .then((functionResult) => {
        functionsExecuted.add(func.name.toLowerCase())

        // Add telemetry event for successful function call
        if (span) {
          const eventData: { name: string; args?: string; result?: string } = {
            name: func.name,
          }
          if (!excludeContentFromTelemetry) {
            eventData.args = func.args
            eventData.result = functionResult ?? ''
          }
          span.addEvent('function.call', eventData)
        }

        return {
          role: 'function' as const,
          result: functionResult ?? '',
          functionId: func.id,
        }
      })
      .catch((e) => {
        if (e instanceof FunctionError) {
          const result = e.getFixingInstructions()

          // Add telemetry event for function error
          if (span) {
            const errorEventData: {
              name: string
              args?: string
              message: string
              fixing_instructions?: string
            } = {
              name: func.name,
              message: e.toString(),
            }
            if (!excludeContentFromTelemetry) {
              errorEventData.args = func.args
              errorEventData.fixing_instructions = result
            }
            span.addEvent('function.error', errorEventData)
          }

          mem.add(
            {
              role: 'function' as const,
              functionId: func.id,
              isError: true,
              result,
            },
            sessionId
          )
          mem.addTag('error')

          if (ai.getOptions().debug) {
            const logger = ai.getLogger()
            logger(`❌ Function Error Correction:\n${result}`, {
              tags: ['error'],
            })
          }
        } else {
          throw e
        }
      }) as FunctionPromise

    return promise
  })

  // Wait for all promises to resolve
  const results = await Promise.all(promises)

  for (const result of results) {
    if (result) {
      mem.add(result, sessionId)
    }
  }

  return functionsExecuted
}

export function parseFunctionCalls(
  ai: Readonly<AxAIService>,
  functionCalls: Readonly<AxChatResponseResult['functionCalls']>,
  values: Record<string, unknown>,
  model?: string
): AxChatResponseFunctionCall[] | undefined {
  if (!functionCalls || functionCalls.length === 0) {
    return
  }
  if (!ai.getFeatures(model).functions) {
    throw new Error('Functions are not supported by the AI service')
  }

  const funcs: AxChatResponseFunctionCall[] = functionCalls.map((f) => ({
    id: f.id,
    name: f.function.name,
    args: f.function.params as string,
  }))

  // for (const [i, f] of funcs.entries()) {
  //   values['functionName' + i] = f.name;
  //   values['functionArguments' + i] =
  //     typeof f.args === 'object' ? JSON.stringify(f.args) : f.args;
  // }
  return funcs
}



================================================
FILE: src/ax/dsp/generate.test.ts
================================================
import { ReadableStream } from 'stream/web'

import { describe, expect, it } from 'vitest'

import { validateAxMessageArray } from '../ai/base.js'
import { AxMockAIService } from '../ai/mock/api.js'
import type { AxChatResponse } from '../ai/types.js'

import { AxGen } from './generate.js'
import type { AxProgramForwardOptions } from './program.js'
import { AxSignature } from './sig.js'

function createStreamingResponse(
  chunks: AxChatResponse['results']
): ReadableStream<AxChatResponse> {
  return new ReadableStream<AxChatResponse>({
    start(controller) {
      let count = 0

      const processChunks = async () => {
        if (count >= chunks.length || controller.desiredSize === null) {
          // Check if controller is already closed
          if (controller.desiredSize !== null) {
            controller.close()
          }
          return
        }

        const chunk = chunks[count]
        if (!chunk) {
          return
        }

        const response: AxChatResponse = {
          results: [chunk],
          modelUsage: {
            ai: 'test-ai',
            model: 'test-model',
            tokens: {
              promptTokens: 10 + count,
              completionTokens: 5 + count,
              totalTokens: 15 + 2 * count,
            },
          },
        }

        if (!controller.desiredSize || controller.desiredSize <= 0) {
          return
        }

        controller.enqueue(response)
        count++

        // Schedule next chunk
        if (count < chunks.length) {
          setTimeout(processChunks, 10)
        } else {
          // Check if controller is still open before closing
          if (controller.desiredSize !== null) {
            controller.close()
          }
        }
      }

      // Start processing
      setTimeout(processChunks, 10)
    },
    cancel() {},
  })
}

describe('AxGen forward and streamingForward', () => {
  const signature = 'userQuestion:string -> modelAnswer:string'

  it('should return non-streaming output from forward when stream option is false', async () => {
    // Prepare a non-streaming (plain) response.
    const nonStreamingResponse: AxChatResponse = {
      results: [
        { content: 'Model Answer: Non-stream response', finishReason: 'stop' },
      ],
      modelUsage: {
        ai: 'test-ai',
        model: 'test-model',
        tokens: {
          promptTokens: 0,
          completionTokens: 0,
          totalTokens: 0,
        },
      },
    }
    const ai = new AxMockAIService({
      features: { functions: false, streaming: false },
      chatResponse: nonStreamingResponse,
    })

    const gen = new AxGen<{ userQuestion: string }, { modelAnswer: string }>(
      signature
    )
    // Call forward with stream disabled.
    const response = await gen.forward(
      ai,
      { userQuestion: 'test' },
      { stream: false }
    )
    expect(response).toEqual({ modelAnswer: 'Non-stream response' })
  })

  it('should return aggregated output from forward when stream option is true', async () => {
    // Prepare a streaming response that enqueues three chunks with a timer.
    const chunks: AxChatResponse['results'] = [
      { content: 'Model Answer: chunk 1 ' },
      { content: 'chunk 2 ' },
      { content: 'chunk 3', finishReason: 'stop' },
    ]
    const streamingResponse = createStreamingResponse(chunks)
    const ai = new AxMockAIService({
      features: { functions: false, streaming: true },
      // Provide chatResponse as a function that accepts request params and returns the stream
      chatResponse: streamingResponse,
    })

    const gen = new AxGen<{ userQuestion: string }, { modelAnswer: string }>(
      signature
    )
    // Call forward with stream enabled.
    // Even though the underlying AI service streams, forward() aggregates
    // the chunks and returns an object.
    const response = await gen.forward(
      ai,
      { userQuestion: 'test' },
      { stream: true }
    )
    expect(response).toBeDefined()
    expect(response.modelAnswer).toContain('chunk 1')
    expect(response.modelAnswer).toContain('chunk 2')
    expect(response.modelAnswer).toContain('chunk 3')
  })
})

describe('AxProgramForwardOptions types', () => {
  it('should allow "disable" as a value for thinkingTokenBudget', () => {
    const options: AxProgramForwardOptions = {
      ai: new AxMockAIService({
        features: { functions: false, streaming: false },
      }), // Mock AI service
      thinkingTokenBudget: 'none',
    }
    // If this compiles, the type test passes implicitly.
    // We can add a simple assertion to make the test explicit.
    expect(options.thinkingTokenBudget).toBe('none')
  })

  it('should allow other valid values for thinkingTokenBudget', () => {
    const options: AxProgramForwardOptions = {
      ai: new AxMockAIService({
        features: { functions: false, streaming: false },
      }), // Mock AI service
      thinkingTokenBudget: 'minimal',
    }
    expect(options.thinkingTokenBudget).toBe('minimal')
  })

  it('should allow showThoughts option', () => {
    const options: AxProgramForwardOptions = {
      ai: new AxMockAIService({
        features: { functions: false, streaming: false },
      }), // Mock AI service
      showThoughts: true,
    }
    expect(options.showThoughts).toBe(true)
  })

  it('should ensure showThoughts is false when thinkingTokenBudget is none', () => {
    const options: AxProgramForwardOptions = {
      ai: new AxMockAIService({
        features: { functions: false, streaming: false },
      }),
      thinkingTokenBudget: 'none',
      showThoughts: true, // This should be overridden
    }
    expect(options.thinkingTokenBudget).toBe('none')
    expect(options.showThoughts).toBe(true) // This validates the type allows both options
  })
})

describe('AxGen thoughtFieldName', () => {
  const signature = 'userQuestion:string -> modelAnswer:string'

  it('should return thought with custom field name when thoughtFieldName is provided', async () => {
    // Mock AI service to return a response with a thought
    const ai = new AxMockAIService({
      features: { functions: false, streaming: false },
      chatResponse: {
        results: [
          {
            thought: 'This is a custom thought.',
            content: 'Model Answer: Test output',
            finishReason: 'stop',
          },
        ],
        modelUsage: {
          ai: 'test-ai',
          model: 'test-model',
          tokens: { promptTokens: 0, completionTokens: 0, totalTokens: 0 },
        },
      },
    })

    const gen = new AxGen<
      { userQuestion: string },
      { modelAnswer: string; customThought?: string }
    >(signature, { thoughtFieldName: 'customThought' })
    const response = await gen.forward(ai, { userQuestion: 'test' })
    expect(response).toEqual({
      modelAnswer: 'Test output',
      customThought: 'This is a custom thought.',
    })
  })

  it('should return thought with default field name "thought" when thoughtFieldName is not provided', async () => {
    // Mock AI service
    const ai = new AxMockAIService({
      features: { functions: false, streaming: false },
      chatResponse: {
        results: [
          {
            thought: 'This is a default thought.',
            content: 'Model Answer: Test output',
            finishReason: 'stop',
          },
        ],
        modelUsage: {
          ai: 'test-ai',
          model: 'test-model',
          tokens: { promptTokens: 0, completionTokens: 0, totalTokens: 0 },
        },
      },
    })

    const gen = new AxGen<
      { userQuestion: string },
      { modelAnswer: string; thought?: string }
    >(signature)
    const response = await gen.forward(ai, { userQuestion: 'test' })
    expect(response).toEqual({
      modelAnswer: 'Test output',
      thought: 'This is a default thought.',
    })
  })

  it('should stream thought with custom field name when thoughtFieldName is provided', async () => {
    const chunks: AxChatResponse['results'] = [
      { thought: 'Thinking...' },
      { content: 'Model Answer: chunk 1 ' },
      { thought: 'Still thinking...' },
      { content: 'chunk 2 ' },
      { content: 'chunk 3', finishReason: 'stop' },
    ]
    const streamingResponse = createStreamingResponse(chunks)
    const ai = new AxMockAIService({
      features: { functions: false, streaming: true },
      chatResponse: streamingResponse,
    })

    const gen = new AxGen<
      { userQuestion: string },
      { modelAnswer: string; customThought?: string }
    >(signature, { thoughtFieldName: 'customThought' })
    const stream = await gen.streamingForward(ai, { userQuestion: 'test' })

    const finalResponse: { modelAnswer?: string; customThought?: string } = {}
    for await (const result of stream) {
      if (result.delta.modelAnswer) {
        finalResponse.modelAnswer =
          (finalResponse.modelAnswer ?? '') + result.delta.modelAnswer
      }
      if (result.delta.customThought) {
        finalResponse.customThought =
          (finalResponse.customThought ?? '') + result.delta.customThought
      }
    }

    expect(finalResponse).toBeDefined()
    expect(finalResponse.modelAnswer).toEqual('chunk 1 chunk 2 chunk 3')
    expect(finalResponse.customThought).toEqual('Thinking...Still thinking...')
  })

  it('should stream thought with default field name "thought" when thoughtFieldName is not provided', async () => {
    const chunks: AxChatResponse['results'] = [
      { thought: 'Thinking...' },
      { content: 'Model Answer: chunk 1 ' },
      { thought: 'Still thinking...' },
      { content: 'chunk 2 ' },
      { content: 'chunk 3', finishReason: 'stop' },
    ]
    const streamingResponse = createStreamingResponse(chunks)
    const ai = new AxMockAIService({
      features: { functions: false, streaming: true },
      chatResponse: streamingResponse,
    })

    const gen = new AxGen<
      { userQuestion: string },
      { modelAnswer: string; thought?: string }
    >(signature)
    const stream = await gen.streamingForward(ai, { userQuestion: 'test' })

    const finalResponse: { modelAnswer?: string; thought?: string } = {}
    for await (const result of stream) {
      if (result.delta.modelAnswer) {
        finalResponse.modelAnswer =
          (finalResponse.modelAnswer ?? '') + result.delta.modelAnswer
      }
      if (result.delta.thought) {
        finalResponse.thought =
          (finalResponse.thought ?? '') + result.delta.thought
      }
    }

    expect(finalResponse).toBeDefined()
    expect(finalResponse.modelAnswer).toEqual('chunk 1 chunk 2 chunk 3')
    expect(finalResponse.thought).toEqual('Thinking...Still thinking...')
  })
})

describe('AxGen forward and streamingForward with multiple outputs', () => {
  const signature =
    'userQuestion:string -> modelAnswer:string, anotherAnswer:string'

  it('should return non-streaming output for a signature with two outputs when stream option is false', async () => {
    const nonStreamingResponse: AxChatResponse = {
      results: [
        {
          content: 'Model Answer: response1\nAnother Answer: response2',
          finishReason: 'stop',
        },
      ],
      modelUsage: {
        ai: 'test-ai',
        model: 'test-model',
        tokens: {
          promptTokens: 0,
          completionTokens: 0,
          totalTokens: 0,
        },
      },
    }
    const ai = new AxMockAIService({
      features: { functions: false, streaming: false },
      chatResponse: nonStreamingResponse,
    })

    const gen = new AxGen<
      { userQuestion: string },
      { modelAnswer: string; anotherAnswer: string }
    >(signature)
    const response = await gen.forward(
      ai,
      { userQuestion: 'test' },
      { stream: false }
    )
    expect(response).toEqual({
      modelAnswer: 'response1',
      anotherAnswer: 'response2',
    })
  })

  it('should return aggregated output from forward for a signature with three outputs when stream option is true', async () => {
    const signatureWithThreeOutputs =
      'userQuestion:string -> modelAnswer:string, anotherAnswer:string, thirdAnswer:string'
    const chunks: AxChatResponse['results'] = [
      { content: 'Model Answer: resp1\n' },
      { content: 'Another Answer: resp2\n' },
      { content: 'Third Answer: resp3', finishReason: 'stop' },
    ]
    const streamingResponse = createStreamingResponse(chunks)
    const ai = new AxMockAIService({
      features: { functions: false, streaming: true },
      chatResponse: streamingResponse,
    })
    const gen = new AxGen<
      { userQuestion: string },
      { modelAnswer: string; anotherAnswer: string; thirdAnswer: string }
    >(signatureWithThreeOutputs)
    const response = await gen.forward(
      ai,
      { userQuestion: 'test' },
      { stream: true }
    )
    expect(response).toEqual({
      modelAnswer: 'resp1',
      anotherAnswer: 'resp2',
      thirdAnswer: 'resp3',
    })
  })

  it('should yield streaming multi-output fields from streamingForward for a signature with two outputs', async () => {
    const signatureWithTwoOutputs =
      'userQuestion:string -> modelAnswer:string, anotherAnswer:string'
    const chunks: AxChatResponse['results'] = [
      { content: 'Model Answer: resp1\n' },
      { content: 'Another Answer: resp2', finishReason: 'stop' },
    ]
    const streamingResponse = createStreamingResponse(chunks)
    const ai = new AxMockAIService({
      features: { functions: false, streaming: true },
      chatResponse: streamingResponse,
    })

    const gen = new AxGen<
      { userQuestion: string },
      { modelAnswer: string; anotherAnswer: string }
    >(signatureWithTwoOutputs)
    const stream = await gen.streamingForward(ai, { userQuestion: 'test' })

    const expectedOutputs = [
      { version: 0, delta: { modelAnswer: 'resp1' } },
      { version: 0, delta: { anotherAnswer: 'resp2' } },
    ]

    let outputIndex = 0
    for await (const result of stream) {
      expect(result).toEqual(expectedOutputs[outputIndex])
      outputIndex++
    }
    expect(outputIndex).toBe(expectedOutputs.length)
  })
})

it('should yield streaming multi-output fields from streamingForward for a signature with five outputs', async () => {
  const signatureWithFiveOutputs =
    'userQuestion:string -> answerA:string, answerB:string, answerC:string, answerD:string, answerE:string'

  const chunks: AxChatResponse['results'] = [
    { content: 'Answer A: r1\n' },
    { content: 'Answer B: r2\n' },
    { content: 'Answer C: r3\n' },
    { content: 'Answer D: r4\n' },
    { content: 'Answer E: r5', finishReason: 'stop' },
  ]
  const streamingResponse = createStreamingResponse(chunks)
  const ai = new AxMockAIService({
    features: { functions: false, streaming: true },
    chatResponse: streamingResponse,
  })

  const gen = new AxGen<
    { userQuestion: string },
    {
      answerA: string
      answerB: string
      answerC: string
      answerD: string
      answerE: string
    }
  >(signatureWithFiveOutputs)
  const stream = await gen.streamingForward(ai, { userQuestion: 'test' })

  const expectedOutputs = [
    { version: 0, delta: { answerA: 'r1' } },
    { version: 0, delta: { answerB: 'r2' } },
    { version: 0, delta: { answerC: 'r3' } },
    { version: 0, delta: { answerD: 'r4' } },
    { version: 0, delta: { answerE: 'r5' } },
  ]

  let outputIndex = 0
  for await (const result of stream) {
    expect(result).toEqual(expectedOutputs[outputIndex])
    outputIndex++
  }
  expect(outputIndex).toBe(expectedOutputs.length)
})

describe('Error handling in AxGen', () => {
  const signature = 'userQuestion:string -> modelAnswer:string'

  it('should properly wrap errors with cause mechanism', async () => {
    const originalError = new Error('AI service failed')
    const ai = new AxMockAIService({
      features: { functions: false, streaming: false },
      // Mock a failure in the chat method using chatResponse function
      chatResponse: () => Promise.reject(originalError),
    })

    const gen = new AxGen<{ userQuestion: string }, { modelAnswer: string }>(
      signature
    )
    try {
      await gen.forward(ai, { userQuestion: 'test' })
      // If forward does not throw, fail the test
      throw new Error('Test should have failed but did not.')
    } catch (e) {
      const error = e as Error
      expect(error.message).toContain('Generate failed')
      // Check if the original error is available as the cause
      expect(error.cause).toBe(originalError)
    }
  })

  it('should handle streaming errors gracefully', async () => {
    const originalError = new Error('Streaming failed mid-stream')
    // Create a stream that errors after first chunk
    const chatResponseFunction = async () => {
      return new ReadableStream({
        start(controller) {
          controller.enqueue({
            results: [{ content: 'Model Answer: First part...' }],
            modelUsage: {
              ai: 'test-ai',
              model: 'test-model',
              tokens: { promptTokens: 0, completionTokens: 0, totalTokens: 0 },
            },
          })
          // Simulate an error after the first chunk
          setTimeout(() => {
            controller.error(originalError)
          }, 10)
        },
      })
    }

    const ai = new AxMockAIService({
      features: { functions: false, streaming: true },
      chatResponse: chatResponseFunction,
    })

    const gen = new AxGen<{ userQuestion: string }, { modelAnswer: string }>(
      signature
    )
    const streaming = await gen.streamingForward(ai, { userQuestion: 'test' })
    try {
      // eslint-disable-next-line @typescript-eslint/no-unused-vars
      for await (const _ of streaming) {
        // Process stream
      }
      // Fail if the loop completes without error
      throw new Error('Stream processing should have failed.')
    } catch (e) {
      const error = e as Error
      expect(error.message).toContain('Generate failed')
      expect(error.cause).toBe(originalError)
    }
  })
})

describe('AxGen Message Validation', () => {
  it('should pass validation for valid AxMessage array (direct function test)', () => {
    expect(() =>
      validateAxMessageArray([{ role: 'user', content: 'hello' }])
    ).not.toThrow()
  })

  it('should pass validation for AxMessage array with non-string content (direct function test)', () => {
    expect(() =>
      validateAxMessageArray([
        { role: 'user', content: [{ type: 'text', text: 'hello' }] },
      ])
    ).not.toThrow()
  })
})

describe('AxGen Signature Validation', () => {
  it('should validate signature on construction and fail for incomplete signature', () => {
    // This should throw when trying to create AxGen with a signature that has only input fields
    const sig = new AxSignature()
    sig.addInputField({
      name: 'userInput',
      type: { name: 'string', isArray: false },
    })
    // Note: no output fields added

    expect(() => new AxGen(sig)).toThrow('must have at least one output field')
  })

  it('should validate signature on construction and pass for complete signature', () => {
    const sig = new AxSignature()
    sig.addInputField({
      name: 'userInput',
      type: { name: 'string', isArray: false },
    })
    sig.addOutputField({
      name: 'responseText',
      type: { name: 'string', isArray: false },
    })

    expect(() => new AxGen(sig)).not.toThrow()
  })

  it('should validate signature when using string signature', () => {
    // Should work with valid string signature
    expect(
      () => new AxGen('userInput:string -> responseText:string')
    ).not.toThrow()

    // Should fail with incomplete string signature (missing arrow)
    expect(() => new AxGen('userInput:string')).toThrow()
  })
})



================================================
FILE: src/ax/dsp/generate.ts
================================================
import { ReadableStream } from 'node:stream/web'

import {
  context,
  type Context,
  type Span,
  SpanKind,
  trace,
} from '@opentelemetry/api'

import { validateAxMessageArray } from '../ai/base.js'
import type {
  AxAIService,
  AxChatResponse,
  AxChatResponseResult,
  AxFunction,
} from '../ai/types.js'
import { mergeFunctionCalls } from '../ai/util.js'
import { AxMemory } from '../mem/memory.js'
import type { AxAIMemory } from '../mem/types.js'
import { AxAIServiceStreamTerminatedError } from '../util/apicall.js'

import {
  assertAssertions,
  assertStreamingAssertions,
  type AxAssertion,
  AxAssertionError,
  type AxStreamingAssertion,
} from './asserts.js'
import {
  type extractionState,
  extractValues,
  streamingExtractFinalValue,
  streamingExtractValues,
  streamValues,
} from './extract.js'
import {
  type AxFieldProcessor,
  processFieldProcessors,
  processStreamingFieldProcessors,
} from './fieldProcessor.js'
import {
  type AxChatResponseFunctionCall,
  parseFunctionCalls,
  parseFunctions,
  processFunctions,
} from './functions.js'
import {
  type AxGenDeltaOut,
  type AxProgramExamples,
  type AxProgramForwardOptions,
  type AxProgramStreamingForwardOptions,
  AxProgramWithSignature,
  type AxSetExamplesOptions,
} from './program.js'
import { AxPromptTemplate } from './prompt.js'
import type { AxIField, AxSignature } from './sig.js'
import type {
  AxGenIn as AxGenInType,
  AxGenOut as AxGenOutType,
  AxMessage,
} from './types.js'
import { mergeDeltas } from './util.js'
import { handleValidationError, ValidationError } from './validate.js'

export type AxGenerateResult<OUT extends AxGenOutType> = OUT & {
  thought?: string
}

export interface AxResponseHandlerArgs<T> {
  ai: Readonly<AxAIService>
  model?: string
  res: T
  mem: AxAIMemory
  sessionId?: string
  traceId?: string
  functions?: Readonly<AxFunction[]>
  fastFail?: boolean
  span?: Span
}

export interface AxStreamingEvent<T> {
  event: 'delta' | 'done' | 'error'
  data: {
    contentDelta?: string
    partialValues?: Partial<T>
    error?: string
    functions?: AxChatResponseFunctionCall[]
  }
}

export class AxGen<
  IN extends AxGenInType,
  OUT extends AxGenerateResult<AxGenOutType> = AxGenerateResult<AxGenOutType>,
> extends AxProgramWithSignature<IN, OUT> {
  private promptTemplate: AxPromptTemplate
  private asserts: AxAssertion[]
  private streamingAsserts: AxStreamingAssertion[]
  private options?: Omit<AxProgramForwardOptions, 'functions'>
  private functions?: AxFunction[]
  private functionsExecuted: Set<string> = new Set<string>()
  private fieldProcessors: AxFieldProcessor[] = []
  private streamingFieldProcessors: AxFieldProcessor[] = []
  private values: AxGenOutType = {}
  private excludeContentFromTrace: boolean = false
  private thoughtFieldName: string

  constructor(
    signature: NonNullable<ConstructorParameters<typeof AxSignature>[0]>,
    options?: Readonly<AxProgramForwardOptions>
  ) {
    super(signature, { description: options?.description })

    this.options = options
    this.thoughtFieldName = options?.thoughtFieldName ?? 'thought'
    const promptTemplateOptions = {
      functions: options?.functions,
      thoughtFieldName: this.thoughtFieldName,
    }
    this.promptTemplate = new (options?.promptTemplate ?? AxPromptTemplate)(
      this.signature,
      promptTemplateOptions
    )
    this.asserts = this.options?.asserts ?? []
    this.streamingAsserts = this.options?.streamingAsserts ?? []
    this.excludeContentFromTrace = options?.excludeContentFromTrace ?? false
    this.usage = []

    if (options?.functions) {
      this.functions = parseFunctions(options.functions)
    }
  }

  public addAssert = (fn: AxAssertion['fn'], message?: string) => {
    this.asserts.push({ fn, message })
  }

  public addStreamingAssert = (
    fieldName: string,
    fn: AxStreamingAssertion['fn'],
    message?: string
  ) => {
    this.streamingAsserts.push({ fieldName, fn, message })
  }

  private addFieldProcessorInternal = (
    fieldName: string,
    fn: AxFieldProcessor['process'],
    streaming = false
  ) => {
    const field = this.signature
      .getOutputFields()
      .find((f) => f.name === fieldName)

    if (!field) {
      throw new Error(`addFieldProcessor: field ${fieldName} not found`)
    }

    if (streaming) {
      const ft = field.type?.name
      const isText = !ft || ft === 'string' || ft === 'code'

      if (!isText) {
        throw new Error(
          `addFieldProcessor: field ${fieldName} is must be a text field`
        )
      }
      this.streamingFieldProcessors.push({ field, process: fn })
    } else {
      this.fieldProcessors.push({ field, process: fn })
    }
  }

  public addStreamingFieldProcessor = (
    fieldName: string,
    fn: AxFieldProcessor['process']
  ) => {
    this.addFieldProcessorInternal(fieldName, fn, true)
  }

  public addFieldProcessor = (
    fieldName: string,
    fn: AxFieldProcessor['process']
  ) => {
    this.addFieldProcessorInternal(fieldName, fn, false)
  }

  private async forwardSendRequest({
    ai,
    mem,
    options,
    traceContext,
    firstStep,
  }: Readonly<{
    ai: Readonly<AxAIService>
    mem: AxAIMemory
    options?: Omit<AxProgramForwardOptions, 'ai' | 'mem'>
    traceContext?: Context
    firstStep: boolean
  }>) {
    const {
      sessionId,
      traceId,
      modelConfig,
      model,
      rateLimiter,
      stream,
      functions: _functions,
      functionCall: _functionCall,
      thinkingTokenBudget,
      showThoughts,
    } = options ?? {}

    const chatPrompt = mem?.history(sessionId) ?? []

    if (chatPrompt.length === 0) {
      throw new Error('No chat prompt found')
    }

    // biome-ignore lint/complexity/useFlatMap: you cannot use flatMap here
    const functions = _functions
      ?.map((f) => ('toFunction' in f ? f.toFunction() : f))
      ?.flat()

    let functionCall = _functionCall ?? this.options?.functionCall

    if (
      !firstStep &&
      (functionCall === 'required' || typeof functionCall === 'function')
    ) {
      functionCall = undefined
    }

    const res = await ai.chat(
      {
        chatPrompt,
        functions,
        functionCall,
        modelConfig,
        model,
      },
      {
        sessionId,
        traceId,
        rateLimiter,
        stream,
        debug: false, // we do our own debug logging
        thinkingTokenBudget,
        showThoughts,
        traceContext,
        abortSignal: options?.abortSignal,
      }
    )

    return res
  }

  private async *forwardCore({
    ai,
    mem,
    options,
    firstStep,
    span,
    traceContext,
  }: Readonly<{
    ai: Readonly<AxAIService>
    mem: AxAIMemory
    options: Omit<AxProgramForwardOptions, 'ai' | 'mem'>
    firstStep: boolean
    span?: Span
    traceContext?: Context
  }>) {
    const { sessionId, traceId, functions: _functions } = options ?? {}
    const fastFail = options?.fastFail ?? this.options?.fastFail
    const model = options.model

    // biome-ignore lint/complexity/useFlatMap: you cannot use flatMap here
    const functions = _functions
      ?.map((f) => ('toFunction' in f ? f.toFunction() : f))
      ?.flat()

    const res = await this.forwardSendRequest({
      ai,
      mem,
      options,
      traceContext,
      firstStep,
    })

    if (res instanceof ReadableStream) {
      yield* this.processStreamingResponse({
        ai,
        model,
        res,
        mem,
        traceId,
        sessionId,
        functions,
        fastFail,
        span,
      })

      this.getLogger(ai, options)?.('', { tags: ['responseEnd'] })
    } else {
      yield await this.processResponse({
        ai,
        model,
        res,
        mem,
        traceId,
        sessionId,
        functions,
        span,
      })
    }
  }

  private async *processStreamingResponse({
    ai,
    model,
    res,
    mem,
    sessionId,
    traceId,
    functions,
    fastFail,
    span,
  }: Readonly<AxResponseHandlerArgs<ReadableStream<AxChatResponse>>>) {
    const streamingValidation =
      fastFail ?? ai.getFeatures(model).functionCot !== true
    const functionCalls: NonNullable<AxChatResponseResult['functionCalls']> = []
    this.values = {}
    const xstate: extractionState = {
      extractedFields: [],
      streamedIndex: {},
      s: -1,
    }

    let content = ''

    mem.addResult(
      {
        content: '',
        functionCalls: [],
      },
      sessionId
    )

    for await (const v of res) {
      const result = v.results[0]
      if (!result) {
        continue
      }

      if (v.modelUsage) {
        this.usage.push(v.modelUsage)
      }

      if (result.functionCalls && result.functionCalls.length > 0) {
        mergeFunctionCalls(functionCalls, result.functionCalls)
        mem.updateResult(
          {
            name: result.name,
            content,
            functionCalls,
            delta: result.functionCalls?.[0]?.function?.params as string,
          },
          sessionId
        )
      } else if (result.content && result.content.length > 0) {
        if (result.thought && result.thought.length > 0) {
          yield {
            [this.thoughtFieldName]: result.thought,
          } as AxGenDeltaOut<OUT>['delta']
        }

        content += result.content
        mem.updateResult(
          { name: result.name, content, delta: result.content },
          sessionId
        )

        const skip = streamingExtractValues(
          this.signature,
          this.values,
          xstate,
          content,
          streamingValidation
        )

        if (skip) {
          continue
        }

        if (this.streamingAsserts.length !== 0) {
          await assertStreamingAssertions(
            this.streamingAsserts,
            xstate,
            content
          )
        }

        if (this.streamingFieldProcessors.length !== 0) {
          await processStreamingFieldProcessors(
            this.streamingFieldProcessors,
            content,
            xstate,
            mem,
            this.values,
            sessionId
          )
        }

        yield* streamValues<OUT>(
          this.signature,
          content,
          this.values as Record<string, OUT>,
          xstate
        )

        await assertAssertions(this.asserts, this.values)
      } else if (result.thought && result.thought.length > 0) {
        this.values[this.thoughtFieldName] =
          (this.values[this.thoughtFieldName] ?? '') + result.thought
        yield {
          [this.thoughtFieldName]: result.thought,
        } as AxGenDeltaOut<OUT>['delta']
      }

      if (result.finishReason === 'length') {
        throw new Error(
          `Max tokens reached before completion\nContent: ${content}`
        )
      }
    }

    const funcs = parseFunctionCalls(ai, functionCalls, this.values, model)
    if (funcs) {
      if (!functions) {
        throw new Error('Functions are not defined')
      }
      const fx = await processFunctions(
        ai,
        functions,
        funcs,
        mem,
        sessionId,
        traceId,
        span,
        this.excludeContentFromTrace
      )
      this.functionsExecuted = new Set([...this.functionsExecuted, ...fx])
    } else {
      streamingExtractFinalValue(this.signature, this.values, xstate, content)

      await assertStreamingAssertions(
        this.streamingAsserts,
        xstate,
        content,
        true
      )
      await assertAssertions(this.asserts, this.values)

      if (this.fieldProcessors.length) {
        await processFieldProcessors(
          this.fieldProcessors,
          this.values,
          mem,
          sessionId
        )
      }

      if (this.streamingFieldProcessors.length !== 0) {
        await processStreamingFieldProcessors(
          this.streamingFieldProcessors,
          content,
          xstate,
          mem,
          this.values,
          sessionId,
          true
        )
      }

      yield* streamValues<OUT>(
        this.signature,
        content,
        this.values as Record<string, OUT>,
        xstate
      )
    }
  }

  private async processResponse({
    ai,
    res,
    mem,
    sessionId,
    traceId,
    functions,
    span,
  }: Readonly<AxResponseHandlerArgs<AxChatResponse>>): Promise<OUT> {
    this.values = {}

    let results = res.results ?? []

    if (results.length > 1) {
      results = results.filter((r) => r.functionCalls)
    }

    for (const result of results) {
      if (res.modelUsage) {
        this.usage.push(res.modelUsage)
      }

      mem.addResult(result, sessionId)

      if (result.functionCalls?.length) {
        const funcs = parseFunctionCalls(ai, result.functionCalls, this.values)
        if (funcs) {
          if (!functions) {
            throw new Error('Functions are not defined')
          }
          const fx = await processFunctions(
            ai,
            functions,
            funcs,
            mem,
            sessionId,
            traceId,
            span,
            this.excludeContentFromTrace
          )
          this.functionsExecuted = new Set([...this.functionsExecuted, ...fx])
        }
      } else if (result.content) {
        if (result.thought && result.thought.length > 0) {
          this.values[this.thoughtFieldName] = result.thought
        }

        extractValues(this.signature, this.values, result.content)
        await assertAssertions(this.asserts, this.values)

        if (this.fieldProcessors.length) {
          await processFieldProcessors(
            this.fieldProcessors,
            this.values,
            mem,
            sessionId
          )
        }
      }

      if (result.finishReason === 'length') {
        throw new Error(
          `Max tokens reached before completion\nContent: ${result.content}`
        )
      }
    }

    // Strip out values whose signature fields have isInternal: true
    for (const field of this.signature.getOutputFields()) {
      if (field.isInternal) {
        delete this.values[field.name]
      }
    }

    return { ...this.values } as unknown as OUT
  }

  private async *_forward2(
    ai: Readonly<AxAIService>,
    values: IN | AxMessage<IN>[],
    options: Readonly<AxProgramForwardOptions>,
    span?: Span,
    traceContext?: Context
  ) {
    const stopFunction = (
      options?.stopFunction ?? this.options?.stopFunction
    )?.toLowerCase()

    const maxRetries = options.maxRetries ?? this.options?.maxRetries ?? 10
    const maxSteps = options.maxSteps ?? this.options?.maxSteps ?? 10
    const debugHideSystemPrompt = options.debugHideSystemPrompt
    const memOptions = {
      debug: this.isDebug(ai, options),
      debugHideSystemPrompt,
    }

    const mem =
      options.mem ?? this.options?.mem ?? new AxMemory(10000, memOptions)

    let err: ValidationError | AxAssertionError | undefined

    if (options?.functions && options.functions.length > 0) {
      const promptTemplateClass =
        this.options?.promptTemplate ?? AxPromptTemplate
      const currentPromptTemplateOptions = {
        functions: options.functions,
        thoughtFieldName: this.thoughtFieldName,
      }
      this.promptTemplate = new promptTemplateClass(
        this.signature,
        currentPromptTemplateOptions
      )
    }

    // New logic:
    let prompt
    if (Array.isArray(values)) {
      // Validate AxMessage array items
      validateAxMessageArray(values)

      // We'll need to decide how to get the 'individual' IN for demos/examples if needed by render.
      // For now, assume render will handle the array directly.
      // The generic type for render might need to be T (from render<T extends ...>)
      // and T will be inferred as ReadonlyArray<AxMessage>
      prompt = this.promptTemplate.render(values, {
        examples: this.examples,
        demos: this.demos,
      })
    } else {
      // Ensure `values` here is correctly inferred as AxGenInType
      prompt = this.promptTemplate.render(values as AxGenInType, {
        // Cast if necessary
        examples: this.examples,
        demos: this.demos,
      })
    }

    mem.add(prompt, options?.sessionId)

    multiStepLoop: for (let n = 0; n < maxSteps; n++) {
      const firstStep = n === 0
      for (let errCount = 0; errCount < maxRetries; errCount++) {
        try {
          const generator = this.forwardCore({
            options,
            ai,
            mem,
            firstStep,
            span,
            traceContext,
          })
          for await (const delta of generator) {
            if (delta !== undefined) {
              yield { version: errCount, delta }
            }
          }

          const lastMemItem = mem.getLast(options?.sessionId)
          const shouldContinue = this.shouldContinueSteps(
            lastMemItem,
            stopFunction
          )

          if (shouldContinue) {
            continue multiStepLoop
          }

          this.getLogger(ai, options)?.('', { tags: ['responseEnd'] })
          return
        } catch (e) {
          let errorFields: AxIField[] | undefined

          span?.recordException(e as Error)

          if (e instanceof ValidationError) {
            errorFields = e.getFixingInstructions()
            err = e

            // Add telemetry event for validation error
            if (span) {
              span.addEvent('validation.error', {
                message: e.toString(),
                fixing_instructions:
                  errorFields?.map((f) => f.title).join(', ') ?? '',
              })
            }
          } else if (e instanceof AxAssertionError) {
            const e1 = e as AxAssertionError
            errorFields = e1.getFixingInstructions()
            err = e

            // Add telemetry event for assertion error
            if (span) {
              span.addEvent('assertion.error', {
                message: e1.toString(),
                fixing_instructions:
                  errorFields?.map((f) => f.title).join(', ') ?? '',
              })
            }
          } else if (e instanceof AxAIServiceStreamTerminatedError) {
            // Do nothing allow error correction to happen
          } else {
            throw enhanceError(e, ai, this.signature)
          }

          if (errorFields) {
            handleValidationError(
              mem,
              errorFields,
              ai,
              this.promptTemplate,
              options.sessionId
            )
          }
        }
      }

      throw enhanceError(
        new Error(`Unable to fix validation error: ${err?.toString()}`),
        ai,
        this.signature
      )
    }

    throw enhanceError(
      new Error(`Max steps reached: ${maxSteps}`),
      ai,
      this.signature
    )
  }

  private shouldContinueSteps(
    lastMemItem: ReturnType<AxAIMemory['getLast']>,
    stopFunction: string | undefined
  ) {
    const stopFunctionExecuted =
      stopFunction && this.functionsExecuted.has(stopFunction)

    const isFunction = lastMemItem?.chat?.role === 'function'
    const isProcessor = lastMemItem?.tags
      ? lastMemItem.tags.some((tag) => tag === 'processor')
      : false

    if (isFunction && stopFunction && stopFunctionExecuted) {
      return false
    }

    if (isFunction || isProcessor) {
      return true
    }

    return false
  }

  public async *_forward1(
    ai: Readonly<AxAIService>,
    values: IN | AxMessage<IN>[],
    options: Readonly<AxProgramForwardOptions>
  ) {
    const tracer =
      options?.tracer ?? this.options?.tracer ?? ai.getOptions().tracer

    let functions: AxFunction[] | undefined = this.functions

    if (options?.functions) {
      functions = parseFunctions(options.functions, this.functions)
    }

    if (!tracer) {
      yield* this._forward2(ai, values, {
        ...options,
        functions,
      })
      return
    }

    const funcNames = functions?.map((f) => f.name).join(',')

    const attributes = {
      signature: JSON.stringify(this.signature.toJSON(), null, 2),
      ...(this.examples
        ? { examples: JSON.stringify(this.examples, null, 2) }
        : {}),
      ...(funcNames ? { provided_functions: funcNames } : {}),
      ...(options?.model ? { model: options.model } : {}),
      ...(options?.thinkingTokenBudget
        ? { thinking_token_budget: options.thinkingTokenBudget }
        : {}),
      ...(options?.showThoughts ? { show_thoughts: options.showThoughts } : {}),
      ...(options?.maxSteps ? { max_steps: options.maxSteps } : {}),
      ...(options?.maxRetries ? { max_retries: options.maxRetries } : {}),
      ...(options?.fastFail ? { fast_fail: options.fastFail } : {}),
    }

    const traceLabel = options.traceLabel ?? this.options?.traceLabel
    const spanName = traceLabel ? `${traceLabel} (AxGen)` : 'AxGen'

    const span = tracer.startSpan(spanName, {
      kind: SpanKind.SERVER,
      attributes,
    })

    const currentContext = context.active()
    const traceContext = trace.setSpan(currentContext, span)

    try {
      if (!this.excludeContentFromTrace) {
        span.addEvent('input', { content: JSON.stringify(values, null, 2) })
      }

      yield* this._forward2(
        ai,
        values,
        {
          ...options,
          functions,
        },
        span,
        traceContext
      )

      if (!this.excludeContentFromTrace) {
        span.addEvent('output', {
          content: JSON.stringify(this.values, null, 2),
        })
      }
    } finally {
      span.end()
    }
  }

  public override async forward(
    ai: Readonly<AxAIService>,
    values: IN | AxMessage<IN>[],
    options?: Readonly<AxProgramForwardOptions>
  ): Promise<OUT> {
    const generator = this._forward1(ai, values, options ?? {})

    let buffer = {} as AxGenDeltaOut<OUT>['delta']
    let currentVersion = 0

    for await (const item of generator) {
      if (item.version !== currentVersion) {
        buffer = {}
      }
      currentVersion = item.version
      buffer = mergeDeltas(buffer, item.delta)
    }

    this.trace = { ...values, ...buffer } as unknown as OUT
    return buffer as OUT
  }

  override async *streamingForward(
    ai: Readonly<AxAIService>,
    values: IN | AxMessage<IN>[],
    options?: Readonly<AxProgramStreamingForwardOptions>
  ) {
    yield* this._forward1(ai, values, {
      ...options,
      stream: true,
    })
  }

  public override setExamples(
    examples: Readonly<AxProgramExamples<IN, OUT>>,
    options?: Readonly<AxSetExamplesOptions>
  ) {
    super.setExamples(examples, options)
    // No need to update prompt template - all fields can be missing in examples
  }

  private isDebug(
    ai: Readonly<AxAIService>,
    options?: Readonly<AxProgramForwardOptions>
  ) {
    return (
      options?.debug ?? this.options?.debug ?? ai.getOptions().debug ?? false
    )
  }

  private getLogger(
    ai: Readonly<AxAIService>,
    options?: Readonly<AxProgramForwardOptions>
  ) {
    return options?.logger ?? this.options?.logger ?? ai.getLogger()
  }
}

export type AxGenerateErrorDetails = {
  model?: string
  maxTokens?: number
  streaming: boolean
  signature: {
    input: Readonly<AxIField[]>
    output: Readonly<AxIField[]>
    description?: string
  }
}

export class AxGenerateError extends Error {
  public readonly details: AxGenerateErrorDetails

  constructor(
    message: string,
    details: Readonly<AxGenerateErrorDetails>,
    options?: ErrorOptions
  ) {
    super(message, options)
    this.name = 'AxGenerateError'
    this.details = details
  }
}

function enhanceError(
  e: unknown,
  ai: Readonly<AxAIService>,
  signature: Readonly<AxSignature>
): Error {
  const originalError = e instanceof Error ? e : new Error(String(e))
  const model = ai.getLastUsedChatModel() as string | undefined
  const modelConfig = ai.getLastUsedModelConfig()

  const details = {
    model: model,
    maxTokens: modelConfig?.maxTokens,
    streaming: modelConfig?.stream ?? false,
    signature: {
      input: signature.getInputFields(),
      output: signature.getOutputFields(),
      description: signature.getDescription(),
    },
  }

  // Return custom error with short message and details as object property
  return new AxGenerateError('Generate failed', details, {
    cause: originalError,
  })
}



================================================
FILE: src/ax/dsp/globals.ts
================================================
export const axGlobals = {
  signatureStrict: true, // Controls reservedNames enforcement in signature parsing/validation
}



================================================
FILE: src/ax/dsp/jsonschema.ts
================================================
import type { AxFunctionJSONSchema } from '../ai/types.js'

// Extended type to handle flexible JSON schemas with union types
type FlexibleJSONSchema = AxFunctionJSONSchema & {
  anyOf?: FlexibleJSONSchema[]
  oneOf?: FlexibleJSONSchema[]
  allOf?: FlexibleJSONSchema[]
  properties?: Record<string, FlexibleJSONSchema | undefined>
}

interface ValidationError {
  path: string
  issue: string
  fix: string
  example?: string
}

export const validateJSONSchema = (
  schema: Readonly<AxFunctionJSONSchema>
): void => {
  const errors: ValidationError[] = []

  const validateSchemaObject = (
    schema: Readonly<FlexibleJSONSchema | undefined>,
    path: string = ''
  ): void => {
    // Skip validation if schema is undefined or null
    if (!schema || typeof schema !== 'object') {
      return
    }

    const validTypes = [
      'array',
      'integer',
      'number',
      'string',
      'boolean',
      'null',
      'object',
    ]

    // Handle schemas with anyOf (union types)
    if (schema.anyOf && Array.isArray(schema.anyOf)) {
      if (schema.anyOf.length === 0) {
        errors.push({
          path: path || 'root',
          issue: 'anyOf array is empty',
          fix: 'Add at least one schema to the anyOf array',
          example: 'anyOf: [{ type: "string" }, { type: "null" }]',
        })
      }
      // Validate each schema in anyOf
      schema.anyOf.forEach((subSchema: FlexibleJSONSchema, index: number) => {
        validateSchemaObject(subSchema, `${path}anyOf[${index}].`)
      })
      return
    }

    // Handle schemas with oneOf
    if (schema.oneOf && Array.isArray(schema.oneOf)) {
      if (schema.oneOf.length === 0) {
        errors.push({
          path: path || 'root',
          issue: 'oneOf array is empty',
          fix: 'Add at least one schema to the oneOf array',
          example: 'oneOf: [{ type: "string" }, { type: "number" }]',
        })
      }
      schema.oneOf.forEach((subSchema: FlexibleJSONSchema, index: number) => {
        validateSchemaObject(subSchema, `${path}oneOf[${index}].`)
      })
      return
    }

    // Handle schemas with allOf
    if (schema.allOf && Array.isArray(schema.allOf)) {
      if (schema.allOf.length === 0) {
        errors.push({
          path: path || 'root',
          issue: 'allOf array is empty',
          fix: 'Add at least one schema to the allOf array',
          example:
            'allOf: [{ type: "object" }, { properties: { name: { type: "string" } } }]',
        })
      }
      schema.allOf.forEach((subSchema: FlexibleJSONSchema, index: number) => {
        validateSchemaObject(subSchema, `${path}allOf[${index}].`)
      })
      return
    }

    // Skip validation if no type is specified (might be a reference or other valid schema)
    if (!schema.type) {
      return
    }

    if (!validTypes.includes(schema.type)) {
      errors.push({
        path: path || 'root',
        issue: `Invalid type '${schema.type}'`,
        fix: `Change type to one of: ${validTypes.join(', ')}`,
        example: `{ type: "string" } or { type: "object" }`,
      })
      return
    }

    if (schema.type === 'object') {
      if (schema.properties) {
        if (
          typeof schema.properties !== 'object' ||
          Array.isArray(schema.properties)
        ) {
          errors.push({
            path: path || 'root',
            issue: 'properties must be an object, not an array or primitive',
            fix: 'Change properties to be an object with property names as keys',
            example:
              'properties: { name: { type: "string" }, age: { type: "number" } }',
          })
        } else {
          for (const key in schema.properties) {
            const value = schema.properties[key]
            // Skip undefined or null properties
            if (value === undefined || value === null) {
              continue
            }
            if (typeof value !== 'object') {
              errors.push({
                path: `${path}${key}`,
                issue: `Property schema must be an object, got ${typeof value}`,
                fix: 'Define the property as a proper schema object',
                example: `${key}: { type: "string", description: "..." }`,
              })
              continue
            }
            validateSchemaObject(value, `${path}${key}.`)
          }
        }
      }

      if (schema.required) {
        if (!Array.isArray(schema.required)) {
          errors.push({
            path: path || 'root',
            issue: `'required' must be an array, got ${typeof schema.required}`,
            fix: 'Change required to be an array of property names',
            example:
              'required: ["name", "email"] instead of required: "name,email"',
          })
        } else if (schema.required.length === 0) {
          // This is valid but might be worth noting
        } else {
          // Validate that required properties exist in properties
          if (schema.properties) {
            for (const requiredProp of schema.required) {
              if (typeof requiredProp !== 'string') {
                errors.push({
                  path: `${path}required`,
                  issue: `Required property names must be strings, got ${typeof requiredProp}`,
                  fix: 'Ensure all items in required array are strings',
                  example:
                    'required: ["name", "email"] not required: [123, "email"]',
                })
              } else if (!(requiredProp in schema.properties)) {
                errors.push({
                  path: `${path}required`,
                  issue: `Required property '${requiredProp}' is not defined in properties`,
                  fix: `Either add '${requiredProp}' to properties or remove it from required`,
                  example: `properties: { ${requiredProp}: { type: "string" } }`,
                })
              }
            }
          }
        }
      }
    }

    if (schema.type === 'array') {
      if (schema.items) {
        if (typeof schema.items !== 'object') {
          errors.push({
            path: `${path}items`,
            issue: `Array items schema must be an object, got ${typeof schema.items}`,
            fix: 'Define items as a proper schema object',
            example:
              'items: { type: "string" } or items: { type: "object", properties: {...} }',
          })
        } else {
          validateSchemaObject(schema.items, `${path}items.`)
        }
      }
    }
  }

  validateSchemaObject(schema)

  if (errors.length > 0) {
    const errorMessage = [
      'JSON Schema validation failed:',
      '',
      ...errors.map((error, index) => {
        const parts = [
          `${index + 1}. Path: ${error.path}`,
          `   Issue: ${error.issue}`,
          `   Fix: ${error.fix}`,
        ]
        if (error.example) {
          parts.push(`   Example: ${error.example}`)
        }
        return parts.join('\n')
      }),
      '',
      'Please fix these issues and try again.',
    ].join('\n')

    throw new Error(errorMessage)
  }
}

// Example Usage:

/*
const validSchema: AxFunctionJSONSchema = {
  type: 'object',
  properties: {
    id: { type: 'integer' },
    name: { type: 'string' },
    email: { type: 'string' },
    isActive: { type: 'boolean' },
    tags: {
      type: 'array',
      items: { type: 'string' }
    },
    optionalField: {
      anyOf: [
        { type: 'string' },
        { type: 'null' }
      ]
    }
  },
  required: ['id', 'name', 'email']
};

const invalidSchema: any = {
  type: 'object',
  properties: {
    id: { type: 'integer' },
    name: { type: 'string' },
    email: { type: 'unknownType' }, // Invalid type
    isActive: { type: 'boolean' },
    tags: {
      type: 'array',
      items: { type: 'string' }
    }
  },
  required: 'id,name,email' // Invalid 'required' field
};

try {
  validateJSONSchema(validSchema);
} catch (error) {
  console.error('Schema validation failed:', error.message);
}

try {
  validateJSONSchema(invalidSchema);
} catch (error) {
  console.error('Schema validation failed:', error.message);
}
*/



================================================
FILE: src/ax/dsp/loader.ts
================================================
import type { AxFieldValue } from './types.js'

export type AxDataRow = { row: Record<string, AxFieldValue> }

export class AxHFDataLoader {
  private rows: AxDataRow[] = []
  private baseUrl: string

  private dataset: string
  private split: string
  private config: string
  private options?: Readonly<{ offset?: number; length?: number }>

  constructor({
    dataset,
    split,
    config,
    options,
  }: Readonly<{
    dataset: string
    split: string
    config: string
    options?: Readonly<{ offset?: number; length?: number }>
  }>) {
    this.baseUrl = 'https://datasets-server.huggingface.co/rows'
    this.dataset = dataset
    this.split = split
    this.config = config
    this.options = options
  }

  private async fetchDataFromAPI(url: string): Promise<AxDataRow[]> {
    try {
      const response = await fetch(url)
      if (!response.ok) {
        throw new Error(`Error fetching data: ${response.statusText}`)
      }
      const data = (await response.json()) as { rows: AxDataRow[] }
      if (!data?.rows) {
        throw new Error('Invalid data format')
      }
      return data.rows
    } catch (error) {
      console.error('Error fetching data from API:', error)
      throw error
    }
  }

  // https://datasets-server.huggingface.co/rows?dataset=hotpot_qa&config=distractor&split=train&offset=0&length=100

  public async loadData() {
    const offset = this.options?.offset ?? 0
    const length = this.options?.length ?? 100
    const ds = encodeURIComponent(this.dataset)

    const url = `${this.baseUrl}?dataset=${ds}&config=${this.config}&split=${this.split}&offset=${offset}&length=${length}`

    console.log('Downloading data from API.')
    this.rows = (await this.fetchDataFromAPI(url)) as AxDataRow[]
    return this.rows
  }

  public setData(rows: AxDataRow[]) {
    this.rows = rows
  }

  public getData() {
    return this.rows
  }

  public async getRows<T>({
    count,
    fields,
    renameMap,
  }: Readonly<{
    count: number
    fields: readonly string[]
    renameMap?: Record<string, string>
  }>): Promise<T[]> {
    if (this.rows.length === 0) {
      throw new Error('No data loaded, call loadData or setData first.')
    }
    const dataRows = this.rows.slice(0, count)

    return dataRows
      .map((item) => {
        const result: Record<string, AxFieldValue> = {}

        fields.forEach((field) => {
          const keys = field.split('.')
          // Initial value should match the type of the rows, and be indexable by string
          let value: AxFieldValue | unknown = item.row
          for (const key of keys) {
            // Use type assertion to tell TypeScript that value will always be an object that can be indexed with string keys
            if (
              Object.prototype.hasOwnProperty.call(
                value as Record<string, unknown>,
                key
              )
            ) {
              value = (value as Record<string, unknown>)[key]
            }
          }
          if (!value) {
            return
          }
          const resultFieldName =
            renameMap && field in renameMap ? renameMap[field] : field
          if (!resultFieldName) {
            throw new Error(`Invalid field name: ${field}`)
          }
          result[resultFieldName] = value as AxFieldValue
        })

        return result
      })
      .filter((v) => Object.keys(v).length !== 0) as T[]
  }
}



================================================
FILE: src/ax/dsp/modelinfo.test.ts
================================================
import { describe, expect, it } from 'vitest'

import { getModelInfo } from './modelinfo.js'

const models = [
  {
    key: 'claude-3',
    model: 'claude-3-5-sonnet',
    description: 'Claude 3.5 Sonnet',
  },
]

const modelInfo = [
  {
    name: 'claude-3-5-sonnet',
    currency: 'usd',
    promptTokenCostPer1M: 15000,
    completionTokenCostPer1M: 75000,
  },
  {
    name: 'gpt-4o-mini',
    currency: 'usd',
    promptTokenCostPer1M: 10000,
    completionTokenCostPer1M: 30000,
  },
]

describe('getModelInfo', () => {
  it('should return correct model info for exact match', () => {
    const result = getModelInfo({ model: 'claude-3-5-sonnet', modelInfo })
    expect(result).not.toBeNull()
    expect(result?.name).toBe('claude-3-5-sonnet')
    expect(result?.promptTokenCostPer1M).toBe(15000)
  })

  it('should handle model mapping', () => {
    const result = getModelInfo({ model: 'claude-3', modelInfo, models })
    expect(result).not.toBeNull()
    expect(result?.name).toBe('claude-3-5-sonnet')
    expect(result?.promptTokenCostPer1M).toBe(15000)
  })

  it('should handle vendor prefixes', () => {
    const result = getModelInfo({
      model: 'anthropic.claude-3-5-sonnet',
      modelInfo,
    })
    expect(result).not.toBeNull()
    expect(result?.name).toBe('claude-3-5-sonnet')
    expect(result?.promptTokenCostPer1M).toBe(15000)
  })

  describe('model name variations', () => {
    it('should handle date postfix', () => {
      const result = getModelInfo({
        model: 'claude-3-5-sonnet-20241022',
        modelInfo,
      })
      expect(result).not.toBeNull()
      expect(result?.name).toBe('claude-3-5-sonnet')
    })

    it('should handle version postfix', () => {
      const result = getModelInfo({
        model: 'claude-3-5-sonnet-v2:0',
        modelInfo,
      })
      expect(result).not.toBeNull()
      expect(result?.name).toBe('claude-3-5-sonnet')
    })

    it('should handle alternative date format', () => {
      const result = getModelInfo({
        model: 'claude-3-5-sonnet@20241022',
        modelInfo,
      })
      expect(result).not.toBeNull()
      expect(result?.name).toBe('claude-3-5-sonnet')
    })

    it('should handle latest postfix', () => {
      const result = getModelInfo({
        model: 'claude-3-5-sonnet-latest',
        modelInfo,
      })
      expect(result).not.toBeNull()
      expect(result?.name).toBe('claude-3-5-sonnet')
    })

    it('should handle numeric id postfix', () => {
      const result = getModelInfo({ model: 'gpt-4o-mini-8388383', modelInfo })
      expect(result).not.toBeNull()
      expect(result?.name).toBe('gpt-4o-mini')
    })

    it('should handle complex version with date', () => {
      const result = getModelInfo({
        model: 'claude-3-5-sonnet-v2@20241022',
        modelInfo,
      })
      expect(result).not.toBeNull()
      expect(result?.name).toBe('claude-3-5-sonnet')
    })

    it('should handle vendor prefix with version', () => {
      const result = getModelInfo({
        model: 'anthropic.claude-3-5-sonnet-20241022-v2:0',
        modelInfo,
      })
      expect(result).not.toBeNull()
      expect(result?.name).toBe('claude-3-5-sonnet')
    })
  })

  it('should handle unknown model', () => {
    const result = getModelInfo({ model: 'unknown-model', modelInfo })
    expect(result).toBeNull()
  })
})



================================================
FILE: src/ax/dsp/modelinfo.ts
================================================
import type { AxAIInputModelList, AxModelInfo } from '../ai/types.js'

interface GetModelInfoParams<TModel = string, TEmbedModel = undefined> {
  model: TModel
  modelInfo: readonly AxModelInfo[]
  models?: AxAIInputModelList<TModel, TEmbedModel>
}

export function getModelInfo<TModel = string, TEmbedModel = undefined>({
  model,
  modelInfo,
  models,
}: Readonly<
  GetModelInfoParams<TModel, TEmbedModel>
>): Readonly<AxModelInfo> | null {
  // First check if there's a mapping for this model
  const modelEntry = models?.find((v) => v.key === model)
  const mappedModel =
    modelEntry && 'model' in modelEntry
      ? (modelEntry.model as string)
      : (model as string)

  // Try exact match first
  const exactMatch = modelInfo.find((v) => v.name === model)
  if (exactMatch) return exactMatch

  // Handle normalization if no exact match
  const normalizedName = mappedModel
    // Remove vendor prefixes
    .replace(/^(anthropic\.|openai\.)/, '')
    // Remove various postfixes one by one, stopping after first match
    .replace(/-latest$/, '')
    .replace(/-\d{8}$/, '') // YYYYMMDD
    .replace(/-v\d+:\d+$/, '') // v2:0
    .replace(/@\d{8}$/, '') // @YYYYMMDD
    .replace(/-\d{2,}(-[a-zA-Z0-9-]+)?$/, '') // XX or XXXXX-something
    .replace(/-v\d+@\d{8}$/, '') // vX@YYYYMMDD
    .replace(/-v\d+$/, '') // Remove standalone version number

  // Try to find a match with the normalized name
  const normalizedMatch = modelInfo.find((v) => v.name === normalizedName)
  if (normalizedMatch) return normalizedMatch

  // Return default if no match found
  return null
}



================================================
FILE: src/ax/dsp/optimizer.test.ts
================================================
import { describe, expect, it } from 'vitest'

import type { AxAIService } from '../ai/types.js'

import type { AxOptimizer } from './optimizer.js'
import { AxBootstrapFewShot } from './optimizers/bootstrapFewshot.js'
import { AxMiPRO } from './optimizers/miproV2.js'

// Mock dependencies
const mockAI = {
  name: 'mock',
  chat: async () => ({ results: [{ content: 'mock response' }] }),
} as unknown as AxAIService

// Removed unused mockProgram

const mockExamples = [
  { input: 'test input', output: 'test output' },
  { input: 'test input 2', output: 'test output 2' },
]

describe('Optimizer Interface', () => {
  it('AxBootstrapFewShot implements AxOptimizer interface', () => {
    const optimizer = new AxBootstrapFewShot({
      studentAI: mockAI,
      examples: mockExamples,
    })

    // TypeScript check - this should compile without errors
    const typedOptimizer: AxOptimizer = optimizer

    expect(typedOptimizer).toBeDefined()
    expect(typeof typedOptimizer.compile).toBe('function')
    expect(typeof typedOptimizer.getStats).toBe('function')
  })

  it('AxMiPRO implements AxOptimizer interface', () => {
    const optimizer = new AxMiPRO({
      studentAI: mockAI,
      examples: mockExamples,
    })

    // TypeScript check - this should compile without errors
    const typedOptimizer: AxOptimizer = optimizer

    expect(typedOptimizer).toBeDefined()
    expect(typeof typedOptimizer.compile).toBe('function')
    expect(typeof typedOptimizer.getStats).toBe('function')
  })

  it('Both optimizers have compatible compile method signatures', () => {
    const bootstrap = new AxBootstrapFewShot({
      studentAI: mockAI,
      examples: mockExamples,
    })

    const mipro = new AxMiPRO({
      studentAI: mockAI,
      examples: mockExamples,
    })

    // Type check: both should be assignable to the common interface
    const optimizers: AxOptimizer[] = [bootstrap, mipro]

    expect(optimizers).toHaveLength(2)

    // Both should have the same compile method signature
    for (const optimizer of optimizers) {
      expect(typeof optimizer.compile).toBe('function')
      expect(optimizer.compile).toHaveLength(3) // program, metricFn and options
    }
  })

  it('Both optimizers support getStats method', () => {
    const bootstrap = new AxBootstrapFewShot({
      studentAI: mockAI,
      examples: mockExamples,
    })

    const mipro = new AxMiPRO({
      studentAI: mockAI,
      examples: mockExamples,
    })

    // getStats should be available (may return undefined before compilation)
    const bootstrapStats = bootstrap.getStats()
    const miproStats = mipro.getStats()

    // Stats can be undefined before compilation, but method should exist
    expect(bootstrapStats !== null).toBe(true)
    expect(miproStats !== null).toBe(true)
  })
})



================================================
FILE: src/ax/dsp/optimizer.ts
================================================
import type { AxAIService } from '../ai/types.js'

import type { AxProgram, AxProgramDemos } from './program.js'
import type { AxFieldValue, AxGenIn, AxGenOut } from './types.js'

// Common types used by optimizers
export type AxExample = Record<string, AxFieldValue>

export type AxMetricFn = <T extends AxGenOut = AxGenOut>(
  arg0: Readonly<{ prediction: T; example: AxExample }>
) => number | Promise<number>

export type AxMetricFnArgs = Parameters<AxMetricFn>[0]

// Multi-objective metric function for Pareto optimization
export type AxMultiMetricFn = <T extends AxGenOut = AxGenOut>(
  arg0: Readonly<{ prediction: T; example: AxExample }>
) => Record<string, number>

// Progress tracking interface for real-time updates
export interface AxOptimizationProgress {
  round: number
  totalRounds: number
  currentScore: number
  bestScore: number
  tokensUsed: number
  timeElapsed: number
  successfulExamples: number
  totalExamples: number
  currentConfiguration?: Record<string, unknown>
  convergenceInfo?: {
    improvement: number
    stagnationRounds: number
    isConverging: boolean
  }
}

// Cost tracking interface for monitoring resource usage
export interface AxCostTracker {
  trackTokens(count: number, model: string): void
  getCurrentCost(): number
  getTokenUsage(): Record<string, number>
  getTotalTokens(): number
  isLimitReached(): boolean
  reset(): void
}

// Checkpoint interface for saving/loading optimization state
export interface AxOptimizationCheckpoint {
  version: string
  timestamp: number
  optimizerType: string
  optimizerConfig: Record<string, unknown>

  // Current optimization state
  currentRound: number
  totalRounds: number
  bestScore: number
  bestConfiguration?: Record<string, unknown>

  // Historical data
  scoreHistory: number[]
  configurationHistory: Record<string, unknown>[]

  // Resource usage
  stats: AxOptimizationStats

  // Optimizer-specific state
  optimizerState: Record<string, unknown>

  // Examples and validation data
  examples: readonly AxExample[]
  validationSet?: readonly AxExample[]
}

// Simple checkpoint functions - users implement these as needed
export type AxCheckpointSaveFn = (
  checkpoint: Readonly<AxOptimizationCheckpoint>
) => Promise<string>
export type AxCheckpointLoadFn = (
  checkpointId: string
) => Promise<AxOptimizationCheckpoint | null>

// Cost tracker configuration options
export interface AxCostTrackerOptions {
  // Cost-based limits
  costPerModel?: Record<string, number>
  maxCost?: number

  // Token-based limits
  maxTokens?: number
}

// Enhanced optimizer arguments - no longer includes program
export type AxOptimizerArgs = {
  studentAI: AxAIService
  teacherAI?: AxAIService // For generating high-quality examples/corrections
  examples: readonly AxExample[]

  // Evaluation strategy
  validationSet?: readonly AxExample[]

  // Quality thresholds
  minSuccessRate?: number
  targetScore?: number

  // Monitoring & callbacks
  onProgress?: (progress: Readonly<AxOptimizationProgress>) => void
  onEarlyStop?: (reason: string, stats: Readonly<AxOptimizationStats>) => void
  costTracker?: AxCostTracker

  // Checkpointing
  checkpointSave?: AxCheckpointSaveFn
  checkpointLoad?: AxCheckpointLoadFn
  checkpointInterval?: number // Save checkpoint every N rounds
  resumeFromCheckpoint?: string // Checkpoint ID to resume from

  // Reproducibility
  seed?: number
}

// Enhanced optimization statistics
export interface AxOptimizationStats {
  totalCalls: number
  successfulDemos: number
  estimatedTokenUsage: number
  earlyStopped: boolean
  earlyStopping?: {
    bestScoreRound: number
    patienceExhausted: boolean
    reason: string
  }

  // Resource usage tracking
  resourceUsage: {
    totalTokens: number
    totalTime: number
    avgLatencyPerEval: number
    peakMemoryUsage?: number
    costByModel: Record<string, number>
  }

  // Quality metrics
  convergenceInfo: {
    converged: boolean
    finalImprovement: number
    stagnationRounds: number
    convergenceThreshold: number
  }

  // Evaluation breakdown
  evaluationBreakdown?: {
    trainingScore: number
    validationScore: number
    crossValidationScores?: number[]
    standardDeviation?: number
  }
}

// Simplified result - no program since it's passed to compile
export interface AxOptimizerResult<OUT extends AxGenOut> {
  demos?: AxProgramDemos<AxGenIn, OUT>[]
  stats: AxOptimizationStats
  bestScore: number
  finalConfiguration?: Record<string, unknown>

  // Optimization history for analysis
  scoreHistory?: number[]
  configurationHistory?: Record<string, unknown>[]
}

// Pareto optimization result for multi-objective optimization
export interface AxParetoResult<OUT extends AxGenOut = AxGenOut>
  extends AxOptimizerResult<OUT> {
  paretoFront: ReadonlyArray<{
    demos: readonly AxProgramDemos<AxGenIn, OUT>[]
    scores: Readonly<Record<string, number>>
    configuration: Readonly<Record<string, unknown>>
    dominatedSolutions: number
  }>

  // Multi-objective specific stats
  hypervolume?: number
  paretoFrontSize: number
  convergenceMetrics?: Record<string, number>
}

// Compile options that can override constructor arguments
export interface AxCompileOptions {
  // Method-specific options
  maxIterations?: number
  earlyStoppingPatience?: number
  verbose?: boolean

  // Override args for this specific run
  overrideValidationSet?: readonly AxExample[]
  overrideTargetScore?: number
  overrideCostTracker?: AxCostTracker
  overrideTeacherAI?: AxAIService

  // Progress monitoring overrides
  overrideOnProgress?: (progress: Readonly<AxOptimizationProgress>) => void
  overrideOnEarlyStop?: (
    reason: string,
    stats: Readonly<AxOptimizationStats>
  ) => void

  // Checkpointing overrides
  overrideCheckpointSave?: AxCheckpointSaveFn
  overrideCheckpointLoad?: AxCheckpointLoadFn
  overrideCheckpointInterval?: number
  saveCheckpointOnComplete?: boolean
}

// Enhanced base optimizer interface
export interface AxOptimizer<
  IN extends AxGenIn = AxGenIn,
  OUT extends AxGenOut = AxGenOut,
> {
  /**
   * Optimize a program using the provided metric function
   * @param program The program to optimize (moved from constructor)
   * @param metricFn Evaluation metric function to assess program performance
   * @param options Optional configuration options that can override constructor settings
   * @returns Optimization result containing demos, stats, and configuration
   */
  compile(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMetricFn,
    options?: AxCompileOptions
  ): Promise<AxOptimizerResult<OUT>>

  /**
   * Optimize a program with real-time streaming updates
   * @param program The program to optimize
   * @param metricFn Evaluation metric function
   * @param options Optional configuration options
   * @returns Async iterator yielding optimization progress
   */
  compileStream?(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMetricFn,
    options?: AxCompileOptions
  ): AsyncIterableIterator<AxOptimizationProgress>

  /**
   * Multi-objective optimization using Pareto frontier
   * @param program The program to optimize
   * @param metricFn Multi-objective metric function
   * @param options Optional configuration options
   * @returns Pareto optimization result
   */
  compilePareto?(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMultiMetricFn,
    options?: AxCompileOptions
  ): Promise<AxParetoResult<OUT>>

  /**
   * Get current optimization statistics
   * @returns Current optimization statistics
   */
  getStats(): AxOptimizationStats

  /**
   * Cancel ongoing optimization gracefully
   * @returns Promise that resolves when cancellation is complete
   */
  cancel?(): Promise<void>

  /**
   * Reset optimizer state for reuse with different programs
   */
  reset?(): void

  /**
   * Get optimizer-specific configuration
   * @returns Current optimizer configuration
   */
  getConfiguration?(): Record<string, unknown>

  /**
   * Update optimizer configuration
   * @param config New configuration to merge with existing
   */
  updateConfiguration?(config: Readonly<Record<string, unknown>>): void

  /**
   * Validate that the optimizer can handle the given program
   * @param program Program to validate
   * @returns Validation result with any issues found
   */
  validateProgram?(program: Readonly<AxProgram<IN, OUT>>): {
    isValid: boolean
    issues: string[]
    suggestions: string[]
  }
}

// Specific optimizer options interfaces

export interface AxBootstrapOptimizerOptions {
  maxRounds?: number
  maxExamples?: number
  maxDemos?: number
  batchSize?: number
  earlyStoppingPatience?: number
  teacherAI?: AxAIService
  costMonitoring?: boolean
  maxTokensPerGeneration?: number
  verboseMode?: boolean
  debugMode?: boolean

  // Enhanced options
  adaptiveBatching?: boolean
  dynamicTemperature?: boolean
  qualityThreshold?: number
  diversityWeight?: number
}

export interface AxMiPROOptimizerOptions {
  numCandidates?: number
  initTemperature?: number
  maxBootstrappedDemos?: number
  maxLabeledDemos?: number
  numTrials?: number
  minibatch?: boolean
  minibatchSize?: number
  minibatchFullEvalSteps?: number
  programAwareProposer?: boolean
  dataAwareProposer?: boolean
  viewDataBatchSize?: number
  tipAwareProposer?: boolean
  fewshotAwareProposer?: boolean
  verbose?: boolean
  earlyStoppingTrials?: number
  minImprovementThreshold?: number

  // Enhanced options
  bayesianOptimization?: boolean
  acquisitionFunction?:
    | 'expected_improvement'
    | 'upper_confidence_bound'
    | 'probability_improvement'
  explorationWeight?: number
}

// Legacy compile options (for backward compatibility)
export interface AxBootstrapCompileOptions extends AxCompileOptions {
  valset?: readonly AxExample[]
  maxDemos?: number
  teacherProgram?: Readonly<AxProgram<AxGenIn, AxGenOut>>
}

export interface AxMiPROCompileOptions extends AxCompileOptions {
  valset?: readonly AxExample[]
  teacher?: Readonly<AxProgram<AxGenIn, AxGenOut>>
  auto?: 'light' | 'medium' | 'heavy'

  // Enhanced MiPRO options
  instructionCandidates?: string[]
  customProposer?: (
    context: Readonly<{
      programSummary: string
      dataSummary: string
      previousInstructions: string[]
    }>
  ) => Promise<string[]>
}

// Default cost tracker implementation
export class AxDefaultCostTracker implements AxCostTracker {
  private tokenUsage: Record<string, number> = {}
  private totalTokens = 0

  // Configuration options
  private readonly costPerModel: Record<string, number>
  private readonly maxCost?: number
  private readonly maxTokens?: number

  constructor(options?: AxCostTrackerOptions) {
    this.costPerModel = options?.costPerModel ?? {}
    this.maxCost = options?.maxCost
    this.maxTokens = options?.maxTokens
  }

  trackTokens(count: number, model: string): void {
    this.tokenUsage[model] = (this.tokenUsage[model] || 0) + count
    this.totalTokens += count
  }

  getCurrentCost(): number {
    // Calculate cost on-demand
    let totalCost = 0
    for (const [model, tokens] of Object.entries(this.tokenUsage)) {
      const costPer1K = this.costPerModel[model] || 0.001 // Default fallback
      totalCost += (tokens / 1000) * costPer1K
    }
    return totalCost
  }

  getTokenUsage(): Record<string, number> {
    return { ...this.tokenUsage }
  }

  getTotalTokens(): number {
    return this.totalTokens
  }

  isLimitReached(): boolean {
    // Check token limit if configured
    if (this.maxTokens !== undefined && this.totalTokens >= this.maxTokens) {
      return true
    }

    // Check cost limit if configured (calculate cost on-demand)
    if (this.maxCost !== undefined) {
      const currentCost = this.getCurrentCost()
      if (currentCost >= this.maxCost) {
        return true
      }
    }

    return false
  }

  reset(): void {
    this.tokenUsage = {}
    this.totalTokens = 0
  }
}

/**
 * Abstract base class for optimizers that provides common functionality
 * and standardized handling of AxOptimizerArgs
 */
export abstract class AxBaseOptimizer<
  IN extends AxGenIn = AxGenIn,
  OUT extends AxGenOut = AxGenOut,
> implements AxOptimizer<IN, OUT>
{
  // Common AxOptimizerArgs fields
  protected readonly studentAI: AxAIService
  protected readonly teacherAI?: AxAIService
  protected readonly examples: readonly AxExample[]
  protected readonly validationSet?: readonly AxExample[]
  protected readonly targetScore?: number
  protected readonly minSuccessRate?: number
  protected readonly onProgress?: (
    progress: Readonly<AxOptimizationProgress>
  ) => void
  protected readonly onEarlyStop?: (
    reason: string,
    stats: Readonly<AxOptimizationStats>
  ) => void
  protected readonly costTracker?: AxCostTracker
  protected readonly seed?: number

  // Checkpointing fields
  protected readonly checkpointSave?: AxCheckpointSaveFn
  protected readonly checkpointLoad?: AxCheckpointLoadFn
  protected readonly checkpointInterval?: number
  protected readonly resumeFromCheckpoint?: string

  // Checkpoint state
  private currentRound: number = 0
  private scoreHistory: number[] = []
  private configurationHistory: Record<string, unknown>[] = []

  // Common optimization statistics
  protected stats: AxOptimizationStats

  constructor(args: Readonly<AxOptimizerArgs>) {
    if (args.examples.length === 0) {
      throw new Error('No examples found')
    }

    // Set common fields from AxOptimizerArgs
    this.studentAI = args.studentAI
    this.teacherAI = args.teacherAI
    this.examples = args.examples
    this.validationSet = args.validationSet
    this.targetScore = args.targetScore
    this.minSuccessRate = args.minSuccessRate
    this.onProgress = args.onProgress
    this.onEarlyStop = args.onEarlyStop
    this.seed = args.seed

    // Set up checkpointing
    this.checkpointSave = args.checkpointSave
    this.checkpointLoad = args.checkpointLoad
    this.checkpointInterval = args.checkpointInterval ?? 10 // Default: checkpoint every 10 rounds
    this.resumeFromCheckpoint = args.resumeFromCheckpoint

    // Set up cost tracker with default if not provided
    const costTracker = new AxDefaultCostTracker({
      maxTokens: 1000000,
    })
    this.costTracker = args.costTracker ?? costTracker

    // Initialize common stats structure
    this.stats = this.initializeStats()
  }

  /**
   * Initialize the optimization statistics structure
   */
  protected initializeStats(): AxOptimizationStats {
    return {
      totalCalls: 0,
      successfulDemos: 0,
      estimatedTokenUsage: 0,
      earlyStopped: false,
      resourceUsage: {
        totalTokens: 0,
        totalTime: 0,
        avgLatencyPerEval: 0,
        costByModel: {},
      },
      convergenceInfo: {
        converged: false,
        finalImprovement: 0,
        stagnationRounds: 0,
        convergenceThreshold: 0.01,
      },
    }
  }

  /**
   * Set up reproducible random seed if provided
   */
  protected setupRandomSeed(): void {
    if (this.seed !== undefined) {
      // Note: For full reproducibility, we'd need a proper PRNG
      Math.random = (() => {
        let seed = this.seed!
        return () => {
          seed = (seed * 9301 + 49297) % 233280
          return seed / 233280
        }
      })()
    }
  }

  /**
   * Check if optimization should stop early due to cost limits
   */
  protected checkCostLimits(): boolean {
    return this.costTracker?.isLimitReached() ?? false
  }

  /**
   * Check if target score has been reached
   */
  protected checkTargetScore(currentScore: number): boolean {
    return this.targetScore !== undefined && currentScore >= this.targetScore
  }

  /**
   * Update resource usage statistics
   */
  protected updateResourceUsage(
    startTime: number,
    tokensUsed: number = 0
  ): void {
    this.stats.resourceUsage.totalTime = Date.now() - startTime
    this.stats.resourceUsage.totalTokens += tokensUsed

    if (this.stats.totalCalls > 0) {
      this.stats.resourceUsage.avgLatencyPerEval =
        this.stats.resourceUsage.totalTime / this.stats.totalCalls
    }
  }

  /**
   * Trigger early stopping with appropriate callbacks
   */
  protected triggerEarlyStopping(reason: string, bestScoreRound: number): void {
    this.stats.earlyStopped = true
    this.stats.earlyStopping = {
      bestScoreRound,
      patienceExhausted: reason.includes('improvement'),
      reason,
    }

    if (this.onEarlyStop) {
      this.onEarlyStop(reason, this.stats)
    }
  }

  /**
   * Get the validation set, with fallback to a split of examples
   */
  protected getValidationSet(options?: AxCompileOptions): readonly AxExample[] {
    return (
      options?.overrideValidationSet ||
      this.validationSet ||
      this.examples.slice(0, Math.floor(this.examples.length * 0.2))
    )
  }

  /**
   * Get the AI service to use for a specific task, preferring teacher when available
   * @param preferTeacher Whether to prefer teacher AI over student AI
   * @param options Optional compile options that may override teacher AI
   * @returns The appropriate AI service to use
   */
  protected getAIService(
    preferTeacher: boolean = false,
    options?: AxCompileOptions
  ): AxAIService {
    // Check for override teacher AI first
    if (preferTeacher && options?.overrideTeacherAI) {
      return options.overrideTeacherAI
    }

    // Then check for configured teacher AI
    if (preferTeacher && this.teacherAI) {
      return this.teacherAI
    }

    return this.studentAI
  }

  /**
   * Check if teacher AI is available (including overrides)
   * @param options Optional compile options that may override teacher AI
   * @returns True if teacher AI is configured or overridden
   */
  protected hasTeacherAI(options?: AxCompileOptions): boolean {
    return (
      options?.overrideTeacherAI !== undefined || this.teacherAI !== undefined
    )
  }

  /**
   * Get teacher AI if available, otherwise return student AI
   * @param options Optional compile options that may override teacher AI
   * @returns Teacher AI if available, otherwise student AI
   */
  protected getTeacherOrStudentAI(options?: AxCompileOptions): AxAIService {
    return options?.overrideTeacherAI || this.teacherAI || this.studentAI
  }

  /**
   * Execute a task with teacher AI if available, otherwise use student AI
   * @param task Function that takes an AI service and returns a promise
   * @param preferTeacher Whether to prefer teacher AI (default: true)
   * @param options Optional compile options that may override teacher AI
   * @returns Result of the task execution
   */
  protected async executeWithTeacher<T>(
    task: (ai: AxAIService) => Promise<T>,
    preferTeacher: boolean = true,
    options?: AxCompileOptions
  ): Promise<T> {
    const ai = this.getAIService(preferTeacher, options)
    return await task(ai)
  }

  /**
   * Abstract method that must be implemented by concrete optimizers
   */
  public abstract compile(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMetricFn,
    options?: AxCompileOptions
  ): Promise<AxOptimizerResult<OUT>>

  /**
   * Get current optimization statistics
   */
  public getStats(): AxOptimizationStats {
    return { ...this.stats }
  }

  /**
   * Reset optimizer state for reuse with different programs
   */
  public reset(): void {
    this.stats = this.initializeStats()
    this.costTracker?.reset()
    this.currentRound = 0
    this.scoreHistory = []
    this.configurationHistory = []
  }

  /**
   * Basic program validation that can be extended by concrete optimizers
   */
  public validateProgram(program: Readonly<AxProgram<IN, OUT>>): {
    isValid: boolean
    issues: string[]
    suggestions: string[]
  } {
    const issues: string[] = []
    const suggestions: string[] = []

    // Check if program has required methods for optimization
    if (!('forward' in program) || typeof program.forward !== 'function') {
      issues.push('Program must have a forward method')
    }

    // Check if we have enough examples
    if (this.examples.length < 2) {
      issues.push('Need at least 2 examples for optimization')
      suggestions.push('Provide more training examples')
    }

    // Check if validation set is reasonable
    const valSetSize = this.getValidationSet().length
    if (valSetSize < 1) {
      issues.push('Validation set is empty')
      suggestions.push('Provide examples or a validation set')
    }

    return {
      isValid: issues.length === 0,
      issues,
      suggestions,
    }
  }

  /**
   * Multi-objective optimization using Pareto frontier
   * Default implementation that leverages the single-objective compile method
   * @param program The program to optimize
   * @param metricFn Multi-objective metric function that returns multiple scores
   * @param options Optional configuration options
   * @returns Pareto optimization result with frontier of non-dominated solutions
   */
  public async compilePareto(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMultiMetricFn,
    options?: AxCompileOptions
  ): Promise<AxParetoResult<OUT>> {
    const startTime = Date.now()

    if (options?.verbose) {
      console.log('Starting Pareto optimization using base implementation')
      console.log('This will run multiple single-objective optimizations')
    }

    // Strategy 1: Generate different weighted combinations of objectives
    const solutions = await this.generateWeightedSolutions(
      program,
      metricFn,
      options
    )

    // Strategy 2: Generate constraint-based solutions (optimize one objective while constraining others)
    const constraintSolutions = await this.generateConstraintSolutions(
      program,
      metricFn,
      options
    )

    // Combine all solutions
    const allSolutions = [...solutions, ...constraintSolutions]

    if (options?.verbose) {
      console.log(`Generated ${allSolutions.length} candidate solutions`)
    }

    // Find Pareto frontier
    const paretoFront = this.findParetoFrontier(allSolutions)

    // Calculate hypervolume if possible
    const hypervolume = this.calculateHypervolume(paretoFront)

    if (options?.verbose) {
      console.log(`Found ${paretoFront.length} non-dominated solutions`)
      console.log(`Hypervolume: ${hypervolume?.toFixed(4) || 'N/A'}`)
    }

    // Update stats
    this.updateResourceUsage(startTime)
    this.stats.convergenceInfo.converged = true

    // Calculate best score as the maximum across all objectives and solutions
    const bestScore =
      paretoFront.length > 0
        ? Math.max(
            ...paretoFront.map((sol) => Math.max(...Object.values(sol.scores)))
          )
        : 0

    return {
      demos: paretoFront.length > 0 ? [...paretoFront[0]!.demos] : undefined,
      stats: this.stats,
      bestScore,
      paretoFront,
      hypervolume,
      paretoFrontSize: paretoFront.length,
      finalConfiguration: {
        paretoFrontSize: paretoFront.length,
        hypervolume,
        strategy: 'weighted_combinations_and_constraints',
        numSolutions: allSolutions.length,
      },
    }
  }

  /**
   * Generate solutions using different weighted combinations of objectives
   */
  private async generateWeightedSolutions(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMultiMetricFn,
    options?: AxCompileOptions
  ): Promise<
    Array<{
      scores: Record<string, number>
      demos?: AxProgramDemos<AxGenIn, OUT>[]
      configuration: Record<string, unknown>
    }>
  > {
    const solutions: Array<{
      scores: Record<string, number>
      demos?: AxProgramDemos<AxGenIn, OUT>[]
      configuration: Record<string, unknown>
    }> = []

    // First, determine the objectives by running the metric on a sample
    const sampleExample = this.examples[0]!
    const samplePrediction = await program.forward(
      this.studentAI,
      sampleExample as IN
    )
    const sampleScores = await metricFn({
      prediction: samplePrediction,
      example: sampleExample,
    })
    const objectives = Object.keys(sampleScores)

    if (options?.verbose) {
      console.log(`Detected objectives: ${objectives.join(', ')}`)
    }

    // Generate different weight combinations
    const weightCombinations = this.generateWeightCombinations(objectives)

    for (let i = 0; i < weightCombinations.length; i++) {
      const weights = weightCombinations[i]!

      if (options?.verbose) {
        console.log(`Optimizing with weights: ${JSON.stringify(weights)}`)
      }

      // Create a weighted single-objective metric
      const weightedMetric: AxMetricFn = async ({ prediction, example }) => {
        const scores = await metricFn({ prediction, example })
        let weightedScore = 0
        for (const [objective, score] of Object.entries(scores)) {
          weightedScore += score * (weights[objective] || 0)
        }
        return weightedScore
      }

      try {
        // Use the concrete optimizer's compile method
        const result = await this.compile(program, weightedMetric, {
          ...options,
          verbose: false, // Suppress inner optimization logs
        })

        // Evaluate the result with the multi-objective metric
        const scores = await this.evaluateWithMultiObjective(
          program,
          result,
          metricFn
        )

        solutions.push({
          scores,
          demos: result.demos,
          configuration: {
            ...result.finalConfiguration,
            weights,
            strategy: 'weighted_combination',
          },
        })
      } catch (error) {
        if (options?.verbose) {
          console.warn(
            `Failed optimization with weights ${JSON.stringify(weights)}:`,
            error
          )
        }
        continue
      }
    }

    return solutions
  }

  /**
   * Generate solutions using constraint-based optimization
   */
  private async generateConstraintSolutions(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMultiMetricFn,
    options?: AxCompileOptions
  ): Promise<
    Array<{
      scores: Record<string, number>
      demos?: AxProgramDemos<AxGenIn, OUT>[]
      configuration: Record<string, unknown>
    }>
  > {
    const solutions: Array<{
      scores: Record<string, number>
      demos?: AxProgramDemos<AxGenIn, OUT>[]
      configuration: Record<string, unknown>
    }> = []

    // Get objectives from a sample evaluation
    const sampleExample = this.examples[0]!
    const samplePrediction = await program.forward(
      this.studentAI,
      sampleExample as IN
    )
    const sampleScores = await metricFn({
      prediction: samplePrediction,
      example: sampleExample,
    })
    const objectives = Object.keys(sampleScores)

    // For each objective, optimize it while constraining others
    for (const primaryObjective of objectives) {
      if (options?.verbose) {
        console.log(
          `Optimizing ${primaryObjective} with constraints on other objectives`
        )
      }

      // Create a constraint-based metric
      const constraintMetric: AxMetricFn = async ({ prediction, example }) => {
        const scores = await metricFn({ prediction, example })

        // Primary objective score
        const primaryScore = scores[primaryObjective] || 0

        // Penalty for violating constraints on other objectives
        let penalty = 0
        for (const [objective, score] of Object.entries(scores)) {
          if (objective !== primaryObjective) {
            // Simple constraint: other objectives should be at least 0.3
            // This is a heuristic - in practice you'd set domain-specific thresholds
            if (score < 0.3) {
              penalty += (0.3 - score) * 2 // Penalty factor
            }
          }
        }

        return primaryScore - penalty
      }

      try {
        const result = await this.compile(program, constraintMetric, {
          ...options,
          verbose: false,
        })

        const scores = await this.evaluateWithMultiObjective(
          program,
          result,
          metricFn
        )

        solutions.push({
          scores,
          demos: result.demos,
          configuration: {
            ...result.finalConfiguration,
            primaryObjective,
            strategy: 'constraint_based',
          },
        })
      } catch (error) {
        if (options?.verbose) {
          console.warn(
            `Failed constraint optimization for ${primaryObjective}:`,
            error
          )
        }
        continue
      }
    }

    return solutions
  }

  /**
   * Generate different weight combinations for objectives
   */
  private generateWeightCombinations(
    objectives: string[]
  ): Record<string, number>[] {
    const combinations: Record<string, number>[] = []

    // Single-objective focus (one objective gets weight 1, others get 0)
    for (const objective of objectives) {
      const weights: Record<string, number> = {}
      for (const obj of objectives) {
        weights[obj] = obj === objective ? 1 : 0
      }
      combinations.push(weights)
    }

    // Equal weights
    const equalWeights: Record<string, number> = {}
    for (const objective of objectives) {
      equalWeights[objective] = 1 / objectives.length
    }
    combinations.push(equalWeights)

    // If we have 2 objectives, generate more granular combinations
    if (objectives.length === 2) {
      const [obj1, obj2] = objectives
      for (let w1 = 0.1; w1 <= 0.9; w1 += 0.2) {
        const w2 = 1 - w1
        combinations.push({ [obj1!]: w1, [obj2!]: w2 })
      }
    }

    // If we have 3 objectives, generate some key combinations
    if (objectives.length === 3) {
      const [obj1, obj2, obj3] = objectives
      combinations.push(
        { [obj1!]: 0.5, [obj2!]: 0.3, [obj3!]: 0.2 },
        { [obj1!]: 0.3, [obj2!]: 0.5, [obj3!]: 0.2 },
        { [obj1!]: 0.2, [obj2!]: 0.3, [obj3!]: 0.5 }
      )
    }

    return combinations
  }

  /**
   * Evaluate a single-objective result with multi-objective metrics
   */
  private async evaluateWithMultiObjective(
    program: Readonly<AxProgram<IN, OUT>>,
    result: Readonly<AxOptimizerResult<OUT>>,
    metricFn: AxMultiMetricFn
  ): Promise<Record<string, number>> {
    const valSet = this.getValidationSet()
    const allScores: Record<string, number[]> = {}

    // Apply the optimized configuration to the program
    const testProgram = { ...program }
    if (result.demos && 'setDemos' in testProgram) {
      ;(
        testProgram as unknown as { setDemos: (demos: unknown) => void }
      ).setDemos(result.demos)
    }

    // Evaluate on validation set
    const evalSet = valSet.slice(0, Math.min(5, valSet.length))

    for (const example of evalSet) {
      try {
        const prediction = await testProgram.forward(
          this.studentAI,
          example as IN
        )
        const scores = await metricFn({ prediction, example })

        // Collect scores for each objective
        for (const [objective, score] of Object.entries(scores)) {
          if (!allScores[objective]) {
            allScores[objective] = []
          }
          allScores[objective]!.push(score)
        }
      } catch {
        // Skip failed predictions
        continue
      }
    }

    // Calculate average scores for each objective
    const avgScores: Record<string, number> = {}
    for (const [objective, scores] of Object.entries(allScores)) {
      avgScores[objective] =
        scores.length > 0
          ? scores.reduce((sum, score) => sum + score, 0) / scores.length
          : 0
    }

    return avgScores
  }

  /**
   * Find the Pareto frontier from a set of solutions
   */
  private findParetoFrontier(
    solutions: Array<{
      scores: Record<string, number>
      demos?: AxProgramDemos<AxGenIn, OUT>[]
      configuration: Record<string, unknown>
    }>
  ): Array<{
    demos: readonly AxProgramDemos<AxGenIn, OUT>[]
    scores: Readonly<Record<string, number>>
    configuration: Readonly<Record<string, unknown>>
    dominatedSolutions: number
  }> {
    const paretoFront: Array<{
      demos: readonly AxProgramDemos<AxGenIn, OUT>[]
      scores: Readonly<Record<string, number>>
      configuration: Readonly<Record<string, unknown>>
      dominatedSolutions: number
    }> = []

    // For each solution, check if it's dominated by any other solution
    for (let i = 0; i < solutions.length; i++) {
      const solutionA = solutions[i]!
      let isDominated = false
      let dominatedCount = 0

      for (let j = 0; j < solutions.length; j++) {
        if (i === j) continue

        const solutionB = solutions[j]!

        // Check if B dominates A
        if (this.dominates(solutionB.scores, solutionA.scores)) {
          isDominated = true
          break
        }

        // Count how many solutions A dominates
        if (this.dominates(solutionA.scores, solutionB.scores)) {
          dominatedCount++
        }
      }

      // If A is not dominated by any solution, it's on the Pareto frontier
      if (!isDominated) {
        paretoFront.push({
          demos: solutionA.demos || [],
          scores: solutionA.scores,
          configuration: solutionA.configuration,
          dominatedSolutions: dominatedCount,
        })
      }
    }

    return paretoFront
  }

  /**
   * Check if solution A dominates solution B
   * A dominates B if A is better or equal in all objectives and strictly better in at least one
   */
  private dominates(
    scoresA: Record<string, number>,
    scoresB: Record<string, number>
  ): boolean {
    const objectives = Object.keys(scoresA)

    // Check if A is at least as good as B in all objectives
    let atLeastAsGood = true
    let strictlyBetter = false

    for (const objective of objectives) {
      const scoreA = scoresA[objective] || 0
      const scoreB = scoresB[objective] || 0

      if (scoreA < scoreB) {
        atLeastAsGood = false
        break
      }

      if (scoreA > scoreB) {
        strictlyBetter = true
      }
    }

    return atLeastAsGood && strictlyBetter
  }

  /**
   * Calculate hypervolume of the Pareto frontier
   * Simplified implementation using reference point at origin
   */
  private calculateHypervolume(
    paretoFront: Array<{
      scores: Readonly<Record<string, number>>
    }>
  ): number | undefined {
    if (paretoFront.length === 0) return undefined

    // For simplicity, calculate 2D hypervolume if we have exactly 2 objectives
    const firstSolution = paretoFront[0]!
    const objectives = Object.keys(firstSolution.scores)

    if (objectives.length === 2) {
      const [obj1, obj2] = objectives
      let hypervolume = 0

      // Sort solutions by first objective (descending)
      const sortedSolutions = [...paretoFront].sort(
        (a, b) => (b.scores[obj1!] || 0) - (a.scores[obj1!] || 0)
      )

      let prevScore2 = 0
      for (const solution of sortedSolutions) {
        const score1 = solution.scores[obj1!] || 0
        const score2 = solution.scores[obj2!] || 0

        // Calculate area contribution
        hypervolume += score1 * (score2 - prevScore2)
        prevScore2 = Math.max(prevScore2, score2)
      }

      return hypervolume
    }

    // For higher dimensions, return undefined (would need more complex algorithm)
    return undefined
  }

  /**
   * Save current optimization state to checkpoint
   */
  protected async saveCheckpoint(
    optimizerType: string,
    optimizerConfig: Record<string, unknown>,
    bestScore: number,
    bestConfiguration?: Record<string, unknown>,
    optimizerState: Record<string, unknown> = {},
    options?: AxCompileOptions
  ): Promise<string | undefined> {
    const saveFn = options?.overrideCheckpointSave || this.checkpointSave
    if (!saveFn) return undefined

    const checkpoint: AxOptimizationCheckpoint = {
      version: '1.0.0',
      timestamp: Date.now(),
      optimizerType,
      optimizerConfig,
      currentRound: this.currentRound,
      totalRounds:
        this.stats.resourceUsage.totalTime > 0 ? this.currentRound : 0,
      bestScore,
      bestConfiguration,
      scoreHistory: [...this.scoreHistory],
      configurationHistory: [...this.configurationHistory],
      stats: { ...this.stats },
      optimizerState,
      examples: this.examples,
      validationSet: this.validationSet,
    }

    return await saveFn(checkpoint)
  }

  /**
   * Load optimization state from checkpoint
   */
  protected async loadCheckpoint(
    checkpointId: string,
    options?: AxCompileOptions
  ): Promise<AxOptimizationCheckpoint | null> {
    const loadFn = options?.overrideCheckpointLoad || this.checkpointLoad
    if (!loadFn) return null

    return await loadFn(checkpointId)
  }

  /**
   * Restore optimizer state from checkpoint
   */
  protected restoreFromCheckpoint(
    checkpoint: Readonly<AxOptimizationCheckpoint>
  ): void {
    this.currentRound = checkpoint.currentRound
    this.scoreHistory = [...checkpoint.scoreHistory]
    this.configurationHistory = [...checkpoint.configurationHistory]
    this.stats = { ...checkpoint.stats }
  }

  /**
   * Check if checkpoint should be saved
   */
  protected shouldSaveCheckpoint(
    round: number,
    options?: AxCompileOptions
  ): boolean {
    const interval =
      options?.overrideCheckpointInterval || this.checkpointInterval
    return interval !== undefined && round % interval === 0
  }

  /**
   * Update optimization progress and handle checkpointing
   */
  protected async updateOptimizationProgress(
    round: number,
    score: number,
    configuration: Record<string, unknown>,
    optimizerType: string,
    optimizerConfig: Record<string, unknown>,
    bestScore: number,
    bestConfiguration?: Record<string, unknown>,
    optimizerState: Record<string, unknown> = {},
    options?: AxCompileOptions
  ): Promise<void> {
    this.currentRound = round
    this.scoreHistory.push(score)
    this.configurationHistory.push(configuration)

    // Save checkpoint if needed
    if (this.shouldSaveCheckpoint(round, options)) {
      await this.saveCheckpoint(
        optimizerType,
        optimizerConfig,
        bestScore,
        bestConfiguration,
        optimizerState,
        options
      )
    }
  }

  /**
   * Save final checkpoint on completion
   */
  protected async saveFinalCheckpoint(
    optimizerType: string,
    optimizerConfig: Record<string, unknown>,
    bestScore: number,
    bestConfiguration?: Record<string, unknown>,
    optimizerState: Record<string, unknown> = {},
    options?: AxCompileOptions
  ): Promise<void> {
    if (options?.saveCheckpointOnComplete !== false) {
      await this.saveCheckpoint(
        optimizerType,
        optimizerConfig,
        bestScore,
        bestConfiguration,
        { ...optimizerState, final: true },
        options
      )
    }
  }
}



================================================
FILE: src/ax/dsp/parser.test.ts
================================================
import { describe, expect, it } from 'vitest'

import { parseSignature } from './parser.js'

describe('SignatureParser', () => {
  describe('basic parsing', () => {
    it('parses a simple signature without description', () => {
      const sig = parseSignature('userQuestion:string -> modelAnswer:number')

      expect(sig.desc).toBeUndefined()
      expect(sig.inputs).toHaveLength(1)
      expect(sig.outputs).toHaveLength(1)

      const input0 = sig.inputs[0] as {
        name: string
        type: { name: string; isArray: boolean }
        isOptional: boolean
        desc?: string
      }
      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(input0).toEqual({
        name: 'userQuestion',
        type: { name: 'string', isArray: false },
        isOptional: undefined,
        desc: undefined,
      })

      expect(output0).toEqual({
        name: 'modelAnswer',
        type: { name: 'number', isArray: false },
        isOptional: false,
        isInternal: false,
        desc: undefined,
      })
    })

    it('parses a signature with description', () => {
      const sig = parseSignature(
        '"This is a test" userQuestion:string -> modelAnswer:number'
      )

      expect(sig.desc).toBe('This is a test')
      expect(sig.inputs).toHaveLength(1)
      expect(sig.outputs).toHaveLength(1)
    })
  })

  describe('field descriptions', () => {
    it('parses fields with descriptions', () => {
      const sig = parseSignature(
        'userQuestion:string "input description" -> modelAnswer:number "output description"'
      )

      const input0 = sig.inputs[0] as {
        name: string
        type: { name: string; isArray: boolean }
        isOptional: boolean
        desc?: string
      }
      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(input0.desc).toBe('input description')
      expect(output0.desc).toBe('output description')
    })

    it('handles both single and double quoted descriptions', () => {
      const sig = parseSignature(
        'userQuestion:string "double quotes", userParam:number \'single quotes\' -> modelAnswer:string "result"'
      )

      const input0 = sig.inputs[0] as {
        name: string
        type: { name: string; isArray: boolean }
        isOptional: boolean
        desc?: string
      }
      const input1 = sig.inputs[1] as {
        name: string
        type: { name: string; isArray: boolean }
        isOptional: boolean
        desc?: string
      }
      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(input0.desc).toBe('double quotes')
      expect(input1.desc).toBe('single quotes')
      expect(output0.desc).toBe('result')
    })
  })

  describe('optional fields', () => {
    it('parses optional input fields', () => {
      const sig = parseSignature(
        'requiredField:string, optionalField?:number -> modelAnswer:string'
      )

      const input0 = sig.inputs[0] as {
        name: string
        type: { name: string; isArray: boolean }
        isOptional: boolean
        desc?: string
      }
      const input1 = sig.inputs[1] as {
        name: string
        type: { name: string; isArray: boolean }
        isOptional: boolean
        desc?: string
      }

      expect(input0.isOptional).toBe(undefined)
      expect(input1.isOptional).toBe(true)
    })

    it('parses optional output fields', () => {
      const sig = parseSignature(
        'userQuestion:string -> requiredField:string, optionalField?:number'
      )

      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }
      const output1 = sig.outputs[1] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(output0.isOptional).toBe(false)
      expect(output1.isOptional).toBe(true)
    })
  })

  describe('internal marker', () => {
    it('parses output field with internal marker', () => {
      const sig = parseSignature('userQuestion:string -> modelAnswer!:number')
      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }
      expect(output0.isInternal).toBe(true)
    })

    it('parses output field with both optional and internal markers', () => {
      const sig = parseSignature('userQuestion:string -> modelAnswer?!:number')
      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }
      expect(output0.isOptional).toBe(true)
      expect(output0.isInternal).toBe(true)
    })

    it('throws error for input field with internal marker', () => {
      expect(() =>
        parseSignature('userQuestion!:string -> modelAnswer:number')
      ).toThrow(/cannot use the internal marker/)
    })
  })

  describe('array types', () => {
    it('parses array types', () => {
      const sig = parseSignature(
        'userQuestions:string[] -> modelAnswers:number[]'
      )

      const input0 = sig.inputs[0] as {
        name: string
        type: { name: string; isArray: boolean }
        isOptional: boolean
        desc?: string
      }
      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(input0.type?.isArray).toBe(true)
      expect(output0.type?.isArray).toBe(true)
    })

    it('handles mix of array and non-array types', () => {
      const sig = parseSignature(
        'userQuestion:string, userQuestions:number[] -> modelAnswers:boolean[]'
      )

      const input0 = sig.inputs[0] as {
        name: string
        type: { name: string; isArray: boolean }
        isOptional: boolean
        desc?: string
      }
      const input1 = sig.inputs[1] as {
        name: string
        type: { name: string; isArray: boolean }
        isOptional: boolean
        desc?: string
      }
      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(input0.type?.isArray).toBe(false)
      expect(input1.type?.isArray).toBe(true)
      expect(output0.type?.isArray).toBe(true)
    })
  })

  describe('class types', () => {
    it('parses class types with single class', () => {
      const sig = parseSignature(
        'userQuestion:string -> categoryType:class "option1, option2"'
      )

      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(output0.type?.name).toBe('class')
      if (output0.type?.name === 'class') {
        const classType = output0.type as {
          name: 'class'
          isArray: boolean
          options: string[]
        }
        expect(classType.options).toEqual(['option1', 'option2'])
      }
    })

    it('parses class types with multiple options', () => {
      const sig = parseSignature(
        'userQuestion:string -> categoryType:class "positive, negative, neutral"'
      )

      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(output0.type?.name).toBe('class')
      if (output0.type?.name === 'class') {
        const classType = output0.type as {
          name: 'class'
          isArray: boolean
          options: string[]
        }
        expect(classType.options).toEqual(['positive', 'negative', 'neutral'])
      }
    })

    it('handles array of options', () => {
      const sig = parseSignature(
        'userQuestion:string -> categoryTypes:class[] "option1, option2"'
      )

      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(output0.type?.name).toBe('class')
      expect(output0.type?.isArray).toBe(true)
      if (output0.type?.name === 'class') {
        const classType = output0.type as {
          name: 'class'
          isArray: boolean
          options: string[]
        }
        expect(classType.options).toEqual(['option1', 'option2'])
      }
    })

    it('throws error for input field with class type', () => {
      expect(() =>
        parseSignature('categoryType:class "a,b" -> modelAnswer:string')
      ).toThrow(/cannot use the "class" type/)
    })

    it('throws error for missing class options', () => {
      expect(() =>
        parseSignature('userQuestion:string -> categoryType:class ""')
      ).toThrow(/Missing class options/)
    })

    it('parses class types with pipe separator', () => {
      const sig = parseSignature(
        'userQuestion:string -> categoryType:class "option1 | option2 | option3"'
      )

      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(output0.type?.name).toBe('class')
      if (output0.type?.name === 'class') {
        const classType = output0.type as {
          name: 'class'
          isArray: boolean
          options: string[]
        }
        expect(classType.options).toEqual(['option1', 'option2', 'option3'])
      }
    })

    it('parses class types with mixed separators', () => {
      const sig = parseSignature(
        'userQuestion:string -> categoryType:class "option1, option2 | option3"'
      )

      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(output0.type?.name).toBe('class')
      if (output0.type?.name === 'class') {
        const classType = output0.type as {
          name: 'class'
          isArray: boolean
          options: string[]
        }
        expect(classType.options).toEqual(['option1', 'option2', 'option3'])
      }
    })

    it('parses class options with mixed separators and spacing', () => {
      const sig = parseSignature(
        'userQuestion:string -> categoryType:class "valid, option,with,comma"'
      )

      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(output0.type?.name).toBe('class')
      if (output0.type?.name === 'class') {
        const classType = output0.type as {
          name: 'class'
          isArray: boolean
          options: string[]
        }
        expect(classType.options).toEqual(['valid', 'option', 'with', 'comma'])
      }
    })

    it('parses class options with pipe separators and mixed spacing', () => {
      const sig = parseSignature(
        'userQuestion:string -> categoryType:class "valid | option|with|pipe"'
      )

      const output0 = sig.outputs[0] as {
        name: string
        type:
          | { name: string; isArray: boolean }
          | { name: 'class'; isArray: boolean; options: string[] }
        isOptional: boolean
        isInternal: boolean
        desc?: string
      }

      expect(output0.type?.name).toBe('class')
      if (output0.type?.name === 'class') {
        const classType = output0.type as {
          name: 'class'
          isArray: boolean
          options: string[]
        }
        expect(classType.options).toEqual(['valid', 'option', 'with', 'pipe'])
      }
    })
  })

  describe('duplicate fields', () => {
    it('throws error for duplicate input fields', () => {
      expect(() =>
        parseSignature(
          'userQuestion:string, userQuestion:number -> modelAnswer:string'
        )
      ).toThrow(/Duplicate input field name/)
    })

    it('throws error for duplicate output fields', () => {
      expect(() =>
        parseSignature(
          'userQuestion:string -> modelAnswer:string, modelAnswer:number'
        )
      ).toThrow(/Duplicate output field name/)
    })

    it('throws error for fields in both input and output', () => {
      expect(() =>
        parseSignature('userQuestion:string -> userQuestion:string')
      ).toThrow(/appears in both inputs and outputs/)
    })
  })

  describe('error cases', () => {
    it('throws on empty signature', () => {
      expect(() => parseSignature('')).toThrow('Empty signature provided')
    })

    it('throws on missing arrow', () => {
      expect(() =>
        parseSignature('userQuestion:string modelAnswer:string')
      ).toThrow('Expected "->"')
    })

    it('throws on missing output fields', () => {
      expect(() => parseSignature('userQuestion:string ->')).toThrow(
        'No output fields specified'
      )
    })

    it('throws on invalid type', () => {
      expect(() =>
        parseSignature('userQuestion:invalid -> modelAnswer:string')
      ).toThrow('Invalid type "invalid"')
    })

    it('throws on unterminated string', () => {
      expect(() =>
        parseSignature(
          'userQuestion:string "unterminated -> modelAnswer:string'
        )
      ).toThrow('Unterminated string')
    })

    it('throws on unexpected content after signature', () => {
      expect(() =>
        parseSignature(
          'userQuestion:string -> modelAnswer:string extra content'
        )
      ).toThrow('Unexpected content after signature')
    })

    it('throws on invalid field name characters', () => {
      expect(() =>
        parseSignature('invalid-name:string -> modelAnswer:string')
      ).toThrow('Expected "->"')
    })

    it('throws on field names starting with numbers', () => {
      expect(() =>
        parseSignature('1name:string -> modelAnswer:string')
      ).toThrow('cannot start with a number')
    })
  })

  describe('whitespace handling', () => {
    ;[
      'userQuestion:string -> modelAnswer:number',
      ' userQuestion:string -> modelAnswer:number',
      'userQuestion:string -> modelAnswer:number ',
      ' userQuestion:string  ->  modelAnswer:number ',
      '\tuserQuestion:string -> modelAnswer:number\n',
    ].forEach((sigStr) => {
      it(`handles various whitespace patterns for signature: "${sigStr}"`, () => {
        const sig = parseSignature(sigStr)
        expect(sig.inputs).toHaveLength(1)
        expect(sig.outputs).toHaveLength(1)
        expect(sig.inputs[0]?.name).toBe('userQuestion')
        expect(sig.outputs[0]?.name).toBe('modelAnswer')
      })
    })
  })
})



================================================
FILE: src/ax/dsp/parser.ts
================================================
// Updated type definitions

export type TypeNotClass =
  | 'string'
  | 'number'
  | 'boolean'
  | 'json'
  | 'image'
  | 'audio'
  | 'datetime'
  | 'date'
  | 'code'
export type Type = TypeNotClass | 'class'
export type ParsedIdentifier = string
export type ParsedString = string

export type ParsedSignature = {
  desc?: string
  inputs: InputParsedField[]
  outputs: OutputParsedField[]
}

export type InputParsedField = {
  name: ParsedIdentifier
  desc?: string
  type?: { name: TypeNotClass; isArray: boolean }
  isOptional?: boolean
}

export type OutputParsedField = {
  name: ParsedIdentifier
  desc?: string
  type?:
    | { name: TypeNotClass; isArray: boolean; options?: string[] }
    | { name: 'class'; isArray: boolean; options: string[] }
  isOptional?: boolean
  isInternal?: boolean
}

import { axGlobals } from './globals.js'

class SignatureValidationError extends Error {
  constructor(
    message: string,
    public readonly position: number,
    public readonly context: string,
    public readonly suggestion?: string
  ) {
    super(message)
    this.name = 'SignatureValidationError'
  }
}

class SignatureParser {
  private input: string
  private position: number
  private currentFieldName: string | null = null
  private currentSection: 'description' | 'inputs' | 'outputs' = 'description'

  constructor(input: string) {
    this.input = input.trim()
    this.position = 0

    if (!this.input) {
      throw new SignatureValidationError(
        'Empty signature provided',
        0,
        '',
        'A signature must contain at least input and output fields separated by "->". Example: "userQuery:string -> aiResponse:string"'
      )
    }
  }

  parse(): ParsedSignature {
    try {
      this.skipWhitespace()
      const optionalDesc = this.parseParsedString()
      this.skipWhitespace()

      this.currentSection = 'inputs'
      // Use the specialized input field parser
      const inputs = this.parseFieldList(
        this.parseInputField.bind(this),
        'input'
      )
      this.skipWhitespace()

      if (this.position >= this.input.length) {
        throw new SignatureValidationError(
          'Incomplete signature: Missing output section',
          this.position,
          this.getErrorContext(),
          'Add "->" followed by output fields. Example: "-> responseText:string"'
        )
      }

      this.expectArrow()
      this.skipWhitespace()

      if (this.position >= this.input.length) {
        throw new SignatureValidationError(
          'Incomplete signature: No output fields specified after "->"',
          this.position,
          this.getErrorContext(),
          'Add at least one output field. Example: "-> responseText:string"'
        )
      }

      this.currentSection = 'outputs'
      // Use the specialized output field parser
      const outputs = this.parseFieldList(
        this.parseOutputField.bind(this),
        'output'
      )

      // Check for any remaining content that shouldn't be there
      this.skipWhitespace()
      if (this.position < this.input.length) {
        const remaining = this.input.slice(this.position)
        throw new SignatureValidationError(
          `Unexpected content after signature: "${remaining}"`,
          this.position,
          this.getErrorContext(),
          'Remove any extra content after the output fields'
        )
      }

      // Validate the parsed signature
      this.validateParsedSignature({
        desc: optionalDesc?.trim(),
        inputs,
        outputs,
      })

      return {
        desc: optionalDesc?.trim(),
        inputs,
        outputs,
      }
    } catch (error) {
      if (error instanceof SignatureValidationError) {
        throw error
      }

      // Wrap other errors with better context
      const errorMessage =
        error instanceof Error ? error.message : 'Unknown error'
      throw new SignatureValidationError(
        errorMessage,
        this.position,
        this.getErrorContext()
      )
    }
  }

  private validateParsedSignature(signature: Readonly<ParsedSignature>): void {
    // Check for duplicate field names within inputs
    const inputNames = new Set<string>()
    for (const field of signature.inputs) {
      if (inputNames.has(field.name)) {
        throw new SignatureValidationError(
          `Duplicate input field name: "${field.name}"`,
          0,
          '',
          'Each field name must be unique within the signature'
        )
      }
      inputNames.add(field.name)
    }

    // Check for duplicate field names within outputs
    const outputNames = new Set<string>()
    for (const field of signature.outputs) {
      if (outputNames.has(field.name)) {
        throw new SignatureValidationError(
          `Duplicate output field name: "${field.name}"`,
          0,
          '',
          'Each field name must be unique within the signature'
        )
      }
      outputNames.add(field.name)
    }

    // Check for field names that appear in both inputs and outputs
    for (const outputField of signature.outputs) {
      if (inputNames.has(outputField.name)) {
        throw new SignatureValidationError(
          `Field name "${outputField.name}" appears in both inputs and outputs`,
          0,
          '',
          'Use different names for input and output fields to avoid confusion'
        )
      }
    }

    // Validate that we have at least one input and one output
    if (signature.inputs.length === 0) {
      throw new SignatureValidationError(
        'Signature must have at least one input field',
        0,
        '',
        'Add an input field before "->". Example: "userInput:string -> ..."'
      )
    }

    if (signature.outputs.length === 0) {
      throw new SignatureValidationError(
        'Signature must have at least one output field',
        0,
        '',
        'Add an output field after "->". Example: "... -> responseText:string"'
      )
    }
  }

  private getErrorContext(): string {
    const start = Math.max(0, this.position - 25)
    const end = Math.min(this.input.length, this.position + 25)
    const before = this.input.slice(start, this.position)
    const after = this.input.slice(this.position, end)
    const pointer = ' '.repeat(before.length) + '^'

    const lines = [
      `Position ${this.position} in signature:`,
      `"${before}${after}"`,
      ` ${pointer}`,
    ]

    return lines.join('\n')
  }

  private parseFieldList<T extends InputParsedField | OutputParsedField>(
    parseFieldFn: () => T,
    section: 'input' | 'output'
  ): T[] {
    const fields: T[] = []
    this.skipWhitespace()

    if (this.position >= this.input.length) {
      throw new SignatureValidationError(
        `Empty ${section} section: Expected at least one field`,
        this.position,
        this.getErrorContext(),
        `Add a ${section} field. Example: ${section === 'input' ? 'userInput:string' : 'responseText:string'}`
      )
    }

    // Parse first field
    try {
      fields.push(parseFieldFn())
    } catch (error) {
      if (error instanceof SignatureValidationError) {
        throw error
      }
      throw new SignatureValidationError(
        `Invalid first ${section} field: ${error instanceof Error ? error.message : 'Unknown error'}`,
        this.position,
        this.getErrorContext()
      )
    }

    this.skipWhitespace()

    // Parse remaining fields
    while (this.position < this.input.length) {
      if (
        this.input[this.position] === '-' &&
        this.position + 1 < this.input.length &&
        this.input[this.position + 1] === '>'
      ) {
        break
      }

      if (this.match(',')) {
        this.skipWhitespace()
        if (this.position >= this.input.length) {
          throw new SignatureValidationError(
            `Unexpected end of input after comma in ${section} section`,
            this.position,
            this.getErrorContext(),
            `Add another ${section} field after the comma`
          )
        }
        try {
          fields.push(parseFieldFn())
        } catch (error) {
          if (error instanceof SignatureValidationError) {
            throw error
          }
          throw new SignatureValidationError(
            `Invalid ${section} field after comma: ${error instanceof Error ? error.message : 'Unknown error'}`,
            this.position,
            this.getErrorContext()
          )
        }
        this.skipWhitespace()
      } else {
        break
      }
    }

    return fields
  }

  // -------------------------------
  // Parse input fields (no "class" type and no internal flag)
  // -------------------------------
  private parseInputField(): InputParsedField {
    this.skipWhitespace()
    const name = this.parseParsedIdentifier()
    this.currentFieldName = name

    // Validate field name for inputs
    this.validateFieldName(name, 'input')

    // Only the optional marker is allowed
    let isOptional = undefined
    while (true) {
      if (this.match('?')) {
        isOptional = true
        continue
      }
      if (this.match('!')) {
        throw new SignatureValidationError(
          `Input field "${name}" cannot use the internal marker "!"`,
          this.position - 1,
          this.getErrorContext(),
          'Internal markers (!) are only allowed on output fields'
        )
      }
      break
    }

    let type: { name: TypeNotClass; isArray: boolean } | undefined
    this.skipWhitespace()
    if (this.match(':')) {
      this.skipWhitespace()
      // Disallow the "class" type in input fields
      if (/^class\b/.test(this.input.slice(this.position))) {
        throw new SignatureValidationError(
          `Input field "${name}" cannot use the "class" type`,
          this.position,
          this.getErrorContext(),
          'Class types are only allowed on output fields. Use "string" type for input classifications'
        )
      } else {
        try {
          const typeName = this.parseTypeNotClass()
          const isArray = this.match('[]')
          type = { name: typeName, isArray }

          // Validate specific type constraints for input fields
          if ((typeName === 'image' || typeName === 'audio') && isArray) {
            throw new SignatureValidationError(
              `Input field "${name}": Arrays of ${typeName} are not supported`,
              this.position,
              this.getErrorContext(),
              `Use a single ${typeName} type instead: "${typeName}"`
            )
          }
        } catch (error) {
          if (error instanceof SignatureValidationError) {
            throw error
          }
          throw new SignatureValidationError(
            `Input field "${name}": ${error instanceof Error ? error.message : 'Unknown error'}`,
            this.position,
            this.getErrorContext()
          )
        }
      }
    }

    this.skipWhitespace()
    const desc = this.parseParsedString()

    return {
      name,
      desc: desc?.trim(),
      type,
      isOptional,
    }
  }

  // -------------------------------
  // Parse output fields (supports both "class" type and the internal marker)
  // -------------------------------
  private parseOutputField(): OutputParsedField {
    this.skipWhitespace()
    const name = this.parseParsedIdentifier()
    this.currentFieldName = name

    // Validate field name for outputs
    this.validateFieldName(name, 'output')

    let isOptional = false
    let isInternal = false
    while (true) {
      if (this.match('?')) {
        isOptional = true
        continue
      }
      if (this.match('!')) {
        isInternal = true
        continue
      }
      break
    }

    let type:
      | { name: TypeNotClass; isArray: boolean; options?: string[] }
      | { name: 'class'; isArray: boolean; options: string[] }
      | undefined
    this.skipWhitespace()
    if (this.match(':')) {
      this.skipWhitespace()
      if (this.match('class')) {
        const isArray = this.match('[]')
        this.skipWhitespace()
        const classNamesString = this.parseParsedString()
        if (!classNamesString) {
          throw new SignatureValidationError(
            `Output field "${name}": Missing class options after "class" type`,
            this.position,
            this.getErrorContext(),
            'Add class names in quotes. Example: class "positive, negative, neutral"'
          )
        }
        const options = classNamesString
          .split(/[,|]/)
          .map((s) => s.trim())
          .filter((s) => s.length > 0)

        if (options.length === 0) {
          throw new SignatureValidationError(
            `Output field "${name}": Empty class list provided`,
            this.position,
            this.getErrorContext(),
            'Provide at least one class option. Example: "positive, negative"'
          )
        }

        type = { name: 'class', isArray, options }
      } else {
        try {
          const typeName = this.parseTypeNotClass()
          const isArray = this.match('[]')
          type = { name: typeName, isArray }

          // Validate specific type constraints
          if (typeName === 'image' && isArray) {
            throw new SignatureValidationError(
              `Output field "${name}": Arrays of images are not supported`,
              this.position,
              this.getErrorContext(),
              'Use a single image type instead: "image"'
            )
          }

          if (typeName === 'audio' && isArray) {
            throw new SignatureValidationError(
              `Output field "${name}": Arrays of audio are not supported`,
              this.position,
              this.getErrorContext(),
              'Use a single audio type instead: "audio"'
            )
          }

          if (typeName === 'image') {
            throw new SignatureValidationError(
              `Output field "${name}": Image type is not supported in output fields`,
              this.position,
              this.getErrorContext(),
              'Image types can only be used in input fields'
            )
          }

          if (typeName === 'audio') {
            throw new SignatureValidationError(
              `Output field "${name}": Audio type is not supported in output fields`,
              this.position,
              this.getErrorContext(),
              'Audio types can only be used in input fields'
            )
          }
        } catch (error) {
          if (error instanceof SignatureValidationError) {
            throw error
          }
          throw new SignatureValidationError(
            `Output field "${name}": ${error instanceof Error ? error.message : 'Unknown error'}`,
            this.position,
            this.getErrorContext()
          )
        }
      }
    }

    this.skipWhitespace()
    const desc = this.parseParsedString()

    return {
      name,
      desc: desc?.trim(),
      type,
      isOptional,
      isInternal,
    }
  }

  private validateFieldName(name: string, fieldType: 'input' | 'output'): void {
    // Check for reserved/generic names that should be more descriptive
    if (axGlobals.signatureStrict) {
      const reservedNames = [
        'text',
        'object',
        'image',
        'string',
        'number',
        'boolean',
        'json',
        'array',
        'datetime',
        'date',
        'time',
        'type',
        'class',
        'input',
        'output',
        'data',
        'value',
        'result',
        'response',
        'request',
        'item',
        'element',
      ]

      if (reservedNames.includes(name.toLowerCase())) {
        const suggestions =
          fieldType === 'input'
            ? ['userInput', 'questionText', 'documentContent', 'messageText']
            : ['responseText', 'analysisResult', 'categoryType', 'summaryText']

        throw new SignatureValidationError(
          `Field name "${name}" is too generic`,
          this.position,
          this.getErrorContext(),
          `Use a more descriptive name. Examples: ${suggestions.join(', ')}`
        )
      }
    }

    // Check naming convention
    const camelCaseRegex = /^[a-z][a-zA-Z0-9]*$/
    const snakeCaseRegex = /^[a-z]+(_[a-z0-9]+)*$/

    if (!camelCaseRegex.test(name) && !snakeCaseRegex.test(name)) {
      throw new SignatureValidationError(
        `Invalid field name "${name}"`,
        this.position,
        this.getErrorContext(),
        'Field names must be in camelCase (e.g., "userInput") or snake_case (e.g., "user_input")'
      )
    }

    // Check for minimum length
    if (name.length < 2) {
      throw new SignatureValidationError(
        `Field name "${name}" is too short`,
        this.position,
        this.getErrorContext(),
        'Field names must be at least 2 characters long'
      )
    }

    // Check for maximum length
    if (name.length > 50) {
      throw new SignatureValidationError(
        `Field name "${name}" is too long (${name.length} characters)`,
        this.position,
        this.getErrorContext(),
        'Field names should be 50 characters or less'
      )
    }
  }

  private parseTypeNotClass(): TypeNotClass {
    const types: TypeNotClass[] = [
      'string',
      'number',
      'boolean',
      'json',
      'image',
      'audio',
      'datetime',
      'date',
      'code',
    ]

    const foundType = types.find((type) => this.match(type))
    if (!foundType) {
      const currentWord =
        this.input.slice(this.position).match(/^\w+/)?.[0] || ''
      const suggestion = this.suggestType(currentWord)

      const baseMessage = `Invalid type "${currentWord || 'empty'}"`
      const suggestionPart = suggestion ? `. Did you mean "${suggestion}"?` : ''
      const fullMessage = `${baseMessage}${suggestionPart}`

      throw new SignatureValidationError(
        fullMessage,
        this.position,
        this.getErrorContext(),
        `Expected one of: ${types.join(', ')}`
      )
    }
    return foundType
  }

  private suggestType(input: string): string | null {
    const suggestions: Record<string, string> = {
      str: 'string',
      text: 'string',
      int: 'number',
      integer: 'number',
      float: 'number',
      double: 'number',
      bool: 'boolean',
      object: 'json',
      dict: 'json',
      timestamp: 'datetime',
      time: 'datetime',
      img: 'image',
      picture: 'image',
      sound: 'audio',
      voice: 'audio',
      classification: 'class',
      category: 'class',
    }

    return suggestions[input.toLowerCase()] || null
  }

  private parseParsedIdentifier(): ParsedIdentifier {
    this.skipWhitespace()
    const match = /^[a-zA-Z_][a-zA-Z_0-9]*/.exec(
      this.input.slice(this.position)
    )
    if (match) {
      this.position += match[0].length
      return match[0]
    }

    const invalidMatch = /^\S+/.exec(this.input.slice(this.position))
    const invalidId = invalidMatch ? invalidMatch[0] : ''

    if (invalidId === '') {
      throw new SignatureValidationError(
        'Expected field name but found end of input',
        this.position,
        this.getErrorContext(),
        'Add a field name. Field names must start with a letter or underscore'
      )
    }

    if (/^\d/.test(invalidId)) {
      throw new SignatureValidationError(
        `Invalid field name "${invalidId}" - cannot start with a number`,
        this.position,
        this.getErrorContext(),
        'Field names must start with a letter or underscore. Example: "userInput" or "_internal"'
      )
    }

    throw new SignatureValidationError(
      `Invalid field name "${invalidId}"`,
      this.position,
      this.getErrorContext(),
      'Field names must start with a letter or underscore and contain only letters, numbers, or underscores'
    )
  }

  private parseParsedString(): string | undefined {
    const quoteChars = ["'", '"']
    for (const quoteChar of quoteChars) {
      if (this.match(quoteChar)) {
        let content = ''
        let escaped = false
        const startPos = this.position - 1

        while (this.position < this.input.length) {
          const char = this.input[this.position]
          this.position++
          if (escaped) {
            content += char
            escaped = false
          } else if (char === '\\') {
            escaped = true
          } else if (char === quoteChar) {
            return content
          } else {
            content += char
          }
        }

        const partialString = this.input.slice(
          startPos,
          Math.min(this.position, startPos + 20)
        )
        throw new SignatureValidationError(
          `Unterminated string starting at position ${startPos}`,
          startPos,
          this.getErrorContext(),
          `Add closing ${quoteChar} to complete the string: ${partialString}${quoteChar}`
        )
      }
    }
    return undefined
  }

  private skipWhitespace() {
    const match = /^[\s\t\r\n]+/.exec(this.input.slice(this.position))
    if (match) {
      this.position += match[0].length
    }
  }

  private match(strOrRegex: string | RegExp): boolean {
    let match
    if (typeof strOrRegex === 'string') {
      if (this.input.startsWith(strOrRegex, this.position)) {
        this.position += strOrRegex.length
        return true
      }
    } else {
      match = strOrRegex.exec(this.input.slice(this.position))
      if (match) {
        this.position += match[0].length
        return true
      }
    }
    return false
  }

  private expectArrow() {
    if (!this.match('->')) {
      const found = this.input.slice(this.position, this.position + 10)
      const suggestion = found.includes('>')
        ? 'Use "->" (dash followed by greater-than)'
        : found.includes('-')
          ? 'Add ">" after the dash'
          : 'Add "->" to separate input and output fields'

      throw new SignatureValidationError(
        `Expected "->" but found "${found}..."`,
        this.position,
        this.getErrorContext(),
        suggestion
      )
    }
  }
}

export function parseSignature(input: string): ParsedSignature {
  const parser = new SignatureParser(input)
  return parser.parse()
}



================================================
FILE: src/ax/dsp/program.ts
================================================
import type { Tracer } from '@opentelemetry/api'

import type {
  AxAIService,
  AxChatRequest,
  AxChatResponse,
  AxLoggerFunction,
  AxModelConfig,
  AxRateLimiterFunction,
} from '../ai/types.js'
import type { AxAIMemory } from '../mem/types.js'

import type { AxAssertion, AxStreamingAssertion } from './asserts.js'
import type { AxInputFunctionType } from './functions.js'
import { AxPromptTemplate } from './prompt.js'
import { AxInstanceRegistry } from './registry.js'
import { AxSignature } from './sig.js'
import type { AxFieldValue, AxGenIn, AxGenOut, AxMessage } from './types.js'
import { mergeProgramUsage, validateValue } from './util.js'
export type AxProgramTrace<IN extends AxGenIn, OUT extends AxGenOut> = {
  trace: OUT & IN
  programId: string
}

export type AxProgramDemos<IN extends AxGenIn, OUT extends AxGenOut> = {
  traces: (OUT & IN)[]
  programId: string
}

export type AxProgramExamples<IN extends AxGenIn, OUT extends AxGenOut> =
  | AxProgramDemos<IN, OUT>
  | AxProgramDemos<IN, OUT>['traces']

export type AxProgramForwardOptions = {
  // Execution control
  maxRetries?: number
  maxSteps?: number
  mem?: AxAIMemory

  // AI service and model configuration
  ai?: AxAIService
  modelConfig?: AxModelConfig
  model?: string

  // Session and tracing
  sessionId?: string
  traceId?: string | undefined
  tracer?: Tracer
  rateLimiter?: AxRateLimiterFunction

  // Streaming and output
  stream?: boolean

  // Functions and calls
  functions?: AxInputFunctionType
  functionCall?: AxChatRequest['functionCall']
  stopFunction?: string

  // Behavior control
  fastFail?: boolean
  debug?: boolean
  debugHideSystemPrompt?: boolean

  // Thinking model controls
  thinkingTokenBudget?:
    | 'minimal'
    | 'low'
    | 'medium'
    | 'high'
    | 'highest'
    | 'none'
  showThoughts?: boolean

  // Tracing and logging
  traceLabel?: string
  abortSignal?: AbortSignal
  logger?: AxLoggerFunction

  // AxGen-specific options (previously in AxGenOptions)
  description?: string
  thoughtFieldName?: string
  promptTemplate?: typeof AxPromptTemplate
  asserts?: AxAssertion[]
  streamingAsserts?: AxStreamingAssertion[]
  excludeContentFromTrace?: boolean
}

export type AxProgramStreamingForwardOptions = Omit<
  AxProgramForwardOptions,
  'stream'
>

export type AxGenDeltaOut<OUT extends AxGenOut> = {
  version: number
  delta: Partial<OUT>
}

export type AxGenStreamingOut<OUT extends AxGenOut> = AsyncGenerator<
  AxGenDeltaOut<OUT>,
  // biome-ignore lint/suspicious/noConfusingVoidType: just cause
  void | OUT,
  unknown
>

// eslint-disable-next-line @typescript-eslint/no-empty-object-type
export type AxSetExamplesOptions = {
  // No options needed - all fields can be missing in examples
}

export interface AxTunable<IN extends AxGenIn, OUT extends AxGenOut> {
  setExamples: (
    examples: Readonly<AxProgramExamples<IN, OUT>>,
    options?: Readonly<AxSetExamplesOptions>
  ) => void
  setId: (id: string) => void
  setParentId: (parentId: string) => void
  getTraces: () => AxProgramTrace<IN, OUT>[]
  setDemos: (demos: readonly AxProgramDemos<IN, OUT>[]) => void
}

export interface AxUsable {
  getUsage: () => AxProgramUsage[]
  resetUsage: () => void
}

export type AxProgramUsage = AxChatResponse['modelUsage'] & {
  ai: string
  model: string
}

export interface AxProgramWithSignatureOptions {
  description?: string
}

export class AxProgramWithSignature<IN extends AxGenIn, OUT extends AxGenOut>
  implements AxTunable<IN, OUT>, AxUsable
{
  protected signature: AxSignature
  protected sigHash: string

  protected examples?: OUT[]
  protected examplesOptions?: AxSetExamplesOptions
  protected demos?: OUT[]
  protected trace?: OUT
  protected usage: AxProgramUsage[] = []

  private key: { id: string; custom?: boolean }
  private children: AxInstanceRegistry<Readonly<AxTunable<IN, OUT>>, IN, OUT>

  constructor(
    signature: NonNullable<ConstructorParameters<typeof AxSignature>[0]>,
    options?: Readonly<AxProgramWithSignatureOptions>
  ) {
    this.signature = new AxSignature(signature)

    if (options?.description) {
      this.signature.setDescription(options.description)
    }

    // Validate full signature consistency for use in generation
    this.signature.validate()

    this.sigHash = this.signature?.hash()
    this.children = new AxInstanceRegistry()
    this.key = { id: this.signature.hash() }
  }

  public getSignature() {
    return this.signature
  }

  public register(prog: Readonly<AxTunable<IN, OUT> & AxUsable>) {
    if (this.key) {
      prog.setParentId(this.key.id)
    }
    this.children.register(prog)
  }

  public async forward(
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _ai: Readonly<AxAIService>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _values: IN | AxMessage<IN>[],
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options?: Readonly<AxProgramForwardOptions>
  ): Promise<OUT> {
    throw new Error('forward() not implemented')
  }

  // biome-ignore lint/correctness/useYield: just a placeholder
  public async *streamingForward(
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _ai: Readonly<AxAIService>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _values: IN | AxMessage<IN>[],
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options?: Readonly<AxProgramStreamingForwardOptions>
  ): AxGenStreamingOut<OUT> {
    throw new Error('streamingForward() not implemented')
  }

  public setId(id: string) {
    this.key = { id, custom: true }
    for (const child of Array.from(this.children)) {
      child?.setParentId(id)
    }
  }

  public setParentId(parentId: string) {
    if (!this.key.custom) {
      this.key.id = [parentId, this.key.id].join('/')
    }
  }

  public setExamples(
    examples: Readonly<AxProgramExamples<IN, OUT>>,
    options?: Readonly<AxSetExamplesOptions>
  ) {
    this._setExamples(examples, options)

    if (!('programId' in examples)) {
      return
    }

    for (const child of Array.from(this.children)) {
      child?.setExamples(examples, options)
    }
  }

  private _setExamples(
    examples: Readonly<AxProgramExamples<IN, OUT>>,
    options?: Readonly<AxSetExamplesOptions>
  ) {
    let traces: Record<string, AxFieldValue>[] = []

    if ('programId' in examples && examples.programId === this.key.id) {
      traces = examples.traces
    }

    if (Array.isArray(examples)) {
      traces = examples
    }

    if (traces) {
      this.examplesOptions = options
      const sig = this.signature
      const fields = [...sig.getInputFields(), ...sig.getOutputFields()]

      this.examples = traces.map((e) => {
        const res: Record<string, AxFieldValue> = {}
        for (const f of fields) {
          const value = e[f.name]
          if (value !== undefined) {
            // Only validate the type of fields that are actually set
            // Allow any field to be missing regardless of whether it's required
            validateValue(f, value)
            res[f.name] = value
          }
        }
        return res
      }) as OUT[]
    }
  }

  public getTraces(): AxProgramTrace<IN, OUT>[] {
    let traces: AxProgramTrace<IN, OUT>[] = []

    if (this.trace) {
      traces.push({ trace: this.trace as OUT & IN, programId: this.key.id })
    }

    for (const child of Array.from(this.children)) {
      const _traces = child?.getTraces()
      traces = [...traces, ...(_traces ?? [])]
    }
    return traces
  }

  public getUsage(): AxProgramUsage[] {
    let usage: AxProgramUsage[] = [...(this.usage ?? [])]

    for (const child of Array.from(this.children)) {
      const cu = child?.getUsage()
      usage = [...usage, ...(cu ?? [])]
    }
    return mergeProgramUsage(usage)
  }

  public resetUsage() {
    this.usage = []
    for (const child of Array.from(this.children)) {
      child?.resetUsage()
    }
  }

  public setDemos(demos: readonly AxProgramDemos<IN, OUT>[]) {
    // Check if this program has children and if its programId is not found in demos
    const hasChildren = Array.from(this.children).length > 0
    const hasMatchingDemo = demos.some((demo) => demo.programId === this.key.id)

    if (hasChildren && !hasMatchingDemo) {
      throw new Error(
        `Program with id '${this.key.id}' has children but no matching programId found in demos`
      )
    }

    // biome-ignore lint/complexity/useFlatMap: it can't
    this.demos = demos
      .filter((v) => v.programId === this.key.id)
      .map((v) => v.traces)
      .flat()

    for (const child of Array.from(this.children)) {
      child?.setDemos(demos)
    }
  }
}

export class AxProgram<IN extends AxGenIn, OUT extends AxGenOut>
  implements AxTunable<IN, OUT>, AxUsable
{
  protected trace?: OUT
  protected usage: AxProgramUsage[] = []

  private key: { id: string; custom?: boolean }
  private children: AxInstanceRegistry<
    Readonly<AxTunable<IN, OUT> & AxUsable>,
    IN,
    OUT
  >

  constructor() {
    this.children = new AxInstanceRegistry()
    this.key = { id: this.constructor.name }
  }

  public register(prog: Readonly<AxTunable<IN, OUT> & AxUsable>) {
    if (this.key) {
      prog.setParentId(this.key.id)
    }
    this.children.register(prog)
  }

  public async forward(
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _ai: Readonly<AxAIService>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _values: IN | AxMessage<IN>[],
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options?: Readonly<AxProgramForwardOptions>
  ): Promise<OUT> {
    throw new Error('forward() not implemented')
  }

  // biome-ignore lint/correctness/useYield: just a placeholder
  public async *streamingForward(
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _ai: Readonly<AxAIService>,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _values: IN | AxMessage<IN>[],
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options?: Readonly<AxProgramStreamingForwardOptions>
  ): AxGenStreamingOut<OUT> {
    throw new Error('streamingForward() not implemented')
  }

  public setId(id: string) {
    this.key = { id, custom: true }
    for (const child of Array.from(this.children)) {
      child?.setParentId(id)
    }
  }

  public setParentId(parentId: string) {
    if (!this.key.custom) {
      this.key.id = [parentId, this.key.id].join('/')
    }
  }

  public setExamples(
    examples: Readonly<AxProgramExamples<IN, OUT>>,
    options?: Readonly<AxSetExamplesOptions>
  ) {
    if (!('programId' in examples)) {
      return
    }

    for (const child of Array.from(this.children)) {
      child?.setExamples(examples, options)
    }
  }

  public getTraces(): AxProgramTrace<IN, OUT>[] {
    let traces: AxProgramTrace<IN, OUT>[] = []

    if (this.trace) {
      traces.push({ trace: this.trace as OUT & IN, programId: this.key.id })
    }

    for (const child of Array.from(this.children)) {
      const _traces = child?.getTraces()
      traces = [...traces, ...(_traces ?? [])]
    }
    return traces
  }

  public getUsage(): AxProgramUsage[] {
    let usage: AxProgramUsage[] = [...(this.usage ?? [])]

    for (const child of Array.from(this.children)) {
      const cu = child?.getUsage()
      usage = [...usage, ...(cu ?? [])]
    }
    return mergeProgramUsage(usage)
  }

  public resetUsage() {
    this.usage = []
    for (const child of Array.from(this.children)) {
      child?.resetUsage()
    }
  }

  public setDemos(demos: readonly AxProgramDemos<IN, OUT>[]) {
    // Check if this program has children and if its programId is not found in demos
    const hasChildren = Array.from(this.children).length > 0
    const hasMatchingDemo = demos.some((demo) => demo.programId === this.key.id)

    if (hasChildren && !hasMatchingDemo) {
      throw new Error(
        `Program with id '${this.key.id}' has children but no matching programId found in demos`
      )
    }

    for (const child of Array.from(this.children)) {
      child?.setDemos(demos)
    }
  }
}



================================================
FILE: src/ax/dsp/prompt.test.ts
================================================
import { describe, expect, it } from 'vitest'

import { AxPromptTemplate } from './prompt.js'
import { AxSignature } from './sig.js'
import type { AxMessage } from './types.js'

// Helper to create a basic signature
const createSignature = (desc: string) => {
  return new AxSignature(desc)
}

const defaultSig = createSignature('userQuery:string -> aiResponse:string')

const multiFieldSig = createSignature(
  'userQuestion:string, contextInfo:string -> assistantAnswer:string'
)

// Signature for testing assistant message rendering logic
const assistantTestSig = createSignature(
  'userMessage:string -> thoughtProcess:string "Thought process", mainResponse:string "Main output", optionalResponse?:string "Optional output", internalThoughts!:string "Internal output"'
)

describe('AxPromptTemplate.render', () => {
  type TestExpectedMessage = { role: 'user' | 'assistant'; content: string }

  describe('Single AxGenIn input (existing behavior)', () => {
    it('should render a basic prompt with single AxGenIn', () => {
      const signature = new AxSignature(
        'userQuery:string -> aiResponse:string "the result"'
      )
      const template = new AxPromptTemplate(signature)

      const result = template.render({ userQuery: 'test' }, {})

      expect(result).toHaveLength(2)
      expect(result[0]?.role).toBe('system')
      expect(result[1]?.role).toBe('user')
      const userMessage = result[1] as TestExpectedMessage | undefined
      expect(userMessage?.content).toContain('User Query: test')
    })

    it('should render with examples', () => {
      const signature = new AxSignature(
        'userQuery:string -> aiResponse:string "the result"'
      )
      const template = new AxPromptTemplate(signature)

      const examples = [{ userQuery: 'hello', aiResponse: 'world' }]
      const result = template.render({ userQuery: 'test' }, { examples })

      expect(result).toHaveLength(2)
      expect(result[0]?.role).toBe('system')
      const systemMessage = result[0] as
        | { role: 'system'; content: string }
        | undefined
      expect(systemMessage?.content).toContain('User Query: hello')
      expect(systemMessage?.content).toContain('Ai Response: world')
    })
  })

  describe('examples with missing fields', () => {
    it('should allow missing input fields in examples', () => {
      const signature = new AxSignature(
        'userQuery:string, isUserMessage:boolean -> aiResponse:string'
      )
      const template = new AxPromptTemplate(signature)

      const examples = [{ userQuery: 'hello', aiResponse: 'world' }] // missing isUserMessage

      expect(() => {
        template.render(
          { userQuery: 'test', isUserMessage: true },
          { examples }
        )
      }).not.toThrow()
    })

    it('should handle false boolean values correctly in examples', () => {
      const signature = new AxSignature(
        'userQuery:string, isUserMessage:boolean -> aiResponse:string'
      )
      const template = new AxPromptTemplate(signature)

      const examples = [
        { userQuery: 'hello', isUserMessage: false, aiResponse: 'world' },
      ]

      const result = template.render(
        { userQuery: 'test', isUserMessage: true },
        { examples }
      )

      expect(result).toHaveLength(2)
      expect(result[0]?.role).toBe('system')
      const systemMessage = result[0] as
        | { role: 'system'; content: string }
        | undefined
      expect(systemMessage?.content).toContain('Is User Message: false')
    })

    it('should allow missing output fields in examples', () => {
      const signature = new AxSignature(
        'userQuery:string -> aiResponse:string, categoryType:string'
      )
      const template = new AxPromptTemplate(signature)

      const examples = [{ userQuery: 'hello', aiResponse: 'world' }] // missing category output field

      expect(() => {
        template.render({ userQuery: 'test' }, { examples })
      }).not.toThrow()
    })
  })

  describe('ReadonlyArray<AxMessage> input (new behavior)', () => {
    it('should render with a single user message in history', () => {
      const pt = new AxPromptTemplate(defaultSig)
      const history: ReadonlyArray<AxMessage<{ userQuery: string }>> = [
        { role: 'user', values: { userQuery: 'first message' } },
      ]
      const result = pt.render(history, {})

      expect(result.length).toBe(2)
      expect(result[0]?.role).toBe('system')
      const userMessage = result[1] as TestExpectedMessage | undefined
      expect(userMessage?.role).toBe('user')
      expect(userMessage?.content).toBe('User Query: first message\n')
    })

    it('should combine consecutive user messages', () => {
      const pt = new AxPromptTemplate(multiFieldSig)
      const history: ReadonlyArray<
        AxMessage<{ userQuestion: string; contextInfo: string }>
      > = [
        { role: 'user', values: { userQuestion: 'q1', contextInfo: 'c1' } },
        { role: 'user', values: { userQuestion: 'q2', contextInfo: 'c2' } },
      ]
      const result = pt.render(history, {})

      expect(result.length).toBe(3)
      const userMessage = result[1] as TestExpectedMessage | undefined
      expect(userMessage?.role).toBe('user')
      expect(userMessage?.content).toBe(
        'User Question: q1\n\nContext Info: c1\n'
      )
    })

    it('should handle alternating user and assistant messages', () => {
      const pt = new AxPromptTemplate(multiFieldSig)
      const history: ReadonlyArray<
        AxMessage<{ userQuestion: string; contextInfo: string }>
      > = [
        { role: 'user', values: { userQuestion: 'q1', contextInfo: 'c1' } },
        {
          role: 'assistant',
          values: { userQuestion: 'q1-followup', contextInfo: 'c1-response' },
        },
        { role: 'user', values: { userQuestion: 'q2', contextInfo: 'c2' } },
      ]
      const result = pt.render(history, {})

      expect(result.length).toBe(4)
      expect(result[0]?.role).toBe('system')
      const userMessage1 = result[1] as TestExpectedMessage | undefined
      expect(userMessage1?.role).toBe('user')
      expect(userMessage1?.content).toBe(
        'User Question: q1\n\nContext Info: c1\n'
      )
      const assistantMessage = result[2] as TestExpectedMessage | undefined
      expect(assistantMessage?.role).toBe('assistant')
      expect(assistantMessage?.content).toBe(
        'User Question: q1-followup\n\nContext Info: c1-response\n'
      )
      const userMessage2 = result[3] as TestExpectedMessage | undefined
      expect(userMessage2?.role).toBe('user')
      expect(userMessage2?.content).toBe(
        'User Question: q2\n\nContext Info: c2\n'
      )
    })

    // This test confirms user messages need all required fields
    it('should throw if required field missing in user message history', () => {
      const pt = new AxPromptTemplate(multiFieldSig)
      const history: ReadonlyArray<
        AxMessage<{ userQuestion: string; contextInfo?: string }>
      > = [
        { role: 'user', values: { userQuestion: 'q1' } }, // contextInfo is missing
      ]
      expect(() => pt.render(history, {})).toThrowError(
        "Value for input field 'contextInfo' is required."
      )
    })

    it('should handle empty history array', () => {
      const pt = new AxPromptTemplate(defaultSig)
      const history: ReadonlyArray<AxMessage<{ userQuery: string }>> = []
      const result = pt.render(history, {})

      expect(result.length).toBe(1) // Only system prompt for empty array
      expect(result[0]?.role).toBe('system')
      // If an empty history array resulted in an empty user message, this would be:
      // expect(result.length).toBe(2);
      // const userMessage = result[1] as TestExpectedMessage | undefined;
      // expect(userMessage?.role).toBe('user');
      // expect(userMessage?.content).toBe('');
    })

    describe('Assistant Messages in History', () => {
      it('should render assistant message with input fields', () => {
        const pt = new AxPromptTemplate(assistantTestSig)
        const history: ReadonlyArray<AxMessage<{ userMessage: string }>> = [
          {
            role: 'assistant',
            values: {
              userMessage: 'assistant input value',
            },
          },
        ]
        const result = pt.render(history, {})
        expect(result.length).toBe(2)
        const assistantMsg = result[1] as TestExpectedMessage | undefined
        expect(assistantMsg?.role).toBe('assistant')
        expect(assistantMsg?.content).toBe(
          'User Message: assistant input value\n'
        )
      })

      it('should throw error if required input field is missing in assistant message', () => {
        const pt = new AxPromptTemplate(assistantTestSig)
        const history: ReadonlyArray<AxMessage<{ userMessage?: string }>> = [
          {
            role: 'assistant',
            values: {}, // 'userMessage' is missing
          },
        ]
        expect(() => pt.render(history, {})).toThrowError(
          "Value for input field 'userMessage' is required."
        )
      })

      it('should render assistant message with multiple input fields', () => {
        const pt = new AxPromptTemplate(multiFieldSig)
        const history: ReadonlyArray<
          AxMessage<{ userQuestion: string; contextInfo: string }>
        > = [
          {
            role: 'assistant',
            values: {
              userQuestion: 'What is the answer?',
              contextInfo: 'This is the context',
            },
          },
        ]
        const result = pt.render(history, {})
        expect(result.length).toBe(2)
        const assistantMsg = result[1] as TestExpectedMessage | undefined
        expect(assistantMsg?.role).toBe('assistant')
        expect(assistantMsg?.content).toBe(
          'User Question: What is the answer?\n\nContext Info: This is the context\n'
        )
      })

      it('should throw error if required input field is missing in multi-field assistant message', () => {
        const pt = new AxPromptTemplate(multiFieldSig)
        const history: ReadonlyArray<
          AxMessage<{ userQuestion: string; contextInfo?: string }>
        > = [
          {
            role: 'assistant',
            values: {
              userQuestion: 'What is the answer?',
              // contextInfo is missing
            },
          },
        ]
        expect(() => pt.render(history, {})).toThrowError(
          "Value for input field 'contextInfo' is required."
        )
      })
    })
  })
})



================================================
FILE: src/ax/dsp/prompt.ts
================================================
import type { AxChatRequest } from '../ai/types.js'

import { formatDateWithTimezone } from './datetime.js'
import type { AxInputFunctionType } from './functions.js'
import type { AxField, AxIField, AxSignature } from './sig.js'
import type { AxFieldValue, AxGenIn, AxMessage } from './types.js'
import { validateValue } from './util.js'

type Writeable<T> = { -readonly [P in keyof T]: T[P] }

// Define options type for AxPromptTemplate constructor
export interface AxPromptTemplateOptions {
  functions?: Readonly<AxInputFunctionType>
  thoughtFieldName?: string
}
type AxChatRequestChatPrompt = Writeable<AxChatRequest['chatPrompt'][0]>

type ChatRequestUserMessage = Exclude<
  Extract<AxChatRequestChatPrompt, { role: 'user' }>['content'],
  string
>

const functionCallInstructions = `
## Function Call Instructions
- Complete the task, using the functions defined earlier in this prompt. 
- Call functions step-by-step, using the output of one function as input to the next.
- Use the function results to generate the output fields.`

const formattingRules = `
## Strict Output Formatting Rules
- Output must strictly follow the defined plain-text \`field name: value\` field format.
- Output field, values must strictly adhere to the specified output field formatting rules.
- Do not add any text before or after the output fields, just the field name and value.
- Do not use code blocks.`

export type AxFieldTemplateFn = (
  field: Readonly<AxField>,
  value: Readonly<AxFieldValue>
) => ChatRequestUserMessage

export class AxPromptTemplate {
  private sig: Readonly<AxSignature>
  private fieldTemplates?: Record<string, AxFieldTemplateFn>
  private task: { type: 'text'; text: string }
  private readonly thoughtFieldName: string
  private readonly functions?: Readonly<AxInputFunctionType>

  constructor(
    sig: Readonly<AxSignature>,
    options?: Readonly<AxPromptTemplateOptions>,
    fieldTemplates?: Record<string, AxFieldTemplateFn>
  ) {
    this.sig = sig
    this.fieldTemplates = fieldTemplates
    this.thoughtFieldName = options?.thoughtFieldName ?? 'thought'
    this.functions = options?.functions

    const task = []

    const inArgs = renderDescFields(this.sig.getInputFields())
    const outArgs = renderDescFields(this.sig.getOutputFields())
    task.push(
      `You will be provided with the following fields: ${inArgs}. Your task is to generate new fields: ${outArgs}.`
    )

    // biome-ignore lint/complexity/useFlatMap: you cannot use flatMap here
    const funcs = this.functions
      ?.map((f) => ('toFunction' in f ? f.toFunction() : f))
      ?.flat()

    const funcList = funcs
      ?.map((fn) => `- \`${fn.name}\`: ${formatDescription(fn.description)}`)
      .join('\n')

    if (funcList && funcList.length > 0) {
      task.push(`## Available Functions\n${funcList}`)
    }

    const inputFields = renderInputFields(this.sig.getInputFields())
    task.push(`## Input Fields\n${inputFields}`)

    const outputFields = renderOutputFields(this.sig.getOutputFields())
    task.push(`## Output Fields\n${outputFields}`)

    if (funcList && funcList.length > 0) {
      task.push(functionCallInstructions.trim())
    }

    task.push(formattingRules.trim())

    const desc = this.sig.getDescription()
    if (desc) {
      const text = formatDescription(desc)
      task.push(text)
    }

    this.task = {
      type: 'text' as const,
      text: task.join('\n\n'),
    }
  }

  private renderSingleValueUserContent = <T extends AxGenIn>(
    values: T,
    renderedExamples: ChatRequestUserMessage,
    renderedDemos: ChatRequestUserMessage,
    examplesInSystemPrompt: boolean
  ): string | ChatRequestUserMessage => {
    const completion = this.renderInputFields(values)
    const promptList: ChatRequestUserMessage = examplesInSystemPrompt
      ? completion
      : [...renderedExamples, ...renderedDemos, ...completion]

    const prompt = promptList.filter((v) => v !== undefined)

    return prompt.every((v) => v.type === 'text')
      ? prompt.map((v) => v.text).join('\n')
      : prompt.reduce(combineConsecutiveStrings('\n'), [])
  }

  public render = <T extends AxGenIn>(
    values: T | ReadonlyArray<AxMessage<T>>, // Allow T (AxGenIn) or array of AxMessages
    {
      examples,
      demos,
    }: Readonly<{
      skipSystemPrompt?: boolean
      examples?: Record<string, AxFieldValue>[] // Keep as is, examples are specific structures
      demos?: Record<string, AxFieldValue>[] // Keep as is
    }>
  ): AxChatRequest['chatPrompt'] => {
    const renderedExamples = examples
      ? [
          { type: 'text' as const, text: '\n\n## Examples\n' },
          ...this.renderExamples(examples),
        ]
      : []

    const renderedDemos = demos ? this.renderDemos(demos) : []

    // Check if demos and examples are all text type
    const allTextExamples = renderedExamples.every((v) => v.type === 'text')
    const allTextDemos = renderedDemos.every((v) => v.type === 'text')
    const examplesInSystemPrompt = allTextExamples && allTextDemos

    let systemContent = this.task.text

    if (examplesInSystemPrompt) {
      const combinedItems = [
        { type: 'text' as const, text: systemContent },
        ...renderedExamples,
        ...renderedDemos,
      ]
      combinedItems.reduce(combineConsecutiveStrings(''), [])

      if (combinedItems && combinedItems[0]) {
        systemContent = combinedItems[0].text
      }
    }

    const systemPrompt = {
      role: 'system' as const,
      content: systemContent,
    }

    if (Array.isArray(values)) {
      let userMessages: Extract<
        AxChatRequest['chatPrompt'][number],
        { role: 'user' } | { role: 'assistant' }
      >[] = []

      const history = values as ReadonlyArray<AxMessage<T>>

      for (const [index, message] of history.entries()) {
        let content: string | ChatRequestUserMessage

        if (index === 0) {
          content = this.renderSingleValueUserContent(
            message.values,
            renderedExamples,
            renderedDemos,
            examplesInSystemPrompt
          )
        } else {
          content = this.renderSingleValueUserContent(
            message.values,
            [],
            [],
            false
          )
        }

        if (message.role === 'user') {
          userMessages.push({ role: 'user', content })
          continue
        }

        if (message.role !== 'assistant') {
          throw new Error('Invalid message role')
        }

        if (typeof content !== 'string') {
          throw new Error(
            'Assistant message cannot contain non-text content like images, files,etc'
          )
        }

        userMessages.push({ role: 'assistant', content })
      }
      return [systemPrompt, ...userMessages]
    }

    // values is T (AxGenIn) - existing logic path
    const userContent = this.renderSingleValueUserContent(
      values as T,
      renderedExamples,
      renderedDemos,
      examplesInSystemPrompt
    )

    return [systemPrompt, { role: 'user' as const, content: userContent }]
  }

  public renderExtraFields = (extraFields: readonly AxIField[]) => {
    const prompt: ChatRequestUserMessage = []

    if (!extraFields || extraFields.length === 0) {
      return prompt
    }

    const groupedFields = extraFields.reduce(
      (acc, field) => {
        const title = field.title
        if (!acc[title]) {
          acc[title] = []
        }
        acc[title].push(field)
        return acc
      },
      {} as Record<string, AxIField[]>
    )

    const formattedGroupedFields = Object.entries(groupedFields)
      .map(([title, fields]) => {
        if (fields.length === 1) {
          const field = fields[0]!
          return {
            title,
            name: field.name,
            description: field.description,
          }
        } else if (fields.length > 1) {
          const valuesList = fields
            .map((field) => `- ${field.description}`)
            .join('\n')
          return {
            title,
            name: fields[0]!.name,
            description: valuesList,
          }
        }
      })
      .filter(Boolean) as AxIField[]

    formattedGroupedFields.forEach((field) => {
      const fn = this.fieldTemplates?.[field.name] ?? this.defaultRenderInField
      prompt.push(...fn(field, field.description))
    })

    return prompt
  }

  private renderExamples = (data: Readonly<Record<string, AxFieldValue>[]>) => {
    const list: ChatRequestUserMessage = []
    const exampleContext = {
      isExample: true,
    }

    for (const [index, item] of data.entries()) {
      const renderedInputItem = this.sig
        .getInputFields()
        .map((field) =>
          this.renderInField(field, item, {
            ...exampleContext,
            isInputField: true,
          })
        )
        .filter((v) => v !== undefined)
        .flat()

      const renderedOutputItem = this.sig
        .getOutputFields()
        .map((field) =>
          this.renderInField(field, item, {
            ...exampleContext,
            isInputField: false,
          })
        )
        .filter((v) => v !== undefined)
        .flat()

      const renderedItem = [...renderedInputItem, ...renderedOutputItem]

      if (
        index > 0 &&
        renderedItem.length > 0 &&
        renderedItem[0]?.type === 'text'
      ) {
        list.push({ type: 'text' as const, text: '---\n\n' })
      }

      renderedItem.forEach((v) => {
        if ('text' in v) {
          v.text = v.text + '\n'
        }
        list.push(v)
      })
    }

    return list
  }

  private renderDemos = (data: Readonly<Record<string, AxFieldValue>[]>) => {
    const list: ChatRequestUserMessage = []
    const inputFields = this.sig.getInputFields()
    const outputFields = this.sig.getOutputFields()
    const demoContext = {
      isExample: true,
    }

    for (const item of data) {
      const inputRenderedItems = inputFields
        .map((field) =>
          this.renderInField(field, item, {
            ...demoContext,
            isInputField: true,
          })
        )
        .filter((v) => v !== undefined)
        .flat()

      const outputRenderedItems = outputFields
        .map((field) =>
          this.renderInField(field, item, {
            ...demoContext,
            isInputField: false,
          })
        )
        .filter((v) => v !== undefined)
        .flat()

      const renderedItem = [...inputRenderedItems, ...outputRenderedItems]

      renderedItem.slice(0, -1).forEach((v) => {
        if ('text' in v) {
          v.text = v.text + '\n'
        }
        list.push(v)
      })
    }

    return list
  }

  private renderInputFields = <T extends AxGenIn>(values: T) => {
    const renderedItems = this.sig
      .getInputFields()
      .map((field) => this.renderInField(field, values, undefined))
      .filter((v) => v !== undefined)
      .flat()

    renderedItems
      .filter((v) => v.type === 'text')
      .forEach((v) => {
        v.text = v.text + '\n'
      })

    return renderedItems
  }

  private renderInField = (
    field: Readonly<AxField>,
    values: Readonly<Record<string, AxFieldValue>>,
    context?: {
      isExample?: boolean
      strictExamples?: boolean
      optionalOutputFields?: string[]
      isInputField?: boolean
    }
  ) => {
    const value = values[field.name]

    if (isEmptyValue(field, value, context)) {
      return
    }

    if (field.type) {
      validateValue(field, value!)
    }

    const processedValue = processValue(field, value!)

    const textFieldFn: AxFieldTemplateFn =
      this.fieldTemplates?.[field.name] ?? this.defaultRenderInField

    return textFieldFn(field, processedValue)
  }

  private defaultRenderInField = (
    field: Readonly<AxField>,
    value: Readonly<AxFieldValue>
  ): ChatRequestUserMessage => {
    if (field.type?.name === 'image') {
      const validateImage = (
        value: Readonly<AxFieldValue>
      ): { mimeType: string; data: string } => {
        if (!value) {
          throw new Error('Image field value is required.')
        }

        if (typeof value !== 'object') {
          throw new Error('Image field value must be an object.')
        }
        if (!('mimeType' in value)) {
          throw new Error('Image field must have mimeType')
        }
        if (!('data' in value)) {
          throw new Error('Image field must have data')
        }
        return value as { mimeType: string; data: string }
      }

      let result: ChatRequestUserMessage = [
        { type: 'text', text: `${field.title}: ` as string },
      ]

      if (field.type.isArray) {
        if (!Array.isArray(value)) {
          throw new Error('Image field value must be an array.')
        }
        result = result.concat(
          (value as unknown[]).map((v) => {
            // Cast to unknown[] before map
            const validated = validateImage(v as AxFieldValue)
            return {
              type: 'image',
              mimeType: validated.mimeType,
              image: validated.data,
            }
          })
        )
      } else {
        const validated = validateImage(value)
        result.push({
          type: 'image',
          mimeType: validated.mimeType,
          image: validated.data,
        })
      }
      return result
    }

    if (field.type?.name === 'audio') {
      const validateAudio = (
        value: Readonly<AxFieldValue>
      ): { format?: 'wav'; data: string } => {
        if (!value) {
          throw new Error('Audio field value is required.')
        }

        if (typeof value !== 'object') {
          throw new Error('Audio field value must be an object.')
        }
        if (!('data' in value)) {
          throw new Error('Audio field must have data')
        }
        return value as { format?: 'wav'; data: string }
      }

      let result: ChatRequestUserMessage = [
        { type: 'text', text: `${field.title}: ` as string },
      ]

      if (field.type.isArray) {
        if (!Array.isArray(value)) {
          throw new Error('Audio field value must be an array.')
        }
        result = result.concat(
          (value as unknown[]).map((v) => {
            // Cast to unknown[] before map
            const validated = validateAudio(v as AxFieldValue)
            return {
              type: 'audio',
              format: validated.format ?? 'wav',
              data: validated.data,
            }
          })
        )
      } else {
        const validated = validateAudio(value)
        result.push({
          type: 'audio',
          format: validated.format ?? 'wav',
          data: validated.data,
        })
      }
      return result
    }

    const text = [field.title, ': ']

    if (Array.isArray(value)) {
      text.push('\n')
      text.push(value.map((v) => `- ${v}`).join('\n'))
    } else {
      text.push(value as string)
    }
    return [{ type: 'text', text: text.join('') }]
  }
}

const renderDescFields = (list: readonly AxField[]) =>
  list.map((v) => `\`${v.title}\``).join(', ')

const renderInputFields = (fields: readonly AxField[]) => {
  const rows = fields.map((field) => {
    const name = field.title
    const type = field.type?.name ? toFieldType(field.type) : 'string'

    const requiredMsg = field.isOptional
      ? `This optional ${type} field may be omitted`
      : `A ${type} field`

    const description = field.description
      ? ` ${formatDescription(field.description)}`
      : ''

    return `${name}: (${requiredMsg})${description}`.trim()
  })

  return rows.join('\n')
}

const renderOutputFields = (fields: readonly AxField[]) => {
  const rows = fields.map((field) => {
    const name = field.title
    const type = field.type?.name ? toFieldType(field.type) : 'string'

    const requiredMsg = field.isOptional
      ? `Only include this ${type} field if its value is available`
      : `This ${type} field must be included`

    let description = ''

    if (field.description && field.description.length > 0) {
      const value =
        field.type?.name === 'class'
          ? field.description
          : formatDescription(field.description)
      description = ` ${value}`
    }

    if (field.type?.options && field.type.options.length > 0) {
      if (description.length > 0) {
        description += `. `
      }
      description += `Allowed values: ${field.type.options.join(', ')}`
    }

    return `${name}: (${requiredMsg})${description}`.trim()
  })

  return rows.join('\n')
}

const processValue = (
  field: Readonly<AxField>,
  value: Readonly<AxFieldValue>
): AxFieldValue => {
  if (field.type?.name === 'date' && value instanceof Date) {
    const v = value.toISOString()
    return v.slice(0, v.indexOf('T'))
  }
  if (field.type?.name === 'datetime' && value instanceof Date) {
    return formatDateWithTimezone(value)
  }
  if (field.type?.name === 'image' && typeof value === 'object') {
    return value
  }
  if (field.type?.name === 'audio' && typeof value === 'object') {
    return value
  }
  if (typeof value === 'string') {
    return value
  }
  return JSON.stringify(value, null, 2)
}

export const toFieldType = (type: Readonly<AxField['type']>) => {
  const baseType = (() => {
    switch (type?.name) {
      case 'string':
        return 'string'
      case 'number':
        return 'number'
      case 'boolean':
        return 'boolean'
      case 'date':
        return 'date ("YYYY-MM-DD" format)'
      case 'datetime':
        return 'date time ("YYYY-MM-DD HH:mm Timezone" format)'
      case 'json':
        return 'JSON object'
      case 'class':
        return 'classification class'
      case 'code':
        return 'code'
      default:
        return 'string'
    }
  })()

  return type?.isArray ? `json array of ${baseType} items` : baseType
}

function combineConsecutiveStrings(separator: string) {
  return (acc: ChatRequestUserMessage, current: ChatRequestUserMessage[0]) => {
    if (current.type === 'text') {
      const previous = acc.length > 0 ? acc[acc.length - 1] : null
      if (previous && previous.type === 'text') {
        previous.text += separator + current.text
      } else {
        acc.push(current)
      }
    } else {
      acc.push(current)
    }
    return acc
  }
}

const isEmptyValue = (
  field: Readonly<AxField>,
  value?: Readonly<AxFieldValue>,
  context?: {
    isExample?: boolean
    isInputField?: boolean
  }
) => {
  if (typeof value === 'boolean') {
    return false
  }

  if (
    !value ||
    ((Array.isArray(value) || typeof value === 'string') && value.length === 0)
  ) {
    // Handle examples case - all fields can be missing in examples
    if (context?.isExample) {
      return true
    }

    // Handle non-examples case (regular field validation)
    if (field.isOptional || field.isInternal) {
      return true
    }

    const fieldType = context?.isInputField !== false ? 'input' : 'output'
    throw new Error(`Value for ${fieldType} field '${field.name}' is required.`)
  }
  return false
}

function formatDescription(str: string) {
  const value = str.trim()
  return value.length > 0
    ? `${value.charAt(0).toUpperCase()}${value.slice(1)}${value.endsWith('.') ? '' : '.'}`
    : ''
}



================================================
FILE: src/ax/dsp/registry.ts
================================================
import type { AxTunable, AxUsable } from './program.js'
import type { AxGenIn, AxGenOut } from './types.js'

type AxInstanceRegistryItem<
  T extends AxTunable<IN, OUT>,
  IN extends AxGenIn,
  OUT extends AxGenOut,
> = T & AxUsable

export class AxInstanceRegistry<
  T extends AxTunable<IN, OUT>,
  IN extends AxGenIn,
  OUT extends AxGenOut,
> {
  private reg: Set<AxInstanceRegistryItem<T, IN, OUT>> // To track keys for iteration

  constructor() {
    this.reg = new Set()
  }

  register(instance: AxInstanceRegistryItem<T, IN, OUT>): void {
    this.reg.add(instance)
  }

  *[Symbol.iterator]() {
    const items = Array.from(this.reg)
    for (let i = 0; i < items.length; i++) {
      yield items[i]
    }
  }
}



================================================
FILE: src/ax/dsp/sig.test.ts
================================================
import { describe, expect, it } from 'vitest'

import { extractValues } from './extract.js'
import { parseSignature } from './parser.js'
import { type AxField, AxSignature } from './sig.js'

describe('signature parsing', () => {
  it('parses signature correctly', () => {
    const sig = parseSignature(
      `"hello world" contextInfo?:string "some context", queryText:string 'some query' -> reasoningSteps!?:string, answerList:string[], messageType:class "reminder, follow-up"`
    )

    expect(sig.desc).toBe('hello world')

    expect(sig.inputs[0]).toEqual({
      desc: 'some context',
      name: 'contextInfo',
      type: { name: 'string', isArray: false },
      isOptional: true,
    })

    expect(sig.inputs[1]).toEqual({
      desc: 'some query',
      name: 'queryText',
      type: { name: 'string', isArray: false },
      isOptional: undefined,
    })

    expect(sig.outputs[0]).toEqual({
      desc: undefined,
      name: 'reasoningSteps',
      type: { name: 'string', isArray: false },
      isOptional: true,
      isInternal: true,
    })

    expect(sig.outputs[1]).toEqual({
      desc: undefined,
      name: 'answerList',
      type: { name: 'string', isArray: true },
      isOptional: false,
      isInternal: false,
    })

    expect(sig.outputs[2]).toEqual({
      desc: undefined,
      isInternal: false,
      isOptional: false,
      name: 'messageType',
      type: {
        name: 'class',
        isArray: false,
        options: ['reminder', 'follow-up'],
      },
    })
  })

  it('throws descriptive error for invalid signature', () => {
    expect(() =>
      parseSignature(
        `contextInfo?:string, queryText:boom -> testField:image, answerList:string[]`
      )
    ).toThrow('Invalid type "boom"')
  })

  it('throws error for empty signature', () => {
    expect(() => parseSignature('')).toThrow('Empty signature provided')
  })

  it('throws error for missing arrow', () => {
    expect(() => parseSignature('userInput:string')).toThrow(
      'Missing output section'
    )
  })

  it('throws error for missing output fields', () => {
    expect(() => parseSignature('userInput:string ->')).toThrow(
      'No output fields specified after "->"'
    )
  })

  it('throws error for generic field names', () => {
    expect(() => parseSignature('text:string -> response:string')).toThrow(
      'too generic'
    )
  })

  it('throws error for duplicate field names', () => {
    expect(() =>
      parseSignature(
        'userInput:string, userInput:number -> responseText:string'
      )
    ).toThrow('Duplicate input field name')
  })

  it('throws error for field names in both input and output', () => {
    expect(() =>
      parseSignature('userInput:string -> userInput:string')
    ).toThrow('appears in both inputs and outputs')
  })

  it('throws error for class type in input', () => {
    expect(() =>
      parseSignature('categoryType:class "a, b" -> responseText:string')
    ).toThrow('cannot use the "class" type')
  })

  it('throws error for internal marker in input', () => {
    expect(() =>
      parseSignature('userInput!:string -> responseText:string')
    ).toThrow('cannot use the internal marker')
  })

  it('throws error for image type in output', () => {
    expect(() =>
      parseSignature('userInput:string -> outputImage:image')
    ).toThrow('Image type is not supported in output fields')
  })

  it('allows single class option', () => {
    expect(() =>
      parseSignature('userInput:string -> categoryType:class "only-one"')
    ).not.toThrow()
  })

  it('throws error for empty class options', () => {
    expect(() =>
      parseSignature('userInput:string -> categoryType:class ""')
    ).toThrow('Missing class options after "class" type')
  })

  it('allows any class option names including numbers', () => {
    expect(() =>
      parseSignature(
        'userInput:string -> categoryType:class "valid, 123invalid, option-with-dash"'
      )
    ).not.toThrow()
  })

  it('supports both comma and pipe separators for class options', () => {
    // Test comma separator
    const sig1 = parseSignature(
      'userInput:string -> categoryType:class "positive, negative, neutral"'
    )
    expect(sig1.outputs[0]?.type?.options).toEqual([
      'positive',
      'negative',
      'neutral',
    ])

    // Test pipe separator
    const sig2 = parseSignature(
      'userInput:string -> categoryType:class "positive | negative | neutral"'
    )
    expect(sig2.outputs[0]?.type?.options).toEqual([
      'positive',
      'negative',
      'neutral',
    ])

    // Test mixed separators
    const sig3 = parseSignature(
      'userInput:string -> categoryType:class "positive, negative | neutral"'
    )
    expect(sig3.outputs[0]?.type?.options).toEqual([
      'positive',
      'negative',
      'neutral',
    ])
  })

  it('supports class options with mixed separators and spacing', () => {
    expect(() =>
      parseSignature(
        'userInput:string -> categoryType:class "valid, option,with,comma"'
      )
    ).not.toThrow()

    expect(() =>
      parseSignature(
        'userInput:string -> categoryType:class "valid | option|with|pipe"'
      )
    ).not.toThrow()

    const sig1 = parseSignature(
      'userInput:string -> categoryType:class "valid, option,with,comma"'
    )
    const output1 = sig1.outputs[0]?.type
    if (output1?.name === 'class') {
      expect(output1.options).toEqual(['valid', 'option', 'with', 'comma'])
    }

    const sig2 = parseSignature(
      'userInput:string -> categoryType:class "valid | option|with|pipe"'
    )
    const output2 = sig2.outputs[0]?.type
    if (output2?.name === 'class') {
      expect(output2.options).toEqual(['valid', 'option', 'with', 'pipe'])
    }
  })

  it('throws error for field names that are too short', () => {
    expect(() => parseSignature('a:string -> b:string')).toThrow('too short')
  })

  it('throws error for field names starting with numbers', () => {
    expect(() =>
      parseSignature('1invalid:string -> responseText:string')
    ).toThrow('cannot start with a number')
  })

  it('throws error for invalid field name characters', () => {
    expect(() =>
      parseSignature('user-input:string -> responseText:string')
    ).toThrow('Expected "->"')
  })

  it('provides type suggestions for common mistakes', () => {
    expect(() =>
      parseSignature('userInput:str -> responseText:string')
    ).toThrow('Did you mean "string"?')
    expect(() =>
      parseSignature('userInput:int -> responseText:string')
    ).toThrow('Did you mean "number"?')
    expect(() =>
      parseSignature('userInput:bool -> responseText:string')
    ).toThrow('Did you mean "boolean"?')
  })

  it('throws error for unterminated strings', () => {
    expect(() =>
      parseSignature('userInput:string "unterminated -> responseText:string')
    ).toThrow('Unterminated string')
  })

  it('throws error for unexpected content after signature', () => {
    expect(() =>
      parseSignature('userInput:string -> responseText:string extra content')
    ).toThrow('Unexpected content after signature')
  })

  it('validates array constraints for media types', () => {
    expect(() =>
      parseSignature('userImage:image[] -> responseText:string')
    ).toThrow('Arrays of image are not supported')
    expect(() =>
      parseSignature('userAudio:audio[] -> responseText:string')
    ).toThrow('Arrays of audio are not supported')
  })

  it('allows valid descriptive field names', () => {
    expect(() =>
      parseSignature('userQuestion:string -> analysisResult:string')
    ).not.toThrow()
    expect(() =>
      parseSignature('documentContent:string -> summaryText:string')
    ).not.toThrow()
    expect(() =>
      parseSignature(
        'customer_feedback:string -> sentiment_category:class "positive, negative, neutral"'
      )
    ).not.toThrow()
  })
})

describe('AxSignature class validation', () => {
  it('throws error when adding invalid input field', () => {
    const sig = new AxSignature()
    expect(() =>
      sig.addInputField({
        name: 'text',
        type: { name: 'string', isArray: false },
      })
    ).toThrow('too generic')
  })

  it('throws error when adding invalid output field', () => {
    const sig = new AxSignature()
    expect(() =>
      sig.addOutputField({
        name: 'outputImage',
        type: { name: 'image', isArray: false },
      })
    ).toThrow('image type is not supported in output fields')
  })

  it('throws error when setting non-array input fields', () => {
    const sig = new AxSignature()
    expect(() =>
      sig.setInputFields('not an array' as unknown as readonly AxField[])
    ).toThrow('Input fields must be an array')
  })

  it('throws error when setting non-array output fields', () => {
    const sig = new AxSignature()
    expect(() =>
      sig.setOutputFields('not an array' as unknown as readonly AxField[])
    ).toThrow('Output fields must be an array')
  })

  it('throws error when setting non-string description', () => {
    const sig = new AxSignature()
    expect(() => sig.setDescription(123 as unknown as string)).toThrow(
      'Description must be a string'
    )
  })

  it('validates class options for duplicates', () => {
    expect(
      () =>
        new AxSignature(
          'userInput:string -> categoryType:class "positive, negative, positive"'
        )
    ).toThrow('Duplicate class options found')
  })

  it('validates minimum signature requirements', () => {
    const sig = new AxSignature()

    // Setting fields individually should not trigger full validation
    sig.setOutputFields([
      { name: 'responseText', type: { name: 'string', isArray: false } },
    ])

    // But explicit validation should fail because there's no input field
    expect(() => sig.validate()).toThrow('must have at least one input field')

    sig.setInputFields([
      { name: 'userInput', type: { name: 'string', isArray: false } },
    ])

    // Setting empty output fields should work during construction
    sig.setOutputFields([])

    // But explicit validation should fail because there's no output field
    expect(() => sig.validate()).toThrow('must have at least one output field')
  })

  it('provides helpful suggestions in error messages', () => {
    try {
      new AxSignature('text:string -> response:string')
    } catch (error) {
      expect((error as Error).message).toContain('too generic')
      // The error should have some suggestion, let's check it's informative
      expect(error).toHaveProperty('suggestion')
    }
  })
})

describe('extract values with signatures', () => {
  it('should extract simple answer value', () => {
    const sig = new AxSignature(`userQuestion:string -> responseText:string`)
    const v1 = {}
    extractValues(sig, v1, `Response Text: "hello world"`)

    expect(v1).toEqual({ responseText: '"hello world"' })
  })

  it('should not extract value with no prefix and single output', () => {
    const sig = new AxSignature(`userQuestion:string -> responseText:string`)
    const v1 = {}
    extractValues(sig, v1, `"hello world"`)

    expect(v1).toEqual({})
  })

  it('should extract and parse JSON values', () => {
    const sig = new AxSignature(`userQuestion:string -> analysisResult:json`)

    const v1 = {}
    extractValues(sig, v1, 'Analysis Result: ```json\n{"hello": "world"}\n```')

    expect(v1).toEqual({ analysisResult: { hello: 'world' } })
  })

  it('should extract multiple text values', () => {
    const sig = new AxSignature(
      `documentText:string -> titleText:string, keyPoints:string, descriptionText:string`
    )
    const v1 = {}
    extractValues(
      sig,
      v1,
      `Title Text: Coastal Ecosystem Restoration\nKey Points: Coastal regions prone to natural disasters, Selection criteria based on vulnerability indices and population density, Climate risk assessments conducted for sea-level rise and extreme weather events, Targeted ecosystems include mangrove forests, coral reefs, wetlands\nDescription Text: The project focuses on coastal regions vulnerable to natural disasters like hurricanes and flooding. Selection criteria included vulnerability indices, population density, and proximity to critical infrastructure. Climate risk assessments identified risks related to sea-level rise, storm surges, and extreme weather events. Targeted ecosystems encompass mangrove forests, coral reefs, and wetlands that provide coastal protection, biodiversity support, and livelihood opportunities for local communities.`
    )

    expect(v1).toEqual({
      titleText: 'Coastal Ecosystem Restoration',
      keyPoints:
        'Coastal regions prone to natural disasters, Selection criteria based on vulnerability indices and population density, Climate risk assessments conducted for sea-level rise and extreme weather events, Targeted ecosystems include mangrove forests, coral reefs, wetlands',
      descriptionText:
        'The project focuses on coastal regions vulnerable to natural disasters like hurricanes and flooding. Selection criteria included vulnerability indices, population density, and proximity to critical infrastructure. Climate risk assessments identified risks related to sea-level rise, storm surges, and extreme weather events. Targeted ecosystems encompass mangrove forests, coral reefs, and wetlands that provide coastal protection, biodiversity support, and livelihood opportunities for local communities.',
    })
  })
})

describe('AxSignature', () => {
  it('should create from a valid signature string', () => {
    const sig = new AxSignature(
      'userQuestion:string -> modelAnswer:string, certaintyValue:number'
    )
    expect(sig.getInputFields()).toHaveLength(1)
    expect(sig.getOutputFields()).toHaveLength(2)
    expect(sig.toString()).toBe(
      'userQuestion:string -> modelAnswer:string, certaintyValue:number'
    )
  })

  it('should create from another AxSignature instance', () => {
    const original = new AxSignature(
      'userQuestion:string -> modelAnswer:string, certaintyValue:number'
    )
    const clone = new AxSignature(original)
    expect(clone.toString()).toBe(original.toString())
    expect(clone.hash()).toBe(original.hash())
  })

  it('should throw AxSignatureValidationError for invalid string', () => {
    expect(() => new AxSignature('invalid-signature')).toThrow(
      'Invalid Signature'
    )
  })

  it('should set and get description', () => {
    const sig = new AxSignature('userQuestion:string -> modelAnswer:string')
    sig.setDescription('This is a Q&A signature.')
    expect(sig.getDescription()).toBe('This is a Q&A signature.')
    expect(sig.toString()).toContain('"This is a Q&A signature."')
  })

  it('should add input and output fields', () => {
    const sig = new AxSignature('userQuestion:string -> modelAnswer:string')
    sig.addInputField({
      name: 'userEmail',
      type: { name: 'string', isArray: false },
      description: 'User email address',
    })
    sig.addOutputField({
      name: 'userResponse',
      type: { name: 'string', isArray: false },
      description: 'User response',
    })

    expect(sig.getInputFields().length).toBe(2)
    expect(sig.getOutputFields().length).toBe(2)
  })

  it('should prevent adding fields with reserved names', () => {
    const sig = new AxSignature()
    expect(() =>
      sig.addInputField({
        name: 'string',
        type: { name: 'string', isArray: false },
      })
    ).toThrow('too generic')
    expect(() =>
      sig.addOutputField({
        name: 'response',
        type: { name: 'string', isArray: false },
      })
    ).toThrow('too generic')
  })

  it('should set input and output fields', () => {
    const sig = new AxSignature('userQuestion:string -> modelAnswer:string')
    sig.setInputFields([
      {
        name: 'userEmail',
        type: { name: 'string', isArray: false },
        description: 'User email',
      },
    ])
    sig.setOutputFields([
      {
        name: 'userResponse',
        type: { name: 'string', isArray: false },
        description: 'User response',
      },
    ])

    expect(sig.getInputFields().length).toBe(1)
    expect(sig.getOutputFields().length).toBe(1)
  })

  it('should handle complex field definitions', () => {
    const sig = new AxSignature('userQuestion:string -> modelAnswer:string')
    sig.addInputField({
      name: 'contextInfo',
      type: { name: 'string', isArray: false },
      description: 'Context information',
    })
    sig.addOutputField({
      name: 'confidenceScore',
      type: { name: 'number', isArray: false },
      description: 'Confidence score',
      isOptional: true,
    })

    expect(sig.getInputFields().length).toBe(2)
    expect(sig.getOutputFields().length).toBe(2)
  })

  it('should generate a consistent hash', () => {
    const sig1 = new AxSignature(
      'userQuestion:string -> modelAnswer:string, certaintyValue:number'
    )
    const sig2 = new AxSignature(
      'userQuestion:string -> modelAnswer:string, certaintyValue:number'
    )
    const sig3 = new AxSignature('userQuestion:string -> modelAnswer:string')

    expect(sig1.hash()).toBe(sig2.hash())
    expect(sig1.hash()).not.toBe(sig3.hash())
  })

  it('should update hash when modified', () => {
    const sig = new AxSignature('userQuestion:string -> modelAnswer:string')
    const initialHash = sig.hash()
    sig.addOutputField({
      name: 'certaintyValue',
      type: { name: 'number', isArray: false },
    })
    const modifiedHash = sig.hash()

    expect(initialHash).not.toBe(modifiedHash)
  })

  it('should return a JSON representation', () => {
    const sig = new AxSignature(
      '"Q&A" userQuestion:string -> modelAnswer:string, certaintyValue:number'
    )
    const json = sig.toJSON()

    expect(json.id).toBe(sig.hash())
    expect(json.description).toBe('Q&A')
    expect(json.inputFields).toHaveLength(1)
    expect(json.outputFields).toHaveLength(2)
  })
})

describe('extractValues with AxSignature', () => {
  it('should extract values based on a signature', () => {
    const sig = new AxSignature('userQuestion:string -> modelAnswer:string')
    const result: Record<string, unknown> = {}
    const content = `Model Answer: The answer is 42.`

    extractValues(sig, result, content)

    expect(result).toEqual({ modelAnswer: 'The answer is 42.' })
  })

  it('should handle missing optional fields', () => {
    const sig = new AxSignature(
      'userQuestion:string -> modelAnswer:string, memoText?:string'
    )
    const content = 'Model Answer: The answer is 42.'
    const result = {}
    extractValues(sig, result, content)

    expect(result).toEqual({ modelAnswer: 'The answer is 42.' })
  })

  it('should not return internal fields', () => {
    const sig2 = new AxSignature(
      'userQuestion:string -> modelAnswer:string, thoughtProcess!:string'
    )
    const result: Record<string, unknown> = {}
    const content = `Model Answer: The answer is 42.
Thought Process: I am thinking.`

    extractValues(sig2, result, content)

    expect(result).toEqual({ modelAnswer: 'The answer is 42.' })
  })

  it('should create signature with mixed input fields and output field', () => {
    // Create a new empty AxSignature
    const sig = new AxSignature()

    // Add first input field (required)
    sig.addInputField({
      name: 'userQuestion',
      type: { name: 'string', isArray: false },
      description: 'User question input',
    })

    // Add second input field (optional)
    sig.addInputField({
      name: 'contextInfo',
      type: { name: 'string', isArray: false },
      description: 'Optional context information',
      isOptional: true,
    })

    // Add output field with descriptive name (not "response" which is too generic)
    sig.addOutputField({
      name: 'answerText',
      type: { name: 'string', isArray: false },
      description: 'Generated answer text',
    })

    // Verify the signature was created correctly
    expect(sig.getInputFields()).toHaveLength(2)
    expect(sig.getOutputFields()).toHaveLength(1)

    // Check input fields
    const inputFields = sig.getInputFields()
    expect(inputFields[0]?.name).toBe('userQuestion')
    expect(inputFields[0]?.isOptional).toBeUndefined()
    expect(inputFields[1]?.name).toBe('contextInfo')
    expect(inputFields[1]?.isOptional).toBe(true)

    // Check output field
    const outputFields = sig.getOutputFields()
    expect(outputFields[0]?.name).toBe('answerText')

    // Verify signature string representation includes descriptions
    expect(sig.toString()).toBe(
      'userQuestion:string "User question input", contextInfo?:string "Optional context information" -> answerText:string "Generated answer text"'
    )

    // Verify we can generate a hash
    expect(sig.hash()).toBeTruthy()
  })

  it('should fail when using generic field name "response"', () => {
    const sig = new AxSignature()

    // This should throw an error because "response" is too generic
    expect(() =>
      sig.addOutputField({
        name: 'response',
        type: { name: 'string', isArray: false },
      })
    ).toThrow('too generic')
  })

  it('should validate full signature consistency when explicitly called', () => {
    const sig = new AxSignature()

    // Add only input field - should work without throwing
    sig.addInputField({
      name: 'userQuestion',
      type: { name: 'string', isArray: false },
    })

    // Full validation should fail because there's no output field
    expect(() => sig.validate()).toThrow('must have at least one output field')

    // Add output field
    sig.addOutputField({
      name: 'answerText',
      type: { name: 'string', isArray: false },
    })

    // Now full validation should pass
    expect(() => sig.validate()).not.toThrow()
  })

  it('should cache validation results and avoid redundant validation', () => {
    const sig = new AxSignature()
    sig.addInputField({
      name: 'userInput',
      type: { name: 'string', isArray: false },
    })
    sig.addOutputField({
      name: 'responseText',
      type: { name: 'string', isArray: false },
    })

    // First validation should pass and cache the result
    const result1 = sig.validate()
    expect(result1).toBe(true)

    // Second validation should return cached result (true) without re-validating
    const result2 = sig.validate()
    expect(result2).toBe(true)

    // Modify signature - this should invalidate cache
    sig.addInputField({
      name: 'contextInfo',
      type: { name: 'string', isArray: false },
    })

    // Validation should run again and pass
    const result3 = sig.validate()
    expect(result3).toBe(true)

    // Another call should use cached result
    const result4 = sig.validate()
    expect(result4).toBe(true)
  })
})



================================================
FILE: src/ax/dsp/sig.ts
================================================
import { createHash } from 'crypto'

import type { AxFunctionJSONSchema } from '../ai/types.js'

import { axGlobals } from './globals.js'
import {
  type InputParsedField,
  type OutputParsedField,
  type ParsedSignature,
  parseSignature,
} from './parser.js'

export interface AxField {
  name: string
  title?: string
  description?: string
  type?: {
    name:
      | 'string'
      | 'number'
      | 'boolean'
      | 'json'
      | 'image'
      | 'audio'
      | 'date'
      | 'datetime'
      | 'class'
      | 'code'
    isArray?: boolean
    options?: string[]
  }
  isOptional?: boolean
  isInternal?: boolean
}

export type AxIField = Omit<AxField, 'title'> & { title: string }

class AxSignatureValidationError extends Error {
  constructor(
    message: string,
    public readonly fieldName?: string,
    public readonly suggestion?: string
  ) {
    super(message)
    this.name = 'AxSignatureValidationError'
  }
}

export interface AxSignatureConfig {
  description?: string
  inputs: readonly AxField[]
  outputs: readonly AxField[]
}

export class AxSignature {
  private description?: string
  private inputFields: AxIField[]
  private outputFields: AxIField[]

  private sigHash: string
  private sigString: string

  // Validation caching - stores hash when validation last passed
  private validatedAtHash?: string

  constructor(signature?: Readonly<AxSignature | string | AxSignatureConfig>) {
    if (!signature) {
      this.inputFields = []
      this.outputFields = []
      this.sigHash = ''
      this.sigString = ''
      return
    }

    if (typeof signature === 'string') {
      let sig: ParsedSignature
      try {
        sig = parseSignature(signature)
      } catch (e) {
        if (e instanceof Error) {
          // Preserve the suggestion if it's a SignatureValidationError
          const suggestion =
            'suggestion' in e &&
            typeof (e as { suggestion: unknown }).suggestion === 'string'
              ? (e as { suggestion: string }).suggestion
              : 'Please check the signature format. Example: "userInput:string -> responseText:string"'
          throw new AxSignatureValidationError(
            `Invalid Signature: ${e.message}`,
            undefined,
            suggestion
          )
        }
        throw new AxSignatureValidationError(
          `Invalid Signature: ${signature}`,
          undefined,
          'Please check the signature format. Example: "userInput:string -> responseText:string"'
        )
      }
      this.description = sig.desc
      this.inputFields = sig.inputs.map((v) => this.parseParsedField(v))
      this.outputFields = sig.outputs.map((v) => this.parseParsedField(v))
      ;[this.sigHash, this.sigString] = this.updateHash()
    } else if (signature instanceof AxSignature) {
      this.description = signature.getDescription()
      this.inputFields = structuredClone(
        signature.getInputFields()
      ) as AxIField[]
      this.outputFields = structuredClone(
        signature.getOutputFields()
      ) as AxIField[]
      this.sigHash = signature.hash()
      this.sigString = signature.toString()
      // Copy validation state if the source signature was validated
      if (signature.validatedAtHash === this.sigHash) {
        this.validatedAtHash = this.sigHash
      }
    } else if (typeof signature === 'object' && signature !== null) {
      // Handle AxSignatureConfig object
      if (!('inputs' in signature) || !('outputs' in signature)) {
        throw new AxSignatureValidationError(
          'Invalid signature object: missing inputs or outputs',
          undefined,
          'Signature object must have "inputs" and "outputs" arrays. Example: { inputs: [...], outputs: [...] }'
        )
      }

      if (
        !Array.isArray(signature.inputs) ||
        !Array.isArray(signature.outputs)
      ) {
        throw new AxSignatureValidationError(
          'Invalid signature object: inputs and outputs must be arrays',
          undefined,
          'Both "inputs" and "outputs" must be arrays of AxField objects'
        )
      }

      try {
        this.description = signature.description
        this.inputFields = signature.inputs.map((v) => this.parseField(v))
        this.outputFields = signature.outputs.map((v) => this.parseField(v))
        ;[this.sigHash, this.sigString] = this.updateHash()
      } catch (error) {
        if (error instanceof AxSignatureValidationError) {
          throw error
        }
        throw new AxSignatureValidationError(
          `Failed to create signature from object: ${error instanceof Error ? error.message : 'Unknown error'}`,
          undefined,
          'Check that all fields in inputs and outputs arrays are valid AxField objects'
        )
      }
    } else {
      throw new AxSignatureValidationError(
        'Invalid signature argument type',
        undefined,
        'Signature must be a string, another AxSignature instance, or an object with inputs and outputs arrays'
      )
    }
  }

  private parseParsedField = (
    field: Readonly<InputParsedField | OutputParsedField>
  ): AxIField => {
    if (!field.name || field.name.length === 0) {
      throw new AxSignatureValidationError(
        'Field name is required',
        field.name,
        'Every field must have a descriptive name. Example: "userInput", "responseText"'
      )
    }

    const title = this.toTitle(field.name)
    return {
      name: field.name,
      title,
      description: 'desc' in field ? field.desc : undefined,
      type: field.type ?? { name: 'string', isArray: false },
      ...('isInternal' in field ? { isInternal: field.isInternal } : {}),
      ...('isOptional' in field ? { isOptional: field.isOptional } : {}),
    }
  }

  private parseField = (field: Readonly<AxField>): AxIField => {
    const title =
      !field.title || field.title.length === 0
        ? this.toTitle(field.name)
        : field.title

    if (field.type && (!field.type.name || field.type.name.length === 0)) {
      throw new AxSignatureValidationError(
        'Field type name is required',
        field.name,
        'Specify a valid type. Available types: string, number, boolean, json, image, audio, date, datetime, class, code'
      )
    }

    return { ...field, title }
  }

  public setDescription = (desc: string) => {
    if (typeof desc !== 'string') {
      throw new AxSignatureValidationError(
        'Description must be a string',
        undefined,
        'Provide a string description for the signature'
      )
    }
    this.description = desc
    this.invalidateValidationCache()
    this.updateHashLight()
  }

  public addInputField = (field: Readonly<AxField>) => {
    try {
      const parsedField = this.parseField(field)
      validateField(parsedField, 'input')

      // Check for duplicate input field names
      for (const existingField of this.inputFields) {
        if (existingField.name === parsedField.name) {
          throw new AxSignatureValidationError(
            `Duplicate input field name: "${parsedField.name}"`,
            parsedField.name,
            'Each field name must be unique within the signature'
          )
        }
      }

      // Check if field name conflicts with existing output fields
      for (const outputField of this.outputFields) {
        if (outputField.name === parsedField.name) {
          throw new AxSignatureValidationError(
            `Field name "${parsedField.name}" appears in both inputs and outputs`,
            parsedField.name,
            'Use different names for input and output fields to avoid confusion'
          )
        }
      }

      this.inputFields.push(parsedField)
      this.invalidateValidationCache()
      this.updateHashLight()
    } catch (error) {
      if (error instanceof AxSignatureValidationError) {
        throw error
      }
      throw new AxSignatureValidationError(
        `Failed to add input field "${field.name}": ${error instanceof Error ? error.message : 'Unknown error'}`,
        field.name
      )
    }
  }

  public addOutputField = (field: Readonly<AxField>) => {
    try {
      const parsedField = this.parseField(field)
      validateField(parsedField, 'output')

      // Check for duplicate output field names
      for (const existingField of this.outputFields) {
        if (existingField.name === parsedField.name) {
          throw new AxSignatureValidationError(
            `Duplicate output field name: "${parsedField.name}"`,
            parsedField.name,
            'Each field name must be unique within the signature'
          )
        }
      }

      // Check if field name conflicts with existing input fields
      for (const inputField of this.inputFields) {
        if (inputField.name === parsedField.name) {
          throw new AxSignatureValidationError(
            `Field name "${parsedField.name}" appears in both inputs and outputs`,
            parsedField.name,
            'Use different names for input and output fields to avoid confusion'
          )
        }
      }

      this.outputFields.push(parsedField)
      this.invalidateValidationCache()
      this.updateHashLight()
    } catch (error) {
      if (error instanceof AxSignatureValidationError) {
        throw error
      }
      throw new AxSignatureValidationError(
        `Failed to add output field "${field.name}": ${error instanceof Error ? error.message : 'Unknown error'}`,
        field.name
      )
    }
  }

  public setInputFields = (fields: readonly AxField[]) => {
    if (!Array.isArray(fields)) {
      throw new AxSignatureValidationError(
        'Input fields must be an array',
        undefined,
        'Provide an array of field objects'
      )
    }

    try {
      const parsedFields = fields.map((v) => {
        const parsed = this.parseField(v)
        validateField(parsed, 'input')
        return parsed
      })
      this.inputFields = parsedFields
      this.invalidateValidationCache()
      this.updateHashLight()
    } catch (error) {
      if (error instanceof AxSignatureValidationError) {
        throw error
      }
      throw new AxSignatureValidationError(
        `Failed to set input fields: ${error instanceof Error ? error.message : 'Unknown error'}`
      )
    }
  }

  public setOutputFields = (fields: readonly AxField[]) => {
    if (!Array.isArray(fields)) {
      throw new AxSignatureValidationError(
        'Output fields must be an array',
        undefined,
        'Provide an array of field objects'
      )
    }

    try {
      const parsedFields = fields.map((v) => {
        const parsed = this.parseField(v)
        validateField(parsed, 'output')
        return parsed
      })
      this.outputFields = parsedFields
      this.invalidateValidationCache()
      this.updateHashLight()
    } catch (error) {
      if (error instanceof AxSignatureValidationError) {
        throw error
      }
      throw new AxSignatureValidationError(
        `Failed to set output fields: ${error instanceof Error ? error.message : 'Unknown error'}`
      )
    }
  }

  public getInputFields = (): Readonly<AxIField[]> => this.inputFields
  public getOutputFields = (): Readonly<AxIField[]> => this.outputFields
  public getDescription = () => this.description

  private invalidateValidationCache = (): void => {
    this.validatedAtHash = undefined
  }

  private toTitle = (name: string) => {
    let result = name.replace(/_/g, ' ')
    result = result.replace(/([A-Z]|[0-9]+)/g, ' $1').trim()
    return result.charAt(0).toUpperCase() + result.slice(1)
  }

  public toJSONSchema = (): AxFunctionJSONSchema => {
    const properties: Record<string, unknown> = {}
    const required: Array<string> = []

    for (const f of this.inputFields) {
      const type = f.type ? f.type.name : 'string'
      if (f.type?.isArray) {
        properties[f.name] = {
          description: f.description,
          type: 'array' as const,
          items: {
            type: type,
            description: f.description,
          },
        }
      } else {
        properties[f.name] = {
          description: f.description,
          type: type,
        }
      }

      if (!f.isOptional) {
        required.push(f.name)
      }
    }

    const schema = {
      type: 'object',
      properties: properties,
      required: required,
    }

    return schema as AxFunctionJSONSchema
  }

  private updateHashLight = (): [string, string] => {
    try {
      // Light validation - only validate individual fields, not full signature consistency
      this.getInputFields().forEach((field) => {
        validateField(field, 'input')
      })
      this.getOutputFields().forEach((field) => {
        validateField(field, 'output')
      })

      this.sigHash = createHash('sha256')
        .update(JSON.stringify(this.inputFields))
        .update(JSON.stringify(this.outputFields))
        .digest('hex')

      this.sigString = renderSignature(
        this.description,
        this.inputFields,
        this.outputFields
      )

      return [this.sigHash, this.sigString]
    } catch (error) {
      if (error instanceof AxSignatureValidationError) {
        throw error
      }
      throw new AxSignatureValidationError(
        `Signature validation failed: ${error instanceof Error ? error.message : 'Unknown error'}`
      )
    }
  }

  private updateHash = (): [string, string] => {
    try {
      this.getInputFields().forEach((field) => {
        validateField(field, 'input')
      })
      this.getOutputFields().forEach((field) => {
        validateField(field, 'output')
      })

      this.validateSignatureConsistency()

      this.sigHash = createHash('sha256')
        .update(this.description ?? '')
        .update(JSON.stringify(this.inputFields))
        .update(JSON.stringify(this.outputFields))
        .digest('hex')

      this.sigString = renderSignature(
        this.description,
        this.inputFields,
        this.outputFields
      )

      return [this.sigHash, this.sigString]
    } catch (error) {
      if (error instanceof AxSignatureValidationError) {
        throw error
      }
      throw new AxSignatureValidationError(
        `Signature validation failed: ${error instanceof Error ? error.message : 'Unknown error'}`
      )
    }
  }

  private validateSignatureConsistency(): void {
    const inputNames = new Set<string>()
    for (const field of this.inputFields) {
      if (inputNames.has(field.name)) {
        throw new AxSignatureValidationError(
          `Duplicate input field name: "${field.name}"`,
          field.name,
          'Each field name must be unique within the signature'
        )
      }
      inputNames.add(field.name)
    }

    const outputNames = new Set<string>()
    for (const field of this.outputFields) {
      if (outputNames.has(field.name)) {
        throw new AxSignatureValidationError(
          `Duplicate output field name: "${field.name}"`,
          field.name,
          'Each field name must be unique within the signature'
        )
      }
      outputNames.add(field.name)
    }

    for (const outputField of this.outputFields) {
      if (inputNames.has(outputField.name)) {
        throw new AxSignatureValidationError(
          `Field name "${outputField.name}" appears in both inputs and outputs`,
          outputField.name,
          'Use different names for input and output fields to avoid confusion'
        )
      }
    }

    if (this.inputFields.length === 0) {
      throw new AxSignatureValidationError(
        'Signature must have at least one input field',
        undefined,
        'Add an input field. Example: "userInput:string -> ..."'
      )
    }

    if (this.outputFields.length === 0) {
      throw new AxSignatureValidationError(
        'Signature must have at least one output field',
        undefined,
        'Add an output field. Example: "... -> responseText:string"'
      )
    }
  }

  public validate = (): boolean => {
    // Check if already validated at current hash
    if (this.validatedAtHash === this.sigHash) {
      return true
    }

    try {
      // Perform full validation
      this.updateHash()

      // Cache validation success
      this.validatedAtHash = this.sigHash

      return true
    } catch (error) {
      // Clear validation cache on failure
      this.validatedAtHash = undefined
      throw error
    }
  }

  public hash = () => this.sigHash

  public toString = () => this.sigString

  public toJSON = () => {
    return {
      id: this.hash(),
      description: this.description,
      inputFields: this.inputFields,
      outputFields: this.outputFields,
    }
  }
}

function renderField(field: Readonly<AxField>): string {
  let result = field.name
  if (field.isOptional) {
    result += '?'
  }
  if (field.isInternal) {
    result += '!'
  }
  if (field.type) {
    result += ':' + field.type.name
    if (field.type.isArray) {
      result += '[]'
    }
    if (field.type.name === 'class' && field.type.options) {
      result += ` "${field.type.options.join(' | ')}"`
    }
  }
  if (field.description && field.type?.name !== 'class') {
    result += ` "${field.description}"`
  }
  return result
}

function renderSignature(
  description: string | undefined,
  inputFields: readonly AxField[],
  outputFields: readonly AxField[]
): string {
  const descriptionPart = description ? `"${description}" ` : ''

  const inputFieldsRendered = inputFields.map(renderField).join(', ')

  const outputFieldsRendered = outputFields.map(renderField).join(', ')

  return `${descriptionPart}${inputFieldsRendered} -> ${outputFieldsRendered}`
}

function isValidCase(inputString: string): boolean {
  const camelCaseRegex = /^[a-z][a-zA-Z0-9]*$/
  const snakeCaseRegex = /^[a-z]+(_[a-z0-9]+)*$/

  return camelCaseRegex.test(inputString) || snakeCaseRegex.test(inputString)
}

function validateField(
  field: Readonly<AxField>,
  context: 'input' | 'output'
): void {
  if (!field.name || field.name.length === 0) {
    throw new AxSignatureValidationError(
      'Field name cannot be blank',
      field.name,
      'Every field must have a descriptive name'
    )
  }

  if (!isValidCase(field.name)) {
    throw new AxSignatureValidationError(
      `Invalid field name '${field.name}' - must be camelCase or snake_case`,
      field.name,
      'Use camelCase (e.g., "userInput") or snake_case (e.g., "user_input")'
    )
  }

  if (axGlobals.signatureStrict) {
    const reservedNames = [
      'text',
      'object',
      'image',
      'string',
      'number',
      'boolean',
      'json',
      'array',
      'datetime',
      'date',
      'time',
      'type',
      'class',
      'input',
      'output',
      'data',
      'value',
      'result',
      'response',
      'request',
      'item',
      'element',
    ]

    if (reservedNames.includes(field.name.toLowerCase())) {
      const suggestions =
        context === 'input'
          ? [
              'userInput',
              'questionText',
              'documentContent',
              'messageText',
              'queryString',
            ]
          : [
              'responseText',
              'analysisResult',
              'categoryType',
              'summaryText',
              'outputData',
            ]

      throw new AxSignatureValidationError(
        `Field name '${field.name}' is too generic`,
        field.name,
        `Use a more descriptive name. Examples for ${context} fields: ${suggestions.join(', ')}`
      )
    }
  }

  if (field.name.length < 2) {
    throw new AxSignatureValidationError(
      `Field name '${field.name}' is too short`,
      field.name,
      'Field names must be at least 2 characters long'
    )
  }

  if (field.name.length > 50) {
    throw new AxSignatureValidationError(
      `Field name '${field.name}' is too long (${field.name.length} characters)`,
      field.name,
      'Field names should be 50 characters or less'
    )
  }

  if (field.type) {
    validateFieldType(field, context)
  }
}

function validateFieldType(
  field: Readonly<AxField>,
  context: 'input' | 'output'
): void {
  if (!field.type) return

  const { type } = field

  if (type.name === 'image' || type.name === 'audio') {
    if (context === 'output') {
      throw new AxSignatureValidationError(
        `${type.name} type is not supported in output fields`,
        field.name,
        `${type.name} types can only be used in input fields`
      )
    }

    if (type.isArray) {
      throw new AxSignatureValidationError(
        `Arrays of ${type.name} are not supported`,
        field.name,
        `Use a single ${type.name} type instead`
      )
    }
  }

  if (type.name === 'class') {
    if (context === 'input') {
      throw new AxSignatureValidationError(
        'Class type is not supported in input fields',
        field.name,
        'Class types are only allowed on output fields. Use "string" type for input classifications'
      )
    }

    if (!type.options || type.options.length === 0) {
      throw new AxSignatureValidationError(
        'Class type requires options',
        field.name,
        'Provide class options. Example: class "positive, negative, neutral"'
      )
    }

    for (const option of type.options) {
      if (!option || option.trim().length === 0) {
        throw new AxSignatureValidationError(
          'Empty class option found',
          field.name,
          'All class options must be non-empty strings'
        )
      }

      const trimmedOption = option.trim()
      if (trimmedOption.includes(',') || trimmedOption.includes('|')) {
        throw new AxSignatureValidationError(
          `Invalid class option "${trimmedOption}"`,
          field.name,
          'Class options cannot contain commas (,) or pipes (|) as they are used to separate options'
        )
      }
    }

    const uniqueOptions = new Set(
      type.options.map((opt) => opt.trim().toLowerCase())
    )
    if (uniqueOptions.size !== type.options.length) {
      throw new AxSignatureValidationError(
        'Duplicate class options found',
        field.name,
        'Each class option must be unique (case-insensitive)'
      )
    }
  }

  if (type.name === 'code' && type.isArray) {
    throw new AxSignatureValidationError(
      'Arrays of code are not commonly supported',
      field.name,
      'Consider using a single code field or an array of strings instead'
    )
  }

  if (field.isInternal && context === 'input') {
    throw new AxSignatureValidationError(
      'Internal marker (!) is not allowed on input fields',
      field.name,
      'Internal markers are only allowed on output fields'
    )
  }
}



================================================
FILE: src/ax/dsp/stopwords.ts
================================================
export const stopwords = new Set([
  '0o',
  '0s',
  '3a',
  '3b',
  '3d',
  '6b',
  '6o',
  'a',
  'a1',
  'a2',
  'a3',
  'a4',
  'ab',
  'able',
  'about',
  'above',
  'abst',
  'ac',
  'accordance',
  'according',
  'accordingly',
  'across',
  'act',
  'actually',
  'ad',
  'added',
  'adj',
  'ae',
  'af',
  'affected',
  'affecting',
  'affects',
  'after',
  'afterwards',
  'ag',
  'again',
  'against',
  'ah',
  'ain',
  "ain't",
  'aj',
  'al',
  'all',
  'allow',
  'allows',
  'almost',
  'alone',
  'along',
  'already',
  'also',
  'although',
  'always',
  'am',
  'among',
  'amongst',
  'amoungst',
  'amount',
  'an',
  'and',
  'announce',
  'another',
  'any',
  'anybody',
  'anyhow',
  'anymore',
  'anyone',
  'anything',
  'anyway',
  'anyways',
  'anywhere',
  'ao',
  'ap',
  'apart',
  'apparently',
  'appear',
  'appreciate',
  'appropriate',
  'approximately',
  'ar',
  'are',
  'aren',
  'arent',
  "aren't",
  'arise',
  'around',
  'as',
  "a's",
  'aside',
  'ask',
  'asking',
  'associated',
  'at',
  'au',
  'auth',
  'av',
  'available',
  'aw',
  'away',
  'awfully',
  'ax',
  'ay',
  'az',
  'b',
  'b1',
  'b2',
  'b3',
  'ba',
  'back',
  'bc',
  'bd',
  'be',
  'became',
  'because',
  'become',
  'becomes',
  'becoming',
  'been',
  'before',
  'beforehand',
  'begin',
  'beginning',
  'beginnings',
  'begins',
  'behind',
  'being',
  'believe',
  'below',
  'beside',
  'besides',
  'best',
  'better',
  'between',
  'beyond',
  'bi',
  'bill',
  'biol',
  'bj',
  'bk',
  'bl',
  'bn',
  'both',
  'bottom',
  'bp',
  'br',
  'brief',
  'briefly',
  'bs',
  'bt',
  'bu',
  'but',
  'bx',
  'by',
  'c',
  'c1',
  'c2',
  'c3',
  'ca',
  'call',
  'came',
  'can',
  'cannot',
  'cant',
  "can't",
  'cause',
  'causes',
  'cc',
  'cd',
  'ce',
  'certain',
  'certainly',
  'cf',
  'cg',
  'ch',
  'changes',
  'ci',
  'cit',
  'cj',
  'cl',
  'clearly',
  'cm',
  "c'mon",
  'cn',
  'co',
  'com',
  'come',
  'comes',
  'con',
  'concerning',
  'consequently',
  'consider',
  'considering',
  'contain',
  'containing',
  'contains',
  'corresponding',
  'could',
  'couldn',
  'couldnt',
  "couldn't",
  'course',
  'cp',
  'cq',
  'cr',
  'cry',
  'cs',
  "c's",
  'ct',
  'cu',
  'currently',
  'cv',
  'cx',
  'cy',
  'cz',
  'd',
  'd2',
  'da',
  'date',
  'dc',
  'dd',
  'de',
  'definitely',
  'describe',
  'described',
  'despite',
  'detail',
  'df',
  'di',
  'did',
  'didn',
  "didn't",
  'different',
  'dj',
  'dk',
  'dl',
  'do',
  'does',
  'doesn',
  "doesn't",
  'doing',
  'don',
  'done',
  "don't",
  'down',
  'downwards',
  'dp',
  'dr',
  'ds',
  'dt',
  'du',
  'due',
  'during',
  'dx',
  'dy',
  'e',
  'e2',
  'e3',
  'ea',
  'each',
  'ec',
  'ed',
  'edu',
  'ee',
  'ef',
  'effect',
  'eg',
  'ei',
  'eight',
  'eighty',
  'either',
  'ej',
  'el',
  'eleven',
  'else',
  'elsewhere',
  'em',
  'empty',
  'en',
  'end',
  'ending',
  'enough',
  'entirely',
  'eo',
  'ep',
  'eq',
  'er',
  'es',
  'especially',
  'est',
  'et',
  'et-al',
  'etc',
  'eu',
  'ev',
  'even',
  'ever',
  'every',
  'everybody',
  'everyone',
  'everything',
  'everywhere',
  'ex',
  'exactly',
  'example',
  'except',
  'ey',
  'f',
  'f2',
  'fa',
  'far',
  'fc',
  'few',
  'ff',
  'fi',
  'fifteen',
  'fifth',
  'fify',
  'fill',
  'find',
  'fire',
  'first',
  'five',
  'fix',
  'fj',
  'fl',
  'fn',
  'fo',
  'followed',
  'following',
  'follows',
  'for',
  'former',
  'formerly',
  'forth',
  'forty',
  'found',
  'four',
  'fr',
  'from',
  'front',
  'node:fs',
  'ft',
  'fu',
  'full',
  'further',
  'furthermore',
  'fy',
  'g',
  'ga',
  'gave',
  'ge',
  'get',
  'gets',
  'getting',
  'gi',
  'give',
  'given',
  'gives',
  'giving',
  'gj',
  'gl',
  'go',
  'goes',
  'going',
  'gone',
  'got',
  'gotten',
  'gr',
  'greetings',
  'gs',
  'gy',
  'h',
  'h2',
  'h3',
  'had',
  'hadn',
  "hadn't",
  'happens',
  'hardly',
  'has',
  'hasn',
  'hasnt',
  "hasn't",
  'have',
  'haven',
  "haven't",
  'having',
  'he',
  'hed',
  "he'd",
  "he'll",
  'hello',
  'help',
  'hence',
  'her',
  'here',
  'hereafter',
  'hereby',
  'herein',
  'heres',
  "here's",
  'hereupon',
  'hers',
  'herself',
  'hes',
  "he's",
  'hh',
  'hi',
  'hid',
  'him',
  'himself',
  'his',
  'hither',
  'hj',
  'ho',
  'home',
  'hopefully',
  'how',
  'howbeit',
  'however',
  "how's",
  'hr',
  'hs',
  'http',
  'hu',
  'hundred',
  'hy',
  'i',
  'i2',
  'i3',
  'i4',
  'i6',
  'i7',
  'i8',
  'ia',
  'ib',
  'ibid',
  'ic',
  'id',
  "i'd",
  'ie',
  'if',
  'ig',
  'ignored',
  'ih',
  'ii',
  'ij',
  'il',
  "i'll",
  'im',
  "i'm",
  'immediate',
  'immediately',
  'importance',
  'important',
  'in',
  'inasmuch',
  'inc',
  'indeed',
  'index',
  'indicate',
  'indicated',
  'indicates',
  'information',
  'inner',
  'insofar',
  'instead',
  'interest',
  'into',
  'invention',
  'inward',
  'io',
  'ip',
  'iq',
  'ir',
  'is',
  'isn',
  "isn't",
  'it',
  'itd',
  "it'd",
  "it'll",
  'its',
  "it's",
  'itself',
  'iv',
  "i've",
  'ix',
  'iy',
  'iz',
  'j',
  'jj',
  'jr',
  'js',
  'jt',
  'ju',
  'just',
  'k',
  'ke',
  'keep',
  'keeps',
  'kept',
  'kg',
  'kj',
  'km',
  'know',
  'known',
  'knows',
  'ko',
  'l',
  'l2',
  'la',
  'largely',
  'last',
  'lately',
  'later',
  'latter',
  'latterly',
  'lb',
  'lc',
  'le',
  'least',
  'les',
  'less',
  'lest',
  'let',
  'lets',
  "let's",
  'lf',
  'like',
  'liked',
  'likely',
  'line',
  'little',
  'lj',
  'll',
  'll',
  'ln',
  'lo',
  'look',
  'looking',
  'looks',
  'los',
  'lr',
  'ls',
  'lt',
  'ltd',
  'm',
  'm2',
  'ma',
  'made',
  'mainly',
  'make',
  'makes',
  'many',
  'may',
  'maybe',
  'me',
  'mean',
  'means',
  'meantime',
  'meanwhile',
  'merely',
  'mg',
  'might',
  'mightn',
  "mightn't",
  'mill',
  'million',
  'mine',
  'miss',
  'ml',
  'mn',
  'mo',
  'more',
  'moreover',
  'most',
  'mostly',
  'move',
  'mr',
  'mrs',
  'ms',
  'mt',
  'mu',
  'much',
  'mug',
  'must',
  'mustn',
  "mustn't",
  'my',
  'myself',
  'model',
  'n',
  'n2',
  'na',
  'name',
  'namely',
  'nay',
  'nc',
  'nd',
  'ne',
  'near',
  'nearly',
  'necessarily',
  'necessary',
  'need',
  'needn',
  "needn't",
  'needs',
  'neither',
  'never',
  'nevertheless',
  'new',
  'next',
  'ng',
  'ni',
  'nine',
  'ninety',
  'nj',
  'nl',
  'nn',
  'no',
  'nobody',
  'non',
  'none',
  'nonetheless',
  'noone',
  'nor',
  'normally',
  'nos',
  'not',
  'noted',
  'nothing',
  'novel',
  'now',
  'nowhere',
  'nr',
  'ns',
  'nt',
  'ny',
  'o',
  'oa',
  'ob',
  'obtain',
  'obtained',
  'obviously',
  'oc',
  'od',
  'of',
  'off',
  'often',
  'og',
  'oh',
  'oi',
  'oj',
  'ok',
  'okay',
  'ol',
  'old',
  'om',
  'omitted',
  'on',
  'once',
  'one',
  'ones',
  'only',
  'onto',
  'oo',
  'op',
  'oq',
  'or',
  'ord',
  'os',
  'ot',
  'other',
  'others',
  'otherwise',
  'ou',
  'ought',
  'our',
  'ours',
  'ourselves',
  'out',
  'outside',
  'over',
  'overall',
  'ow',
  'owing',
  'own',
  'ox',
  'oz',
  'p',
  'p1',
  'p2',
  'p3',
  'page',
  'pagecount',
  'pages',
  'par',
  'part',
  'particular',
  'particularly',
  'pas',
  'past',
  'pc',
  'pd',
  'pe',
  'per',
  'perhaps',
  'pf',
  'ph',
  'pi',
  'pj',
  'pk',
  'pl',
  'placed',
  'please',
  'plus',
  'pm',
  'pn',
  'po',
  'poorly',
  'possible',
  'possibly',
  'potentially',
  'pp',
  'pq',
  'pr',
  'predominantly',
  'present',
  'presumably',
  'previously',
  'primarily',
  'probably',
  'promptly',
  'proud',
  'provides',
  'ps',
  'pt',
  'pu',
  'put',
  'py',
  'q',
  'qj',
  'qu',
  'que',
  'quickly',
  'quite',
  'qv',
  'r',
  'r2',
  'ra',
  'ran',
  'rather',
  'rc',
  'rd',
  're',
  'readily',
  'really',
  'reasonably',
  'recent',
  'recently',
  'ref',
  'refs',
  'regarding',
  'regardless',
  'regards',
  'related',
  'relatively',
  'research',
  'research-articl',
  'respectively',
  'resulted',
  'resulting',
  'results',
  'rf',
  'rh',
  'ri',
  'right',
  'rj',
  'rl',
  'rm',
  'rn',
  'ro',
  'rq',
  'rr',
  'rs',
  'rt',
  'ru',
  'run',
  'rv',
  'ry',
  's',
  's2',
  'sa',
  'said',
  'same',
  'saw',
  'say',
  'saying',
  'says',
  'sc',
  'sd',
  'se',
  'sec',
  'second',
  'secondly',
  'section',
  'see',
  'seeing',
  'seem',
  'seemed',
  'seeming',
  'seems',
  'seen',
  'self',
  'selves',
  'sensible',
  'sent',
  'serious',
  'seriously',
  'seven',
  'several',
  'sf',
  'shall',
  'shan',
  "shan't",
  'she',
  'shed',
  "she'd",
  "she'll",
  'shes',
  "she's",
  'should',
  'shouldn',
  "shouldn't",
  "should've",
  'show',
  'showed',
  'shown',
  'showns',
  'shows',
  'si',
  'side',
  'significant',
  'significantly',
  'similar',
  'similarly',
  'since',
  'sincere',
  'six',
  'sixty',
  'sj',
  'sl',
  'slightly',
  'sm',
  'sn',
  'so',
  'some',
  'somebody',
  'somehow',
  'someone',
  'somethan',
  'something',
  'sometime',
  'sometimes',
  'somewhat',
  'somewhere',
  'soon',
  'sorry',
  'sp',
  'specifically',
  'specified',
  'specify',
  'specifying',
  'sq',
  'sr',
  'ss',
  'st',
  'still',
  'stop',
  'strongly',
  'sub',
  'substantially',
  'successfully',
  'such',
  'sufficiently',
  'suggest',
  'sup',
  'sure',
  'sy',
  'system',
  'sz',
  't',
  't1',
  't2',
  't3',
  'take',
  'taken',
  'taking',
  'tb',
  'tc',
  'td',
  'te',
  'tell',
  'ten',
  'tends',
  'tf',
  'th',
  'than',
  'thank',
  'thanks',
  'thanx',
  'that',
  "that'll",
  'thats',
  "that's",
  "that've",
  'the',
  'their',
  'theirs',
  'them',
  'themselves',
  'then',
  'thence',
  'there',
  'thereafter',
  'thereby',
  'thered',
  'therefore',
  'therein',
  "there'll",
  'thereof',
  'therere',
  'theres',
  "there's",
  'thereto',
  'thereupon',
  "there've",
  'these',
  'they',
  'theyd',
  "they'd",
  "they'll",
  'theyre',
  "they're",
  "they've",
  'thickv',
  'thin',
  'think',
  'third',
  'this',
  'thorough',
  'thoroughly',
  'those',
  'thou',
  'though',
  'thoughh',
  'thousand',
  'three',
  'throug',
  'through',
  'throughout',
  'thru',
  'thus',
  'ti',
  'til',
  'tip',
  'tj',
  'tl',
  'tm',
  'tn',
  'to',
  'together',
  'too',
  'took',
  'top',
  'toward',
  'towards',
  'tp',
  'tq',
  'tr',
  'tried',
  'tries',
  'truly',
  'try',
  'trying',
  'ts',
  "t's",
  'tt',
  'tv',
  'twelve',
  'twenty',
  'twice',
  'two',
  'tx',
  'u',
  'u201d',
  'ue',
  'ui',
  'uj',
  'uk',
  'um',
  'un',
  'under',
  'unfortunately',
  'unless',
  'unlike',
  'unlikely',
  'until',
  'unto',
  'uo',
  'up',
  'upon',
  'ups',
  'ur',
  'us',
  'use',
  'used',
  'useful',
  'usefully',
  'usefulness',
  'uses',
  'using',
  'usually',
  'ut',
  'v',
  'va',
  'value',
  'various',
  'vd',
  've',
  've',
  'very',
  'via',
  'viz',
  'vj',
  'vo',
  'vol',
  'vols',
  'volumtype',
  'vq',
  'vs',
  'vt',
  'vu',
  'w',
  'wa',
  'want',
  'wants',
  'was',
  'wasn',
  'wasnt',
  "wasn't",
  'way',
  'we',
  'wed',
  "we'd",
  'welcome',
  'well',
  "we'll",
  'well-b',
  'went',
  'were',
  "we're",
  'weren',
  'werent',
  "weren't",
  "we've",
  'what',
  'whatever',
  "what'll",
  'whats',
  "what's",
  'when',
  'whence',
  'whenever',
  "when's",
  'where',
  'whereafter',
  'whereas',
  'whereby',
  'wherein',
  'wheres',
  "where's",
  'whereupon',
  'wherever',
  'whether',
  'which',
  'while',
  'whim',
  'whither',
  'who',
  'whod',
  'whoever',
  'whole',
  "who'll",
  'whom',
  'whomever',
  'whos',
  "who's",
  'whose',
  'why',
  "why's",
  'wi',
  'widely',
  'will',
  'willing',
  'wish',
  'with',
  'within',
  'without',
  'wo',
  'won',
  'wonder',
  'wont',
  "won't",
  'words',
  'world',
  'would',
  'wouldn',
  'wouldnt',
  "wouldn't",
  'www',
  'x',
  'x1',
  'x2',
  'x3',
  'xf',
  'xi',
  'xj',
  'xk',
  'xl',
  'xn',
  'xo',
  'xs',
  'xt',
  'xv',
  'xx',
  'y',
  'y2',
  'yes',
  'yet',
  'yj',
  'yl',
  'you',
  'youd',
  "you'd",
  "you'll",
  'your',
  'youre',
  "you're",
  'yours',
  'yourself',
  'yourselves',
  "you've",
  'yr',
  'ys',
  'yt',
  'z',
  'zero',
  'zi',
  'zz',
  'task',
])



================================================
FILE: src/ax/dsp/strutil.ts
================================================
const trimNonAlphaNum = (str: string) => {
  return str.replace(/^\W+|\W+$/g, '')
}

const splitIntoTwo = (
  str: string,
  separator: Readonly<RegExp | string>
): string[] => {
  const index = str.search(separator)
  if (index === -1) {
    return [str] // No separator found, return the original string as the only part
  }
  const matchResult = str.match(separator)
  if (!matchResult) {
    throw new Error('Match failed unexpectedly.')
  }
  const firstPart = str.substring(0, index)
  const secondPart = str.substring(index + matchResult[0].length)
  return [firstPart, secondPart]
}

const dedup = (seq: readonly string[]): string[] => {
  const seen = new Set<string>()
  const result: string[] = []

  for (const x of seq) {
    if (!seen.has(x)) {
      seen.add(x)
      result.push(x)
    }
  }

  return result
}

const extractIdAndText = (input: string): { id: number; text: string } => {
  const match = input.match(/^(\d+)[.,\s]+(.*)$/)
  if (!match || match.length < 3) {
    throw new Error(
      'line must start with a number, a dot and then text. e.g. "1. hello"'
    )
  }

  const id = parseInt(match[1] as string, 10)
  const text = (match[2] as string).trim()
  return { id, text }
}

const extractIndexPrefixedText = (input: string): string => {
  const match = input.match(/^(\d+)[.,\s]+(.*)$/)
  // Check if match is not null and if the second capturing group is present
  if (match && match[2] !== undefined) {
    return match[2].trim()
  }
  return input
}

const batchArray = <T>(arr: readonly T[], size: number): T[][] => {
  const chunkedArr: T[][] = []
  for (let i = 0; i < arr.length; i += size) {
    chunkedArr.push(arr.slice(i, i + size))
  }
  return chunkedArr
}

export const AxStringUtil = {
  trimNonAlphaNum,
  splitIntoTwo,
  dedup,
  extractIdAndText,
  extractIndexPrefixedText,
  batchArray,
}



================================================
FILE: src/ax/dsp/template.test.ts
================================================
import { describe, expect, it } from 'vitest'

import { AxGen } from './generate.js'
import { AxSignature } from './sig.js'
import { ax, f, s } from './template.js'

describe('AxSignature Tagged Templates', () => {
  it('should create basic signature from template', () => {
    const sig = s`userQuestion:string -> modelAnswer:string`

    expect(sig.getInputFields()).toHaveLength(1)
    expect(sig.getOutputFields()).toHaveLength(1)
    expect(sig.getInputFields()[0]?.name).toBe('userQuestion')
    expect(sig.getOutputFields()[0]?.name).toBe('modelAnswer')
  })

  it('should handle simple string interpolation', () => {
    const inputType = 'string'
    const outputType = 'number'
    const sig = s`inputValue:${inputType} -> outputValue:${outputType}`

    expect(sig.getInputFields()[0]?.type?.name).toBe('string')
    expect(sig.getOutputFields()[0]?.type?.name).toBe('number')
  })

  it('should handle field type interpolation', () => {
    const inputType = f.string('User question')
    const outputType = f.class(
      ['positive', 'negative'],
      'Sentiment classification'
    )

    const sig = s`userQuestion:${inputType} -> sentimentValue:${outputType}`

    const inputField = sig.getInputFields()[0]
    const outputField = sig.getOutputFields()[0]

    expect(inputField?.name).toBe('userQuestion')
    expect(inputField?.type?.name).toBe('string')
    expect(inputField?.description).toBe('User question')

    expect(outputField?.name).toBe('sentimentValue')
    expect(outputField?.type?.name).toBe('class')
    expect(outputField?.type?.options).toEqual(['positive', 'negative'])
  })

  it('should handle description interpolation', () => {
    const description = 'Analyze customer feedback'
    const sig = s`"${description}" feedback:string -> sentiment:string`

    expect(sig.getDescription()).toBe(description)
  })

  it('should handle complex multi-field signatures', () => {
    const sig = s`
      emailText:${f.string('Input text')} -> 
      categoryType:${f.class(['tech', 'business', 'sports'])},
      confidenceScore:${f.number('Confidence score 0-1')},
      tagList:${f.array(f.string())}
    `

    expect(sig.getInputFields()).toHaveLength(1)
    expect(sig.getOutputFields()).toHaveLength(3)

    const categoryField = sig.getOutputFields()[0]
    const confidenceField = sig.getOutputFields()[1]
    const tagsField = sig.getOutputFields()[2]

    expect(categoryField?.name).toBe('categoryType')
    expect(categoryField?.type?.name).toBe('class')
    expect(categoryField?.type?.options).toEqual(['tech', 'business', 'sports'])

    expect(confidenceField?.name).toBe('confidenceScore')
    expect(confidenceField?.type?.name).toBe('number')
    expect(confidenceField?.description).toBe('Confidence score 0-1')

    expect(tagsField?.name).toBe('tagList')
    expect(tagsField?.type?.name).toBe('string')
    expect(tagsField?.type?.isArray).toBe(true)
  })

  it('should handle optional and internal fields', () => {
    const sig = s`
      userInput:string -> 
      outValue:${f.optional(f.string())},
      reasoningText:${f.internal(f.string('Internal reasoning'))}
    `

    const outputField = sig.getOutputFields()[0]
    const reasoningField = sig.getOutputFields()[1]

    expect(outputField?.isOptional).toBe(true)
    expect(reasoningField?.isInternal).toBe(true)
    expect(reasoningField?.description).toBe('Internal reasoning')
  })

  it('should handle code fields', () => {
    const sig = s`
      problemDesc:string -> 
      solutionCode:${f.code('python', 'Python code solution')}
    `

    const solutionField = sig.getOutputFields()[0]
    expect(solutionField?.type?.name).toBe('code')
    expect(solutionField?.type?.options).toBeUndefined()
    expect(solutionField?.description).toBe('Python code solution')
  })

  it('should handle date and datetime fields', () => {
    const sig = s`
      eventDesc:string -> 
      startDate:${f.date('Event start date')},
      creationTime:${f.datetime('Creation timestamp')}
    `

    const startDateField = sig.getOutputFields()[0]
    const createdAtField = sig.getOutputFields()[1]

    expect(startDateField?.type?.name).toBe('date')
    expect(startDateField?.description).toBe('Event start date')

    expect(createdAtField?.type?.name).toBe('datetime')
    expect(createdAtField?.description).toBe('Creation timestamp')
  })

  it('should handle json and boolean fields', () => {
    const sig = s`
      jsonData:${f.json('Input JSON data')} -> 
      isValidFlag:${f.boolean('Validation result')},
      metaInfo:${f.json()}
    `

    const inputField = sig.getInputFields()[0]
    const isValidField = sig.getOutputFields()[0]
    const metadataField = sig.getOutputFields()[1]

    expect(inputField?.type?.name).toBe('json')
    expect(inputField?.description).toBe('Input JSON data')

    expect(isValidField?.type?.name).toBe('boolean')
    expect(isValidField?.description).toBe('Validation result')

    expect(metadataField?.type?.name).toBe('json')
  })

  it('should handle array fields of different types', () => {
    const sig = s`
      inputText:string -> 
      tagList:${f.array(f.string())},
      scoreList:${f.array(f.number())},
      flagList:${f.array(f.boolean())},
      categoryList:${f.array(f.class(['a', 'b', 'c']))}
    `

    const fields = sig.getOutputFields()

    expect(fields[0]?.type?.name).toBe('string')
    expect(fields[0]?.type?.isArray).toBe(true)

    expect(fields[1]?.type?.name).toBe('number')
    expect(fields[1]?.type?.isArray).toBe(true)

    expect(fields[2]?.type?.name).toBe('boolean')
    expect(fields[2]?.type?.isArray).toBe(true)

    expect(fields[3]?.type?.name).toBe('class')
    expect(fields[3]?.type?.isArray).toBe(true)
    expect(fields[3]?.type?.options).toEqual(['a', 'b', 'c'])
  })

  it('should handle combined modifiers', () => {
    const sig = s`
      inputText:string -> 
      optionalList:${f.optional(f.array(f.string()))},
      internalCategory:${f.internal(f.class(['x', 'y']))},
      complexScores:${f.optional(f.internal(f.array(f.number('Scores'))))}
    `

    const fields = sig.getOutputFields()

    expect(fields[0]?.isOptional).toBe(true)
    expect(fields[0]?.type?.isArray).toBe(true)
    expect(fields[0]?.type?.name).toBe('string')

    expect(fields[1]?.isInternal).toBe(true)
    expect(fields[1]?.type?.name).toBe('class')
    expect(fields[1]?.type?.options).toEqual(['x', 'y'])

    expect(fields[2]?.isOptional).toBe(true)
    expect(fields[2]?.isInternal).toBe(true)
    expect(fields[2]?.type?.isArray).toBe(true)
    expect(fields[2]?.type?.name).toBe('number')
    expect(fields[2]?.description).toBe('Scores')
  })

  it('should be equivalent to string-based signatures', () => {
    const stringSig = new AxSignature(
      'userQuestion:string -> modelAnswer:string, confidenceValue:number'
    )
    const templateSig = s`userQuestion:string -> modelAnswer:string, confidenceValue:number`

    expect(templateSig.getInputFields()).toHaveLength(
      stringSig.getInputFields().length
    )
    expect(templateSig.getOutputFields()).toHaveLength(
      stringSig.getOutputFields().length
    )

    expect(templateSig.getInputFields()[0]?.name).toBe(
      stringSig.getInputFields()[0]?.name
    )
    expect(templateSig.getOutputFields()[0]?.name).toBe(
      stringSig.getOutputFields()[0]?.name
    )
    expect(templateSig.getOutputFields()[1]?.name).toBe(
      stringSig.getOutputFields()[1]?.name
    )
  })
})

describe('Field Builders', () => {
  it('should create string fields', () => {
    const field1 = f.string()
    const field2 = f.string('Description')

    expect(field1.type).toBe('string')
    expect(field1.description).toBeUndefined()

    expect(field2.type).toBe('string')
    expect(field2.description).toBe('Description')
  })

  it('should create class fields', () => {
    const classField = f.class(['option1', 'option2'], 'Classification')

    expect(classField.type).toBe('class')
    expect(classField.options).toEqual(['option1', 'option2'])
    expect(classField.description).toBe('Classification')
  })

  it('should create code fields', () => {
    const codeField = f.code('javascript', 'JS code')

    expect(codeField.type).toBe('code')
    expect(codeField.options).toEqual(['javascript'])
    expect(codeField.description).toBe('JS code')
  })

  it('should create array fields', () => {
    const arrayField = f.array(f.string('Item'))

    expect(arrayField.type).toBe('string')
    expect(arrayField.isArray).toBe(true)
    expect(arrayField.description).toBe('Item')
  })

  it('should create optional fields', () => {
    const optionalField = f.optional(f.number('Score'))

    expect(optionalField.type).toBe('number')
    expect(optionalField.isOptional).toBe(true)
    expect(optionalField.description).toBe('Score')
  })

  it('should create internal fields', () => {
    const internalField = f.internal(f.string('Reasoning'))

    expect(internalField.type).toBe('string')
    expect(internalField.isInternal).toBe(true)
    expect(internalField.description).toBe('Reasoning')
  })

  it('should chain modifiers', () => {
    const complexField = f.optional(f.internal(f.array(f.class(['a', 'b']))))

    expect(complexField.type).toBe('class')
    expect(complexField.isArray).toBe(true)
    expect(complexField.isOptional).toBe(true)
    expect(complexField.isInternal).toBe(true)
    expect(complexField.options).toEqual(['a', 'b'])
  })
})

describe('AxGen Tagged Templates', () => {
  it('should create AxGen instance from template', () => {
    const gen = ax`
      "A simple summarizer"
      textToSummarize:string -> summary:string
    `
    expect(gen).toBeInstanceOf(AxGen)
    const sig = new AxSignature(gen.getSignature())

    expect(sig.getDescription()).toBe('A simple summarizer')
    expect(sig.getInputFields()[0]?.name).toBe('textToSummarize')
    expect(sig.getOutputFields()[0]?.name).toBe('summary')
  })

  it('should handle field type interpolation with AxGen', () => {
    const gen = ax`
      userQuestion:${f.string('User question')} -> 
      sentiment:${f.class(['positive', 'negative'])}
    `
    const sig = new AxSignature(gen.getSignature())

    const inputField = sig.getInputFields()[0]
    const outputField = sig.getOutputFields()[0]

    expect(inputField?.description).toBe('User question')
    expect(outputField?.type?.name).toBe('class')
  })

  it('should handle complex multi-field signatures with AxGen', () => {
    const gen = ax`
      emailText:${f.string('Email content')} -> 
      categoryType:${f.class(['urgent', 'normal'])},
      actionItems:${f.array(f.string())}
    `
    const sig = new AxSignature(gen.getSignature())

    expect(sig.getOutputFields()).toHaveLength(2)
    expect(sig.getOutputFields()[0]?.name).toBe('categoryType')
    expect(sig.getOutputFields()[1]?.name).toBe('actionItems')
    expect(sig.getOutputFields()[1]?.type?.isArray).toBe(true)
  })

  it('should handle optional and internal fields with AxGen', () => {
    const gen = ax`
      userInput:string -> 
      primaryResponse:${f.string()},
      secondaryResponse:${f.optional(f.string())},
      debuggingInfo:${f.internal(f.json())}
    `
    const sig = new AxSignature(gen.getSignature())
    const secondaryField = sig.getOutputFields()[1]
    const debugField = sig.getOutputFields()[2]

    expect(secondaryField?.isOptional).toBe(true)
    expect(debugField?.isInternal).toBe(true)
  })

  it('should be equivalent to AxGen constructor with string signature', () => {
    const stringGen = new AxGen('userQuestion:string -> modelAnswer:string')
    const templateGen = ax`userQuestion:string -> modelAnswer:string`

    const stringSig = new AxSignature(stringGen.getSignature())
    const templateSig = new AxSignature(templateGen.getSignature())

    expect(templateSig.toString()).toBe(stringSig.toString())
  })
})



================================================
FILE: src/ax/dsp/template.ts
================================================
/* eslint-disable @typescript-eslint/no-unused-vars */
// Added to allow the standard tagged template rest parameters usage.

import { AxGen, type AxGenerateResult } from './generate.js'
import type { AxProgramForwardOptions } from './program.js'
import { AxSignature } from './sig.js'
import type { AxGenIn, AxGenOut } from './types.js'

// Type for template interpolation values
export type AxSignatureTemplateValue =
  | string
  | AxFieldType
  | AxFieldDescriptor
  | AxSignature

export interface AxFieldType {
  readonly type:
    | 'string'
    | 'number'
    | 'boolean'
    | 'json'
    | 'image'
    | 'audio'
    | 'date'
    | 'datetime'
    | 'class'
    | 'code'
  readonly isArray?: boolean
  readonly options?: readonly string[]
  readonly description?: string
  readonly isOptional?: boolean
  readonly isInternal?: boolean
}

export interface AxFieldDescriptor {
  readonly name: string
  readonly type?: AxFieldType
  readonly description?: string
  readonly isOptional?: boolean
  readonly isInternal?: boolean
}

// Main tagged template function for creating signatures
export function s(
  strings: TemplateStringsArray,
  // eslint-disable-next-line functional/functional-parameters
  ...values: readonly AxSignatureTemplateValue[]
): AxSignature {
  let result = ''

  for (let i = 0; i < strings.length; i++) {
    // Add the literal part first
    result += strings[i] ?? ''

    // Then process the value (if any)
    if (i < values.length) {
      const val = values[i]

      // When the value is a field type with optional/internal flags we need to add
      // the markers (?) / (!) on the FIELD NAME (the part just written in result).
      if (isAxFieldType(val)) {
        // Detect the last field name before the ':' we just wrote in the literal.
        // Look for pattern like "fieldName:" at the end of result
        const fieldNameMatch = result.match(/(\w+)\s*:\s*$/)
        if (fieldNameMatch && (val.isOptional || val.isInternal)) {
          const fieldName = fieldNameMatch[1]
          let modifiedFieldName = fieldName

          // Add markers in the correct order: fieldName?! (optional first, then internal)
          if (val.isOptional) modifiedFieldName += '?'
          if (val.isInternal) modifiedFieldName += '!'

          // Replace the field name in the result
          result = result.replace(/(\w+)(\s*:\s*)$/, `${modifiedFieldName}$2`)
        }

        // Now append the converted type string (without optional/internal markers)

        const { isOptional: _o, isInternal: _i, ...typeNoFlags } = val
        result += convertFieldTypeToString(typeNoFlags)
      } else if (isAxFieldDescriptor(val)) {
        result += convertFieldDescriptorToString(val)
      } else if (typeof val === 'string' || val instanceof AxSignature) {
        result += convertValueToSignatureString(val)
      } else {
        throw new Error('Unsupported template interpolation value')
      }
    }
  }

  return new AxSignature(result)
}

// Tagged template function that returns AxGen instances
export function ax<
  IN extends AxGenIn = AxGenIn,
  OUT extends AxGenerateResult<AxGenOut> = AxGenerateResult<AxGenOut>,
>(
  strings: TemplateStringsArray,
  // eslint-disable-next-line functional/functional-parameters
  ...values: readonly AxSignatureTemplateValue[]
): AxGen<IN, OUT> {
  let result = ''

  for (let i = 0; i < strings.length; i++) {
    // Add the literal part first
    result += strings[i] ?? ''

    // Then process the value (if any)
    if (i < values.length) {
      const val = values[i]

      // When the value is a field type with optional/internal flags we need to add
      // the markers (?) / (!) on the FIELD NAME (the part just written in result).
      if (isAxFieldType(val)) {
        // Detect the last field name before the ':' we just wrote in the literal.
        // Look for pattern like "fieldName:" at the end of result
        const fieldNameMatch = result.match(/(\w+)\s*:\s*$/)
        if (fieldNameMatch && (val.isOptional || val.isInternal)) {
          const fieldName = fieldNameMatch[1]
          let modifiedFieldName = fieldName

          // Add markers in the correct order: fieldName?! (optional first, then internal)
          if (val.isOptional) modifiedFieldName += '?'
          if (val.isInternal) modifiedFieldName += '!'

          // Replace the field name in the result
          result = result.replace(/(\w+)(\s*:\s*)$/, `${modifiedFieldName}$2`)
        }

        // Now append the converted type string (without optional/internal markers)

        const { isOptional: _o, isInternal: _i, ...typeNoFlags } = val
        result += convertFieldTypeToString(typeNoFlags)
      } else if (isAxFieldDescriptor(val)) {
        result += convertFieldDescriptorToString(val)
      } else if (typeof val === 'string' || val instanceof AxSignature) {
        result += convertValueToSignatureString(val)
      } else {
        throw new Error('Unsupported template interpolation value')
      }
    }
  }

  return new AxGen<IN, OUT>(result)
}

function convertValueToSignatureString(
  value: AxSignatureTemplateValue
): string {
  if (typeof value === 'string') {
    return value
  }

  if (isAxFieldType(value)) {
    return convertFieldTypeToString(value)
  }

  if (isAxFieldDescriptor(value)) {
    return convertFieldDescriptorToString(value)
  }

  if (value instanceof AxSignature) {
    // Extract the signature string without description
    const sigString = value.toString()
    const arrowIndex = sigString.indexOf(' -> ')
    if (arrowIndex !== -1) {
      return sigString.substring(arrowIndex + 4) // Return just the output part
    }
    return sigString
  }

  throw new Error(`Unsupported template value type: ${typeof value}`)
}

function convertFieldTypeToString(fieldType: Readonly<AxFieldType>): string {
  let result = fieldType.type

  // Add array notation
  if (fieldType.isArray) {
    result += '[]'
  }

  // Add options only for class types
  if (
    fieldType.options &&
    fieldType.options.length > 0 &&
    fieldType.type === 'class'
  ) {
    result += ` "${fieldType.options.join(', ')}"`
  }

  // Add description
  if (fieldType.description) {
    result += ` "${fieldType.description}"`
  }

  return result
}

function convertFieldDescriptorToString(
  descriptor: Readonly<AxFieldDescriptor>
): string {
  let result = descriptor.name

  if (descriptor.isOptional) {
    result += '?'
  }

  if (descriptor.isInternal) {
    result += '!'
  }

  if (descriptor.type) {
    result += ':' + convertFieldTypeToString(descriptor.type)
  }

  if (descriptor.description && !descriptor.type?.description) {
    result += ` "${descriptor.description}"`
  }

  return result
}

function isAxFieldType(value: unknown): value is AxFieldType {
  return (
    value !== null &&
    typeof value === 'object' &&
    value !== undefined &&
    'type' in value &&
    typeof (value as Record<string, unknown>).type === 'string'
  )
}

function isAxFieldDescriptor(value: unknown): value is AxFieldDescriptor {
  return (
    value !== null &&
    typeof value === 'object' &&
    value !== undefined &&
    'name' in value &&
    typeof (value as Record<string, unknown>).name === 'string'
  )
}

// Helper functions for type-safe field creation
export const f = {
  string: (desc?: string): AxFieldType => ({
    type: 'string',
    description: desc,
  }),

  number: (desc?: string): AxFieldType => ({
    type: 'number',
    description: desc,
  }),

  boolean: (desc?: string): AxFieldType => ({
    type: 'boolean',
    description: desc,
  }),

  date: (desc?: string): AxFieldType => ({
    type: 'date',
    description: desc,
  }),

  datetime: (desc?: string): AxFieldType => ({
    type: 'datetime',
    description: desc,
  }),

  json: (desc?: string): AxFieldType => ({
    type: 'json',
    description: desc,
  }),

  image: (desc?: string): AxFieldType => ({
    type: 'image',
    description: desc,
  }),

  audio: (desc?: string): AxFieldType => ({
    type: 'audio',
    description: desc,
  }),

  class: (options: readonly string[], desc?: string): AxFieldType => ({
    type: 'class',
    options,
    description: desc,
  }),

  code: (language: string, desc?: string): AxFieldType => ({
    type: 'code',
    options: [language],
    description: desc,
  }),

  array: <T extends AxFieldType>(
    baseType: T
  ): T & { readonly isArray: true } => ({
    ...baseType,
    isArray: true,
  }),

  optional: <T extends AxFieldType>(
    baseType: T
  ): T & { readonly isOptional: true } => ({
    ...baseType,
    isOptional: true,
  }),

  internal: <T extends AxFieldType>(
    baseType: T
  ): T & { readonly isInternal: true } => ({
    ...baseType,
    isInternal: true,
  }),
}

// Utility function to create field descriptors
export function createField(
  name: string,
  type?: AxFieldType,
  options?: Readonly<{
    description?: string
    isOptional?: boolean
    isInternal?: boolean
  }>
): AxFieldDescriptor {
  return {
    name,
    type,
    description: options?.description,
    isOptional: options?.isOptional,
    isInternal: options?.isInternal,
  }
}



================================================
FILE: src/ax/dsp/types.ts
================================================
export type AxFieldValue =
  | string
  | string[]
  | number
  | boolean
  | object
  | null
  | undefined
  | { mimeType: string; data: string }
  | { mimeType: string; data: string }[]
  | { format?: 'wav'; data: string }
  | { format?: 'wav'; data: string }[]

export type AxGenIn = { [key: string]: AxFieldValue }

export type AxGenOut = { [key: string]: AxFieldValue }

export type AxMessage<IN extends AxGenIn> =
  | { role: 'user'; values: IN }
  | { role: 'assistant'; values: IN }



================================================
FILE: src/ax/dsp/util.test.ts
================================================
/* spell-checker: disable */
import { describe, expect, it, test } from 'vitest'

import { LRUCache, matchesContent, parseMarkdownList } from './util.js'

// Tests for parseMarkdownList
describe('parseMarkdownList', () => {
  it('parses a simple markdown list', () => {
    const content = `Output 1:
    - value1
    - value2
    - value3`

    const result = parseMarkdownList(content)

    expect(result).toEqual(['value1', 'value2', 'value3'])
  })

  it('parses a simple markdown list 2', () => {
    const content = `
      * value1
      * value2
      * value3`

    const result = parseMarkdownList(content)
    expect(result).toEqual(['value1', 'value2', 'value3'])
  })

  it('parses a numbered markdown list', () => {
    const content = `Output 1:
    1. value1
    2. value2
    3. value3`

    const result = parseMarkdownList(content)
    expect(result).toEqual(['value1', 'value2', 'value3'])
  })

  it('fails on non-list content', () => {
    const content = 'not a list'

    expect(() => parseMarkdownList(content)).toThrow()
  })

  it('fails on mixed content', () => {
    const content = `
    - value1
    Header
    - value3`

    expect(() => parseMarkdownList(content)).toThrow()
  })
})

describe('matchesContent', () => {
  describe('exact matches', () => {
    test('should find exact match at the end', () => {
      expect(matchesContent('hello world how are you', 'are you')).toBe(16)
    })

    test('should find exact match with content after it', () => {
      expect(matchesContent('hello world how are you doing', 'are you')).toBe(
        16
      )
    })

    test('should find exact match from startIndex', () => {
      expect(matchesContent('are you hello are you there', 'are you', 10)).toBe(
        14
      )
    })

    test('should not find exact match before startIndex', () => {
      const result = matchesContent('are you hello world', 'are you', 5)
      expect(result).toBe(-1)
    })

    test('should find match within other text', () => {
      expect(matchesContent('howareyouthere', 'are you')).toBe(-1)
    })
  })

  describe('partial matches', () => {
    test('should find single character partial match', () => {
      expect(matchesContent('hello world how a', 'are you')).toBe(-2)
    })

    test('should find two character partial match', () => {
      expect(matchesContent('hello world how ar', 'are you')).toBe(-2)
    })

    test('should find partial word match', () => {
      expect(matchesContent('hello world how are', 'are you')).toBe(-2)
    })

    test('should find partial match within word', () => {
      expect(matchesContent('howare', 'are you')).toBe(-2)
    })
  })

  describe('no matches', () => {
    test('should return -1 for no match at all', () => {
      expect(matchesContent('hello world', 'are you')).toBe(-1)
    })

    test('should return -1 when content is shorter than prefix', () => {
      expect(matchesContent('hi', 'hello')).toBe(-1)
    })

    test('should return -1 when partial match is followed by wrong character', () => {
      expect(matchesContent('hello world how are w', 'are you')).toBe(-1)
    })
  })

  describe('edge cases', () => {
    test('should handle empty content', () => {
      expect(matchesContent('', 'are you')).toBe(-3)
    })

    test('should handle whitespace-only content', () => {
      expect(matchesContent('   ', 'are you')).toBe(-3)
      expect(matchesContent('\t\n  ', 'are you')).toBe(-3)
      expect(matchesContent('\n\n', 'are you')).toBe(-3)
    })

    test('should handle empty prefix', () => {
      expect(matchesContent('hello world', '')).toBe(0)
    })

    test('should handle multi-character matches at the end', () => {
      expect(matchesContent('hello worlare', 'are you')).toBe(-2)
    })
  })

  describe('prefix cache', () => {
    test('should reuse cached prefixes', () => {
      let prefixCache = new LRUCache<string, string[]>(500)

      // First call creates cache
      matchesContent('hello a', 'are you', 0, prefixCache)

      // Get the cached prefixes
      const cachedPrefixes = prefixCache.get('are you')
      expect(cachedPrefixes).toBeDefined()
      expect(cachedPrefixes).toEqual([
        'a',
        'ar',
        'are',
        'are ',
        'are y',
        'are yo',
        'are you',
      ])

      // Second call should use cache
      matchesContent('hello ar', 'are you')
      const cachedPrefixesAfterSecondCall = prefixCache.get('are you')
      expect(cachedPrefixesAfterSecondCall).toBe(cachedPrefixes)
    })
  })
})



================================================
FILE: src/ax/dsp/util.ts
================================================
import { ColorLog } from '../util/log.js'

import type { AxExample, AxOptimizationStats } from './optimizer.js'
import type { AxProgramUsage } from './program.js'
import type { AxField } from './sig.js'
import type { AxFieldValue, AxGenOut } from './types.js'

const colorLog = new ColorLog()

export const updateProgressBar = (
  current: number,
  total: number,
  success: number,
  elapsedTime: number, // in seconds
  msg: string,
  progressBarWidth = 20 // Default width of the progress bar
): void => {
  const percentage = ((current / total) * 100).toFixed(1)
  const filledBarLength = Math.round((progressBarWidth * current) / total)
  const emptyBarLength = progressBarWidth - filledBarLength
  const filledBar = colorLog.blueBright('█'.repeat(filledBarLength))
  const emptyBar = ' '.repeat(emptyBarLength)
  const itemsPerSecond =
    elapsedTime > 0 ? (current / elapsedTime).toFixed(2) : '0.00'

  process.stdout.write(
    `\r${msg}: ${current} / ${total} (${colorLog.yellow(percentage)}%): 100%|${filledBar}${emptyBar}| Success: ${success}/${total} [${colorLog.red(elapsedTime.toFixed(2))}, ${itemsPerSecond}it/s]`
  )
}

export const validateValue = (
  field: Readonly<AxField>,
  value: Readonly<AxFieldValue>
): void => {
  const ft = field.type ?? { name: 'string', isArray: false }

  const validateSingleValue = (
    expectedType: string,
    val: Readonly<AxFieldValue>
  ): boolean => {
    switch (expectedType) {
      case 'class':
        return typeof val === 'string'
      case 'code':
        return typeof val === 'string'
      case 'string':
        return typeof val === 'string'
      case 'number':
        return typeof val === 'number'
      case 'boolean':
        return typeof val === 'boolean'
      case 'date':
        return val instanceof Date || typeof val === 'string'
      case 'datetime':
        return val instanceof Date || typeof val === 'string'
      case 'json':
        return typeof val === 'object' || typeof val === 'string'
      default:
        return false // Unknown or unsupported type
    }
  }

  const validImage = (val: Readonly<AxFieldValue>): boolean => {
    if (
      !val ||
      typeof val !== 'object' ||
      !('mimeType' in val) ||
      !('data' in val)
    ) {
      return false
    }
    return true
  }

  if (field.type?.name === 'image') {
    let msg: string | undefined
    if (Array.isArray(value)) {
      for (const item of value) {
        if (!validImage(item)) {
          msg = 'object ({ mimeType: string; data: string })'
          break
        }
      }
    } else if (!validImage(value)) {
      msg = 'object ({ mimeType: string; data: string })'
    }

    if (msg) {
      throw new Error(
        `Validation failed: Expected '${field.name}' to be type '${msg}' instead got '${value}'`
      )
    }
    return
  }

  const validAudio = (val: Readonly<AxFieldValue>): boolean => {
    if (!val || typeof val !== 'object' || !('data' in val)) {
      return false
    }
    return true
  }

  if (field.type?.name === 'audio') {
    let msg: string | undefined
    if (Array.isArray(value)) {
      for (const item of value) {
        if (!validAudio(item)) {
          msg = 'object ({ data: string; format?: string })'
          break
        }
      }
    } else if (!validAudio(value)) {
      msg = 'object ({ data: string; format?: string })'
    }

    if (msg) {
      throw new Error(
        `Validation failed: Expected '${field.name}' to be type '${msg}' instead got '${value}'`
      )
    }
    return
  }

  let isValid = true

  if (ft.isArray) {
    if (!Array.isArray(value)) {
      isValid = false
    } else {
      for (const item of value) {
        if (!validateSingleValue(ft.name, item)) {
          isValid = false
          break
        }
      }
    }
  } else {
    isValid = validateSingleValue(ft.name, value)
  }

  if (!isValid) {
    const gotType = Array.isArray(value) ? 'array' : typeof value
    throw new Error(
      `Validation failed: Expected '${field.name}' to be a ${field.type?.isArray ? 'an array of ' : ''}${ft.name} instead got '${gotType}' (${JSON.stringify(value)})`
    )
  }
}

export function mergeProgramUsage(
  usages: readonly AxProgramUsage[]
): AxProgramUsage[] {
  const usageMap: { [key: string]: AxProgramUsage } = {}

  for (const usage of usages) {
    const key = `${usage.ai}:${usage.model}`

    if (!usageMap[key]) {
      usageMap[key] = { ...usage }
      continue
    }

    const currentUsage = usageMap[key]
    if (currentUsage) {
      const tokens = currentUsage.tokens ?? {
        promptTokens: 0,
        completionTokens: 0,
        totalTokens: 0,
      }
      tokens.promptTokens += usage?.tokens?.promptTokens ?? 0
      tokens.completionTokens += usage?.tokens?.completionTokens ?? 0
      tokens.totalTokens += usage?.tokens?.totalTokens ?? 0
      currentUsage.tokens = tokens
    }
  }

  return Object.values(usageMap)
}

/**
 * Parses a markdown list from a string. This is a very forgiving parser that
 * will try to handle anything that looks vaguely like a markdown list.
 */
export const parseMarkdownList = (input: string): string[] => {
  // Handle empty input
  if (!input.trim()) {
    return []
  }

  const listBullets = new Set(['-', '*', '+'])
  const numberedListRegex = /^\d+[\s]*[.)\]]\s*/

  const lines = input.split('\n')
  const list = []

  for (const line of lines) {
    const trimmedLine = line.trim()
    // Skip empty lines
    if (!trimmedLine) {
      continue
    }

    // Check for bullet points
    if (trimmedLine[0] && listBullets.has(trimmedLine[0])) {
      list.push(trimmedLine.slice(1).trim())
    }
    // Check for numbered lists (e.g., "1.", "2.", etc.)
    else if (numberedListRegex.test(trimmedLine)) {
      list.push(trimmedLine.replace(numberedListRegex, '').trim())
    }
    // If it's not a list item and we haven't collected any items yet, do nothing
    else if (list.length === 0) {
      // Skip non-list lines at the beginning
    }
    // If we've already started collecting list items, then this non-list line
    //is an error
    else {
      throw new Error('Could not parse markdown list: mixed content detected')
    }
  }

  // If we didn't find any list items, throw error
  if (list.length === 0) {
    throw new Error('Could not parse markdown list: no valid list items found')
  }

  return list
}

export function mergeDeltas<OUT extends AxGenOut>(
  base: Partial<AxGenOut>,
  delta: Partial<AxGenOut>
) {
  for (const key of Object.keys(delta)) {
    const baseValue = base[key]
    const deltaValue = delta[key]

    if (baseValue === undefined && Array.isArray(deltaValue)) {
      base[key] = [...deltaValue]
    } else if (Array.isArray(baseValue) && Array.isArray(deltaValue)) {
      // Concatenate arrays
      base[key] = [...(baseValue ?? []), ...deltaValue]
    } else if (
      (baseValue === undefined || typeof baseValue === 'string') &&
      typeof deltaValue === 'string'
    ) {
      // Concatenate strings
      base[key] = (baseValue ?? '') + deltaValue
    } else {
      // For all other types, overwrite with the new value
      base[key] = deltaValue
    }
  }
  return base as OUT
}

export class LRUCache<K, V> {
  private cache = new Map<K, V>()
  private readonly maxSize: number

  constructor(maxSize: number) {
    this.maxSize = maxSize
  }

  get(key: K): V | undefined {
    const value = this.cache.get(key)
    if (value) {
      // Refresh position by deleting and re-adding
      this.cache.delete(key)
      this.cache.set(key, value)
    }
    return value
  }

  set(key: K, value: V): void {
    if (this.cache.has(key)) {
      this.cache.delete(key)
    } else if (this.cache.size >= this.maxSize) {
      // Remove oldest entry (first item in map)
      const firstKey = this.cache.keys().next().value
      if (firstKey) {
        this.cache.delete(firstKey)
      }
    }
    this.cache.set(key, value)
  }
}

const globalPrefixCache = new LRUCache<string, string[]>(500)

/**
 * Checks if a streaming string matches a prefix, either fully or partially from the end.
 * For streaming content, partial matches are checked from shortest to longest since
 * the content grows at the end and we want to detect partial prefixes as they form.
 * @param content The string to check (potentially streaming)
 * @param prefix The prefix to look for
 * @param startIndex Optional starting index for the search
 * @returns
 *   - index >= 0: Position of full match
 *   - -1: No match found
 *   - -2: Partial match from the end
 *   - -3: String is only whitespace
 */
export function matchesContent(
  content: string,
  prefix: string,
  startIndex = 0,
  prefixCache: LRUCache<string, string[]> = globalPrefixCache
): number {
  // Check if string starts with a markdown block with optional language
  if (/^```[a-zA-Z]*\s*$/.test(content)) {
    return -4
  }

  // Check if string is only whitespace
  if (/^[\s`]*$/.test(content)) {
    return -3
  }

  // First check if the complete prefix exists anywhere after startIndex
  const exactMatchIndex = content.indexOf(prefix, startIndex)

  if (exactMatchIndex !== -1) {
    return exactMatchIndex
  }

  // Get or create cached prefixes
  const prefixes =
    prefixCache.get(prefix) ??
    Array.from({ length: prefix.length }, (_, i) => prefix.slice(0, i + 1))

  // Set in cache if it wasn't there
  if (!prefixCache.get(prefix)) {
    prefixCache.set(prefix, prefixes)
  }

  // Get the content slice we'll check for partial matches
  const contentEnd = content.slice(
    Math.max(startIndex, content.length - prefix.length)
  )

  // Check for partial matches at the end, starting from shortest to longest
  // Skip the full prefix as it was already checked
  for (let i = 0; i < prefixes.length - 1; i++) {
    const partialPrefix = prefixes[i]
    if (partialPrefix === '\n' || partialPrefix === ':') {
      continue
    }
    if (partialPrefix && contentEnd.endsWith(partialPrefix)) {
      return -2
    }
  }

  return -1
}

export const formatTime = (ms: number): string => {
  const seconds = Math.floor(ms / 1000)
  if (seconds < 60) return `${seconds}s`

  const minutes = Math.floor(seconds / 60)
  const remainingSeconds = seconds % 60
  if (minutes < 60) return `${minutes}m ${remainingSeconds}s`

  const hours = Math.floor(minutes / 60)
  const remainingMinutes = minutes % 60
  return `${hours}h ${remainingMinutes}m ${remainingSeconds}s`
}

export const calculateETA = (
  current: number,
  total: number,
  elapsedMs: number
): string => {
  if (current === 0) return 'calculating...'

  const msPerItem = elapsedMs / current
  const remainingItems = total - current
  const etaMs = msPerItem * remainingItems

  return formatTime(etaMs)
}

interface ProgressConfigInfo {
  maxRounds: number
  batchSize: number
  earlyStoppingPatience: number
  costMonitoring: boolean
  verboseMode: boolean
  debugMode: boolean
}

export const updateDetailedProgress = <T extends AxGenOut = AxGenOut>(
  roundIndex: number,
  current: number,
  total: number,
  elapsedTime: number,
  example: Readonly<AxExample>,
  stats: Readonly<AxOptimizationStats>,
  configInfo: Readonly<ProgressConfigInfo>,
  result?: T,
  error?: Error
): void => {
  // Clear line and create a formatted output
  process.stdout.write('\r\x1b[K')

  const percentage = ((current / total) * 100).toFixed(1)
  const formattedTime = formatTime(elapsedTime)
  const itemsPerSecond =
    elapsedTime > 0 ? ((current / elapsedTime) * 1000).toFixed(2) : '0.00'
  const eta = calculateETA(current, total, elapsedTime)

  // Basic progress info (always shown)
  let output = `Round ${roundIndex + 1}/${configInfo.maxRounds}: ${current}/${total} (${percentage}%) [${formattedTime}, ${itemsPerSecond} it/s, ETA: ${eta}]`

  // Add success stats
  const successRate =
    stats.totalCalls > 0 ? (stats.successfulDemos / stats.totalCalls) * 100 : 0
  output += ` | Success: ${stats.successfulDemos}/${stats.totalCalls} (${successRate.toFixed(1)}%)`

  // Additional info for verbose mode
  if (configInfo.verboseMode || configInfo.debugMode) {
    if (configInfo.costMonitoring) {
      output += `\n  Tokens: ~${stats.estimatedTokenUsage.toLocaleString()} total`
    }

    output += `\n  Batch: ${Math.floor(current / configInfo.batchSize) + 1}/${Math.ceil(total / configInfo.batchSize)}`

    if (configInfo.earlyStoppingPatience > 0 && stats.earlyStopping) {
      output += `\n  Best round: ${stats.earlyStopping.bestScoreRound + 1}, Patience: ${configInfo.earlyStoppingPatience}`
    }
  }

  // Debug mode gets even more info
  if (configInfo.debugMode) {
    // Truncate example keys for display
    const exampleKeys = Object.keys(example)
      .map((k) => {
        const valueStr = JSON.stringify(example[k])
        const truncated =
          valueStr.length > 30 ? `${valueStr.substring(0, 30)}...` : valueStr
        return `${k}: ${truncated}`
      })
      .join(', ')

    output += `\n  Example: {${exampleKeys}}`

    if (error) {
      output += `\n  ERROR: ${error.message}`
    } else if (result) {
      // Truncate result for display
      const resultStr = JSON.stringify(result)
      const truncatedResult =
        resultStr.length > 50 ? `${resultStr.substring(0, 50)}...` : resultStr
      output += `\n  Result: ${truncatedResult}`
    }

    // Add temperature info
    output += `\n  Temperature: ${(0.7 + 0.001 * current).toFixed(3)}`
  }

  console.log(output)
}



================================================
FILE: src/ax/dsp/validate.ts
================================================
import type { AxAIService } from '../ai/types.js'
import type { AxAIMemory } from '../mem/types.js'

import { AxPromptTemplate, toFieldType } from './prompt.js'
import type { AxField, AxIField } from './sig.js'

export class ValidationError extends Error {
  private fields: AxField[]

  constructor({
    message,
    fields,
  }: Readonly<{
    message: string
    fields: AxField[]
    value?: string
  }>) {
    super(message)
    this.fields = fields
    this.name = this.constructor.name
  }

  public getFixingInstructions = () => {
    return this.fields.map((field) => ({
      name: 'outputError',
      title: 'Output Correction Required',
      description: `The section labeled '${field.title}' either was not generated by the LLM or does not match the expected format of '${toFieldType(field.type)}'. ${this.message} Please revise your response to ensure it conforms to the specified format.`,
    }))
  }

  override toString(): string {
    return [
      `${this.name}: ${this.message}`,
      ...this.fields.map(
        (field) =>
          `  - ${field.title}: Expected format '${toFieldType(field.type)}'`
      ),
    ].join('\n')
  }

  [Symbol.for('nodejs.util.inspect.custom')](
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _depth: number,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options: Record<string, unknown>
  ) {
    return this.toString()
  }
}

export function handleValidationError(
  mem: AxAIMemory,
  errorFields: AxIField[],
  ai: Readonly<AxAIService>,
  promptTemplate: Readonly<AxPromptTemplate>,
  sessionId?: string
) {
  mem.add(
    {
      role: 'user' as const,
      content: promptTemplate.renderExtraFields(errorFields),
    },
    sessionId
  )
  mem.addTag('error')

  if (ai.getOptions().debug) {
    const errors = errorFields
      .map((field) => `- ${field.title}: ${field.description}`)
      .join('\n')

    const logger = ai.getLogger()
    logger(`❌ Error Correction:\n${errors}`, {
      tags: ['error'],
    })
  }
}



================================================
FILE: src/ax/dsp/optimizers/bootstrapFewshot.ts
================================================
import {
  AxBaseOptimizer,
  type AxBootstrapCompileOptions,
  type AxBootstrapOptimizerOptions,
  type AxMetricFn,
  type AxOptimizerArgs,
  type AxOptimizerResult,
} from '../optimizer.js'
import type { AxProgram, AxProgramDemos, AxProgramTrace } from '../program.js'
import type { AxFieldValue, AxGenIn, AxGenOut } from '../types.js'
import { updateDetailedProgress, updateProgressBar } from '../util.js'

// Define model config interface
interface ModelConfig {
  temperature: number
  max_tokens?: number
  [key: string]: number | string | boolean | undefined
}

export class AxBootstrapFewShot<
  IN extends AxGenIn = AxGenIn,
  OUT extends AxGenOut = AxGenOut,
> extends AxBaseOptimizer<IN, OUT> {
  private maxRounds: number
  private maxDemos: number
  private maxExamples: number
  private batchSize: number
  private earlyStoppingPatience: number
  private costMonitoring: boolean
  private maxTokensPerGeneration: number
  private verboseMode: boolean
  private debugMode: boolean
  private traces: AxProgramTrace<IN, OUT>[] = []

  constructor(
    args: Readonly<AxOptimizerArgs & { options?: AxBootstrapOptimizerOptions }>
  ) {
    // Call parent constructor
    super(args)

    const options = args.options || {}

    this.maxRounds = options.maxRounds ?? 3
    this.maxDemos = options.maxDemos ?? 4
    this.maxExamples = options.maxExamples ?? 16
    this.batchSize = options.batchSize ?? 1
    this.earlyStoppingPatience = options.earlyStoppingPatience ?? 0
    this.costMonitoring = options.costMonitoring ?? false
    this.maxTokensPerGeneration = options.maxTokensPerGeneration ?? 0
    this.verboseMode = options.verboseMode ?? true
    this.debugMode = options.debugMode ?? false

    // Note: teacherAI from options can be used via compile options overrideTeacherAI
    // The base class provides methods to access teacher AI with fallbacks
  }

  private async compileRound(
    program: Readonly<AxProgram<IN, OUT>>,
    roundIndex: number,
    metricFn: AxMetricFn,
    options?: { maxRounds?: number; maxDemos?: number } | undefined
  ) {
    const st = new Date().getTime()
    const maxDemos = options?.maxDemos ?? this.maxDemos
    const aiOpt = {
      modelConfig: {
        temperature: 0.7,
      } as ModelConfig,
    }

    // Apply token limit if specified
    if (this.maxTokensPerGeneration > 0) {
      aiOpt.modelConfig.max_tokens = this.maxTokensPerGeneration
    }

    const examples = randomSample(this.examples, this.maxExamples)
    const previousSuccessCount = this.traces.length

    // Process examples in batches if batch size > 1
    for (let i = 0; i < examples.length; i += this.batchSize) {
      if (i > 0) {
        aiOpt.modelConfig.temperature = 0.7 + 0.001 * i
      }

      const batch = examples.slice(i, i + this.batchSize)

      // Process batch sequentially for now (could be parallelized if AI service supports it)
      for (const ex of batch) {
        if (!ex) {
          continue
        }

        // Use remaining examples as demonstration examples (excluding current one)
        const exList = examples.filter((e) => e !== ex)
        program.setExamples(exList as unknown as readonly (OUT & IN)[])

        // Use teacher AI if provided, otherwise use student AI
        const aiService = this.getTeacherOrStudentAI()

        this.stats.totalCalls++
        let res: OUT
        let error: Error | undefined

        try {
          res = await program.forward(aiService, ex as IN, aiOpt)

          // Estimate token usage if cost monitoring is enabled
          if (this.costMonitoring) {
            // Very rough estimate - replace with actual token counting from your AI service
            this.stats.estimatedTokenUsage +=
              JSON.stringify(ex).length / 4 + JSON.stringify(res).length / 4
          }

          const score = await metricFn({ prediction: res, example: ex })
          const success = score >= 0.5 // Assuming a threshold of 0.5 for success
          if (success) {
            this.traces = [...this.traces, ...program.getTraces()]
            this.stats.successfulDemos++
          }
        } catch (err) {
          error = err as Error
          res = {} as OUT
        }

        const current =
          i + examples.length * roundIndex + (batch.indexOf(ex) + 1)
        const total = examples.length * this.maxRounds
        const et = new Date().getTime() - st

        // Use enhanced progress reporting if verbose or debug mode is enabled
        if (this.verboseMode || this.debugMode) {
          // Create a configuration object to pass to updateDetailedProgress
          const configInfo = {
            maxRounds: this.maxRounds,
            batchSize: this.batchSize,
            earlyStoppingPatience: this.earlyStoppingPatience,
            costMonitoring: this.costMonitoring,
            verboseMode: this.verboseMode,
            debugMode: this.debugMode,
          }

          updateDetailedProgress(
            roundIndex,
            current,
            total,
            et,
            ex,
            this.stats,
            configInfo,
            res,
            error
          )
        } else {
          // Use the standard progress bar for normal mode
          updateProgressBar(
            current,
            total,
            this.traces.length,
            et,
            'Tuning Prompt',
            30
          )
        }

        if (this.traces.length >= maxDemos) {
          return
        }
      }
    }

    // Check if we should early stop based on no improvement
    if (this.earlyStoppingPatience > 0) {
      const newSuccessCount = this.traces.length
      const improvement = newSuccessCount - previousSuccessCount

      if (!this.stats.earlyStopping) {
        this.stats.earlyStopping = {
          bestScoreRound: improvement > 0 ? roundIndex : 0,
          patienceExhausted: false,
          reason: 'No improvement detected',
        }
      } else if (improvement > 0) {
        this.stats.earlyStopping.bestScoreRound = roundIndex
      } else if (
        roundIndex - this.stats.earlyStopping.bestScoreRound >=
        this.earlyStoppingPatience
      ) {
        this.stats.earlyStopping.patienceExhausted = true
        this.stats.earlyStopped = true
        this.stats.earlyStopping.reason = `No improvement for ${this.earlyStoppingPatience} rounds`

        if (this.verboseMode || this.debugMode) {
          console.log(
            `\nEarly stopping triggered after ${roundIndex + 1} rounds. No improvement for ${this.earlyStoppingPatience} rounds.`
          )
        }

        return
      }
    }
  }

  public async compile(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMetricFn,
    options?: AxBootstrapCompileOptions
  ): Promise<AxOptimizerResult<OUT>> {
    const maxRounds = options?.maxIterations ?? this.maxRounds
    this.traces = []

    // Reset stats using parent method
    this.reset()

    for (let i = 0; i < maxRounds; i++) {
      await this.compileRound(program, i, metricFn, options)

      // Break early if early stopping was triggered
      if (this.stats.earlyStopped) {
        break
      }
    }

    if (this.traces.length === 0) {
      throw new Error(
        'No demonstrations found. Either provide more examples or improve the existing ones.'
      )
    }

    const demos: AxProgramDemos<IN, OUT>[] = groupTracesByKeys(this.traces)

    // Calculate best score from traces
    let bestScore = 0
    if (this.traces.length > 0) {
      // Simple approximation - in a real implementation you'd track scores properly
      bestScore =
        this.stats.successfulDemos / Math.max(1, this.stats.totalCalls)
    }

    return {
      demos,
      stats: this.stats,
      bestScore,
      finalConfiguration: {
        maxRounds: this.maxRounds,
        maxDemos: this.maxDemos,
        batchSize: this.batchSize,
        successRate: bestScore,
      },
    }
  }
}

function groupTracesByKeys<IN extends AxGenIn, OUT extends AxGenOut>(
  programTraces: readonly AxProgramTrace<IN, OUT>[]
): AxProgramDemos<IN, OUT>[] {
  const groupedTraces = new Map<string, Record<string, AxFieldValue>[]>()

  // Group all traces by their keys
  for (const programTrace of programTraces) {
    if (groupedTraces.has(programTrace.programId)) {
      const traces = groupedTraces.get(programTrace.programId)
      if (traces) {
        traces.push(programTrace.trace)
      }
    } else {
      groupedTraces.set(programTrace.programId, [programTrace.trace])
    }
  }

  // Convert the Map into an array of ProgramDemos
  const programDemosArray: AxProgramDemos<IN, OUT>[] = []
  groupedTraces.forEach((traces, programId) => {
    programDemosArray.push({
      traces: traces as unknown as (OUT & IN)[],
      programId,
    })
  })

  return programDemosArray
}

const randomSample = <T>(array: readonly T[], n: number): T[] => {
  // Clone the array to avoid modifying the original array
  const clonedArray = [...array]
  // Shuffle the cloned array
  for (let i = clonedArray.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1))
    const caI = clonedArray[i]
    const caJ = clonedArray[j]

    if (!caI || !caJ) {
      throw new Error('Invalid array elements')
    }

    ;[clonedArray[i], clonedArray[j]] = [caJ, caI]
  }
  // Return the first `n` items of the shuffled array
  return clonedArray.slice(0, n)
}



================================================
FILE: src/ax/dsp/optimizers/miproV2.ts
================================================
import type { AxAIService } from '../../ai/types.js'
import { AxGen } from '../generate.js'
import {
  AxBaseOptimizer,
  type AxCompileOptions,
  type AxExample,
  type AxMetricFn,
  type AxMiPROCompileOptions,
  type AxMiPROOptimizerOptions,
  type AxOptimizerArgs,
  type AxOptimizerResult,
} from '../optimizer.js'
import type { AxProgram, AxProgramDemos } from '../program.js'
import type { AxGenIn, AxGenOut } from '../types.js'
import { updateProgressBar } from '../util.js'

import { AxBootstrapFewShot } from './bootstrapFewshot.js'

interface ConfigType extends Record<string, unknown> {
  instruction: string
  bootstrappedDemos: number
  labeledExamples: number
}

// Extended result interface to include the optimized AxGen
export interface AxMiPROResult<IN extends AxGenIn, OUT extends AxGenOut>
  extends AxOptimizerResult<OUT> {
  optimizedGen?: AxGen<IN, OUT>
}

export class AxMiPRO<
  IN extends AxGenIn = AxGenIn,
  OUT extends AxGenOut = AxGenOut,
> extends AxBaseOptimizer<IN, OUT> {
  // MiPRO-specific options
  private maxBootstrappedDemos: number
  private maxLabeledDemos: number
  private numCandidates: number
  private initTemperature: number
  private numTrials: number
  private minibatch: boolean
  private minibatchSize: number
  private minibatchFullEvalSteps: number
  private programAwareProposer: boolean
  private dataAwareProposer: boolean
  private viewDataBatchSize: number
  private tipAwareProposer: boolean
  private fewshotAwareProposer: boolean
  private verbose: boolean
  private earlyStoppingTrials: number
  private minImprovementThreshold: number
  private bayesianOptimization: boolean
  private acquisitionFunction:
    | 'expected_improvement'
    | 'upper_confidence_bound'
    | 'probability_improvement'
  private explorationWeight: number

  constructor(
    args: Readonly<AxOptimizerArgs & { options?: AxMiPROOptimizerOptions }>
  ) {
    // Call parent constructor with base args
    super(args)

    const options = args.options || {}

    // MiPRO-specific options with proper defaults
    this.numCandidates = options.numCandidates ?? 5
    this.initTemperature = options.initTemperature ?? 0.7
    this.maxBootstrappedDemos = options.maxBootstrappedDemos ?? 3
    this.maxLabeledDemos = options.maxLabeledDemos ?? 4
    this.numTrials = options.numTrials ?? 30
    this.minibatch = options.minibatch ?? true
    this.minibatchSize = options.minibatchSize ?? 25
    this.minibatchFullEvalSteps = options.minibatchFullEvalSteps ?? 10
    this.programAwareProposer = options.programAwareProposer ?? true
    this.dataAwareProposer = options.dataAwareProposer ?? true
    this.viewDataBatchSize = options.viewDataBatchSize ?? 10
    this.tipAwareProposer = options.tipAwareProposer ?? true
    this.fewshotAwareProposer = options.fewshotAwareProposer ?? true
    this.verbose = options.verbose ?? false
    this.earlyStoppingTrials = options.earlyStoppingTrials ?? 5
    this.minImprovementThreshold = options.minImprovementThreshold ?? 0.01
    this.bayesianOptimization = options.bayesianOptimization ?? false
    this.acquisitionFunction =
      options.acquisitionFunction ?? 'expected_improvement'
    this.explorationWeight = options.explorationWeight ?? 0.1

    // Update convergence threshold in stats
    this.stats.convergenceInfo.convergenceThreshold =
      this.minImprovementThreshold
  }

  /**
   * Configures the optimizer for light, medium, or heavy optimization
   * @param level The optimization level: "light", "medium", or "heavy"
   */
  public configureAuto(level: 'light' | 'medium' | 'heavy'): void {
    switch (level) {
      case 'light':
        this.numCandidates = 3
        this.numTrials = 10
        this.minibatch = true
        this.minibatchSize = 20
        break
      case 'medium':
        this.numCandidates = 5
        this.numTrials = 20
        this.minibatch = true
        this.minibatchSize = 25
        break
      case 'heavy':
        this.numCandidates = 7
        this.numTrials = 30
        this.minibatch = true
        this.minibatchSize = 30
        break
    }
  }

  /**
   * Generates creative tips for instruction generation
   */
  private generateTips(): string[] {
    return [
      'Be very specific and detailed in your instructions.',
      'Focus on step-by-step reasoning in your instructions.',
      'Provide clear constraints and guidelines in your instructions.',
      'Keep your instructions concise and to the point.',
      'Emphasize accuracy and precision in your instructions.',
      'Include examples of good outputs in your instructions.',
      'Focus on handling edge cases in your instructions.',
      'Explicitly outline the reasoning process in your instructions.',
    ]
  }

  /**
   * Generates instruction candidates using the teacher model if available
   * @param options Optional compile options that may override teacher AI
   * @returns Array of generated instruction candidates
   */
  private async proposeInstructionCandidates(
    options?: AxCompileOptions
  ): Promise<string[]> {
    const instructions: string[] = []
    const aiToUse = this.getTeacherOrStudentAI(options)

    // Generate random tips for tip-aware proposing
    const tips = this.tipAwareProposer ? this.generateTips() : []

    // Generate instructions for each candidate
    for (let i = 0; i < this.numCandidates; i++) {
      const tipIndex = tips.length > 0 ? i % tips.length : -1
      const tipToUse = tipIndex >= 0 ? tips[tipIndex] : ''

      const instruction = await this.generateInstruction({
        tip: tipToUse,
        candidateIndex: i,
        ai: aiToUse,
      })

      instructions.push(instruction)
    }

    return instructions
  }

  private async generateInstruction({
    tip,
    candidateIndex,
  }: Readonly<{
    tip: string | undefined
    candidateIndex: number
    ai: Readonly<AxAIService>
  }>): Promise<string> {
    // For now, use simple instruction generation
    // TODO: Implement proper program-aware and data-aware instruction generation using the AI
    const baseInstructions = [
      'Analyze the input carefully and provide a detailed response.',
      'Think step by step and provide a clear answer.',
      'Consider all aspects of the input before responding.',
      'Provide a concise but comprehensive response.',
      'Focus on accuracy and clarity in your response.',
    ]

    let instruction =
      baseInstructions[candidateIndex % baseInstructions.length] ||
      baseInstructions[0]!

    if (tip) {
      instruction = `${instruction} ${tip}`
    }

    return instruction
  }

  /**
   * Bootstraps few-shot examples for the program
   */
  private async bootstrapFewShotExamples(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMetricFn
  ): Promise<AxProgramDemos<IN, OUT>[]> {
    if (this.verbose) {
      console.log('Bootstrapping few-shot examples...')
    }

    // Initialize the bootstrapper for this program
    const bootstrapper = new AxBootstrapFewShot<IN, OUT>({
      studentAI: this.studentAI,
      examples: this.examples,
      options: {
        maxDemos: this.maxBootstrappedDemos,
        maxRounds: 3,
        verboseMode: this.verbose,
      },
    })

    const result = await bootstrapper.compile(program, metricFn, {
      maxDemos: this.maxBootstrappedDemos,
    })

    return (result.demos || []) as AxProgramDemos<IN, OUT>[]
  }

  /**
   * Selects labeled examples directly from the training set
   */
  private selectLabeledExamples(): AxExample[] {
    const selectedExamples: AxExample[] = []

    // Random sampling from the training set
    const indices = new Set<number>()
    while (
      indices.size < this.maxLabeledDemos &&
      indices.size < this.examples.length
    ) {
      const idx = Math.floor(Math.random() * this.examples.length)
      if (!indices.has(idx)) {
        indices.add(idx)
        const example = this.examples[idx]
        if (example) {
          selectedExamples.push(example)
        }
      }
    }

    return selectedExamples
  }

  /**
   * Runs optimization to find the best combination of few-shot examples and instructions
   */
  private async runOptimization(
    program: Readonly<AxProgram<IN, OUT>>,
    bootstrappedDemos: readonly AxProgramDemos<IN, OUT>[],
    labeledExamples: readonly AxExample[],
    instructions: readonly string[],
    valset: readonly AxExample[],
    metricFn: AxMetricFn,
    options?: AxCompileOptions
  ): Promise<{ bestConfig: ConfigType; bestScore: number }> {
    let bestConfig: ConfigType = {
      instruction: instructions[0] || '',
      bootstrappedDemos: Math.min(1, bootstrappedDemos.length),
      labeledExamples: Math.min(1, labeledExamples.length),
    }
    let bestScore = 0
    let stagnationRounds = 0
    const scoreHistory: number[] = []

    // Check for checkpoint resume
    let startRound = 0
    if (this.resumeFromCheckpoint) {
      const checkpoint = await this.loadCheckpoint(
        this.resumeFromCheckpoint,
        options
      )
      if (checkpoint && checkpoint.optimizerType === 'MiPRO') {
        if (this.verbose || options?.verbose) {
          console.log(
            `Resuming from checkpoint at round ${checkpoint.currentRound}`
          )
        }

        this.restoreFromCheckpoint(checkpoint)
        startRound = checkpoint.currentRound
        bestScore = checkpoint.bestScore
        bestConfig = (checkpoint.bestConfiguration as ConfigType) || bestConfig
        stagnationRounds =
          checkpoint.stats.convergenceInfo?.stagnationRounds || 0
      }
    }

    // Optimization loop with early stopping and checkpointing
    for (let i = startRound; i < this.numTrials; i++) {
      const config: ConfigType = {
        instruction:
          instructions[i % instructions.length] || instructions[0] || '',
        bootstrappedDemos: Math.min(
          Math.floor(Math.random() * (bootstrappedDemos.length + 1)),
          this.maxBootstrappedDemos
        ),
        labeledExamples: Math.min(
          Math.floor(Math.random() * (labeledExamples.length + 1)),
          this.maxLabeledDemos
        ),
      }

      const score = await this.evaluateConfig(
        program,
        config,
        bootstrappedDemos,
        labeledExamples,
        valset,
        metricFn
      )

      scoreHistory.push(score)

      // Check for improvement
      const improvement = score - bestScore
      if (improvement > this.minImprovementThreshold) {
        bestScore = score
        bestConfig = config
        stagnationRounds = 0
      } else {
        stagnationRounds++
      }

      // Update optimization progress with checkpointing
      await this.updateOptimizationProgress(
        i + 1,
        score,
        config,
        'MiPRO',
        this.getConfiguration(),
        bestScore,
        bestConfig,
        {
          stagnationRounds,
          bootstrappedDemos: bootstrappedDemos.length,
          labeledExamples: labeledExamples.length,
          instructions: instructions.length,
        },
        options
      )

      // Progress callback
      if (this.onProgress) {
        this.onProgress({
          round: i + 1,
          totalRounds: this.numTrials,
          currentScore: score,
          bestScore,
          tokensUsed: this.stats.resourceUsage.totalTokens,
          timeElapsed: Date.now(),
          successfulExamples: this.stats.successfulDemos,
          totalExamples: this.examples.length,
          currentConfiguration: config,
          convergenceInfo: {
            improvement,
            stagnationRounds,
            isConverging: stagnationRounds < this.earlyStoppingTrials,
          },
        })
      }

      // Update progress bar
      updateProgressBar(
        i + 1,
        this.numTrials,
        Math.round(bestScore * 100),
        0,
        'Running MIPROv2 optimization',
        30
      )

      // Cost tracking check (handles token/time/cost budgets)
      if (this.checkCostLimits()) {
        this.triggerEarlyStopping('Cost limit reached', i + 1)
        break
      }

      // Early stopping check
      if (stagnationRounds >= this.earlyStoppingTrials) {
        this.triggerEarlyStopping(
          `No improvement for ${this.earlyStoppingTrials} trials`,
          i - stagnationRounds + 1
        )
        break
      }

      // Target score check
      if (this.checkTargetScore(bestScore)) {
        this.triggerEarlyStopping(
          `Target score ${this.targetScore} reached`,
          i + 1
        )
        break
      }
    }

    // Update convergence info
    this.stats.convergenceInfo.stagnationRounds = stagnationRounds
    this.stats.convergenceInfo.finalImprovement =
      scoreHistory.length > 1 ? bestScore - scoreHistory[0]! : 0
    this.stats.convergenceInfo.converged =
      stagnationRounds < this.earlyStoppingTrials

    return { bestConfig, bestScore }
  }

  private async evaluateConfig(
    program: Readonly<AxProgram<IN, OUT>>,
    config: Readonly<ConfigType>,
    bootstrappedDemos: readonly AxProgramDemos<IN, OUT>[],
    labeledExamples: readonly AxExample[],
    valset: readonly AxExample[],
    metricFn: AxMetricFn
  ): Promise<number> {
    // Create a copy of the program and apply the configuration
    const testProgram = { ...program }
    this.applyConfigToProgram(
      testProgram,
      config,
      bootstrappedDemos,
      labeledExamples
    )

    let totalScore = 0
    let count = 0

    // Evaluate on a subset of validation examples
    const evalSet = valset.slice(0, Math.min(5, valset.length))

    for (const example of evalSet) {
      try {
        const prediction = await testProgram.forward(
          this.studentAI,
          example as IN
        )
        const score = await metricFn({ prediction, example })
        totalScore += score
        count++
        this.stats.totalCalls++
      } catch {
        // Skip failed predictions
        continue
      }
    }

    return count > 0 ? totalScore / count : 0
  }

  private applyConfigToProgram(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    program: any,
    config: Readonly<ConfigType>,
    bootstrappedDemos: readonly AxProgramDemos<IN, OUT>[],
    labeledExamples: readonly AxExample[]
  ): void {
    // Set instruction if the program supports it
    if (program.setInstruction) {
      program.setInstruction(config.instruction)
    }

    // Set demos if needed
    if (config.bootstrappedDemos > 0 && program.setDemos) {
      program.setDemos(bootstrappedDemos.slice(0, config.bootstrappedDemos))
    }

    // Set examples if needed
    if (config.labeledExamples > 0 && program.setExamples) {
      program.setExamples(labeledExamples.slice(0, config.labeledExamples))
    }
  }

  /**
   * The main compile method to run MIPROv2 optimization
   */
  public async compile(
    program: Readonly<AxProgram<IN, OUT>>,
    metricFn: AxMetricFn,
    options?: AxCompileOptions
  ): Promise<AxMiPROResult<IN, OUT>> {
    const startTime = Date.now()

    // Initialize random seed if provided
    this.setupRandomSeed()

    // Configure auto settings if provided (cast to access MiPRO-specific options)
    const miproOptions = options as AxMiPROCompileOptions
    if (miproOptions?.auto) {
      this.configureAuto(miproOptions.auto)
    }

    // Use validation set from parent class method
    const valset =
      this.getValidationSet(options) ||
      (miproOptions?.valset ??
        this.examples.slice(0, Math.floor(this.examples.length * 0.2)))

    if (this.verbose || options?.verbose) {
      console.log(`Starting MIPROv2 optimization with ${this.numTrials} trials`)
      console.log(
        `Using ${this.examples.length} examples for training and ${valset.length} for validation`
      )
      if (this.teacherAI) {
        console.log('Using separate teacher model for instruction generation')
      }
    }

    // Step 1: Bootstrap few-shot examples
    let bootstrappedDemos: AxProgramDemos<IN, OUT>[] = []
    if (this.maxBootstrappedDemos > 0) {
      bootstrappedDemos = await this.bootstrapFewShotExamples(program, metricFn)

      if (this.verbose) {
        console.log(
          `Generated ${bootstrappedDemos.length} bootstrapped demonstrations`
        )
      }
    }

    // Step 2: Select labeled examples from training set
    let labeledExamples: AxExample[] = []
    if (this.maxLabeledDemos > 0) {
      labeledExamples = this.selectLabeledExamples()

      if (this.verbose) {
        console.log(
          `Selected ${labeledExamples.length} labeled examples from training set`
        )
      }
    }

    // Step 3: Generate instruction candidates
    const instructions = await this.proposeInstructionCandidates(options)

    if (this.verbose) {
      console.log(`Generated ${instructions.length} instruction candidates`)
      if (this.hasTeacherAI(options)) {
        console.log('Using teacher AI for instruction generation')
      }
    }

    // Step 4: Run optimization to find the best configuration
    const { bestConfig, bestScore } = await this.runOptimization(
      program,
      bootstrappedDemos,
      labeledExamples,
      instructions,
      valset,
      metricFn,
      options
    )

    if (this.verbose || options?.verbose) {
      console.log(`Optimization complete. Best score: ${bestScore}`)
      console.log(`Best configuration: ${JSON.stringify(bestConfig)}`)
    }

    // Check if target score was reached
    if (this.checkTargetScore(bestScore)) {
      this.triggerEarlyStopping(
        `Target score ${this.targetScore} reached with score ${bestScore}`,
        this.numTrials
      )
    }

    // Create a new AxGen instance with the optimized configuration
    let signature
    if (
      'getSignature' in program &&
      typeof program.getSignature === 'function'
    ) {
      signature = program.getSignature()
    } else {
      // Fallback: create a basic signature
      signature = 'input -> output'
    }

    const optimizedGen = new AxGen<IN, OUT>(signature)

    // Apply the best configuration to the new AxGen
    this.applyConfigToAxGen(
      optimizedGen,
      bestConfig,
      bootstrappedDemos,
      labeledExamples
    )

    // Update stats using parent class method
    this.updateResourceUsage(startTime)
    this.stats.convergenceInfo.converged = true
    this.stats.convergenceInfo.finalImprovement = bestScore

    // Save final checkpoint
    await this.saveFinalCheckpoint(
      'MiPRO',
      this.getConfiguration(),
      bestScore,
      bestConfig,
      {
        bootstrappedDemos: bootstrappedDemos.length,
        labeledExamples: labeledExamples.length,
        instructions: instructions.length,
        optimizedGen: !!optimizedGen,
      },
      options
    )

    return {
      demos: bootstrappedDemos,
      stats: this.stats,
      bestScore,
      optimizedGen,
      finalConfiguration: {
        instruction: bestConfig.instruction,
        bootstrappedDemos: bestConfig.bootstrappedDemos,
        labeledExamples: bestConfig.labeledExamples,
        numCandidates: this.numCandidates,
        numTrials: this.numTrials,
      },
    }
  }

  /**
   * Applies a configuration to an AxGen instance
   */
  private applyConfigToAxGen(
    axgen: Readonly<AxGen<IN, OUT>>,
    config: Readonly<ConfigType>,
    bootstrappedDemos: readonly AxProgramDemos<IN, OUT>[],
    labeledExamples: readonly AxExample[]
  ): void {
    // Set instruction if the AxGen supports it
    if (
      'setInstruction' in axgen &&
      typeof axgen.setInstruction === 'function'
    ) {
      axgen.setInstruction(config.instruction)
    }

    // Set demos if needed
    if (config.bootstrappedDemos > 0) {
      axgen.setDemos(bootstrappedDemos.slice(0, config.bootstrappedDemos))
    }

    // Set examples if needed
    if (config.labeledExamples > 0) {
      axgen.setExamples(
        labeledExamples.slice(
          0,
          config.labeledExamples
        ) as unknown as readonly (OUT & IN)[]
      )
    }
  }

  /**
   * Get optimizer-specific configuration
   * @returns Current optimizer configuration
   */
  public getConfiguration(): Record<string, unknown> {
    return {
      numCandidates: this.numCandidates,
      initTemperature: this.initTemperature,
      maxBootstrappedDemos: this.maxBootstrappedDemos,
      maxLabeledDemos: this.maxLabeledDemos,
      numTrials: this.numTrials,
      minibatch: this.minibatch,
      minibatchSize: this.minibatchSize,
      minibatchFullEvalSteps: this.minibatchFullEvalSteps,
      programAwareProposer: this.programAwareProposer,
      dataAwareProposer: this.dataAwareProposer,
      tipAwareProposer: this.tipAwareProposer,
      fewshotAwareProposer: this.fewshotAwareProposer,
      earlyStoppingTrials: this.earlyStoppingTrials,
      minImprovementThreshold: this.minImprovementThreshold,
      bayesianOptimization: this.bayesianOptimization,
      acquisitionFunction: this.acquisitionFunction,
      explorationWeight: this.explorationWeight,
    }
  }

  /**
   * Update optimizer configuration
   * @param config New configuration to merge with existing
   */
  public updateConfiguration(config: Readonly<Record<string, unknown>>): void {
    if (config.numCandidates !== undefined) {
      this.numCandidates = config.numCandidates as number
    }
    if (config.initTemperature !== undefined) {
      this.initTemperature = config.initTemperature as number
    }
    if (config.maxBootstrappedDemos !== undefined) {
      this.maxBootstrappedDemos = config.maxBootstrappedDemos as number
    }
    if (config.maxLabeledDemos !== undefined) {
      this.maxLabeledDemos = config.maxLabeledDemos as number
    }
    if (config.numTrials !== undefined) {
      this.numTrials = config.numTrials as number
    }
    if (config.minibatch !== undefined) {
      this.minibatch = config.minibatch as boolean
    }
    if (config.minibatchSize !== undefined) {
      this.minibatchSize = config.minibatchSize as number
    }
    if (config.earlyStoppingTrials !== undefined) {
      this.earlyStoppingTrials = config.earlyStoppingTrials as number
    }
    if (config.minImprovementThreshold !== undefined) {
      this.minImprovementThreshold = config.minImprovementThreshold as number
    }
    if (config.verbose !== undefined) {
      this.verbose = config.verbose as boolean
    }
  }

  /**
   * Reset optimizer state for reuse with different programs
   */
  public override reset(): void {
    super.reset()
    // Update convergence threshold after reset
    this.stats.convergenceInfo.convergenceThreshold =
      this.minImprovementThreshold
  }

  /**
   * Validate that the optimizer can handle the given program
   * @param program Program to validate
   * @returns Validation result with any issues found
   */
  public override validateProgram(program: Readonly<AxProgram<IN, OUT>>): {
    isValid: boolean
    issues: string[]
    suggestions: string[]
  } {
    // Start with base validation
    const result = super.validateProgram(program)

    // Add MiPRO-specific validation
    if (
      this.examples.length <
      this.maxBootstrappedDemos + this.maxLabeledDemos
    ) {
      result.issues.push(
        `Not enough examples: need at least ${
          this.maxBootstrappedDemos + this.maxLabeledDemos
        }, got ${this.examples.length}`
      )
      result.suggestions.push(
        'Reduce maxBootstrappedDemos or maxLabeledDemos, or provide more examples'
      )
    }

    // Check if validation set is reasonable for MiPRO
    const valSetSize = this.getValidationSet().length
    if (valSetSize < 5) {
      result.issues.push(
        'Validation set too small for reliable MiPRO optimization'
      )
      result.suggestions.push(
        'Provide more examples or a larger validation set'
      )
    }

    return {
      isValid: result.issues.length === 0,
      issues: result.issues,
      suggestions: result.suggestions,
    }
  }
}



================================================
FILE: src/ax/funcs/code.ts
================================================
import * as _crypto from 'node:crypto'
import * as _fs from 'node:fs'
import * as _http from 'node:http'
import * as _https from 'node:https'
import * as _os from 'node:os'
import * as _process from 'node:process'
import { runInNewContext } from 'node:vm'

import type { AxFunction } from '../ai/types.js'

export enum AxJSInterpreterPermission {
  FS = 'node:fs',
  NET = 'net',
  OS = 'os',
  CRYPTO = 'crypto',
  PROCESS = 'process',
}

type Context = {
  console: Console
  fs: unknown
  http: unknown
  https: unknown
  os: unknown
  crypto: unknown
  process: unknown
}

export class AxJSInterpreter {
  private permissions: readonly AxJSInterpreterPermission[]

  constructor({
    permissions = [],
  }:
    | Readonly<{ permissions?: readonly AxJSInterpreterPermission[] }>
    | undefined = {}) {
    this.permissions = permissions ?? []
  }

  private codeInterpreterJavascript(code: string): unknown {
    const context: Partial<Context> = { console }

    if (this.permissions.includes(AxJSInterpreterPermission.FS)) {
      context.fs = _fs
    }

    if (this.permissions.includes(AxJSInterpreterPermission.NET)) {
      context.http = _http
      context.https = _https
    }

    if (this.permissions.includes(AxJSInterpreterPermission.OS)) {
      context.os = _os
    }

    if (this.permissions.includes(AxJSInterpreterPermission.CRYPTO)) {
      context.crypto = _crypto
    }

    if (this.permissions.includes(AxJSInterpreterPermission.PROCESS)) {
      context.process = _process
    }

    return runInNewContext(`(function() { ${code} })()`, context)
  }

  public toFunction(): AxFunction {
    return {
      name: 'javascriptInterpreter',
      description:
        'Use this function to run Javascript code and get any expected return value',
      parameters: {
        type: 'object',
        properties: {
          code: {
            type: 'string',
            description: 'JS code with a return value in the end.',
          },
        },
        required: ['code'],
      },

      func: ({ code }: Readonly<{ code: string }>) =>
        this.codeInterpreterJavascript(code),
    }
  }
}



================================================
FILE: src/ax/funcs/docker.ts
================================================
import type { AxFunction } from '../ai/types.js'

export interface AxDockerContainer {
  Id: string
  Names: string[]
  Image: string
  ImageID: string
  Command: string
  Created: number
  State: {
    Status: string
    Running: boolean
    Paused: boolean
    Restarting: boolean
    OOMKilled: boolean
    Dead: boolean
    Pid: number
    ExitCode: number
    Error: string
    StartedAt: Date
    FinishedAt: Date
  }
  Status: string
  Ports: Array<{
    IP: string
    PrivatePort: number
    PublicPort: number
    Type: string
  }>
  Labels: { [key: string]: string }
  SizeRw: number
  SizeRootFs: number
  HostConfig: {
    NetworkMode: string
  }
  NetworkSettings: {
    Networks: {
      [key: string]: {
        IPAddress: string
        IPPrefixLen: number
        Gateway: string
        MacAddress: string
      }
    }
  }
  Mounts: Array<{
    Type: string
    Source: string
    Destination: string
    Mode: string
    RW: boolean
    Propagation: string
  }>
}

export class AxDockerSession {
  private readonly apiUrl: string
  private containerId: string | null = null

  constructor(apiUrl: string = 'http://localhost:2375') {
    this.apiUrl = apiUrl
  }

  async pullImage(imageName: string): Promise<void> {
    const response = await this.fetchDockerAPI(
      `/images/create?fromImage=${encodeURIComponent(imageName)}`,
      {
        method: 'POST',
      }
    )

    if (!response.ok) {
      throw new Error(`Failed to pull image: ${response.statusText}`)
    }

    // Wait for the pull to complete
    await response.text()
  }

  async createContainer({
    imageName,
    volumes = [],
    doNotPullImage,
    tag,
  }: Readonly<{
    imageName: string
    volumes?: Array<{ hostPath: string; containerPath: string }>
    doNotPullImage?: boolean
    tag?: string
  }>) {
    const binds = volumes.map((v) => `${v.hostPath}:${v.containerPath}`)

    if (!doNotPullImage) {
      await this.pullImage(imageName)
    }

    const containerConfig = {
      Image: imageName,
      Tty: true,
      OpenStdin: false,
      AttachStdin: false,
      AttachStdout: false,
      AttachStderr: false,
      HostConfig: { Binds: binds },
      Labels: {} as Record<string, string>,
    }

    if (tag) {
      containerConfig.Labels['com.example.tag'] = tag
    }

    const response = await this.fetchDockerAPI(`/containers/create`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(containerConfig),
    })

    if (!response.ok) {
      throw new Error(`Failed to create container: ${response.statusText}`)
    }

    const data = (await response.json()) as { Id: string }
    this.containerId = data.Id

    return data
  }

  async findOrCreateContainer({
    imageName,
    volumes = [],
    doNotPullImage,
    tag,
  }: Readonly<{
    imageName: string
    volumes?: Array<{ hostPath: string; containerPath: string }>
    doNotPullImage?: boolean
    tag: string
  }>): Promise<{ Id: string; isNew: boolean }> {
    // First, try to find existing containers with the given tag
    const existingContainers = await this.listContainers(true)
    const matchingContainers = existingContainers.filter(
      (container) =>
        container.Labels && container.Labels['com.example.tag'] === tag
    )

    if (matchingContainers && matchingContainers.length > 0) {
      // Randomly select a container from the matching ones
      const randomIndex = Math.floor(Math.random() * matchingContainers.length)
      const selectedContainer = matchingContainers[randomIndex]

      if (selectedContainer) {
        // Connect to the selected container
        await this.connectToContainer(selectedContainer.Id)
        return { Id: selectedContainer.Id, isNew: false }
      }
    }

    // If no container with the tag exists, create a new one
    const newContainer = await this.createContainer({
      imageName,
      volumes,
      doNotPullImage,
      tag,
    })

    return { Id: newContainer.Id, isNew: true }
  }

  async startContainer(): Promise<void> {
    if (!this.containerId) {
      throw new Error('No container created or connected')
    }

    const response = await this.fetchDockerAPI(
      `/containers/${this.containerId}/start`,
      {
        method: 'POST',
      }
    )

    if (!response.ok) {
      throw new Error(`Failed to start container: ${response.statusText}`)
    }
  }

  async connectToContainer(containerId: string): Promise<void> {
    const response = await this.fetchDockerAPI(
      `/containers/${containerId}/json`
    )

    if (!response.ok) {
      throw new Error(`Failed to connect to container: ${response.statusText}`)
    }

    this.containerId = containerId
  }

  async stopContainers({
    tag,
    remove,
    timeout = 10,
  }: Readonly<{ tag?: string; remove?: boolean; timeout?: number }>): Promise<
    Array<{ Id: string; Action: 'stopped' | 'removed' }>
  > {
    const results: Array<{ Id: string; Action: 'stopped' | 'removed' }> = []

    // List all containers
    const containers = await this.listContainers(true)

    // Filter containers by tag if provided
    const targetContainers = tag
      ? containers.filter(
          (container) => container.Labels['com.example.tag'] === tag
        )
      : containers

    for (const container of targetContainers) {
      // Stop the container if it's running
      if (container.State.Status === 'running') {
        const stopResponse = await this.fetchDockerAPI(
          `/containers/${container.Id}/stop?t=${timeout}`,
          { method: 'POST' }
        )

        if (!stopResponse.ok) {
          console.warn(
            `Failed to stop container ${container.Id}: ${stopResponse.statusText}`
          )
          continue
        }

        results.push({ Id: container.Id, Action: 'stopped' })
      }

      // Remove the container if the remove flag is set
      if (remove) {
        const removeResponse = await this.fetchDockerAPI(
          `/containers/${container.Id}`,
          { method: 'DELETE' }
        )

        if (!removeResponse.ok) {
          console.warn(
            `Failed to remove container ${container.Id}: ${removeResponse.statusText}`
          )
          continue
        }

        results.push({ Id: container.Id, Action: 'removed' })
      }
    }

    return results
  }

  async listContainers(all: boolean = false): Promise<AxDockerContainer[]> {
    const response = await this.fetchDockerAPI(`/containers/json?all=${all}`, {
      method: 'GET',
    })
    return response.json() as Promise<AxDockerContainer[]>
  }

  async getContainerLogs(): Promise<string> {
    if (!this.containerId) {
      throw new Error('No container created or connected')
    }
    const response = await this.fetchDockerAPI(
      `/containers/${this.containerId}/logs?stdout=true&stderr=true`,
      { method: 'GET' }
    )
    return response.text()
  }

  async executeCommand(command: string) {
    console.log('Executing command:', command)

    if (!this.containerId) {
      throw new Error('No container created or connected')
    }

    // Check container state
    const containerInfo = await this.getContainerInfo(this.containerId)

    if (containerInfo.State.Status !== 'running') {
      await this.startContainer()

      // Wait for the container to be in the "running" state
      await this.waitForContainerToBeRunning(this.containerId)
    }

    // Create exec instance
    const createResponse = await this.fetchDockerAPI(
      `/containers/${this.containerId}/exec`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          Cmd: ['sh', '-c', command],
          AttachStdout: true,
          AttachStderr: true,
        }),
      }
    )

    if (!createResponse.ok) {
      throw new Error(
        `Failed to create exec instance: ${createResponse.statusText}`
      )
    }

    const execData = (await createResponse.json()) as { Id: string }

    // Start exec instance
    const startResponse = await this.fetchDockerAPI(
      `/exec/${execData.Id}/start`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          Detach: false,
          Tty: false,
        }),
      }
    )

    if (!startResponse.ok) {
      throw new Error(
        `Failed to start exec instance: ${startResponse.statusText}`
      )
    }

    // Return the output
    return await startResponse.text()
  }

  // Add these new methods to the class:

  private async getContainerInfo(
    containerId: string
  ): Promise<AxDockerContainer> {
    const response = await this.fetchDockerAPI(
      `/containers/${containerId}/json`
    )
    if (!response.ok) {
      throw new Error(`Failed to get container info: ${response.statusText}`)
    }
    return response.json() as Promise<AxDockerContainer>
  }

  private async waitForContainerToBeRunning(
    containerId: string,
    timeout: number = 30000
  ): Promise<void> {
    const startTime = Date.now()
    while (Date.now() - startTime < timeout) {
      const containerInfo = await this.getContainerInfo(containerId)
      if (containerInfo.State.Status === 'running') {
        return
      }
      await new Promise((resolve) => setTimeout(resolve, 1000)) // Wait for 1 second before checking again
    }
    throw new Error('Timeout waiting for container to start')
  }

  private async fetchDockerAPI(
    endpoint: string,
    options?: Readonly<RequestInit>
  ): Promise<Response> {
    const url = new URL(endpoint, this.apiUrl).toString()
    return await fetch(url, options)
  }

  public toFunction(): AxFunction {
    return {
      name: 'commandExecution',
      description:
        'Use this function to execute shell commands, scripts, and programs. This function enables interaction with the file system, running system utilities, and performing tasks that require a shell interface.',
      parameters: {
        type: 'object',
        properties: {
          command: {
            type: 'string',
            description:
              'Shell command to execute. eg. `ls -l` or `echo "Hello, World!"`.',
          },
        },
        required: ['command'],
      },

      func: async ({ command }: Readonly<{ command: string }>) =>
        await this.executeCommand(command),
    }
  }
}



================================================
FILE: src/ax/funcs/embed.ts
================================================
import type {
  AxAIService,
  AxAIServiceActionOptions,
  AxFunction,
} from '../ai/types.js'

export class AxEmbeddingAdapter {
  private aiService: AxAIService
  private info: {
    name: string
    description: string
    argumentDescription: string
  }
  private func: (
    args: readonly number[],
    extra?: Readonly<AxAIServiceActionOptions>
  ) => Promise<unknown>

  constructor({
    ai,
    info,
    func,
  }: Readonly<{
    ai: AxAIService
    info: Readonly<{
      name: string
      description: string
      argumentDescription: string
    }>
    func: (
      args: readonly number[],
      extra?: Readonly<AxAIServiceActionOptions>
    ) => Promise<unknown>
  }>) {
    this.aiService = ai
    this.info = info
    this.func = func
  }

  private async embedAdapter(
    text: string,
    extra?: Readonly<AxAIServiceActionOptions>
  ): Promise<unknown> {
    const embedRes = await this.aiService.embed(
      { texts: [text] },
      {
        sessionId: extra?.sessionId,
        abortSignal: extra?.abortSignal,
      }
    )
    const embeds = embedRes.embeddings.at(0)

    if (!embeds) {
      throw new Error('Failed to embed text')
    }

    return this.func.length === 2 ? this.func(embeds, extra) : this.func(embeds)
  }

  public toFunction(): AxFunction {
    return {
      name: this.info.name,
      description: this.info.description,
      parameters: {
        type: 'object',
        properties: {
          text: {
            type: 'string',
            description: this.info.argumentDescription,
          },
        },
        required: ['text'],
      },
      func: ({ text }: Readonly<{ text: string }>, options) =>
        this.embedAdapter(text, options),
    }
  }
}



================================================
FILE: src/ax/mcp/client.test.ts
================================================
import { beforeEach, describe, expect, it, vi } from 'vitest'

import { AxMCPClient } from './client.js'
import type { AxMCPTransport } from './transport.js'
import type {
  JSONRPCResponse,
  JSONRPCSuccessResponse,
  MCPFunctionDescription,
} from './types.js'

// Mock the transport
const createMockTransport = () => {
  const mockTransport: AxMCPTransport = {
    send: vi.fn(),
    sendNotification: vi.fn(),
  }
  return mockTransport
}

// Fake transport for testing
class FakeTransport {
  sendResponses: Record<string, JSONRPCResponse<unknown>> = {}
  send = (
    request: Readonly<{ method: string; [key: string]: unknown }>
  ): Promise<JSONRPCResponse<unknown>> => {
    const response = this.sendResponses[request.method]
    if (response) {
      return Promise.resolve(response)
    }
    return Promise.resolve({ jsonrpc: '2.0', id: 'default-id', result: {} })
  }
  sendNotification = vi.fn(
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    (notification: unknown): Promise<void> => Promise.resolve()
  )
  connect?(): Promise<void> {
    return Promise.resolve()
  }
}

describe('AxMCPClient', () => {
  let mockTransport: AxMCPTransport
  let consoleSpy: ReturnType<typeof vi.spyOn>
  let transport: FakeTransport
  let client: AxMCPClient

  beforeEach(() => {
    mockTransport = createMockTransport()
    consoleSpy = vi.spyOn(console, 'log').mockImplementation(() => {})

    // Setup mock responses
    vi.mocked(mockTransport.send).mockImplementation(async (request) => {
      if (request.method === 'initialize') {
        return {
          jsonrpc: '2.0',
          id: request.id,
          result: {
            protocolVersion: '2024-11-05',
            capabilities: {
              tools: true,
              resources: true,
              prompts: true,
            },
            serverInfo: {
              name: 'TestServer',
              version: '1.0.0',
            },
          },
        }
      }

      if (request.method === 'tools/list') {
        const tools: MCPFunctionDescription[] = [
          {
            name: 'function1',
            description: 'Description for function 1',
            inputSchema: {
              type: 'object',
              properties: {
                param1: {
                  type: 'string',
                  description: 'Parameter 1',
                },
              },
            },
          },
          {
            name: 'function2',
            description: 'Description for function 2',
            inputSchema: {
              type: 'object',
              properties: {
                param2: {
                  type: 'number',
                  description: 'Parameter 2',
                },
              },
            },
          },
        ]

        return {
          jsonrpc: '2.0',
          id: request.id,
          result: {
            name: 'TestTools',
            description: 'Test tools list',
            tools,
          },
        }
      }

      if (request.method === 'tools/call') {
        return {
          jsonrpc: '2.0',
          id: request.id,
          result: { success: true, data: 'Function result' },
        }
      }

      if (request.method === 'ping') {
        return {
          jsonrpc: '2.0',
          id: request.id,
          result: {},
        }
      }

      return {
        jsonrpc: '2.0',
        id: request.id,
        result: {},
      }
    })

    transport = new FakeTransport()

    // Set default responses for init and tools/list
    transport.sendResponses.initialize = {
      jsonrpc: '2.0',
      id: 'init-id',
      result: {
        protocolVersion: '2024-11-05',
        capabilities: {
          tools: true,
          resources: true,
          prompts: false,
        },
      },
    }

    transport.sendResponses['tools/list'] = {
      jsonrpc: '2.0',
      id: 'tools-list-id',
      result: {
        tools: [
          {
            name: 'testFn',
            description: 'Test function',
            inputSchema: {
              properties: { arg: { type: 'string' } },
              required: ['arg'],
              type: 'object',
            },
          },
        ],
      },
    }

    // Default ping response
    transport.sendResponses.ping = {
      jsonrpc: '2.0',
      id: 'ping-id',
      result: {},
    }

    client = new AxMCPClient(transport, { debug: false })
  })

  describe('with mock transport', () => {
    it('should initialize and discover functions', async () => {
      const client = new AxMCPClient(mockTransport)
      await client.init()

      // Verify initialize was called
      expect(mockTransport.send).toHaveBeenCalledWith(
        expect.objectContaining({
          method: 'initialize',
        })
      )

      // Verify tools/list was called
      expect(mockTransport.send).toHaveBeenCalledWith(
        expect.objectContaining({
          method: 'tools/list',
        })
      )

      // Verify functions were discovered
      const functions = client.toFunction()
      expect(functions).toHaveLength(2)
      expect(functions[0]?.name).toBe('function1')
      expect(functions[1]?.name).toBe('function2')
    })

    it('should apply function overrides', async () => {
      const client = new AxMCPClient(mockTransport, {
        functionOverrides: [
          {
            name: 'function1',
            updates: {
              name: 'renamedFunction1',
              description: 'New description for function 1',
            },
          },
        ],
      })

      await client.init()

      const functions = client.toFunction()
      expect(functions).toHaveLength(2)

      // Check that the override was applied
      const firstFunction = functions[0]
      expect(firstFunction?.name).toBe('renamedFunction1')
      expect(firstFunction?.description).toBe('New description for function 1')

      // Check that the other function was not affected
      const secondFunction = functions[1]
      expect(secondFunction?.name).toBe('function2')
      expect(secondFunction?.description).toBe('Description for function 2')
    })

    it('should use original function name when calling functions', async () => {
      const client = new AxMCPClient(mockTransport, {
        functionOverrides: [
          {
            name: 'function1',
            updates: {
              name: 'renamedFunction1',
            },
          },
        ],
      })

      await client.init()

      const functions = client.toFunction()
      const firstFunction = functions[0]

      if (!firstFunction) {
        throw new Error('Function not found')
      }

      // Call the renamed function
      await firstFunction.func({ param1: 'test' })

      // Verify the original name was used in the call
      expect(mockTransport.send).toHaveBeenCalledWith(
        expect.objectContaining({
          method: 'tools/call',
          params: {
            name: 'function1', // Original name, not the renamed one
            arguments: { param1: 'test' },
          },
        })
      )
    })

    it('should log debug information when debug is enabled', async () => {
      const client = new AxMCPClient(mockTransport, { debug: true })
      await client.init()

      // Verify debug logs were printed
      expect(consoleSpy).toHaveBeenCalled()
      expect(consoleSpy).toHaveBeenCalledWith(
        expect.stringContaining('Sending request')
      )
      expect(consoleSpy).toHaveBeenCalledWith(
        expect.stringContaining('Received response')
      )
      expect(consoleSpy).toHaveBeenCalledWith(
        expect.stringContaining('Discovered 2 functions')
      )
    })

    it('should not log debug information when debug is disabled', async () => {
      consoleSpy.mockClear()

      const client = new AxMCPClient(mockTransport, { debug: false })
      await client.init()

      // Verify no debug logs were printed
      expect(consoleSpy).not.toHaveBeenCalled()
    })

    it('should ping the server', async () => {
      const client = new AxMCPClient(mockTransport)
      await client.init()

      await client.ping()

      // Verify ping was called
      expect(mockTransport.send).toHaveBeenCalledWith(
        expect.objectContaining({
          method: 'ping',
        })
      )
    })

    it('should throw an error when tools are not supported', async () => {
      // Override the initialize response to indicate tools are not supported
      vi.mocked(mockTransport.send).mockImplementationOnce(async (request) => {
        if (request.method === 'initialize') {
          return {
            jsonrpc: '2.0',
            id: request.id,
            result: {
              protocolVersion: '2024-11-05',
              capabilities: {
                tools: false,
              },
              serverInfo: {
                name: 'TestServer',
                version: '1.0.0',
              },
            },
          }
        }
        return { jsonrpc: '2.0', id: request.id, result: {} }
      })

      const client = new AxMCPClient(mockTransport)

      // Expect init to throw an error
      await expect(client.init()).rejects.toThrow('Tools are not supported')
    })

    it('should handle RPC errors', async () => {
      // Override the send method to return an error
      vi.mocked(mockTransport.send).mockImplementationOnce(async () => {
        return {
          jsonrpc: '2.0',
          id: 1,
          error: {
            code: 123,
            message: 'Test error',
          },
        } as JSONRPCResponse
      })

      const client = new AxMCPClient(mockTransport)

      // Expect init to throw an error
      await expect(client.init()).rejects.toThrow('RPC Error 123: Test error')
    })

    it('should handle invalid responses', async () => {
      // Override the send method to return an invalid response
      vi.mocked(mockTransport.send).mockImplementationOnce(async () => {
        return {
          jsonrpc: '2.0',
          id: 1,
          // No result or error property
        } as JSONRPCResponse
      })

      const client = new AxMCPClient(mockTransport)

      // Expect init to throw an error
      await expect(client.init()).rejects.toThrow(
        'Invalid response no result or error'
      )
    })
  })

  describe('with fake transport', () => {
    it('init should succeed with correct protocol version and discover functions', async () => {
      await client.init()
      const functions = client.toFunction()
      expect(functions.length).toBe(1)
      expect(functions[0]?.name).toBe('testFn')
    })

    it('init should fail with incorrect protocol version', async () => {
      transport.sendResponses.initialize = {
        jsonrpc: '2.0',
        id: 'initialize-id',
        result: {
          protocolVersion: 'wrong-version',
          capabilities: {
            tools: true,
            resources: true,
            prompts: false,
          },
        },
      }
      await expect(client.init()).rejects.toThrow(/Protocol version mismatch/)
    })

    it('ping should succeed with empty response', async () => {
      await expect(client.ping()).resolves.toBeUndefined()
    })

    it('ping should fail with non-empty response', async () => {
      transport.sendResponses.ping = {
        jsonrpc: '2.0',
        id: 'ping-id',
        result: { unexpected: 'data' },
      }
      await expect(client.ping()).rejects.toThrow(/Unexpected ping response/)
    })

    it('cancelRequest cancels an active pending request', async () => {
      // Override transport.send to return a pending promise
      const pendingPromise = new Promise<JSONRPCSuccessResponse<unknown>>(
        () => {
          // This promise intentionally never resolves
        }
      )
      transport.send = vi.fn(() => pendingPromise)

      // Call a private sendRequest via casting client as any
      const sendRequestPromise = (
        client as unknown as {
          sendRequest(
            method: string,
            params: unknown
          ): Promise<{ id: string; result: unknown }>
        }
      ).sendRequest('longRunningMethod', {})

      // Get the active request id from client.activeRequests
      const activeRequests: Map<string, { reject: (reason: unknown) => void }> =
        (
          client as unknown as {
            activeRequests: Map<string, { reject: (reason: unknown) => void }>
          }
        ).activeRequests
      const activeRequestIds = Array.from(activeRequests.keys())
      expect(activeRequestIds.length).toBeGreaterThan(0)
      const requestId = activeRequestIds[0]

      // Ensure requestId is defined
      if (!requestId) {
        throw new Error('No active request ID found')
      }

      // Cancel the active request
      client.cancelRequest(requestId)

      await expect(sendRequestPromise).rejects.toThrow(
        `Request ${requestId} cancelled`
      )

      // Verify that sendNotification was called for cancellation
      expect(transport.sendNotification).toHaveBeenCalledWith(
        expect.objectContaining({
          method: 'notifications/cancelled',
          params: { requestId, reason: 'Client cancelled request' },
        })
      )
    })
  })
})



================================================
FILE: src/ax/mcp/client.ts
================================================
import { v4 as uuidv4 } from 'uuid'

import type { AxFunction, AxLoggerFunction } from '../ai/types.js'

import type { AxMCPTransport } from './transport.js'
import type {
  JSONRPCNotification,
  JSONRPCRequest,
  MCPInitializeParams,
  MCPInitializeResult,
  MCPToolsListResult,
} from './types.js'

/**
 * Configuration for overriding function properties
 */
interface FunctionOverride {
  /** Original function name to override */
  name: string
  /** Updates to apply to the function */
  updates: {
    /** Alternative name for the function */
    name?: string
    /** Alternative description for the function */
    description?: string
  }
}

/**
 * Options for the MCP client
 */
interface AxMCPClientOptions {
  /** Enable debug logging */
  debug?: boolean
  /** Logger function for debug output */
  logger?: AxLoggerFunction
  /**
   * List of function overrides
   * Use this to provide alternative names and descriptions for functions
   * while preserving their original functionality
   *
   * Example:
   * ```
   * functionOverrides: [
   *   {
   *     name: "original-function-name",
   *     updates: {
   *       name: "new-function-name",
   *       description: "New function description"
   *     }
   *   }
   * ]
   * ```
   */
  functionOverrides?: FunctionOverride[]
}

export class AxMCPClient {
  private functions: AxFunction[] = []
  private activeRequests: Map<string, { reject: (reason: unknown) => void }> =
    new Map()
  private capabilities: {
    tools?: boolean
    resources?: boolean
    prompts?: boolean
  } = {}
  private logger: AxLoggerFunction

  constructor(
    private readonly transport: AxMCPTransport,
    private readonly options: Readonly<AxMCPClientOptions> = {}
  ) {
    this.logger = options.logger ?? ((message: string) => console.log(message))
  }

  async init(): Promise<void> {
    if ('connect' in this.transport) {
      await this.transport.connect?.()
    }

    const { result: res } = await this.sendRequest<
      MCPInitializeParams,
      MCPInitializeResult
    >('initialize', {
      protocolVersion: '2024-11-05',
      capabilities: {
        roots: { listChanged: true },
        sampling: {},
      },
      clientInfo: {
        name: 'AxMCPClient',
        version: '1.0.0',
      },
    })

    const expectedProtocolVersion = '2024-11-05'
    if (res.protocolVersion !== expectedProtocolVersion) {
      throw new Error(
        `Protocol version mismatch. Expected ${expectedProtocolVersion} but got ${res.protocolVersion}`
      )
    }

    if (res.capabilities.tools) {
      this.capabilities.tools = true
    }

    if (res.capabilities.resources) {
      this.capabilities.resources = true
    }

    if (res.capabilities.prompts) {
      this.capabilities.prompts = true
    }

    await this.sendNotification('notifications/initialized')

    await this.discoverFunctions()
  }

  private async discoverFunctions(): Promise<void> {
    if (!this.capabilities.tools) {
      throw new Error('Tools are not supported')
    }

    const { result: res } = await this.sendRequest<
      undefined,
      MCPToolsListResult
    >('tools/list')

    this.functions = res.tools.map((fn): AxFunction => {
      // Check if there's an override for this function
      const override = this.options.functionOverrides?.find(
        (o) => o.name === fn.name
      )

      const parameters = fn.inputSchema.properties
        ? {
            properties: fn.inputSchema.properties,
            required: fn.inputSchema.required ?? [],
            type: fn.inputSchema.type,
          }
        : undefined

      return {
        name: override?.updates.name ?? fn.name,
        description: override?.updates.description ?? fn.description,
        parameters,
        func: async (args) => {
          // Always use original name when calling the function
          const { result } = await this.sendRequest<{
            name: string
            // eslint-disable-next-line functional/functional-parameters
            arguments: unknown
          }>('tools/call', { name: fn.name, arguments: args })
          return result
        },
      }
    })

    if (this.options.debug) {
      this.logger(`> Discovered ${this.functions.length} functions:`, {
        tags: ['discovery'],
      })
      for (const fn of this.functions) {
        this.logger(`  - ${fn.name}: ${fn.description}`, {
          tags: ['discovery'],
        })
      }
    }
  }

  async ping(timeout = 3000): Promise<void> {
    const pingPromise = this.sendRequest('ping')
    const timeoutPromise = new Promise((_, reject) =>
      setTimeout(
        () => reject(new Error('Ping response timeout exceeded')),
        timeout
      )
    )
    const response = (await Promise.race([pingPromise, timeoutPromise])) as {
      result: unknown
    }
    const { result } = response
    if (
      typeof result !== 'object' ||
      result === null ||
      Object.keys(result).length !== 0
    ) {
      throw new Error(`Unexpected ping response: ${JSON.stringify(result)}`)
    }
  }

  toFunction(): AxFunction[] {
    return this.functions
  }

  cancelRequest(id: string): void {
    if (this.activeRequests.has(id)) {
      this.sendNotification('notifications/cancelled', {
        requestId: id,
        reason: 'Client cancelled request',
      })
      const entry = this.activeRequests.get(id)
      if (entry) {
        entry.reject(new Error(`Request ${id} cancelled`))
      }
      this.activeRequests.delete(id)
    }
  }

  private async sendRequest<T = unknown, R = unknown>(
    method: string,
    params: T = {} as T
  ): Promise<{ id: string; result: R }> {
    const requestId = uuidv4()
    const request: JSONRPCRequest<T> = {
      jsonrpc: '2.0',
      id: requestId,
      method,
      params,
    }

    if (this.options.debug) {
      this.logger(
        `> Sending request ${requestId}:\n${JSON.stringify(request, null, 2)}`,
        { tags: ['requestStart'] }
      )
    }

    const responsePromise = new Promise<{ result: R }>((resolve, reject) => {
      this.activeRequests.set(requestId, { reject })
      this.transport
        .send(request)
        .then((res: unknown) => {
          this.activeRequests.delete(requestId)
          if (this.options.debug) {
            this.logger(
              `> Received response for request ${requestId}:\n${JSON.stringify(res, null, 2)}`,
              { tags: ['responseContent'] }
            )
          }
          if (res !== null && typeof res === 'object' && 'error' in res) {
            const errorObj = res as { error: { code: number; message: string } }
            reject(
              new Error(
                `RPC Error ${errorObj.error.code}: ${errorObj.error.message}`
              )
            )
          } else if (
            res !== null &&
            typeof res === 'object' &&
            'result' in res
          ) {
            resolve({ result: (res as { result: R }).result })
          } else {
            reject(new Error('Invalid response no result or error'))
          }
        })
        .catch((err: unknown) => {
          this.activeRequests.delete(requestId)
          reject(err)
        })
    })

    const { result } = await responsePromise
    return { id: requestId, result }
  }

  private async sendNotification(
    method: string,
    params: Record<string, unknown> = {}
  ): Promise<void> {
    const notification: JSONRPCNotification = {
      jsonrpc: '2.0',
      method,
      params,
    }

    if (this.options.debug) {
      this.logger(
        `➡️ Sending notification: ${JSON.stringify(notification, null, 2)}`,
        { tags: ['requestStart'] }
      )
    }

    await this.transport.sendNotification(notification)
  }
}



================================================
FILE: src/ax/mcp/httpTransport.ts
================================================
import type { AxMCPTransport } from './transport.js'
import type {
  JSONRPCNotification,
  JSONRPCRequest,
  JSONRPCResponse,
} from './types.js'

export class AxMCPHTTPSSETransport implements AxMCPTransport {
  private endpoint: string | null = null
  private sseUrl: string
  private eventSource?: EventSource

  constructor(sseUrl: string) {
    this.sseUrl = sseUrl
  }

  async connect(): Promise<void> {
    return new Promise((resolve, reject) => {
      this.eventSource = new EventSource(this.sseUrl)

      this.eventSource.addEventListener('endpoint', (event: Event) => {
        try {
          const messageEvent = event as MessageEvent
          const data = JSON.parse(messageEvent.data)
          if (!data.uri) {
            throw new Error('Endpoint URI missing in SSE event data')
          }
          this.endpoint = data.uri
          resolve()
        } catch (error) {
          reject(error)
        }
      })

      this.eventSource.onerror = () => {
        reject(new Error('Failed to establish SSE connection'))
      }
    })
  }

  async send(
    message: JSONRPCRequest<unknown> | JSONRPCNotification
  ): Promise<JSONRPCResponse<unknown>> {
    if (!this.endpoint) {
      throw new Error(
        'HTTPTransport endpoint is not initialized. Call connect() first.'
      )
    }

    const res = await fetch(this.endpoint, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(message),
    })

    if (!res.ok) {
      throw new Error(`HTTP error ${res.status}: ${res.statusText}`)
    }

    return res.json() as Promise<JSONRPCResponse<unknown>>
  }

  async sendNotification(
    message: Readonly<JSONRPCNotification>
  ): Promise<void> {
    if (!this.endpoint) {
      throw new Error(
        'HTTPTransport endpoint is not initialized. Call connect() first.'
      )
    }
    await fetch(this.endpoint, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(message),
    })
  }
}

export interface AxMCPStreamableHTTPTransportOptions {
  /**
   * Custom headers to include with all HTTP requests
   * Note: Content-Type, Accept, and Mcp-Session-Id are managed automatically
   */
  headers?: Record<string, string>

  /**
   * Authorization header value (convenience for common use case)
   * If provided, will be added to the headers as 'Authorization'
   */
  authorization?: string
}

/**
 * AxMCPStreambleHTTPTransport implements the 2025-03-26 Streamable HTTP transport specification
 * This transport uses a single HTTP endpoint that supports both POST and GET methods
 */
export class AxMCPStreambleHTTPTransport implements AxMCPTransport {
  private mcpEndpoint: string
  private sessionId?: string
  private eventSource?: EventSource
  private pendingRequests = new Map<
    string | number,
    {
      resolve: (value: JSONRPCResponse<unknown>) => void
      reject: (reason: unknown) => void
    }
  >()
  private messageHandler?: (
    message: JSONRPCRequest<unknown> | JSONRPCNotification
  ) => void
  private customHeaders: Record<string, string>

  constructor(
    mcpEndpoint: string,
    options?: AxMCPStreamableHTTPTransportOptions
  ) {
    this.mcpEndpoint = mcpEndpoint
    this.customHeaders = { ...options?.headers }

    // Add authorization header if provided
    if (options?.authorization) {
      this.customHeaders['Authorization'] = options.authorization
    }
  }

  /**
   * Update custom headers (useful for refreshing tokens)
   */
  setHeaders(headers: Record<string, string>): void {
    this.customHeaders = { ...headers }
  }

  /**
   * Update authorization header (convenience method)
   */
  setAuthorization(authorization: string): void {
    this.customHeaders['Authorization'] = authorization
  }

  /**
   * Get a copy of the current custom headers
   */
  getHeaders(): Record<string, string> {
    return { ...this.customHeaders }
  }

  /**
   * Build headers for HTTP requests, merging custom headers with required ones
   */
  private buildHeaders(
    baseHeaders: Record<string, string>
  ): Record<string, string> {
    const headers = { ...this.customHeaders, ...baseHeaders }

    if (this.sessionId) {
      headers['Mcp-Session-Id'] = this.sessionId
    }

    return headers
  }

  /**
   * Set a handler for incoming server messages (requests/notifications)
   */
  setMessageHandler(
    handler: (message: JSONRPCRequest<unknown> | JSONRPCNotification) => void
  ): void {
    this.messageHandler = handler
  }

  async connect(): Promise<void> {
    // For Streamable HTTP, connection is implicit when making requests
    // But we can optionally open a GET SSE stream for server-initiated messages
    return Promise.resolve()
  }

  /**
   * Opens an SSE stream to listen for server-initiated messages
   */
  async openListeningStream(): Promise<void> {
    return new Promise((resolve, reject) => {
      const headers = this.buildHeaders({
        Accept: 'text/event-stream',
      })

      // Note: EventSource doesn't support custom headers in standard browsers
      // For custom headers with SSE, you may need to use fetch with ReadableStream
      // or use a library that supports custom headers
      const url = new URL(this.mcpEndpoint)

      // If we have custom headers, we need to use fetch instead of EventSource
      if (Object.keys(this.customHeaders).length > 0) {
        this.openListeningStreamWithFetch(headers).then(resolve).catch(reject)
        return
      }

      this.eventSource = new EventSource(url.toString())

      this.eventSource.onopen = () => {
        resolve()
      }

      this.eventSource.onmessage = (event) => {
        try {
          const message = JSON.parse(event.data)
          if (this.messageHandler) {
            this.messageHandler(message)
          }
        } catch (error) {
          console.error('Failed to parse SSE message:', error)
        }
      }

      this.eventSource.onerror = () => {
        reject(new Error('Failed to establish SSE connection'))
      }
    })
  }

  /**
   * Opens an SSE stream using fetch API to support custom headers
   */
  private async openListeningStreamWithFetch(
    headers: Record<string, string>
  ): Promise<void> {
    const response = await fetch(this.mcpEndpoint, {
      method: 'GET',
      headers,
    })

    if (!response.ok) {
      throw new Error(
        `Failed to open SSE stream: ${response.status} ${response.statusText}`
      )
    }

    if (!response.body) {
      throw new Error('No response body available for SSE stream')
    }

    const reader = response.body.getReader()
    const decoder = new TextDecoder()
    let buffer = ''

    const processStream = async (): Promise<void> => {
      try {
        const { done, value } = await reader.read()

        if (done) {
          reader.releaseLock()
          return
        }

        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || '' // Keep incomplete line in buffer

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6) // Remove 'data: ' prefix
            if (data === '[DONE]') {
              return
            }

            try {
              const message = JSON.parse(data)
              if (this.messageHandler) {
                this.messageHandler(message)
              }
            } catch (error) {
              console.error('Failed to parse SSE data:', error)
            }
          }
        }

        // Continue reading
        await processStream()
      } catch (error) {
        reader.releaseLock()
        throw error
      }
    }

    await processStream()
  }

  async send(
    message: Readonly<JSONRPCRequest<unknown>>
  ): Promise<JSONRPCResponse<unknown>> {
    const headers = this.buildHeaders({
      'Content-Type': 'application/json',
      Accept: 'application/json, text/event-stream',
    })

    const response = await fetch(this.mcpEndpoint, {
      method: 'POST',
      headers,
      body: JSON.stringify(message),
    })

    if (!response.ok) {
      if (response.status === 404 && this.sessionId) {
        // Session expired, clear it
        this.sessionId = undefined
        throw new Error('Session expired. Please reinitialize.')
      }
      throw new Error(`HTTP error ${response.status}: ${response.statusText}`)
    }

    // Check if this is the initialization response with session ID
    const sessionIdHeader = response.headers.get('Mcp-Session-Id')
    if (sessionIdHeader) {
      this.sessionId = sessionIdHeader
    }

    const contentType = response.headers.get('Content-Type')

    if (contentType?.includes('text/event-stream')) {
      // Handle SSE response
      return this.handleSSEResponse(response, message.id)
    } else if (contentType?.includes('application/json')) {
      // Handle JSON response
      return response.json() as Promise<JSONRPCResponse<unknown>>
    } else {
      throw new Error(`Unexpected content type: ${contentType}`)
    }
  }

  private async handleSSEResponse(
    response: Response,
    requestId: string | number
  ): Promise<JSONRPCResponse<unknown>> {
    return new Promise((resolve, reject) => {
      const reader = response.body?.getReader()
      if (!reader) {
        reject(new Error('No response body reader available'))
        return
      }

      const decoder = new TextDecoder()
      let buffer = ''

      const processChunk = async (): Promise<void> => {
        try {
          const { done, value } = await reader.read()

          if (done) {
            reader.releaseLock()
            return
          }

          buffer += decoder.decode(value, { stream: true })
          const lines = buffer.split('\n')
          buffer = lines.pop() || '' // Keep incomplete line in buffer

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6) // Remove 'data: ' prefix
              if (data === '[DONE]') {
                return
              }

              try {
                const message = JSON.parse(data)

                // Check if this is the response to our request
                if ('id' in message && message.id === requestId) {
                  resolve(message as JSONRPCResponse<unknown>)
                  return
                }

                // Handle other messages (server requests/notifications)
                if (this.messageHandler) {
                  this.messageHandler(message)
                }
              } catch (error) {
                console.error('Failed to parse SSE data:', error)
              }
            }
          }

          // Continue reading
          await processChunk()
        } catch (error) {
          reader.releaseLock()
          reject(error)
        }
      }

      processChunk().catch(reject)
    })
  }

  async sendNotification(
    message: Readonly<JSONRPCNotification>
  ): Promise<void> {
    const headers = this.buildHeaders({
      'Content-Type': 'application/json',
      Accept: 'application/json, text/event-stream',
    })

    const response = await fetch(this.mcpEndpoint, {
      method: 'POST',
      headers,
      body: JSON.stringify(message),
    })

    if (!response.ok) {
      if (response.status === 404 && this.sessionId) {
        // Session expired, clear it
        this.sessionId = undefined
        throw new Error('Session expired. Please reinitialize.')
      }
      throw new Error(`HTTP error ${response.status}: ${response.statusText}`)
    }

    // For notifications, we expect 202 Accepted with no body
    if (response.status !== 202) {
      console.warn(`Unexpected status for notification: ${response.status}`)
    }
  }

  /**
   * Explicitly terminate the session (if supported by server)
   */
  async terminateSession(): Promise<void> {
    if (!this.sessionId) {
      return
    }

    try {
      const headers = this.buildHeaders({})

      const response = await fetch(this.mcpEndpoint, {
        method: 'DELETE',
        headers,
      })

      if (response.status === 405) {
        // Server doesn't support explicit session termination
        console.info('Server does not support explicit session termination')
      }
    } catch (error) {
      console.error('Failed to terminate session:', error)
    } finally {
      this.sessionId = undefined
    }
  }

  /**
   * Close any open connections
   */
  close(): void {
    if (this.eventSource) {
      this.eventSource.close()
      this.eventSource = undefined
    }
  }
}



================================================
FILE: src/ax/mcp/stdioTransport.ts
================================================
import { type ChildProcessWithoutNullStreams, spawn } from 'node:child_process'
import readline from 'node:readline'

import type { AxMCPTransport } from './transport.js'
import type {
  JSONRPCNotification,
  JSONRPCRequest,
  JSONRPCResponse,
} from './types.js'

interface StdioTransportConfig {
  command: string
  args?: string[]
  env?: NodeJS.ProcessEnv
}

export class AxMCPStdioTransport implements AxMCPTransport {
  private process: ChildProcessWithoutNullStreams
  private rl: readline.Interface
  private pendingResponses = new Map<
    string | number,
    (res: JSONRPCResponse) => void
  >()

  constructor(config: Readonly<StdioTransportConfig>) {
    this.process = spawn(config.command, config.args ?? [], {
      env: config.env ? { ...process.env, ...config.env } : process.env,
    })
    this.rl = readline.createInterface({ input: this.process.stdout })
    this.rl.on('line', (line) => {
      const response: JSONRPCResponse = JSON.parse(line)
      const resolver = this.pendingResponses.get(response.id)
      if (resolver) {
        resolver(response)
        this.pendingResponses.delete(response.id)
      }
    })
  }

  async send(
    message: Readonly<JSONRPCRequest<unknown>>
  ): Promise<JSONRPCResponse<unknown>> {
    return new Promise<JSONRPCResponse<unknown>>((resolve) => {
      this.pendingResponses.set(message.id, (res: JSONRPCResponse) => {
        resolve(res as JSONRPCResponse<unknown>)
      })
      this.process.stdin.write(`${JSON.stringify(message)}\n`)
    })
  }

  async sendNotification(
    message: Readonly<JSONRPCNotification>
  ): Promise<void> {
    this.process.stdin.write(`${JSON.stringify(message)}\n`)
  }

  async connect(): Promise<void> {
    // Existing implementation
  }
}



================================================
FILE: src/ax/mcp/transport.ts
================================================
import type {
  JSONRPCNotification,
  JSONRPCRequest,
  JSONRPCResponse,
} from './types.js'

export interface AxMCPTransport {
  /**
   * Sends a JSON-RPC request or notification and returns the response
   * @param message The JSON-RPC request or notification to send
   * @returns A Promise that resolves to the JSON-RPC response
   */
  send(
    message: Readonly<JSONRPCRequest<unknown>>
  ): Promise<JSONRPCResponse<unknown>>

  /**
   * Sends a JSON-RPC notification
   * @param message The JSON-RPC notification to send
   */
  sendNotification(message: Readonly<JSONRPCNotification>): Promise<void>

  /**
   * Connects to the transport if needed
   * This method is optional and only required for transports that need connection setup
   */
  connect?(): Promise<void>
}



================================================
FILE: src/ax/mcp/types.ts
================================================
import type { AxFunctionJSONSchema } from '../ai/types.js'

export interface JSONRPCRequest<T> {
  jsonrpc: '2.0'
  id: string | number
  method: string
  params?: T
}

export interface JSONRPCSuccessResponse<T = unknown> {
  jsonrpc: '2.0'
  id: string | number
  result: T
}

export interface JSONRPCErrorResponse {
  jsonrpc: '2.0'
  id: string | number
  error: {
    code: number
    message: string
    data?: unknown
  }
}

export type JSONRPCResponse<T = unknown> =
  | JSONRPCSuccessResponse<T>
  | JSONRPCErrorResponse

export interface MCPInitializeParams {
  protocolVersion: string
  capabilities: Record<string, unknown>
  clientInfo: {
    name: string
    version: string
  }
}

export interface MCPInitializeResult {
  protocolVersion: string
  capabilities: {
    tools?: unknown[]
    resources?: Record<string, unknown>
    prompts?: unknown[]
  }
  serverInfo: {
    name: string
    version: string
  }
}

export interface MCPFunctionDescription {
  name: string
  description: string
  inputSchema: AxFunctionJSONSchema
}

export interface MCPToolsListResult {
  name: string
  description: string
  tools: MCPFunctionDescription[]
}

export interface JSONRPCNotification {
  jsonrpc: '2.0'
  method: string
  params?: Record<string, unknown>
}



================================================
FILE: src/ax/mem/memory.test.ts
================================================
import { describe, expect, it } from 'vitest'

import type { AxChatRequest, AxChatResponseResult } from '../ai/types.js'

import { MemoryImpl } from './memory.js'

describe('MemoryImpl', () => {
  it('constructor should enforce positive limit', () => {
    expect(() => new MemoryImpl(0)).toThrow(
      "argument 'limit' must be greater than 0"
    )
    expect(() => new MemoryImpl(-1)).toThrow(
      "argument 'limit' must be greater than 0"
    )
  })

  it('add should store single chat message', () => {
    const memory = new MemoryImpl()
    const message: AxChatRequest['chatPrompt'][0] = {
      role: 'user',
      content: 'test message',
    }

    memory.add(message)

    const history = memory.history()
    expect(history.length).toBe(1)
    expect(history[0]).toEqual(message)
  })

  it('add should store array of chat messages', () => {
    const memory = new MemoryImpl()
    const messages: AxChatRequest['chatPrompt'] = [
      {
        role: 'user',
        content: 'message 1',
      },
      {
        role: 'assistant',
        content: 'message 2',
        functionCalls: [],
      },
    ]

    memory.add(messages)

    const history = memory.history()
    expect(history.length).toBe(2)
    expect(history).toEqual(messages)
  })

  it('add should respect memory limit', () => {
    const memory = new MemoryImpl(2)
    const messages: AxChatRequest['chatPrompt'] = [
      { role: 'system', content: 'message 1' },
      { role: 'user', content: 'message 2' },
      { role: 'system', content: 'message 3' },
    ]

    memory.add(messages)

    const history = memory.history()
    expect(history.length).toBe(2)
    expect(history).toEqual(messages.slice(-2))
  })

  it('addResult should store assistant message', () => {
    const memory = new MemoryImpl()
    const result: AxChatResponseResult = {
      content: 'test response',
      name: 'Claude',
      functionCalls: [],
    }

    memory.addResult(result)

    const last = memory.getLast()
    if (!last || last.chat.role !== 'assistant') {
      throw new Error('Last message is not a valid assistant message')
    }
    expect(last.chat.content).toBe(result.content)
    expect(last.chat.name).toBe(result.name)
  })

  it('rewindToTag should remove and return items from tagged message onwards', () => {
    const memory = new MemoryImpl()

    // Add a few messages
    const message1 = {
      role: 'user' as const,
      content: 'first message',
    }
    const message2 = {
      role: 'assistant' as const,
      content: 'second message',
    }

    memory.add(message1)
    memory.add(message2)
    memory.addTag('checkpoint')

    const message3 = {
      role: 'user' as const,
      content: 'third message',
    }

    memory.add(message3)

    // Rewind to checkpoint tag
    const removed = memory.rewindToTag('checkpoint')

    // Check returned items
    expect(removed).toEqual([
      { role: 'assistant', content: 'second message' },
      { role: 'user', content: 'third message' },
    ])

    // Verify memory state
    expect(memory.history()).toEqual([
      { role: 'user', content: 'first message' },
    ])
  })

  it('removeByTag should remove all items with specified tag', () => {
    const memory = new MemoryImpl()

    // Add messages with and without tags
    memory.add({ role: 'user', content: 'first message' })
    memory.add({ role: 'assistant', content: 'second message' })
    memory.addTag('important')

    memory.add({ role: 'user', content: 'third message' })
    memory.add({ role: 'assistant', content: 'fourth message' })
    memory.addTag('important')

    // Remove items with 'important' tag
    const removed = memory.removeByTag('important')

    // Check removed items
    expect(removed).toEqual([
      { role: 'assistant', content: 'second message' },
      { role: 'assistant', content: 'fourth message' },
    ])

    // Verify remaining items
    expect(memory.history()).toEqual([
      { role: 'user', content: 'first message' },
      { role: 'user', content: 'third message' },
    ])
  })

  it('removeTaggedItems should throw for unknown tag', () => {
    const memory = new MemoryImpl()
    const message = {
      role: 'user' as const,
      content: 'test',
    }
    memory.add(message)

    expect(() => memory.removeByTag('unknown')).toThrow(
      'No items found with tag "unknown"'
    )
  })

  it('addResult should ignore empty results', () => {
    const memory = new MemoryImpl()
    const emptyResult: AxChatResponseResult = {
      content: '',
      functionCalls: [],
    }

    memory.addResult(emptyResult)

    expect(memory.history().length).toBe(1)
  })

  it('updateResult should modify last assistant message', () => {
    const memory = new MemoryImpl()
    const initial: AxChatResponseResult = {
      content: 'initial response',
      name: 'Claude',
      functionCalls: [],
    }
    const update: AxChatResponseResult = {
      content: 'updated response',
      name: 'Claude 2.0',
      functionCalls: [],
    }

    memory.addResult(initial)
    memory.updateResult(update)

    const last = memory.getLast()
    if (!last || last.chat.role !== 'assistant') {
      throw new Error('Last message is not a valid assistant message')
    }
    expect(last.chat.content).toBe(update.content)
    expect(last.chat.name).toBe(update.name)
  })

  it('updateResult should add new message if last message is not assistant', () => {
    const memory = new MemoryImpl()
    const userMessage: AxChatRequest['chatPrompt'][0] = {
      role: 'user',
      content: 'test',
    }
    const update: AxChatResponseResult = {
      content: 'response',
      name: 'Claude',
      functionCalls: [],
    }

    memory.add(userMessage)

    expect(() => memory.updateResult(update)).toThrow(
      'No assistant message to update'
    )
  })

  it('addTag should add tag to last message', () => {
    const memory = new MemoryImpl()
    const message1: AxChatRequest['chatPrompt'][0] = {
      role: 'user',
      content: 'test1',
    }
    const message2: AxChatRequest['chatPrompt'][0] = {
      role: 'user',
      content: 'test2',
    }

    memory.add(message1)
    memory.addTag('tag1')
    memory.add(message2)
    memory.addTag('tag2')

    expect(() => memory.rewindToTag('tag2')).not.toThrow()
    expect(() => memory.rewindToTag('tag1')).not.toThrow()
  })

  it('addTag should handle empty memory', () => {
    const memory = new MemoryImpl()

    expect(() => memory.addTag('tag')).not.toThrow()
    expect(memory.history().length).toBe(0)
  })

  it('rewindToTag should remove messages including and after tag', () => {
    const memory = new MemoryImpl()
    const message1: AxChatRequest['chatPrompt'][0] = {
      role: 'user',
      content: 'message 1',
    }
    const message2: AxChatRequest['chatPrompt'][0] = {
      role: 'system',
      content: 'message 2',
    }
    const message3: AxChatRequest['chatPrompt'][0] = {
      role: 'user',
      content: 'message 3',
    }

    memory.add(message1)
    memory.add(message2)
    memory.addTag('checkpoint')
    memory.add(message3)

    memory.rewindToTag('checkpoint')

    const history = memory.history()
    expect(history.length).toBe(1)
    expect(history[0]).toEqual(message1)
  })

  it('rewindToTag should throw for unknown tag', () => {
    const memory = new MemoryImpl()
    const message: AxChatRequest['chatPrompt'][0] = {
      role: 'user',
      content: 'test',
    }
    memory.add(message)

    expect(() => memory.rewindToTag('unknown')).toThrow(
      'Tag "unknown" not found'
    )
  })

  it('reset should clear all messages', () => {
    const memory = new MemoryImpl()
    const message: AxChatRequest['chatPrompt'][0] = {
      role: 'user',
      content: 'test',
    }
    memory.add(message)
    memory.addTag('tag')

    memory.reset()

    expect(memory.history().length).toBe(0)
    expect(() => memory.rewindToTag('tag')).toThrow('Tag "tag" not found')
  })

  it('getLast should return undefined for empty memory', () => {
    const memory = new MemoryImpl()
    expect(memory.getLast()).toBeUndefined()
  })

  it('getLast should return last message', () => {
    const memory = new MemoryImpl()
    const messages: AxChatRequest['chatPrompt'] = [
      { role: 'user', content: 'message 1' },
      { role: 'assistant', content: 'message 2', functionCalls: [] },
    ]

    memory.add(messages)

    const last = memory.getLast()
    expect(last?.chat).toEqual(messages[1])
  })

  it('updateResult should not duplicate logging for streaming function calls', () => {
    const loggedMessages: string[] = []
    const mockLogger = (message: string) => {
      loggedMessages.push(message)
    }

    const memory = new MemoryImpl(10, { debug: true })
    // Override the default logger for testing
    const originalWrite = process.stdout.write
    process.stdout.write = mockLogger as typeof process.stdout.write

    try {
      // Add initial assistant message
      memory.addResult({
        content: '',
        functionCalls: [],
      })

      // Clear logged messages from addResult
      loggedMessages.length = 0

      // Simulate streaming function call with delta
      memory.updateResult({
        content: '',
        functionCalls: [
          {
            id: 'call_1',
            type: 'function',
            function: {
              name: 'getCurrentWeather',
              params: '{"location":"San Francisco","units":"imperial"}',
            },
          },
        ],
        delta: '{"location":"San Francisco","units":"imperial"}',
      })

      // Should only log the delta, not the complete function call
      expect(loggedMessages).toHaveLength(1)
      expect(loggedMessages[0]).toContain(
        '{"location":"San Francisco","units":"imperial"}'
      )
      // Should be green (responseContent color) since it's a delta
      expect(loggedMessages[0]).toContain('\x1B[92m')

      // Reset logged messages
      loggedMessages.length = 0

      // Simulate final update without delta (function call complete)
      memory.updateResult({
        content: '',
        functionCalls: [
          {
            id: 'call_1',
            type: 'function',
            function: {
              name: 'getCurrentWeather',
              params: '{"location":"San Francisco","units":"imperial"}',
            },
          },
        ],
      })

      // Should log the complete function call (function name + parameters + end marker = 3 messages)
      expect(loggedMessages).toHaveLength(3)
      expect(loggedMessages[0]).toContain('[1] getCurrentWeather') // Function name with index
      expect(loggedMessages[1]).toContain(
        '{"location":"San Francisco","units":"imperial"}'
      )
      expect(loggedMessages[2]).toBe('\n') // functionEnd marker with newline
      // Function name should be white bright, args should be blue
      expect(loggedMessages[0]).toContain('\x1B[97m') // whiteBright
      expect(loggedMessages[1]).toContain('\x1B[94m') // blueBright
    } finally {
      // Restore original stdout.write
      process.stdout.write = originalWrite
    }
  })
})



================================================
FILE: src/ax/mem/memory.ts
================================================
import {
  logChatRequest,
  logChatRequestMessage,
  logResponseDelta,
  logResponseResult,
} from '../ai/debug.js'
import type { AxChatRequest, AxChatResponseResult } from '../ai/types.js'

import type { AxAIMemory } from './types.js'

type MemoryData = {
  tags?: string[]
  chat: AxChatRequest['chatPrompt'][number]
}[]

const defaultLimit = 10000

export class MemoryImpl {
  private data: MemoryData = []

  constructor(
    private limit = defaultLimit,
    private options?: {
      debug?: boolean
      debugHideSystemPrompt?: boolean
    }
  ) {
    if (limit <= 0) {
      throw Error("argument 'limit' must be greater than 0")
    }
  }

  private addMemory(
    value: AxChatRequest['chatPrompt'][number] | AxChatRequest['chatPrompt']
  ): void {
    if (Array.isArray(value)) {
      this.data.push(...value.map((chat) => ({ chat: structuredClone(chat) })))
    } else {
      this.data.push({
        chat: structuredClone(value),
      })
    }

    if (this.data.length > this.limit) {
      const removeCount = this.data.length - this.limit
      this.data.splice(0, removeCount)
    }
  }

  add(
    value: AxChatRequest['chatPrompt'][number] | AxChatRequest['chatPrompt']
  ): void {
    this.addMemory(value)

    if (this.options?.debug) {
      debugRequest(value, this.options?.debugHideSystemPrompt)
    }
  }

  private addResultMessage({
    content,
    name,
    functionCalls,
  }: Readonly<AxChatResponseResult>): void {
    const isContentEmpty = typeof content === 'string' && content.trim() === ''

    if (isContentEmpty) {
      this.addMemory({ name, role: 'assistant', functionCalls })
    } else {
      this.addMemory({ content, name, role: 'assistant', functionCalls })
    }
  }

  addResult({
    content,
    name,
    functionCalls,
  }: Readonly<AxChatResponseResult>): void {
    this.addResultMessage({ content, name, functionCalls })

    if (this.options?.debug) {
      debugResponse({ content, name, functionCalls })
    }
  }

  updateResult({
    content,
    name,
    functionCalls,
    delta,
  }: Readonly<AxChatResponseResult & { delta?: string }>): void {
    const lastItem = this.data.at(-1)

    if (!lastItem || lastItem.chat.role !== 'assistant') {
      throw new Error('No assistant message to update')
    }

    if (typeof content === 'string' && content.trim() !== '') {
      lastItem.chat.content = content
    }

    if (name && name.trim() !== '') {
      lastItem.chat.name = name
    }

    if (functionCalls && functionCalls.length > 0) {
      lastItem.chat.functionCalls = functionCalls
    }

    if (this.options?.debug) {
      if (delta && typeof delta === 'string') {
        debugResponseDelta(delta)
      } else if (!delta && (content || functionCalls)) {
        debugResponse({ content, name, functionCalls })
      }
    }
  }

  addTag(name: string): void {
    const lastItem = this.data.at(-1)
    if (!lastItem) {
      return
    }

    if (!lastItem.tags) {
      lastItem.tags = []
    }

    if (!lastItem.tags.includes(name)) {
      lastItem.tags.push(name)
    }
  }

  rewindToTag(name: string): AxChatRequest['chatPrompt'] {
    const tagIndex = this.data.findIndex((item) => item.tags?.includes(name))
    if (tagIndex === -1) {
      throw new Error(`Tag "${name}" not found`)
    }

    // Remove and return the tagged item and everything after it
    const removedItems = this.data.splice(tagIndex)
    return removedItems.map((item) => item.chat)
  }

  removeByTag(name: string): AxChatRequest['chatPrompt'] {
    const indices = this.data.reduce<number[]>((acc, item, index) => {
      if (item.tags?.includes(name)) {
        acc.push(index)
      }
      return acc
    }, [])

    if (indices.length === 0) {
      throw new Error(`No items found with tag "${name}"`)
    }

    return indices
      .reverse()
      .map((index) => this.data.splice(index, 1).at(0)?.chat)
      .filter(Boolean)
      .reverse() as AxChatRequest['chatPrompt']
  }

  history(): AxChatRequest['chatPrompt'] {
    return this.data.map((item) => item.chat)
  }

  getLast():
    | { chat: AxChatRequest['chatPrompt'][number]; tags?: string[] }
    | undefined {
    const lastItem = this.data.at(-1)
    if (!lastItem) return undefined
    // Merge the tags into the chat object so that consumers can inspect them.
    return {
      chat: lastItem.chat,
      tags: lastItem.tags,
    }
  }

  reset(): void {
    this.data = []
  }
}

export class AxMemory implements AxAIMemory {
  private memories = new Map<string, MemoryImpl>()
  private defaultMemory: MemoryImpl

  constructor(
    private limit = defaultLimit,
    private options?: {
      debug?: boolean
      debugHideSystemPrompt?: boolean
    }
  ) {
    this.defaultMemory = new MemoryImpl(limit, options)
  }

  private getMemory(sessionId?: string): MemoryImpl {
    if (!sessionId) {
      return this.defaultMemory
    }

    if (!this.memories.has(sessionId)) {
      this.memories.set(sessionId, new MemoryImpl(this.limit, this.options))
    }

    return this.memories.get(sessionId) as MemoryImpl
  }

  add(
    value: AxChatRequest['chatPrompt'][number] | AxChatRequest['chatPrompt'],
    sessionId?: string
  ): void {
    this.getMemory(sessionId).add(value)
  }

  addResult(result: Readonly<AxChatResponseResult>, sessionId?: string): void {
    this.getMemory(sessionId).addResult(result)
  }

  updateResult(
    result: Readonly<AxChatResponseResult>,
    sessionId?: string
  ): void {
    this.getMemory(sessionId).updateResult(result)
  }

  addTag(name: string, sessionId?: string) {
    this.getMemory(sessionId).addTag(name)
  }

  rewindToTag(name: string, sessionId?: string) {
    return this.getMemory(sessionId).rewindToTag(name)
  }

  history(sessionId?: string) {
    return this.getMemory(sessionId).history()
  }

  getLast(sessionId?: string) {
    return this.getMemory(sessionId).getLast()
  }

  reset(sessionId?: string): void {
    if (!sessionId) {
      this.defaultMemory.reset()
    } else {
      this.memories.set(sessionId, new MemoryImpl(this.limit, this.options))
    }
  }
}

function debugRequest(
  value: AxChatRequest['chatPrompt'][number] | AxChatRequest['chatPrompt'],
  hideSystemPrompt?: boolean
) {
  if (Array.isArray(value)) {
    logChatRequest(value, hideSystemPrompt)
  } else {
    logChatRequestMessage(value, hideSystemPrompt)
  }
}

function debugResponse(value: Readonly<AxChatResponseResult>) {
  logResponseResult(value)
}

function debugResponseDelta(delta: string) {
  logResponseDelta(delta)
}



================================================
FILE: src/ax/mem/types.ts
================================================
import type { AxChatRequest, AxChatResponseResult } from '../ai/types.js'

export interface AxAIMemory {
  add(
    result:
      | Readonly<AxChatRequest['chatPrompt']>
      | Readonly<AxChatRequest['chatPrompt'][number]>,
    sessionId?: string
  ): void
  addResult(result: Readonly<AxChatResponseResult>, sessionId?: string): void
  updateResult(
    result: Readonly<AxChatResponseResult> & {
      delta?: string
    },
    sessionId?: string
  ): void

  history(sessionId?: string): AxChatRequest['chatPrompt']
  reset(sessionId?: string): void

  getLast(
    sessionId?: string
  ): { chat: AxChatRequest['chatPrompt'][number]; tags?: string[] } | undefined

  addTag(name: string, sessionId?: string): void
  rewindToTag(name: string, sessionId?: string): AxChatRequest['chatPrompt']
}



================================================
FILE: src/ax/prompts/agent.test.ts
================================================
import { describe, expect, it } from 'vitest'

import { AxMockAIService } from '../ai/mock/api.js'
import type { AxChatResponse } from '../ai/types.js'
import type { AxMessage } from '../dsp/types.js'

import { AxAgent } from './agent.js'

// Helper function to create streaming responses
function createStreamingResponse(
  chunks: AxChatResponse['results']
): ReadableStream<AxChatResponse> {
  return new ReadableStream({
    start(controller) {
      let count = 0

      const processChunks = async () => {
        if (count >= chunks.length) {
          controller.close()
          return
        }

        const chunk = chunks[count]
        if (chunk) {
          try {
            controller.enqueue({
              results: [
                {
                  content: chunk.content,
                  finishReason: chunk.finishReason,
                },
              ],
              modelUsage: {
                ai: 'test-ai',
                model: 'test-model',
                tokens: {
                  promptTokens: 0,
                  completionTokens: 0,
                  totalTokens: 0,
                },
              },
            })
            count++

            // Small delay between chunks
            await new Promise((resolve) => setTimeout(resolve, 10))
            processChunks()
          } catch (error) {
            controller.error(error)
          }
        }
      }

      processChunks().catch((error) => {
        controller.error(error)
      })
    },

    cancel() {},
  })
}

describe('AxAgent', () => {
  const mockAI = new AxMockAIService({
    features: {
      functions: true,
      streaming: true,
    },
    models: [
      { key: 'gpt4', model: 'gpt-4', description: 'Advanced model' },
      { key: 'gpt35', model: 'gpt-3.5', description: 'Fast model' },
    ],
  })

  it('should handle smart model routing correctly', () => {
    // Create agent with smart routing enabled (default)
    const agent = new AxAgent({
      ai: mockAI,
      name: 'test smart routing agent',
      description: 'Tests the smart model routing functionality of agents',
      signature: 'userQuery: string -> agentResponse: string',
    })

    const func = agent.getFunction()
    expect(func.parameters?.properties?.model).toBeDefined()
    expect(func.parameters?.properties?.model?.enum).toEqual(['gpt4', 'gpt35'])
  })

  it('should disable smart model routing when specified', () => {
    const agent = new AxAgent(
      {
        ai: mockAI,
        name: 'test smart routing disabled',
        description: 'Tests disabling smart model routing',
        signature: 'userQuery: string -> agentResponse: string',
      },
      { disableSmartModelRouting: true }
    )

    const func = agent.getFunction()
    expect(func.parameters?.properties?.model).toBeUndefined()
  })

  it('should update description correctly', () => {
    const agent = new AxAgent({
      ai: mockAI,
      name: 'test description updates',
      description: 'Initial description that is long enough',
      signature: 'userQuery: string -> agentResponse: string',
    })

    const newDescription =
      'Updated description that is also long enough to pass validation'
    agent.setDescription(newDescription)

    const func = agent.getFunction()
    expect(func.description).toBe(newDescription)
  })

  it('should throw error for short description', () => {
    const agent = new AxAgent({
      ai: mockAI,
      name: 'test description validation',
      description: 'Initial description that is long enough',
      signature: 'userQuery: string -> agentResponse: string',
    })

    expect(() => agent.setDescription('Too short')).toThrow()
  })

  it('should expose features correctly', () => {
    const agent = new AxAgent({
      ai: mockAI,
      name: 'test features',
      description: 'Tests the feature reporting of agents',
      signature: 'userQuery: string -> agentResponse: string',
    })

    const features = agent.getFeatures()
    expect(features.canConfigureSmartModelRouting).toBe(false)
    expect(features.excludeFieldsFromPassthrough).toEqual([])
  })

  it('should respect excludeFieldsFromPassthrough option', () => {
    const agent = new AxAgent(
      {
        ai: mockAI,
        name: 'test excluded fields',
        description: 'Tests field exclusion configuration',
        signature: 'userQuery: string -> agentResponse: string',
      },
      {
        excludeFieldsFromPassthrough: ['someField'],
      }
    )

    const features = agent.getFeatures()
    expect(features.excludeFieldsFromPassthrough).toEqual(['someField'])
  })

  it('should update definition correctly using setDefinition', () => {
    const agent = new AxAgent({
      ai: mockAI,
      name: 'test setDefinition',
      description: 'Initial description that is long enough',
      signature: 'userQuery: string -> agentResponse: string',
    })

    const validDefinition = 'A'.repeat(100) // valid definition (100 characters)
    agent.setDefinition(validDefinition)
    // Access the underlying program's signature to verify that the definition was applied
    expect(
      (
        agent as unknown as {
          program: { getSignature: () => { getDescription: () => string } }
        }
      ).program
        .getSignature()
        .getDescription()
    ).toBe(validDefinition)
  })

  it('should throw error when setting a too short definition using setDefinition', () => {
    const agent = new AxAgent({
      ai: mockAI,
      name: 'test setDefinition short',
      description: 'Initial description that is long enough',
      signature: 'userQuery: string -> agentResponse: string',
    })

    expect(() => agent.setDefinition('Too short')).toThrow()
  })

  it('should set definition in constructor if provided and valid', () => {
    const validDefinition = 'D'.repeat(100) // valid definition (100 characters)
    const agent = new AxAgent({
      ai: mockAI,
      name: 'test constructor with definition',
      description: 'Initial description that is long enough',
      definition: validDefinition,
      signature: 'userQuery: string -> agentResponse: string',
    })
    // The underlying signature description should use the provided definition.
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    expect((agent as any).program.getSignature().getDescription()).toBe(
      validDefinition
    )
    // Note: The function description remains the original description.
    expect(agent.getFunction().description).toBe(
      'Initial description that is long enough'
    )
  })

  it('should throw error in constructor for a too short definition', () => {
    expect(
      () =>
        new AxAgent({
          ai: mockAI,
          name: 'test short definition',
          description: 'Initial description that is long enough',
          definition: 'Short definition',
          signature: 'userQuery: string -> agentResponse: string',
        })
    ).toThrow()
  })

  it('should handle AxMessage array input in forward method', async () => {
    // Create a mock AI service with a specific response for this test
    const testMockAI = new AxMockAIService({
      features: { functions: false, streaming: false },
      chatResponse: {
        results: [
          {
            content: 'Agent Response: Mocked response for message array',
            finishReason: 'stop',
          },
        ],
        modelUsage: {
          ai: 'test-ai',
          model: 'test-model',
          tokens: { promptTokens: 10, completionTokens: 5, totalTokens: 15 },
        },
      },
    })

    const agent = new AxAgent({
      ai: testMockAI,
      name: 'test message array forward',
      description: 'Tests handling of AxMessage array input in forward method',
      signature: 'userQuery: string -> agentResponse: string',
    })

    const messages: AxMessage<{ userQuery: string }>[] = [
      { role: 'user', values: { userQuery: 'Hello from message array' } },
      { role: 'assistant', values: { userQuery: 'Previous response' } },
      { role: 'user', values: { userQuery: 'Latest user message' } },
    ]

    const result = await agent.forward(testMockAI, messages)
    expect(result).toBeDefined()
    expect(result.agentResponse).toBe('Mocked response for message array')
  })

  it('should handle AxMessage array input in streamingForward method', async () => {
    // Create streaming response chunks
    const chunks: AxChatResponse['results'] = [
      { content: 'Agent Response: Streaming ' },
      { content: 'response ' },
      { content: 'chunk', finishReason: 'stop' },
    ]
    const streamingResponse = createStreamingResponse(chunks)

    const testMockAI = new AxMockAIService({
      features: { functions: false, streaming: true },
      chatResponse: streamingResponse,
    })

    const agent = new AxAgent({
      ai: testMockAI,
      name: 'test message array streaming',
      description:
        'Tests handling of AxMessage array input in streamingForward method',
      signature: 'userQuery: string -> agentResponse: string',
    })

    const messages: AxMessage<{ userQuery: string }>[] = [
      { role: 'user', values: { userQuery: 'Streaming test message' } },
    ]

    const generator = agent.streamingForward(testMockAI, messages)
    const results = []

    for await (const chunk of generator) {
      results.push(chunk)
    }

    expect(results.length).toBeGreaterThan(0)
    // Verify that we received streaming chunks
    expect(results[0]).toHaveProperty('delta')
  })

  it('should handle empty AxMessage array gracefully', async () => {
    const agent = new AxAgent({
      ai: mockAI,
      name: 'test empty message array',
      description: 'Tests handling of empty AxMessage array input',
      signature: 'userQuery: string -> agentResponse: string',
    })

    const messages: AxMessage<{ userQuery: string }>[] = []

    // This should not throw an error, but may result in an empty or default response
    // depending on how the underlying prompt template handles empty message arrays
    try {
      await agent.forward(mockAI, messages)
      // If it doesn't throw, that's fine - the behavior may vary
    } catch (error) {
      // If it throws, that's also acceptable behavior for empty input
      expect(error).toBeDefined()
    }
  })

  it('should extract values from most recent user message in AxMessage array', async () => {
    // Create a mock AI service for this test
    const testMockAI = new AxMockAIService({
      features: { functions: false, streaming: false },
      chatResponse: {
        results: [
          {
            content: 'Agent Response: Parent response with child interaction',
            finishReason: 'stop',
          },
        ],
        modelUsage: {
          ai: 'test-ai',
          model: 'test-model',
          tokens: { promptTokens: 10, completionTokens: 5, totalTokens: 15 },
        },
      },
    })

    // Create a child agent that will receive injected values
    const childAgent = new AxAgent({
      ai: testMockAI,
      name: 'child agent for injection test',
      description: 'Child agent that receives injected values from parent',
      signature: 'contextInfo: string -> childResponse: string',
    })

    // Create parent agent with the child agent
    const parentAgent = new AxAgent({
      ai: testMockAI,
      name: 'parent agent with child',
      description: 'Parent agent that passes values to child agent',
      signature:
        'userQuery: string, contextInfo: string -> agentResponse: string',
      agents: [childAgent],
    })

    const messages: AxMessage<{ userQuery: string; contextInfo: string }>[] = [
      {
        role: 'user',
        values: { userQuery: 'First message', contextInfo: 'Old context' },
      },
      {
        role: 'assistant',
        values: {
          userQuery: 'Assistant response',
          contextInfo: 'Assistant context',
        },
      },
      {
        role: 'user',
        values: { userQuery: 'Latest message', contextInfo: 'Latest context' },
      },
    ]

    const result = await parentAgent.forward(testMockAI, messages)
    expect(result).toBeDefined()

    // The test verifies that the system can handle message arrays without throwing errors
    // The actual value injection logic is tested implicitly through the successful execution
  })
})



================================================
FILE: src/ax/prompts/agent.ts
================================================
import type {
  AxAIModelList,
  AxAIService,
  AxFunction,
  AxFunctionHandler,
  AxFunctionJSONSchema,
} from '../ai/types.js'
import type { AxInputFunctionType } from '../dsp/functions.js'
import { AxGen } from '../dsp/generate.js'
import type {
  AxGenStreamingOut,
  AxProgramDemos,
  AxProgramExamples,
  AxProgramForwardOptions,
  AxProgramStreamingForwardOptions,
  AxProgramWithSignature,
  AxSetExamplesOptions,
  AxTunable,
  AxUsable,
} from '../dsp/program.js'
import type { AxSignature } from '../dsp/sig.js'
import type { AxGenIn, AxGenOut, AxMessage } from '../dsp/types.js'

/**
 * Interface for agents that can be used as child agents.
 * Provides methods to get the agent's function definition and features.
 */
export interface AxAgentic<IN extends AxGenIn, OUT extends AxGenOut>
  extends AxTunable<IN, OUT>,
    AxUsable {
  getFunction(): AxFunction
  getFeatures(): AxAgentFeatures
}

export type AxAgentOptions = Omit<AxProgramForwardOptions, 'functions'> & {
  disableSmartModelRouting?: boolean
  /** List of field names that should not be automatically passed from parent to child agents */
  excludeFieldsFromPassthrough?: string[]
  debug?: boolean
}

export interface AxAgentFeatures {
  /** Whether this agent can use smart model routing (requires an AI service) */
  canConfigureSmartModelRouting: boolean
  /** List of fields that this agent excludes from parent->child value passing */
  excludeFieldsFromPassthrough: string[]
}

/**
 * Processes a child agent's function, applying model routing and input injection as needed.
 * Handles both the schema modifications and function wrapping.
 */
function processChildAgentFunction<IN extends AxGenIn>(
  childFunction: Readonly<AxFunction>,
  parentValues: IN | AxMessage<IN>[],
  parentInputKeys: string[],
  modelList: AxAIModelList | undefined,
  options: Readonly<{
    debug: boolean
    disableSmartModelRouting: boolean
    excludeFieldsFromPassthrough: string[]
    canConfigureSmartModelRouting: boolean
  }>
): AxFunction {
  const processedFunction = { ...childFunction }

  // Process input field injection
  if (processedFunction.parameters) {
    const childKeys = processedFunction.parameters.properties
      ? Object.keys(processedFunction.parameters.properties)
      : []

    // Find common keys between parent and child, excluding 'model' and specified exclusions
    const commonKeys = parentInputKeys
      .filter((key) => childKeys.includes(key))
      .filter((key) => key !== 'model')
    const injectionKeys = commonKeys.filter(
      (key) => !options.excludeFieldsFromPassthrough.includes(key)
    )

    if (injectionKeys.length > 0) {
      // Remove injected fields from child schema
      processedFunction.parameters = removePropertiesFromSchema(
        processedFunction.parameters,
        injectionKeys
      )

      // Wrap function to inject parent values
      const originalFunc = processedFunction.func
      // add debug logging if enabled
      processedFunction.func = async (childArgs, funcOptions) => {
        // Extract values from parentValues - handle both IN and AxMessage<IN>[] cases
        let valuesToInject: Partial<IN> = {}
        if (Array.isArray(parentValues)) {
          // If parentValues is an array of messages, find the most recent user message
          const lastUserMessage = parentValues
            .filter((msg) => msg.role === 'user')
            .pop()
          if (lastUserMessage) {
            valuesToInject = pick(
              lastUserMessage.values,
              injectionKeys as (keyof IN)[]
            )
          }
        } else {
          // If parentValues is a single IN object
          valuesToInject = pick(parentValues, injectionKeys as (keyof IN)[])
        }

        const updatedChildArgs = {
          ...childArgs,
          ...valuesToInject,
        }

        if (options.debug && injectionKeys.length > 0) {
          const ai = funcOptions?.ai
          if (ai) {
            const logger = ai.getLogger()
            logger(
              `Function Params: ${JSON.stringify(updatedChildArgs, null, 2)}`,
              { tags: ['functionArg'] }
            )
          }
        }

        return await originalFunc(updatedChildArgs, funcOptions)
      }
    }

    return processedFunction
  }

  // Apply smart model routing if enabled
  if (
    modelList &&
    !options.disableSmartModelRouting &&
    options.canConfigureSmartModelRouting
  ) {
    processedFunction.parameters = addModelParameter(
      processedFunction.parameters,
      modelList
    )
  }

  return processedFunction
}

const descriptionError = new Error(
  'Agent description must be at least 20 characters (explain in detail what the agent does)'
)

const definitionError = new Error(
  'Agent definition is the prompt you give to the LLM for the agent. It must be detailed and at least 100 characters'
)

/**
 * An AI agent that can process inputs using an AI service and coordinate with child agents.
 * Supports features like smart model routing and automatic input field passing to child agents.
 */
export class AxAgent<IN extends AxGenIn, OUT extends AxGenOut>
  implements AxAgentic<IN, OUT>
{
  private ai?: AxAIService
  private program: AxProgramWithSignature<IN, OUT>
  private functions?: AxInputFunctionType
  private agents?: AxAgentic<IN, OUT>[]
  private disableSmartModelRouting?: boolean
  private excludeFieldsFromPassthrough: string[]
  private debug?: boolean

  private name: string
  //   private subAgentList?: string
  private func: AxFunction

  constructor(
    {
      ai,
      name,
      description,
      definition,
      signature,
      agents,
      functions,
    }: Readonly<{
      ai?: Readonly<AxAIService>
      name: string
      description: string
      definition?: string
      signature: NonNullable<ConstructorParameters<typeof AxSignature>[0]>
      agents?: AxAgentic<IN, OUT>[]
      functions?: AxInputFunctionType
    }>,
    options?: Readonly<AxAgentOptions>
  ) {
    const { disableSmartModelRouting, excludeFieldsFromPassthrough, debug } =
      options ?? {}

    this.ai = ai
    this.agents = agents
    this.functions = functions
    this.disableSmartModelRouting = disableSmartModelRouting
    this.excludeFieldsFromPassthrough = excludeFieldsFromPassthrough ?? []
    this.debug = debug

    if (!name || name.length < 5) {
      throw new Error(
        'Agent name must be at least 10 characters (more descriptive)'
      )
    }

    if (!description || description.length < 20) {
      throw descriptionError
    }

    if (definition && definition.length < 100) {
      throw definitionError
    }

    this.program = new AxGen<IN, OUT>(signature, {
      ...options,
      description: definition ?? description,
    })

    for (const agent of agents ?? []) {
      this.program.register(
        agent as unknown as Readonly<AxTunable<IN, OUT> & AxUsable>
      )
    }

    this.name = name
    // this.subAgentList = agents?.map((a) => a.getFunction().name).join(', ')

    this.func = {
      name: toCamelCase(this.name),
      description,
      parameters: this.program.getSignature().toJSONSchema(),
      func: () => this.forward,
    }

    const mm = ai?.getModelList()
    // Only add model parameter if smart routing is enabled and model list exists
    if (mm && !this.disableSmartModelRouting) {
      this.func.parameters = addModelParameter(this.func.parameters, mm)
    }
  }

  public setExamples(
    examples: Readonly<AxProgramExamples<IN, OUT>>,
    options?: Readonly<AxSetExamplesOptions>
  ) {
    this.program.setExamples(examples, options)
  }

  public setId(id: string) {
    this.program.setId(id)
  }

  public setParentId(parentId: string) {
    this.program.setParentId(parentId)
  }

  public getTraces() {
    return this.program.getTraces()
  }

  public setDemos(demos: readonly AxProgramDemos<IN, OUT>[]) {
    this.program.setDemos(demos)
  }

  public getUsage() {
    return this.program.getUsage()
  }

  public resetUsage() {
    this.program.resetUsage()
  }

  public getFunction(): AxFunction {
    const boundFunc = this.forward.bind(this)

    // Create a wrapper function that excludes the 'ai' parameter
    const wrappedFunc: AxFunctionHandler = async (
      valuesAndModel: IN & { model: string },
      options?
    ): Promise<string> => {
      const { model, ...values } = valuesAndModel

      const ai = this.ai ?? options?.ai
      if (!ai) {
        throw new Error('AI service is required to run the agent')
      }
      const debug = this.getDebug(ai, options)

      if (debug) {
        const logger = ai.getLogger()
        logger(`🤖 Agent ${this.name} starting...`, {
          tags: ['assistantStart'],
        })
      }

      const ret = await boundFunc(ai, values as unknown as IN, {
        ...options,
        model,
      })

      if (debug) {
        const logger = ai.getLogger()
        logger(`🤖 Agent ${this.name} completed.`, { tags: ['assistantEnd'] })
      }

      const sig = this.program.getSignature()
      const outFields = sig.getOutputFields()
      const result = Object.keys(ret)
        .map((k) => {
          const field = outFields.find((f) => f.name === k)
          if (field) {
            return `${field.title}: ${ret[k]}`
          }
          return `${k}: ${ret[k]}`
        })
        .join('\n')

      return result
    }

    return {
      ...this.func,
      func: wrappedFunc,
    }
  }

  public getFeatures(): AxAgentFeatures {
    return {
      canConfigureSmartModelRouting: this.ai === undefined,
      excludeFieldsFromPassthrough: this.excludeFieldsFromPassthrough,
    }
  }

  /**
   * Initializes the agent's execution context, processing child agents and their functions.
   */
  private init(
    parentAi: Readonly<AxAIService>,
    values: IN | AxMessage<IN>[],
    options: Readonly<AxProgramForwardOptions> | undefined
  ) {
    const ai = this.ai ?? parentAi
    const mm = ai?.getModelList()

    // Get parent's input schema and keys
    const parentSchema = this.program.getSignature().getInputFields()
    const parentKeys = parentSchema.map((p) => p.name)
    const debug = this.getDebug(ai, options)

    // Process each child agent's function
    const agentFuncs = this.agents?.map((agent) => {
      const f = agent.getFeatures()

      const processOptions = {
        debug,
        disableSmartModelRouting: !!this.disableSmartModelRouting,
        excludeFieldsFromPassthrough: f.excludeFieldsFromPassthrough,
        canConfigureSmartModelRouting: f.canConfigureSmartModelRouting,
      }

      return processChildAgentFunction(
        agent.getFunction(),
        values,
        parentKeys,
        mm,
        processOptions
      )
    })

    // Combine all functions
    const functions: AxInputFunctionType = [
      ...(options?.functions ?? this.functions ?? []),
      ...(agentFuncs ?? []),
    ]

    return { ai, functions, debug }
  }

  public async forward(
    parentAi: Readonly<AxAIService>,
    values: IN | AxMessage<IN>[],
    options?: Readonly<AxProgramForwardOptions>
  ): Promise<OUT> {
    const { ai, functions, debug } = this.init(parentAi, values, options)
    return await this.program.forward(ai, values, {
      ...options,
      debug,
      functions,
    })
  }

  public async *streamingForward(
    parentAi: Readonly<AxAIService>,
    values: IN | AxMessage<IN>[],
    options?: Readonly<AxProgramStreamingForwardOptions>
  ): AxGenStreamingOut<OUT> {
    const { ai, functions, debug } = this.init(parentAi, values, options)
    return yield* this.program.streamingForward(ai, values, {
      ...options,
      debug,
      functions,
    })
  }

  /**
   * Updates the agent's description.
   * This updates both the stored description and the function's description.
   *
   * @param description - New description for the agent (must be at least 20 characters)
   * @throws Error if description is too short
   */
  public setDescription(description: string): void {
    if (!description || description.length < 20) {
      throw descriptionError
    }

    this.program.getSignature().setDescription(description)
    this.func.description = description
  }

  public setDefinition(definition: string): void {
    if (!definition || definition.length < 100) {
      throw definitionError
    }

    this.program.getSignature().setDescription(definition)
  }

  private getDebug(
    ai: AxAIService,
    options?: Readonly<AxProgramForwardOptions>
  ): boolean {
    return options?.debug ?? this.debug ?? ai?.getOptions()?.debug ?? false
  }
}

function toCamelCase(inputString: string): string {
  // Split the string by any non-alphanumeric character (including underscores, spaces, hyphens)
  const words = inputString.split(/[^a-zA-Z0-9]/)

  // Map through each word, capitalize the first letter of each word except the first word
  const camelCaseString = words
    .map((word, index) => {
      // Lowercase the word to handle cases like uppercase letters in input
      const lowerWord = word.toLowerCase()

      // Capitalize the first letter of each word except the first one
      if (index > 0 && lowerWord && lowerWord[0]) {
        return lowerWord[0].toUpperCase() + lowerWord.slice(1)
      }

      return lowerWord
    })
    .join('')

  return camelCaseString
}

/**
 * Adds a required model parameter to a JSON Schema definition based on provided model mappings.
 * The model parameter will be an enum with values from the model map keys.
 *
 * @param parameters - The original JSON Schema parameters definition (optional)
 * @param models - Array of model mappings containing keys, model names and descriptions
 * @returns Updated JSON Schema with added model parameter
 */
export function addModelParameter(
  parameters: AxFunctionJSONSchema | undefined,
  models: AxAIModelList
): AxFunctionJSONSchema {
  // If parameters is undefined, create a base schema
  const baseSchema: AxFunctionJSONSchema = parameters
    ? structuredClone(parameters)
    : {
        type: 'object',
        properties: {},
        required: [],
      }

  // Check if model parameter already exists
  if (baseSchema.properties?.model) {
    return baseSchema
  }

  // Create the model property schema
  const modelProperty: AxFunctionJSONSchema & {
    enum: string[]
    description: string
  } = {
    type: 'string',
    enum: models.map((m) => m.key),
    description: `The AI model to use for this function call. Available options: ${models
      .map((m) => `\`${m.key}\` ${m.description}`)
      .join(', ')}`,
  }

  // Create new properties object with model parameter
  const newProperties = {
    ...(baseSchema.properties ?? {}),
    model: modelProperty,
  }

  // Add model to required fields
  const newRequired = [...(baseSchema.required ?? []), 'model']

  // Return updated schema
  return {
    ...baseSchema,
    properties: newProperties,
    required: newRequired,
  }
}

// New helper: removePropertiesFromSchema
//    Clones a JSON schema and removes properties and required fields matching the provided keys.
function removePropertiesFromSchema(
  schema: Readonly<AxFunctionJSONSchema>,
  keys: string[]
): AxFunctionJSONSchema {
  const newSchema = structuredClone(schema)
  if (newSchema.properties) {
    for (const key of keys) {
      delete newSchema.properties[key]
    }
  }
  if (Array.isArray(newSchema.required)) {
    const filteredRequired = newSchema.required.filter(
      (r: string) => !keys.includes(r)
    )
    Object.defineProperty(newSchema, 'required', {
      value: filteredRequired,
      writable: true,
      configurable: true,
    })
  }
  return newSchema
}

// New helper: pick
//    Returns an object composed of the picked object properties.
function pick<T extends object, K extends keyof T>(
  obj: T,
  keys: K[]
): Pick<T, K> {
  const result = {} as Pick<T, K>
  for (const key of keys) {
    if (key in obj) {
      result[key] = obj[key]
    }
  }
  return result
}



================================================
FILE: src/ax/prompts/cot.ts
================================================
import { AxGen } from '../dsp/generate.js'
import type { AxProgramForwardOptions } from '../dsp/program.js'
import { AxSignature } from '../dsp/sig.js'
import type { AxGenIn, AxGenOut } from '../dsp/types.js'

export class AxChainOfThought<
  IN extends AxGenIn = AxGenIn,
  OUT extends AxGenOut = AxGenOut,
> extends AxGen<IN, OUT> {
  constructor(
    signature: Readonly<AxSignature | string>,
    options?: Readonly<
      AxProgramForwardOptions & { setVisibleReasoning?: boolean }
    >
  ) {
    const sig = new AxSignature(signature)
    const description = `Let's work this out in a step by step way in order to ensure we have the right answer.`

    sig.setOutputFields([
      {
        name: 'reason',
        description,
        isInternal: options?.setVisibleReasoning !== true,
      },
      ...sig.getOutputFields(),
    ])

    super(sig, options)
  }
}



================================================
FILE: src/ax/prompts/prompts.test.ts
================================================
import { describe, expect, it } from 'vitest'

import { AxAI } from '../ai/wrap.js'
import { AxSignature } from '../dsp/sig.js'

import { AxChainOfThought } from './cot.js'

const someText = `The technological singularity—or simply the singularity[1]—is a hypothetical future point in time at which technological growth becomes uncontrollable and irreversible.`

const examples = [
  {
    someText:
      'Mathematical platonism is a philosophical view that posits the existence of abstract mathematical objects that are independent of human thought and language. According to this view, mathematical entities such as numbers, shapes, and functions exist in a non-physical realm and can be discovered but not invented.',
    reason: 'Blah blah blah 1',
    shortSummary:
      'A philosophy that suggests mathematical objects exist independently of human thought in a non-physical realm.',
  },
  {
    someText:
      'Quantum entanglement is a physical phenomenon occurring when pairs or groups of particles are generated, interact, or share spatial proximity in ways such that the quantum state of each particle cannot be described independently of the state of the others, even when the particles are separated by large distances. This leads to correlations between observable physical properties of the particles.',
    reason: 'Blah blah blah 2',
    shortSummary:
      'A phenomenon where particles remain interconnected and the state of one affects the state of another, regardless of distance.',
  },
]

const mockFetch = async (_urlObj: unknown, req: unknown): Promise<Response> => {
  const mockRes = {
    choices: [
      {
        message: {
          role: 'assistant',
          content: 'Reason: Blah blah blah\nShort Summary: More blah blah blah',
        },
      },
    ],
  }

  const body = JSON.parse((req as { body: string }).body)

  if (body.stream !== undefined && body.stream !== true) {
    throw new Error('stream must be false or undefined')
  }

  return new Promise((resolve) => {
    resolve({
      ok: true,
      status: 200,
      json: async () => new Promise((resolve) => resolve(mockRes)),
    } as unknown as Response)
  })
}

describe('AxChainOfThought', () => {
  it('should generate prompt correctly', async () => {
    const ai = new AxAI({
      name: 'openai',
      apiKey: 'no-key',
      options: { fetch: mockFetch },
      config: { stream: false },
    })

    // const ai = new AxAI({ name: 'ollama', config: { model: 'nous-hermes2' } });

    const gen = new AxChainOfThought<{ someText: string }>(
      `someText -> shortSummary "summarize in 5 to 10 words"`,
      { setVisibleReasoning: true }
    )
    gen.setExamples(examples)

    const res = await gen.forward(ai, { someText })

    expect(res).toEqual({
      reason: 'Blah blah blah',
      shortSummary: 'More blah blah blah',
    })
  })
})

describe('AxSignature', () => {
  it('should throw error for invalid signature', () => {
    expect(() => new AxSignature(`someText -> output:image`)).toThrow()
  })
})



================================================
FILE: src/ax/prompts/rag.ts
================================================
import { type AxProgramForwardOptions } from '../dsp/program.js'
import { AxStringUtil } from '../dsp/strutil.js'
import type { AxMessage } from '../dsp/types.js'
import { type AxAIService, AxGen, AxSignature } from '../index.js'

import { AxChainOfThought } from './cot.js'

export class AxRAG extends AxChainOfThought<
  { context: string[]; question: string },
  { answer: string }
> {
  private genQuery: AxGen<
    { context: string[]; question: string },
    { query: string }
  >
  private queryFn: (query: string) => Promise<string>
  private maxHops: number

  constructor(
    queryFn: (query: string) => Promise<string>,
    options: Readonly<AxProgramForwardOptions & { maxHops?: number }>
  ) {
    const sig =
      '"Answer questions with short factoid answers." context:string[] "may contain relevant facts", question -> answer'
    super(sig, options)

    this.maxHops = options?.maxHops ?? 3

    const qsig = new AxSignature(
      '"Write a simple search query that will help answer a complex question." context?:string[] "may contain relevant facts", question -> query "question to further our understanding"'
    )
    this.genQuery = new AxGen<
      { context: string[]; question: string },
      { query: string }
    >(qsig)
    this.queryFn = queryFn
    // Note: genQuery is not registered as it has a different output signature than the parent
  }

  public override async forward(
    ai: Readonly<AxAIService>,
    values:
      | { context: string[]; question: string }
      | AxMessage<{ context: string[]; question: string }>[],
    options?: Readonly<AxProgramForwardOptions>
  ): Promise<{ answer: string }> {
    // Extract question from values - handle both cases
    let question: string
    if (Array.isArray(values)) {
      // If values is an array of messages, find the most recent user message
      const lastUserMessage = values.filter((msg) => msg.role === 'user').pop()
      if (!lastUserMessage) {
        throw new Error('No user message found in values array')
      }
      question = lastUserMessage.values.question
    } else {
      // If values is a single object
      question = values.question
    }

    let hop = 0
    let context: string[] = []

    while (hop < this.maxHops) {
      const query = await this.genQuery.forward(ai, { context, question })
      const queryResult = await this.queryFn(query.query)
      context = AxStringUtil.dedup([...context, queryResult])

      hop++
    }

    const res = await super.forward(ai, { context, question }, options)
    return res
  }
}



================================================
FILE: src/ax/trace/trace.ts
================================================
export const axSpanAttributes = {
  // LLM
  LLM_SYSTEM: 'gen_ai.system',
  LLM_OPERATION_NAME: 'gen_ai.operation.name',
  LLM_REQUEST_MODEL: 'gen_ai.request.model',
  LLM_REQUEST_MAX_TOKENS: 'gen_ai.request.max_tokens',
  LLM_REQUEST_TEMPERATURE: 'gen_ai.request.temperature',
  LLM_REQUEST_TOP_K: 'gen_ai.request.top_k',
  LLM_REQUEST_FREQUENCY_PENALTY: 'gen_ai.request.frequency_penalty',
  LLM_REQUEST_PRESENCE_PENALTY: 'gen_ai.request.presence_penalty',
  LLM_REQUEST_STOP_SEQUENCES: 'gen_ai.request.stop_sequences',
  LLM_REQUEST_LLM_IS_STREAMING: 'gen_ai.request.llm_is_streaming',
  LLM_REQUEST_TOP_P: 'gen_ai.request.top_p',

  LLM_USAGE_INPUT_TOKENS: 'gen_ai.usage.input_tokens',
  LLM_USAGE_OUTPUT_TOKENS: 'gen_ai.usage.output_tokens',
  LLM_USAGE_TOTAL_TOKENS: 'gen_ai.usage.total_tokens',
  LLM_USAGE_THOUGHTS_TOKENS: 'gen_ai.usage.thoughts_tokens',

  // Vector DB
  DB_SYSTEM: 'db.system',
  DB_TABLE: 'db.table',
  DB_NAMESPACE: 'db.namespace',
  DB_ID: 'db.id',
  DB_QUERY_TEXT: 'db.query.text',
  DB_VECTOR: 'db.vector',
  DB_OPERATION_NAME: 'db.operation.name',
  DB_VECTOR_QUERY_TOP_K: 'db.vector.query.top_k',

  DB_QUERY_EMBEDDINGS: 'db.query.embeddings',
  DB_QUERY_RESULT: 'db.query.result',

  // Query Embeddings
  DB_QUERY_EMBEDDINGS_VECTOR: 'db.query.embeddings.vector',

  // Query Result (canonical format)
  DB_QUERY_RESULT_ID: 'db.query.result.id',
  DB_QUERY_RESULT_SCORE: 'db.query.result.score',
  DB_QUERY_RESULT_DISTANCE: 'db.query.result.distance',
  DB_QUERY_RESULT_METADATA: 'db.query.result.metadata',
  DB_QUERY_RESULT_VECTOR: 'db.query.result.vector',
  DB_QUERY_RESULT_DOCUMENT: 'db.query.result.document',
}

export const axSpanEvents = {
  GEN_AI_USER_MESSAGE: 'gen_ai.user.message',
  GEN_AI_SYSTEM_MESSAGE: 'gen_ai.system.message',
  GEN_AI_ASSISTANT_MESSAGE: 'gen_ai.assistant.message',
  GEN_AI_TOOL_MESSAGE: 'gen_ai.tool.message', // For tool messages in request & response tool calls
  GEN_AI_CHOICE: 'gen_ai.choice',
  GEN_AI_USAGE: 'gen_ai.usage',
}

export enum AxLLMRequestTypeValues {
  COMPLETION = 'completion',
  CHAT = 'chat',
  RERANK = 'rerank',
  UNKNOWN = 'unknown',
}

export enum AxSpanKindValues {
  WORKFLOW = 'workflow',
  TASK = 'task',
  AGENT = 'agent',
  TOOL = 'tool',
  UNKNOWN = 'unknown',
}



================================================
FILE: src/ax/util/apicall.ts
================================================
import crypto from 'crypto'
import {
  ReadableStream,
  TextDecoderStream as TextDecoderStreamNative,
  TransformStream,
} from 'stream/web'

import { type Span } from '@opentelemetry/api'

import { SSEParser } from './sse.js'
import { TextDecoderStreamPolyfill } from './stream.js'

// Configuration Types
export interface RetryConfig {
  maxRetries: number
  initialDelayMs: number
  maxDelayMs: number
  backoffFactor: number
  retryableStatusCodes: number[]
}

export interface RequestMetrics {
  startTime: number
  retryCount: number
  lastRetryTime?: number
  streamChunks?: number
  lastChunkTime?: number
  streamDuration?: number
  errorTime?: number
}

// Validation Interfaces
interface RequestValidation {
  validateRequest?: (request: unknown) => boolean | Promise<boolean>
}

interface ResponseValidation {
  validateResponse?: (response: unknown) => boolean | Promise<boolean>
}

// API Base Types
export interface AxAPI {
  name?: string
  headers?: Record<string, string>
  put?: boolean
}

// Enhanced API Configuration
export interface AxAPIConfig
  extends AxAPI,
    RequestValidation,
    ResponseValidation {
  url: string | URL
  stream?: boolean
  debug?: boolean
  fetch?: typeof fetch
  span?: Span
  timeout?: number
  retry?: Partial<RetryConfig>
  abortSignal?: AbortSignal
}

// Default Configurations
export const defaultRetryConfig: RetryConfig = {
  maxRetries: 3,
  initialDelayMs: 1000,
  maxDelayMs: 60000,
  backoffFactor: 2,
  retryableStatusCodes: [500, 408, 429, 502, 503, 504],
}

const defaultTimeoutMs = 30000
const textDecoderStream = TextDecoderStreamNative ?? TextDecoderStreamPolyfill

// Error Classes
export class AxAIServiceError extends Error {
  public readonly timestamp: string
  public readonly errorId: string
  public readonly context: Record<string, unknown>

  constructor(
    message: string,
    public readonly url: string,
    public readonly requestBody: unknown,
    public readonly responseBody: unknown,
    context: Record<string, unknown> = {}
  ) {
    super(message)
    this.name = this.constructor.name
    this.timestamp = new Date().toISOString()
    this.errorId = crypto.randomUUID()
    this.context = context

    this.stack = this.toString()
  }

  override toString(): string {
    return [
      `${this.name}: ${this.message}`,
      `URL: ${this.url}`,
      `Request Body: ${JSON.stringify(this.requestBody, null, 2)}`,
      `Response Body: ${JSON.stringify(this.responseBody, null, 2)}`,
      `Context: ${JSON.stringify(this.context, null, 2)}`,
      `Timestamp: ${this.timestamp}`,
      `Error ID: ${this.errorId}`,
    ].join('\n')
  }

  // For Node.js, override the custom inspect method so console.log shows our custom string.
  [Symbol.for('nodejs.util.inspect.custom')](
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _depth: number,
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    _options: Record<string, unknown>
  ) {
    return this.toString()
  }
}

export class AxAIServiceStatusError extends AxAIServiceError {
  constructor(
    public readonly status: number,
    public readonly statusText: string,
    url: string,
    requestBody: unknown,
    responseBody: unknown,
    context?: Record<string, unknown>
  ) {
    super(`HTTP ${status} - ${statusText}`, url, requestBody, {
      httpStatus: status,
      httpStatusText: statusText,
      responseBody,
      ...context,
    })
    this.name = this.constructor.name
  }
}

export class AxAIServiceNetworkError extends AxAIServiceError {
  constructor(
    public readonly originalError: Error,
    url: string,
    requestBody: unknown,
    responseBody: unknown,
    context?: Record<string, unknown>
  ) {
    super(
      `Network Error: ${originalError.message}`,
      url,
      requestBody,
      responseBody,
      {
        originalErrorName: originalError.name,
        originalErrorStack: originalError.stack,
        ...context,
      }
    )
    this.name = this.constructor.name
    this.stack = originalError.stack
  }
}

export class AxAIServiceResponseError extends AxAIServiceError {
  constructor(
    message: string,
    url: string,
    requestBody?: unknown,
    context?: Record<string, unknown>
  ) {
    super(message, url, requestBody, undefined, context)
    this.name = this.constructor.name
  }
}

export class AxAIServiceStreamTerminatedError extends AxAIServiceError {
  constructor(
    url: string,
    requestBody?: unknown,
    public readonly lastChunk?: unknown,
    context?: Record<string, unknown>
  ) {
    super(
      'Stream terminated unexpectedly by remote host',
      url,
      requestBody,
      undefined,
      {
        lastChunk,
        ...context,
      }
    )
    this.name = this.constructor.name
  }
}

export class AxAIServiceTimeoutError extends AxAIServiceError {
  constructor(
    url: string,
    timeoutMs: number,
    requestBody?: unknown,
    context?: Record<string, unknown>
  ) {
    super(
      `Request timed out after ${timeoutMs}ms`,
      url,
      requestBody,
      undefined,
      { timeoutMs, ...context }
    )
    this.name = this.constructor.name
  }
}

export class AxAIServiceAbortedError extends AxAIServiceError {
  constructor(
    url: string,
    reason?: string,
    requestBody?: unknown,
    context?: Record<string, unknown>
  ) {
    super(
      `Request aborted${reason ? `: ${reason}` : ''}`,
      url,
      requestBody,
      undefined,
      { abortReason: reason, ...context }
    )
    this.name = this.constructor.name
  }
}

export class AxAIServiceAuthenticationError extends AxAIServiceError {
  constructor(
    url: string,
    requestBody: unknown,
    responseBody: unknown,
    context?: Record<string, unknown>
  ) {
    super('Authentication failed', url, requestBody, responseBody, context)
    this.name = this.constructor.name
  }
}

// Utility Functions
function calculateRetryDelay(
  attempt: number,
  config: Readonly<RetryConfig>
): number {
  const delay = Math.min(
    config.maxDelayMs,
    config.initialDelayMs * Math.pow(config.backoffFactor, attempt)
  )
  return delay * (0.75 + Math.random() * 0.5)
}

function createRequestMetrics(): RequestMetrics {
  return {
    startTime: Date.now(),
    retryCount: 0,
  }
}

// eslint-disable-next-line functional/prefer-immutable-types
function updateRetryMetrics(metrics: RequestMetrics): void {
  metrics.retryCount++
  metrics.lastRetryTime = Date.now()
}

function shouldRetry(
  error: Error,
  status: number | undefined,
  attempt: number,
  config: Readonly<RetryConfig>
): boolean {
  if (attempt >= config.maxRetries) return false
  if (status && config.retryableStatusCodes.includes(status)) return true

  return (
    error instanceof AxAIServiceNetworkError &&
    !(error instanceof AxAIServiceAuthenticationError)
  )
}

// Enhanced API Call Function
export const apiCall = async <TRequest = unknown, TResponse = unknown>(
  api: Readonly<AxAPIConfig>,
  json: TRequest
): Promise<TResponse | ReadableStream<TResponse>> => {
  const retryConfig: RetryConfig = { ...defaultRetryConfig, ...api.retry }
  const timeoutMs = api.timeout ?? defaultTimeoutMs
  const metrics = createRequestMetrics()
  let timeoutId: NodeJS.Timeout

  const baseUrl = new URL(process.env['PROXY'] ?? api.url)
  const apiPath = `${[baseUrl.pathname, api.name]
    .filter(Boolean)
    .join('/')
    .replace(/\/+/g, '/')}${baseUrl.search}`
  const apiUrl = new URL(apiPath, baseUrl)

  const requestId = crypto.randomUUID()

  // Validate request if validator is provided
  if (api.validateRequest) {
    const isValid = await api.validateRequest(json)
    if (!isValid) {
      throw new AxAIServiceResponseError(
        'Invalid request data',
        apiUrl.href,
        json,
        { validation: 'request' }
      )
    }
  }

  // Set up telemetry
  api.span?.setAttributes({
    'http.request.method': api.put ? 'PUT' : 'POST',
    'url.full': apiUrl.href,
    'request.id': requestId,
    'request.startTime': metrics.startTime,
  })

  let attempt = 0

  while (true) {
    // Combine user abort signal with timeout signal
    const combinedAbortController = new AbortController()

    // Handle user abort signal
    if (api.abortSignal) {
      if (api.abortSignal.aborted) {
        throw new AxAIServiceAbortedError(
          apiUrl.href,
          api.abortSignal.reason,
          json,
          { metrics }
        )
      }

      const userAbortHandler = () => {
        combinedAbortController.abort(
          api.abortSignal!.reason || 'User aborted request'
        )
      }
      api.abortSignal.addEventListener('abort', userAbortHandler, {
        once: true,
      })

      // Clean up listener if we complete before abort
      const originalAbort = combinedAbortController.abort.bind(
        combinedAbortController
      )
      combinedAbortController.abort = (reason?: string) => {
        api.abortSignal!.removeEventListener('abort', userAbortHandler)
        originalAbort(reason)
      }
    }

    timeoutId = setTimeout(() => {
      combinedAbortController.abort('Request timeout')
    }, timeoutMs)

    try {
      // Set up timeout with proper cleanup

      const res = await (api.fetch ?? fetch)(apiUrl, {
        method: api.put ? 'PUT' : 'POST',
        headers: {
          'Content-Type': 'application/json',
          'X-Request-ID': requestId,
          'X-Retry-Count': attempt.toString(),
          ...api.headers,
        },
        body: JSON.stringify(json),
        signal: combinedAbortController.signal,
      })

      clearTimeout(timeoutId)

      // Handle authentication errors
      if (res.status === 401 || res.status === 403) {
        throw new AxAIServiceAuthenticationError(apiUrl.href, json, res.body, {
          metrics,
        })
      }

      // Handle retryable status codes
      if (
        res.status >= 400 &&
        shouldRetry(new Error(), res.status, attempt, retryConfig)
      ) {
        const delay = calculateRetryDelay(attempt, retryConfig)
        attempt++
        updateRetryMetrics(metrics)

        api.span?.addEvent('retry', {
          attempt,
          delay,
          status: res.status,
          'metrics.startTime': metrics.startTime,
          'metrics.retryCount': metrics.retryCount,
          'metrics.lastRetryTime': metrics.lastRetryTime,
        })

        await new Promise((resolve) => setTimeout(resolve, delay))
        continue
      }

      if (res.status >= 400) {
        throw new AxAIServiceStatusError(
          res.status,
          res.statusText,
          apiUrl.href,
          json,
          res.body,
          { metrics }
        )
      }

      // Handle non-streaming response
      if (!api.stream) {
        const resJson = await res.json()

        // Validate response if validator is provided
        if (api.validateResponse) {
          const isValid = await api.validateResponse(resJson)
          if (!isValid) {
            throw new AxAIServiceResponseError(
              'Invalid response data',
              apiUrl.href,
              json,
              { validation: 'response' }
            )
          }
        }

        api.span?.setAttributes({
          'response.time': Date.now() - metrics.startTime,
          'response.retries': metrics.retryCount,
        })

        return resJson as TResponse
      }

      // Handle streaming response
      if (!res.body) {
        throw new AxAIServiceResponseError(
          'Response body is null',
          apiUrl.href,
          json,
          { metrics }
        )
      }

      let lastChunk: TResponse | undefined
      let chunkCount = 0

      // Enhanced tracking stream
      const trackingStream = new TransformStream<TResponse, TResponse>({
        transform(chunk, controller) {
          lastChunk = chunk
          chunkCount++
          metrics.streamChunks = chunkCount
          metrics.lastChunkTime = Date.now()
          controller.enqueue(chunk)

          api.span?.addEvent('stream.chunk', {
            'stream.chunks': chunkCount,
            'stream.duration': Date.now() - metrics.startTime,
            'response.retries': metrics.retryCount,
          })
        },
      })

      // Flag to track if the controller is closed.
      let closed = false

      // Enhanced wrapped stream
      return new ReadableStream<TResponse>({
        start(controller) {
          const reader = res
            .body!.pipeThrough(new textDecoderStream())
            .pipeThrough(new SSEParser<TResponse>())
            .pipeThrough(trackingStream)
            .getReader()

          async function read() {
            try {
              while (true) {
                const { done, value } = await reader.read()
                if (done) {
                  if (!closed) {
                    closed = true
                    controller.close()
                  }
                  break
                }

                // Check if the controller is already closed before enqueuing.
                if (closed) break
                controller.enqueue(value)
              }
            } catch (e) {
              const error = e as Error
              const streamMetrics = {
                ...metrics,
                streamDuration: Date.now() - metrics.startTime,
              }

              if (
                error.name === 'AbortError' ||
                error.message?.includes('aborted')
              ) {
                controller.error(
                  new AxAIServiceStreamTerminatedError(
                    apiUrl.href,
                    json,
                    lastChunk,
                    { streamMetrics }
                  )
                )
              } else if (
                error instanceof TypeError &&
                error.message.includes('cancelled')
              ) {
                controller.error(
                  new AxAIServiceStreamTerminatedError(
                    apiUrl.href,
                    json,
                    lastChunk,
                    {
                      streamMetrics,
                      cancelReason: 'Stream cancelled by client',
                    }
                  )
                )
              } else {
                controller.error(
                  new AxAIServiceNetworkError(
                    error,
                    apiUrl.href,
                    json,
                    res.body,
                    {
                      streamMetrics,
                    }
                  )
                )
              }
              throw error
            } finally {
              clearTimeout(timeoutId)
              reader.releaseLock()
            }
          }

          read()
        },
        // When the consumer cancels the stream, set our flag to stop processing further.
        cancel() {
          closed = true
        },
      })
    } catch (error) {
      if (error instanceof Error && error.name === 'AbortError') {
        // Check if this was a user abort or timeout
        if (api.abortSignal?.aborted) {
          throw new AxAIServiceAbortedError(
            apiUrl.href,
            api.abortSignal.reason,
            json,
            { metrics }
          )
        } else {
          throw new AxAIServiceTimeoutError(apiUrl.href, timeoutMs, json, {
            metrics,
          })
        }
      }

      if (api.span?.isRecording()) {
        api.span.recordException(error as Error)
        api.span.setAttributes({
          'error.time': Date.now() - metrics.startTime,
          'error.retries': metrics.retryCount,
        })
      }

      // Handle retryable network errors
      if (
        error instanceof AxAIServiceNetworkError &&
        shouldRetry(error, undefined, attempt, retryConfig)
      ) {
        const delay = calculateRetryDelay(attempt, retryConfig)
        attempt++
        updateRetryMetrics(metrics)

        api.span?.addEvent('retry', {
          attempt,
          delay,
          error: error.message,
          'metrics.startTime': metrics.startTime,
          'metrics.retryCount': metrics.retryCount,
          'metrics.lastRetryTime': metrics.lastRetryTime,
        })

        await new Promise((resolve) => setTimeout(resolve, delay))
        continue
      }

      if (error instanceof AxAIServiceError) {
        error.context['metrics'] = metrics
      }

      throw error
    } finally {
      if (timeoutId !== undefined) {
        clearTimeout(timeoutId)
      }
    }
  }
}

export function createApiConfig(
  config: Readonly<Partial<AxAPIConfig>>
): AxAPIConfig {
  return {
    timeout: defaultTimeoutMs,
    retry: defaultRetryConfig,
    ...config,
    url: config.url!, // URL is required
  }
}



================================================
FILE: src/ax/util/log.ts
================================================
export class ColorLog {
  // ANSI escape codes for different colors
  private readonly ANSI_WHITE_BRIGHT = '\x1b[97m'
  private readonly ANSI_GREEN_BRIGHT = '\x1b[92m'
  private readonly ANSI_BLUE_BRIGHT = '\x1b[94m'
  private readonly ANSI_YELLOW = '\x1b[93m'
  private readonly ANSI_RED = '\x1b[91m'
  private readonly ANSI_RESET = '\x1b[0m'

  // Method to wrap text with the specified ANSI color code
  private colorize(text: string, colorCode: string): string {
    return `${colorCode}${text}${this.ANSI_RESET}`
  }

  // Public methods to colorize text in various colors
  public whiteBright(text: string): string {
    return this.colorize(text, this.ANSI_WHITE_BRIGHT)
  }

  public greenBright(text: string): string {
    return this.colorize(text, this.ANSI_GREEN_BRIGHT)
  }

  public blueBright(text: string): string {
    return this.colorize(text, this.ANSI_BLUE_BRIGHT)
  }

  public yellow(text: string): string {
    return this.colorize(text, this.ANSI_YELLOW)
  }

  public red(text: string): string {
    return this.colorize(text, this.ANSI_RED)
  }
}



================================================
FILE: src/ax/util/other.ts
================================================
export async function sleep(ms: number) {
  return new Promise((resolve) => setTimeout(resolve, ms))
}



================================================
FILE: src/ax/util/rate-limit.ts
================================================
import { ColorLog } from './log.js'

const colorLog = new ColorLog()

export interface AxRateLimiterTokenUsageOptions {
  debug?: boolean
}

export class AxRateLimiterTokenUsage {
  private options?: Readonly<AxRateLimiterTokenUsageOptions>
  private maxTokens: number
  private refillRate: number
  private currentTokens: number
  private lastRefillTime: number

  constructor(
    maxTokens: number,
    refillRate: number,
    options?: Readonly<AxRateLimiterTokenUsageOptions>
  ) {
    this.maxTokens = maxTokens
    this.refillRate = refillRate
    this.currentTokens = maxTokens
    this.lastRefillTime = Date.now()
    this.options = options
  }

  private refillTokens() {
    const now = Date.now()
    const timeElapsed = (now - this.lastRefillTime) / 1000 // Convert ms to seconds
    const tokensToAdd = timeElapsed * this.refillRate
    this.currentTokens = Math.min(
      this.maxTokens,
      this.currentTokens + tokensToAdd
    )
    this.lastRefillTime = now
  }

  private async waitUntilTokensAvailable(tokens: number): Promise<void> {
    this.refillTokens()
    if (this.currentTokens >= tokens) {
      this.currentTokens -= tokens
      return
    }
    if (this.options?.debug) {
      console.log(
        colorLog.red(
          `Rate limiter: Waiting for ${tokens - this.currentTokens} tokens`
        )
      )
    }
    await new Promise((resolve) => setTimeout(resolve, 100)) // Wait for 100ms before checking again
    return this.waitUntilTokensAvailable(tokens) // Recursive call
  }

  public async acquire(tokens: number): Promise<void> {
    await this.waitUntilTokensAvailable(tokens)
  }
}

/**
 * Example usage of the rate limiter. Limits to 5800 tokens per minute.
const rateLimiter = new AxRateLimiterTokenUsage(5800, 5800 / 60);

const axRateLimiterFunction = async (func, info) => {
  const totalTokens = info.modelUsage?.totalTokens || 0;
  await rateLimiter.acquire(totalTokens);
  return func();
};
**/



================================================
FILE: src/ax/util/sse.ts
================================================
import { TransformStream, TransformStreamDefaultController } from 'stream/web'

interface CurrentEventState {
  event?: string
  rawData: string
  id?: string
  retry?: number
}

interface SSEParserOptions<T> {
  dataParser?: (data: string) => T
  onError?: (error: Error, rawData: string) => void
}

export class SSEParser<T = unknown> extends TransformStream<string, T> {
  private buffer: string = ''
  private currentEvent: CurrentEventState = { rawData: '' }
  private dataParser: (data: string) => T
  private onError: (error: Error, rawData: string) => void

  constructor(options: SSEParserOptions<T> = {}) {
    super({
      transform: (chunk, controller) => this.handleChunk(chunk, controller),
      flush: (controller) => this.handleFlush(controller),
    })

    this.dataParser = options.dataParser || JSON.parse
    this.onError =
      options.onError ||
      ((error, rawData) => {
        console.warn('Failed to parse event data:', error)
        console.log('Raw data that failed to parse:', rawData)
      })
  }

  private handleChunk(
    chunk: string,
    controller: TransformStreamDefaultController<T>
  ): void {
    this.buffer += chunk
    this.processBuffer(controller)
  }

  private handleFlush(controller: TransformStreamDefaultController<T>): void {
    this.processBuffer(controller)
    if (this.currentEvent.rawData) {
      this.processEvent(controller)
    }
  }

  private processBuffer(controller: TransformStreamDefaultController<T>): void {
    // Normalize newlines to \n
    const normalizedBuffer = this.buffer.replace(/\r\n|\r/g, '\n')
    const lines = normalizedBuffer.split('\n')
    this.buffer = lines.pop() || ''

    for (const line of lines) {
      if (line === '') {
        this.processEvent(controller)
      } else {
        this.parseLine(line)
      }
    }
  }

  private parseLine(line: string): void {
    if (line.startsWith(':')) {
      return // Ignore comment lines
    }

    const colonIndex = line.indexOf(':')
    if (colonIndex === -1) {
      this.currentEvent.rawData +=
        (this.currentEvent.rawData && !this.currentEvent.rawData.endsWith('\n')
          ? '\n'
          : '') + line.trim()
      return
    }

    const field = line.slice(0, colonIndex).trim()
    const value = line.slice(colonIndex + 1).trim()

    switch (field) {
      case 'event':
        this.currentEvent.event = value
        break
      case 'data':
        this.currentEvent.rawData +=
          (this.currentEvent.rawData &&
          !this.currentEvent.rawData.endsWith('\n')
            ? '\n'
            : '') + value
        break
      case 'id':
        this.currentEvent.id = value
        break
      case 'retry': {
        const retryValue = parseInt(value, 10)
        if (!isNaN(retryValue)) {
          this.currentEvent.retry = retryValue
        }
        break
      }
    }
  }

  private processEvent(controller: TransformStreamDefaultController<T>): void {
    if (this.currentEvent.rawData) {
      if (!this.currentEvent.event) {
        this.currentEvent.event = 'message'
      }

      if (this.currentEvent.rawData.trim() === '[DONE]') {
        // maybe we want to emit [DONE] to signal the end of the stream
        // controller.enqueue('[DONE]' as any)
        // Reset the current event
        this.currentEvent = { rawData: '' }
        return
      }

      try {
        const parsedData: T = this.dataParser(this.currentEvent.rawData)
        controller.enqueue(parsedData)
      } catch (e) {
        this.onError(e as Error, this.currentEvent.rawData)
      }

      this.currentEvent = { rawData: '' }
    }
  }
}



================================================
FILE: src/ax/util/stream.ts
================================================
import {
  type Transformer,
  TransformStream,
  type TransformStreamDefaultController,
} from 'stream/web'

export interface TextDecoderCommon {
  readonly encoding: string
  readonly fatal: boolean
  readonly ignoreBOM: boolean
}

class TextDecodeTransformer
  implements Transformer<ArrayBuffer | Uint8Array, string>
{
  private decoder

  constructor() {
    this.decoder = new TextDecoder()
  }

  transform(
    chunk: ArrayBuffer | Uint8Array,
    controller: TransformStreamDefaultController<string>
  ) {
    if (!(chunk instanceof ArrayBuffer || ArrayBuffer.isView(chunk))) {
      throw new TypeError('Input data must be a BufferSource')
    }
    const text = this.decoder.decode(chunk, { stream: true })
    if (text.length !== 0) {
      controller.enqueue(text)
    }
  }

  flush(controller: TransformStreamDefaultController<string>) {
    const text = this.decoder.decode()
    if (text.length !== 0) {
      controller.enqueue(text)
    }
  }
}

export class TextDecoderStreamPolyfill extends TransformStream<
  ArrayBuffer | Uint8Array,
  string
> {
  constructor() {
    super(new TextDecodeTransformer())
  }
}



================================================
FILE: src/ax/util/transform.ts
================================================
import {
  type Transformer,
  TransformStream,
  type TransformStreamDefaultController,
} from 'stream/web'

class TypeTransformer<I, O> implements Transformer<I, O> {
  private buffer?: O[]
  private doneCallback?: (args0: readonly O[]) => Promise<void>
  private transformFn: (arg0: I) => O

  constructor(
    transformFn: (arg0: I) => O,
    doneCallback?: (args0: readonly O[]) => Promise<void>
  ) {
    this.transformFn = transformFn
    this.doneCallback = doneCallback
    this.buffer = doneCallback ? [] : undefined
  }

  async transform(obj: I, controller: TransformStreamDefaultController<O>) {
    const val = this.transformFn(obj)
    if (val) {
      controller.enqueue(val)
      this.buffer?.push(val)
    }
  }

  async flush(controller: TransformStreamDefaultController<O>) {
    await this.doneCallback?.(this.buffer ?? [])
    controller.terminate()
  }
}

export class RespTransformStream<I, O> extends TransformStream<I, O> {
  constructor(
    transformFn: (arg0: I) => O,
    doneCallback?: (args0: readonly O[]) => Promise<void>
  ) {
    super(new TypeTransformer<I, O>(transformFn, doneCallback))
  }
}



================================================
FILE: src/docs/abort-requests.md
================================================
# Aborting Requests

The Ax framework supports aborting ongoing LLM requests using the standard Web API `AbortController` and `AbortSignal`. This allows users to cancel requests that are taking too long or are no longer needed.

## Basic Usage

### Using AbortSignal

```typescript
import { AxAI } from '@ax-llm/ax'

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!
})

const abortController = new AbortController()

// Start a request with abort support
const requestPromise = ai.chat(
  {
    chatPrompt: [
      { role: 'user', content: 'Tell me a very long story.' }
    ]
  },
  {
    abortSignal: abortController.signal
  }
)

// Abort the request after 5 seconds
setTimeout(() => {
  abortController.abort('Request took too long')
}, 5000)

try {
  const response = await requestPromise
  console.log('Response:', response)
} catch (error) {
  if (error instanceof AxAIServiceAbortedError) {
    console.log('Request was aborted:', error.message)
  }
}
```

## Common Patterns

### Timeout-Based Abortion

```typescript
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!
})

const abortController = new AbortController()

// Create a timeout that automatically aborts
const timeoutMs = 10000
const timeoutId = setTimeout(() => {
  console.log(`Aborting after ${timeoutMs}ms timeout...`)
  abortController.abort(`Request timeout after ${timeoutMs}ms`)
}, timeoutMs)

const requestPromise = ai.chat({
  chatPrompt: [
    { role: 'user', content: 'Explain quantum computing in detail.' }
  ]
}, {
  abortSignal: abortController.signal
})

try {
  const response = await requestPromise
  clearTimeout(timeoutId) // Clear timeout if request completes
  console.log('Response:', response)
} catch (error) {
  clearTimeout(timeoutId) // Clean up timeout
  if (error instanceof AxAIServiceAbortedError) {
    console.log('Request was aborted:', error.message)
  }
}
```

### Multiple Requests with Shared AbortController

```typescript
const abortController = new AbortController()

// Start multiple requests that share the same abort controller
const requests = [
  ai.chat({
    chatPrompt: [{ role: 'user', content: 'What is machine learning?' }]
  }, { abortSignal: abortController.signal }),
  
  ai.chat({
    chatPrompt: [{ role: 'user', content: 'What is deep learning?' }]
  }, { abortSignal: abortController.signal }),
  
  ai.embed({
    texts: ['Machine learning', 'Deep learning']
  }, { abortSignal: abortController.signal })
]

// Abort all requests after 5 seconds
setTimeout(() => {
  console.log('Aborting all requests...')
  abortController.abort('Batch abort after timeout')
}, 5000)

// Handle all requests
const results = await Promise.allSettled(requests)

results.forEach((result, index) => {
  if (result.status === 'fulfilled') {
    console.log(`✅ Request ${index + 1} completed`)
  } else {
    console.log(`❌ Request ${index + 1} failed:`, result.reason.message)
  }
})
```

### Streaming Requests

Abort works with both regular and streaming requests:

```typescript
const abortController = new AbortController()

try {
  const stream = await ai.chat(
    {
      chatPrompt: [{ role: 'user', content: 'Stream a story.' }]
    },
    { 
      stream: true,
      abortSignal: abortController.signal
    }
  )

  // Abort after 5 seconds
  const timeoutId = setTimeout(() => {
    abortController.abort('Streaming timeout')
  }, 5000)

  if (stream instanceof ReadableStream) {
    const reader = stream.getReader()
    
    try {
      while (true) {
        const { done, value } = await reader.read()
        if (done) break
        
        console.log('Chunk:', value.results[0]?.content)
      }
      clearTimeout(timeoutId) // Clear timeout if stream completes
    } catch (streamError) {
      console.log('Stream was aborted')
    } finally {
      clearTimeout(timeoutId) // Always clean up timeout
      reader.releaseLock()
    }
  }
} catch (error) {
  console.log('Request failed to start')
}
```

### Custom Abort Event Handlers

```typescript
const abortController = new AbortController()

// Listen for abort events
abortController.signal.addEventListener('abort', () => {
  console.log('Request aborted:', abortController.signal.reason)
  // Clean up resources, update UI, etc.
})

const requestPromise = ai.chat({
  chatPrompt: [{ role: 'user', content: 'Hello' }]
}, {
  abortSignal: abortController.signal
})

// Abort with custom reason
setTimeout(() => {
  abortController.abort('User cancelled')
}, 3000)
```

## Error Handling

When a request is aborted, an `AxAIServiceAbortedError` is thrown:

```typescript
import { AxAIServiceAbortedError } from '@ax-llm/ax'

try {
  const response = await ai.chat({
    chatPrompt: [{ role: 'user', content: 'Hello' }]
  }, {
    abortSignal: abortController.signal
  })
} catch (error) {
  if (error instanceof AxAIServiceAbortedError) {
    console.log('Abort reason:', error.context.abortReason)
    console.log('Request URL:', error.url)
    console.log('Error ID:', error.errorId)
  }
}
```

## Integration with Forward Methods

Abort signals work with DSP forward and streaming forward methods:

```typescript
import { AxGen } from '@ax-llm/ax'

const gen = new AxGen('input -> output')
const abortController = new AbortController()

// Regular forward with abort
const response = await gen.forward(
  ai,
  { input: 'Hello' },
  {
    abortSignal: abortController.signal,
    sessionId: 'my-session',
    debug: true,
    maxRetries: 3,
  }
)

// Streaming forward with abort
const stream = gen.streamingForward(
  ai,
  { input: 'Hello' },
  {
    abortSignal: abortController.signal,
    maxSteps: 5,
  }
)

// Abort after 10 seconds
setTimeout(() => {
  abortController.abort('Forward took too long')
}, 10000)
```

## Integration with Existing Options

Abort signals work alongside all existing AI service options:

```typescript
const response = await ai.chat(
  {
    chatPrompt: [{ role: 'user', content: 'Hello' }]
  },
  {
    abortSignal: abortController.signal,
    sessionId: 'my-session',
    debug: true,
    stream: true,
    timeout: 30000, // This timeout works alongside abort
  }
)

// Embed requests also support abort
const embedResponse = await ai.embed(
  {
    texts: ['Text to embed']
  },
  {
    abortSignal: abortController.signal,
    sessionId: 'my-session',
  }
)
```

## Best Practices

1. **Always handle abort errors**: Check for `AxAIServiceAbortedError` in your error handling
2. **Clean up resources**: Use abort event listeners to clean up any associated resources
3. **Clear timeouts**: Always clear auto-abort timeouts to prevent memory leaks
4. **Use Promise.allSettled**: When handling multiple abortable requests
5. **Graceful degradation**: Provide fallbacks when requests are aborted
6. **Reuse AbortController**: For related requests that should be aborted together
7. **Create new AbortController**: For each independent operation

## Error Types

- `AxAIServiceAbortedError` - Thrown when a request is aborted
- Contains `url`, `requestBody`, `context.abortReason`, and other debugging info

## High-Level Component Support

### AxDBManager

Database operations support abort signals:

```typescript
import { AxDBManager } from '@ax-llm/ax'

const dbManager = new AxDBManager({ ai, db })
const abortController = new AbortController()

// Insert with abort support
await dbManager.insert(
  ['Text 1', 'Text 2'],
  { 
    batchSize: 5,
    abortSignal: abortController.signal 
  }
)

// Query with abort support
const results = await dbManager.query(
  'search query',
  { 
    topPercent: 0.1,
    abortSignal: abortController.signal 
  }
)
```

### AxSimpleClassifier

Classification operations support abort signals:

```typescript
import { AxSimpleClassifier, AxSimpleClassifierClass } from '@ax-llm/ax'

const classifier = new AxSimpleClassifier(ai)
const abortController = new AbortController()

// Set classes with abort support
await classifier.setClasses(
  [
    new AxSimpleClassifierClass('positive', ['good', 'great', 'excellent']),
    new AxSimpleClassifierClass('negative', ['bad', 'terrible', 'awful'])
  ],
  { abortSignal: abortController.signal }
)

// Classify with abort support
const result = await classifier.forward(
  'This is amazing!',
  { 
    cutoff: 0.8,
    abortSignal: abortController.signal 
  }
)
```

## Utility Patterns

### Racing a Promise Against Abort

```typescript
async function raceWithAbort<T>(
  requestPromise: Promise<T>,
  abortSignal: AbortSignal
): Promise<T> {
  if (abortSignal.aborted) {
    throw new Error(`Request aborted: ${abortSignal.reason || 'Unknown reason'}`)
  }

  return new Promise<T>((resolve, reject) => {
    const abortHandler = () => {
      reject(new Error(`Request aborted: ${abortSignal.reason || 'Unknown reason'}`))
    }

    abortSignal.addEventListener('abort', abortHandler, { once: true })

    requestPromise
      .then((result) => {
        abortSignal.removeEventListener('abort', abortHandler)
        resolve(result)
      })
      .catch((error) => {
        abortSignal.removeEventListener('abort', abortHandler)
        reject(error)
      })
  })
}

// Usage
const abortController = new AbortController()
const result = await raceWithAbort(
  ai.chat({ chatPrompt: [{ role: 'user', content: 'Hello' }] }),
  abortController.signal
)
``` 


================================================
FILE: src/docs/astro.config.mjs
================================================
import tailwind from "@astrojs/tailwind";
import { defineConfig } from 'astro/config';

// https://astro.build/config
export default defineConfig({
  integrations: [tailwind()],
});


================================================
FILE: src/docs/package.json
================================================
{
  "name": "@ax-llm/ax-docs",
  "type": "module",
  "scripts": {
    "dev": "astro dev",
    "start": "astro dev",
    "build": "astro check && astro build",
    "preview": "astro preview",
    "astro": "astro"
  },
  "dependencies": {
    "@astrojs/check": "^0.9.4",
    "@astrojs/tailwind": "^6.0.2",
    "@tailwindcss/typography": "^0.5.16",
    "astro": "^5.8.2",
    "marked": "^15.0.12"
  },
  "private": "true"
}



================================================
FILE: src/docs/tailwind.config.mjs
================================================
/** @type {import('tailwindcss').Config} */
const plugin = require('tailwindcss/plugin')

/** @type {import('tailwindcss').Config} */
export default {
	content: ['./src/**/*.{astro,html,js,jsx,md,mdx,svelte,ts,tsx,vue}'],
	theme: {
		extend: {},
	},
	plugins: [
        require('@tailwindcss/typography'),
        plugin(function ({addVariant}) {
            addVariant( 
                'prose-inline-code',
                '&.prose :where(:not(pre)>code):not(:where([class~="not-prose"] *))'
            );
        })
    ],
}



================================================
FILE: src/docs/tsconfig.json
================================================
{
  "extends": ["../../tsconfig.json", "astro/tsconfigs/strict"]
}



================================================
FILE: src/docs/.gitignore
================================================
# build output
dist/

# generated types
.astro/

# dependencies
node_modules/

# logs
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*


# environment variables
.env
.env.production

# macOS-specific files
.DS_Store

# api docs
src/content/docs/apidocs*



================================================
FILE: src/docs/src/env.d.ts
================================================
// cspell: disable

// eslint-disable-next-line @typescript-eslint/triple-slash-reference
/// <reference path="../.astro/types.d.ts" />
/// <reference types="astro/client" />



================================================
FILE: src/docs/src/components/Footer.astro
================================================
---

---

<!-- Footer inspired by Humming design -->
<footer
  style="margin-top: 120px; padding: 48px 0; border-top: 1px solid #f1f3f4; background: #fafbfc;"
>
  <div
    style="display: flex; justify-content: space-between; align-items: center; font-size: 14px; font-weight: 500; color: #6c757d; flex-wrap: wrap; gap: 16px;"
  >
    <div style="display: flex; gap: 32px; flex-wrap: wrap;">
      <span>Based on Stanford DSPy</span>
      <span>TypeScript First</span>
    </div>
    <span>Machines as Agents™</span>
  </div>
</footer>

<style>
  @media (max-width: 768px) {
    footer {
      margin-top: 80px !important;
      padding: 32px 0 !important;
    }

    footer div {
      flex-direction: column !important;
      align-items: flex-start !important;
      gap: 16px !important;
    }

    footer div div {
      flex-direction: row !important;
      gap: 16px !important;
    }
  }

  @media (max-width: 480px) {
    footer div div {
      flex-direction: column !important;
      gap: 8px !important;
    }
  }
</style>



================================================
FILE: src/docs/src/components/Header.astro
================================================
---

---

<!-- Header Section inspired by Humming design -->
<header class="pt-20 pb-30">
  <div class="mb-8">
    <div class="text-sm font-medium text-gray-500 mb-4 uppercase tracking-wider">
      Documentation
    </div>
  </div>

  <div class="max-w-4xl pb-6 relative">
    <!-- Gradient border using pseudo-element -->
    <div class="absolute bottom-0 left-0 right-0 h-2 bg-gradient-to-r from-blue-500 via-purple-500 to-cyan-500"></div>
    
    <h1 class="text-6xl font-bold leading-tight text-black mb-6 tracking-tight">
      Build LLM-powered agents<br />with production-ready TypeScript
    </h1>
    <p class="text-xl leading-relaxed text-gray-700 max-w-2xl">
      <b>DSPy for TypeScript.</b> Working with LLMs is complex they don't always
      do what you want. DSPy makes it easier to build amazing things with LLMs. Just
      define your inputs and outputs (signature) and an efficient prompt is auto-generated
      and used. Connect together various signatures to build complex systems and
      workflows using LLMs
    </p>

    <!-- Mobile Badges Section -->
    <div class="mobile-badges-section hidden mt-8 gap-4 flex-col max-w-2xl">
      <a
        href="https://www.npmjs.com/package/@ax-llm/ax"
        target="_blank"
        rel="noopener noreferrer"
        class="flex items-center"
      >
        <img
          src="https://img.shields.io/npm/v/@ax-llm/ax?style=for-the-badge&color=green"
          alt="NPM Package"
          class="h-8 rounded max-w-full object-contain"
        />
      </a>
      <a
        href="https://twitter.com/dosco"
        target="_blank"
        rel="noopener noreferrer"
        class="flex items-center"
      >
        <img
          src="https://img.shields.io/twitter/follow/dosco?style=for-the-badge&color=red"
          alt="Twitter"
          class="h-8 rounded max-w-full object-contain"
        />
      </a>
    </div>
  </div>
</header>


================================================
FILE: src/docs/src/components/Navigation.astro
================================================
---
const sections = [
  //   {
  //     name: 'guides',
  //     slug: '/guides',
  //   },
  {
    name: 'apidocs',
    slug: '/api',
  },
]
---

<nav
  style="background: #ffffff; border-bottom: 1px solid #f1f3f4; position: sticky; top: 0; z-index: 100; backdrop-filter: blur(8px); background: rgba(255, 255, 255, 0.95); overflow-x: hidden;"
>
  <div style="max-width: 1200px; margin: 0 auto; padding: 0 24px; width: 100%;">
    <div
      style="display: flex; align-items: center; justify-content: space-between; height: 72px; min-width: 0;"
    >
      <!-- Left Section: Logo & Badges -->
      <div style="display: flex; align-items: left; gap: 16px;">
        <div
          style="display: flex; align-items: center; gap: 8px; cursor: pointer;"
          id="logo-area"
        >
          <div
            style="font-size: 24px; font-weight: 700; color: #000000; letter-spacing: -0.02em;"
          >
            <a href="/">ax.</a>
          </div>
        </div>

        <!-- Badges next to logo - Desktop -->
        <div
          style="display: flex; align-items: center; gap: 8px; flex-shrink: 0;"
          class="desktop-badges"
        >
          <a
            href="https://www.npmjs.com/package/@ax-llm/ax"
            target="_blank"
            rel="noopener noreferrer"
            style="display: flex; align-items: center; flex-shrink: 0;"
          >
            <img
              src="https://img.shields.io/npm/v/@ax-llm/ax?style=for-the-badge&color=green"
              alt="NPM Package"
              style="height: 28px; border-radius: 4px; max-width: 100%; object-fit: contain;"
            />
          </a>
          <a
            href="https://twitter.com/dosco"
            target="_blank"
            rel="noopener noreferrer"
            style="display: flex; align-items: center; flex-shrink: 0;"
          >
            <img
              src="https://img.shields.io/twitter/follow/dosco?style=for-the-badge&color=red"
              alt="Twitter"
              style="height: 28px; border-radius: 4px; max-width: 100%; object-fit: contain;"
            />
          </a>
        </div>
      </div>

      <!-- Right Section: Optimize, API Docs & GitHub Buttons -->
      <div style="display: flex; align-items: center; gap: 12px;">
        <a
          href="/optimize"
          style="display: flex; align-items: center; gap: 8px; padding: 10px 20px; background: #f8f9fa; color: #1a1a1a; text-decoration: none; font-size: 14px; font-weight: 500; border-radius: 8px; border: 1px solid #e9ecef; transition: all 0.2s ease;"
          onmouseover="this.style.background='#e9ecef';"
          onmouseout="this.style.background='#f8f9fa';"
          class="desktop-api-docs"
        >
          <span>Optimize Guide</span>
        </a>
        <a
          href="https://deepwiki.com/ax-llm/ax"
          target="_blank"
          rel="noopener noreferrer"
          style="display: flex; align-items: center; gap: 8px; padding: 10px 20px; background: #f8f9fa; color: #1a1a1a; text-decoration: none; font-size: 14px; font-weight: 500; border-radius: 8px; border: 1px solid #e9ecef; transition: all 0.2s ease;"
          onmouseover="this.style.background='#e9ecef';"
          onmouseout="this.style.background='#f8f9fa';"
          class="desktop-api-docs"
        >
          <span>DeepWiki</span>
        </a>
        <a
          href="/api"
          style="display: flex; align-items: center; gap: 8px; padding: 10px 20px; background: #f8f9fa; color: #1a1a1a; text-decoration: none; font-size: 14px; font-weight: 500; border-radius: 8px; border: 1px solid #e9ecef; transition: all 0.2s ease;"
          onmouseover="this.style.background='#e9ecef';"
          onmouseout="this.style.background='#f8f9fa';"
          class="desktop-api-docs"
        >
          <span>API Docs</span>
        </a>

        <a
          href="https://github.com/ax-llm/ax"
          target="_blank"
          rel="noopener noreferrer"
          style="display: flex; align-items: center; gap: 8px; padding: 10px 20px; background: #000000; color: #ffffff; text-decoration: none; font-size: 14px; font-weight: 500; border-radius: 8px; transition: all 0.2s ease;"
          onmouseover="this.style.background='#333333';"
          onmouseout="this.style.background='#000000';"
          class="desktop-github"
        >
          <span>GitHub</span>
        </a>

        <!-- Mobile Menu Button -->
        <button
          id="mobile-menu-btn"
          style="display: none; flex-direction: column; gap: 4px; background: none; border: none; cursor: pointer; padding: 8px;"
          class="mobile-menu-btn"
        >
          <div
            style="width: 20px; height: 2px; background: #000000; transition: all 0.3s ease;"
            class="line1"
          >
          </div>
          <div
            style="width: 20px; height: 2px; background: #000000; transition: all 0.3s ease;"
            class="line2"
          >
          </div>
          <div
            style="width: 20px; height: 2px; background: #000000; transition: all 0.3s ease;"
            class="line3"
          >
          </div>
        </button>
      </div>
    </div>

    <!-- Mobile Navigation Menu -->
    <div
      id="mobile-menu"
      style="display: none; flex-direction: column; gap: 0; padding: 16px 0; border-top: 1px solid #f1f3f4; background: #ffffff;"
      class="mobile-menu"
    >
      <a
        href="/optimize"
        style="font-size: 16px; color: #4a4a4a; text-decoration: none; font-weight: 500; padding: 16px 0; border-bottom: 1px solid #f8f9fa;"
      >
        Optimize Guide
      </a>
      <a
        href="https://deepwiki.com/ax-llm/ax"
        target="_blank"
        rel="noopener noreferrer"
        style="font-size: 16px; color: #4a4a4a; text-decoration: none; font-weight: 500; padding: 16px 0; border-bottom: 1px solid #f8f9fa;"
      >
        DeepWiki
      </a>
      <a
        href="/api"
        style="font-size: 16px; color: #4a4a4a; text-decoration: none; font-weight: 500; padding: 16px 0; border-bottom: 1px solid #f8f9fa;"
      >
        API Docs
      </a>

      <a
        href="https://github.com/ax-llm/ax"
        target="_blank"
        rel="noopener noreferrer"
        style="font-size: 16px; color: #4a4a4a; text-decoration: none; font-weight: 500; padding: 16px 0;"
      >
        GitHub
      </a>
    </div>
  </div>
</nav>

<style>
  /* Ensure proper mobile viewport handling */
  html,
  body {
    overflow-x: hidden;
    max-width: 100vw;
  }

  /* Navigation container styles */
  nav {
    width: 100%;
    box-sizing: border-box;
  }

  nav > div {
    width: 100%;
    max-width: 100%;
    box-sizing: border-box;
  }

  /* Prevent badge overflow */
  .desktop-badges img {
    max-width: none;
    height: 28px;
  }

  @media (max-width: 768px) {
    .desktop-github,
    .desktop-badges,
    .desktop-api-docs {
      display: none !important;
    }

    .mobile-menu-btn {
      display: flex !important;
    }

    nav div:first-child {
      padding: 0 16px !important;
    }

    /* Ensure mobile menu doesn't overflow */
    .mobile-menu {
      width: 100%;
      box-sizing: border-box;
      overflow-x: hidden;
    }

    .mobile-menu img {
      max-width: calc(100vw - 64px);
      height: auto;
      max-height: 32px;
    }
  }

  @media (max-width: 1024px) {
    .desktop-badges {
      display: none !important;
    }
  }

  @media (min-width: 769px) {
    .mobile-menu {
      display: none !important;
    }
  }

  /* Mobile menu animation */
  .mobile-menu-open .line1 {
    transform: rotate(-45deg) translate(-5px, 6px);
  }

  .mobile-menu-open .line2 {
    opacity: 0;
  }

  .mobile-menu-open .line3 {
    transform: rotate(45deg) translate(-5px, -6px);
  }
</style>

<script>
  // Logo click to scroll to top
  const logoArea = document.getElementById('logo-area')
  if (logoArea) {
    logoArea.addEventListener('click', () => {
      window.scrollTo({
        top: 0,
        behavior: 'smooth',
      })
    })
  }

  // Mobile menu toggle
  const mobileMenuBtn = document.getElementById('mobile-menu-btn')
  const mobileMenu = document.getElementById('mobile-menu')

  if (mobileMenuBtn && mobileMenu) {
    mobileMenuBtn.addEventListener('click', () => {
      const isOpen = mobileMenu.style.display === 'flex'

      if (isOpen) {
        mobileMenu.style.display = 'none'
        mobileMenuBtn.classList.remove('mobile-menu-open')
      } else {
        mobileMenu.style.display = 'flex'
        mobileMenuBtn.classList.add('mobile-menu-open')
      }
    })
  }
</script>



================================================
FILE: src/docs/src/content/config.ts
================================================
import { defineCollection, z } from 'astro:content'

export const collections = {
  docs: defineCollection({
    schema: z.object({
      title: z.string(),
      description: z.string().optional(),
    }),
  }),
}



================================================
FILE: src/docs/src/content/docs/index.mdx
================================================
---
title: Meet, Ax
description: A framework to build LLM Agents. Multi-modal, Streaming, DSPy, Agents and much more.
template: splash
hero:
  tagline: A framework to build LLM Agents. Multi-modal, Streaming, DSPy, Agents and much more.
  image:
    file: ../../assets/spacy.jpg
  actions:
    - text: Quick Start
      link: ./start/quick/
      icon: right-arrow
      variant: primary
    - text: Github Project
      link: https://github.com/ax-llm/ax
      icon: external
---



================================================
FILE: src/docs/src/content/docs/.gitignore
================================================
03-apidocs/*


================================================
FILE: src/docs/src/content/docs/02-guides/01-dsp.md
================================================
---
title: DSPy Explained
description: Whats DSPy, why it matters and how to use it.
---

Demonstrate, search, predict, or DSPy is a now-famous Stanford paper focused on optimizing the prompting of LLMs. The basic idea is to provide examples instead of instructions.

Ax supports DSPy and allows you to set examples on each prompt. It also allows you to run an optimizer, which runs the prompt using inputs from a test set and validates the outputs against the same test set. In short, the optimizer helps you capture good examples across the entire tree of prompts your workflow is built with.

## Pick a prompt strategy

There are various prompts available in Ax, pick one based on your needs.

1. **Generate** - Generic prompt that all other prompts inherit from.
2. **ChainOfThough** - Increasing performance by reasoning before providing the answer
3. **RAG** - Uses a vector database to add context and improve performance and accuracy.
4. **Agent** - For agentic workflows


## Create a signature

A signature defines the task you want to do, the inputs you’ll provide, and the outputs you expect the LLM to generate.

```typescript
const prompt = new AxGen(
`"Extract customer query details" customerMessage:string -> customerName, customerIssue, ,productName:string, troubleshootingAttempted?:string`)
```

The next optional but most important thing you can do to improve the performance of your prompts is to set examples. When we say “performance,” we mean the number of times the LLM does exactly what you expect correctly over the number of times it fails.

Examples are the best way to communicate to the LLM what you want it to do. The patterns you define in high-quality examples help the LLM much better than the instructions.

```typescript
prompt.setExample([
    {
        customerMessage: "Hello, I'm Jane Smith. I'm having trouble with my UltraPhone X. The screen remains black even after restarting multiple times. I have tried charging it overnight and using a different charger.",
        customerName: "Jane Smith",
        productName: "UltraPhone X",
        troubleshootingAttempted: "Charging it overnight and using a different charger.",
    },
    {
        customerMessage: "Hi, my name is Michael Johnson. My EcoPrinter Pro isn't connecting to Wi-Fi. I've restarted the printer and my router, and also tried connecting via Ethernet cable.",
        customerName: "Michael Johnson",
        productName: "EcoPrinter Pro",
        troubleshootingAttempted: "Restarted the printer and router, and tried connecting via Ethernet cable.",
    },
    {
        customerMessage: "Greetings, I'm Sarah Lee. I'm experiencing issues with my SmartHome Hub. It keeps losing connection with my smart devices. I have reset the hub, checked my internet connection, and re-paired the devices.",
        customerName: "Sarah Lee",
        productName: "SmartHome Hub",
        troubleshootingAttempted: "Reset the hub, checked the internet connection, and re-paired the devices.",
    }
])
```

## Use this prompt

You are now ready to use this prompt in your workflows.

```typescript
# Setup the ai
const ai = new AxAI("openai", { apiKey: process.env.OPENAI_APIKEY })

# Execute the prompt
const { customerName, productName, troubleshootingAttempted } = prompt.forward(ai, { customerMessage })
```

Easy enough! this is all you need

## DAP prompt tuning

What if I want more performance, or do I want to run this with a smaller model? I was told you can tune your prompts with DSPy. Yes, this is true. You can do this. In short, you can use a big LLM to generate better examples for every prompt you use in your entire flow of prompts.

```typescript
// Use the HuggingFace data loader or create one for your own data
const hf = new AxHFDataLoader({
  dataset: 'yixuantt/MultiHopRAG',
  split: 'train',
  config: 'MultiHopRAG',
  options: { length: 5 }
});

await hf.loadData();
```

```typescript
// Fetch some rows, map the data columns to your prompts inputs
const examples = await hf.getRows<{ question: string; answer: string }>({
  count: 20,
  fields: ['query', 'answer'],
  renameMap: { query: 'question', answer: 'answer' }
});
```


```typescript
// Create your prompt
const prompt = new AxGen(`question -> answer`)
```

```typescript
// Setup a Bootstrap Few Shot optimizer to tune the above prompt
const optimize = new AxBootstrapFewShot<
  { question: string },
  { answer: string }
>({
  prompt,
  examples
});
```

```typescript
// Setup a evaluation metric em, f1 scores are a popular way measure retrieval performance.
const metricFn: AxMetricFn = ({ prediction, example }) => {
  return AxEvalUtil.emScore(
    prediction.answer as string,
    example.answer as string
  );
};
```

```typescript
// Run the optimizer
const result = await optimize.compile(metricFn);

// Save the results to use later
await fs.promises.writeFile('./qna-tune-demos.json', values);
```

```typescript
// Use this tuning data in your workflow
const values = await fs.promises.readFile('./qna-tune-demos.json', 'utf8');
const demos = JSON.parse(values);

// Your done now, use this prompt
prompt.setDemos(demos);
```







================================================
FILE: src/docs/src/content/docs/02-guides/02-functions.md
================================================
---
title: LLM Function Calling
description: How to create functions to use in Ax
---

In this guide, we’ll explain how to create functions, function classes, etc. that can be used in Ax. Creation focused functions with clear names and descriptions are critical to a solid workflow. Do not use too many functions on a prompt or make the function itself do too much. Focused functions are better. If you need to use several functions, then look into breaking down the task into multiple prompts or using agents.

### Function definition simple

A function is an object with a `name`, and `description` along with a JSON schema of the function arguments and the function itself

```typescript
// The function
const googleSearchAPI = async (query: string) => {
    const res = await axios.get("http://google.com/?q=" + query)
    return res.json()
}
```

```typescript
// The function definition
const googleSearch AxFunction = {
    name: 'googleSearch',
    description: 'Use this function to search google for links related to the query',
    func: googleSearchAPI,
    parameters: {
        type: 'object',
         properties: {
             query: {
                description: `The query to search for`,
                type: 'string'
            },
        }
    }
}
```

### Function definition as a class

Another way to define functions is as a class with a `toFunction` method.

```typescript
class GoogleSearch {
    private apiKey: string;

    constructor(apiKey: string) {
        this.apiLey = apiKey;
    }


    async query(query: string) {
        const res = await axios.get("http://google.com/?q=" + query)
        return res.json()
    }

    async toFunction() {
        return {
            name: 'googleSearch',
            description: 'Use this function to search google for links related to the query',
            parameters: {
                type: 'object',
                properties: {
                    query: {
                        description: `The query to search for`,
                        type: 'string'
                    },
                }
            },
            func: (query: string) => this.query(query)
        }
    }
}
```


### How to use these functions

Just set the function on the prompt

```typescript
const prompt = new AxGen('inputs -> output', { functions: [ googleSearch ] })
```

Or in the case of function classes

```typescript
const prompt = new AxGen('inputs -> output', { functions: [ new GoogleSearch(apiKey) ] })
```

### Restaurant finding agent

Let's create an agent to help find a restaurant based on the diner's preferences. To do this, we'll start by creating some dummy APIs specifically for this example. We’ll need a function to get the weather, and another one to look up places to eat at.

```typescript title="Weather data function"
const choice = Math.round(Math.random());

const goodDay = {
  temperature: '27C',
  description: 'Clear Sky',
  wind_speed: 5.1,
  humidity: 56
};

const badDay = {
  temperature: '10C',
  description: 'Cloudy',
  wind_speed: 10.6,
  humidity: 70
};

// dummy weather lookup function
const weatherAPI = ({ location }: Readonly<{ location: string }>) => {
  const data = [
    {
      city: 'san francisco',
      weather: choice === 1 ? goodDay : badDay
    },
    {
      city: 'tokyo',
      weather: choice === 1 ? goodDay : badDay
    }
  ];

  return data
    .filter((v) => v.city === location.toLowerCase())
    .map((v) => v.weather);
};
```

```typescript title="Restaurant search function"
// dummy opentable api
const opentableAPI = ({
  location
}: Readonly<{
  location: string;
  outdoor: string;
  cuisine: string;
  priceRange: string;
}>) => {
  const data = [
    {
      name: "Gordon Ramsay's",
      city: 'san francisco',
      cuisine: 'indian',
      rating: 4.8,
      price_range: '$$$$$$',
      outdoor_seating: true
    },
    {
      name: 'Sukiyabashi Jiro',
      city: 'san francisco',
      cuisine: 'sushi',
      rating: 4.7,
      price_range: '$$',
      outdoor_seating: true
    },
    {
      name: 'Oyster Bar',
      city: 'san francisco',
      cuisine: 'seafood',
      rating: 4.5,
      price_range: '$$',
      outdoor_seating: true
    },
    {
      name: 'Quay',
      city: 'tokyo',
      cuisine: 'sushi',
      rating: 4.6,
      price_range: '$$$$',
      outdoor_seating: true
    },
    {
      name: 'White Rabbit',
      city: 'tokyo',
      cuisine: 'indian',
      rating: 4.7,
      price_range: '$$$',
      outdoor_seating: true
    }
  ];

  return data
    .filter((v) => v.city === location?.toLowerCase())
    .sort((a, b) => {
      return a.price_range.length - b.price_range.length;
    });
};
```

The function parameters must be defined in JSON schema for the AI to read and understand.

```typescript
// List of functions available to the AI
const functions: AxFunction[] = [
  {
    name: 'getCurrentWeather',
    description: 'get the current weather for a location',
    func: weatherAPI,
    parameters: {
      type: 'object',
      properties: {
        location: {
          description: 'location to get weather for',
          type: 'string'
        },
        units: {
          type: 'string',
          enum: ['imperial', 'metric'],
          description: 'units to use'
        }
      },
      required: ['location']
    }
  },
  {
    name: 'findRestaurants',
    description: 'find restaurants in a location',
    func: opentableAPI,
    parameters: {
      type: 'object',
      properties: {
        location: {
          description: 'location to find restaurants in',
          type: 'string'
        },
        outdoor: {
          type: 'boolean',
          description: 'outdoor seating'
        },
        cuisine: { type: 'string', description: 'cuisine type' },
        priceRange: {
          type: 'string',
          enum: ['$', '$$', '$$$', '$$$$'],
          description: 'price range'
        }
      },
      required: ['location', 'outdoor', 'cuisine', 'priceRange']
    }
  }
];
```

Let's use this agent.

```typescript
const customerQuery =
  "Give me an ideas for lunch today in San Francisco. I like sushi but I don't want to spend too much or other options are fine as well. Also if its a nice day I'd rather sit outside.";

const ai = new Ax({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string
});

const agent = new AxAgent({
  name: 'Restaurant search agent'
  description:
    'Search for restaurants to dine at based on the weather and food preferences',
  signature:
    `customerQuery:string  -> restaurant:string, priceRange:string "use $ signs to indicate price range"`
    functions,
});

const res = await agent.forward(ai, { customerQuery });
console.log(res);
```

```console title="Run the agent and see the output"
npm run tsx src/examples/food-search.ts

{
  restaurant: 'Sukiyabashi Jiro',
  priceRange: '$$'
}
```



================================================
FILE: src/docs/src/content/docs/02-guides/03-tuning.md
================================================
---
title: Advanced Prompt Tuning
description: Learn how to tune your prompts for better performance using Ax's optimization tools
---

# Advanced Prompt Tuning

Prompt tuning is the process of automatically improving your prompts to get better, more consistent results from language models. Ax provides multiple optimization methods to enhance your prompt performance, reduce token usage, and enable smaller models to produce higher-quality results.

This guide will cover:
- Why prompt tuning matters
- Basic tuning with `AxBootstrapFewShot`
- Advanced tuning with `AxMiPRO` (Model Instruction Program Optimization v2)
- How to apply tuned prompts to your applications
- Best practices for effective tuning

## Why Tune Your Prompts?

Prompt tuning offers several key benefits:

- **Improved accuracy**: Find optimal instructions and examples that help models understand your specific task
- **Reduced costs**: Optimize prompts to use fewer tokens or run effectively on smaller, less expensive models
- **Consistency**: Reduce variability in outputs by providing high-quality demonstrations
- **Domain adaptation**: Tailor general-purpose models to your specific domain with minimal effort

## Basic Tuning with AxBootstrapFewShot

The `AxBootstrapFewShot` optimizer is a straightforward way to improve your prompts through few-shot learning. It generates high-quality examples from your dataset that help the model better understand your task.

### How It Works

1. The optimizer takes your program and examples as input
2. It uses a larger model to generate demonstrations for a subset of examples
3. These demonstrations are evaluated using your metric function
4. The best demonstrations are selected and combined to create an optimized prompt

### Example: Optimizing a Question-Answering Prompt

```typescript
import {
  AxAI,
  AxChainOfThought,
  AxBootstrapFewShot,
  AxEvalUtil,
  AxHFDataLoader,
  type AxMetricFn
} from '@ax-llm/ax'

// 1. Load your dataset (using HuggingFace data loader)
const hf = new AxHFDataLoader({
  dataset: 'hotpot_qa',
  split: 'train'
})

const examples = await hf.getData<{ question: string; answer: string }>({
  count: 100,
  fields: ['question', 'answer']
})

// 2. Create your AI service
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string
})

// 3. Setup the program you want to tune
const program = new AxChainOfThought<{ question: string }, { answer: string }>(
  `question -> answer "in short 2 or 3 words"`
)

// 4. Configure the optimizer
const optimizer = new AxBootstrapFewShot<
  { question: string },
  { answer: string }
>({
  ai,
  program,
  examples
})

// 5. Define your evaluation metric
const metricFn: AxMetricFn = ({ prediction, example }) =>
  AxEvalUtil.emScore(prediction.answer as string, example.answer as string)

// 6. Run the optimizer and save the results
const result = await optimizer.compile(metricFn)
const values = JSON.stringify(result, null, 2)
await fs.promises.writeFile('./tuned-demos.json', values)
```

### Using Your Tuned Prompt

After tuning, you can load and use your optimized prompt:

```typescript
import fs from 'fs'
import { AxAI, AxChainOfThought } from '@ax-llm/ax'

// Load the AI service
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string
})

// Create your program
const program = new AxChainOfThought<{ question: string }, { answer: string }>(
  `question -> answer "in short 2 or 3 words"`
)

// Load the tuned demonstrations
const values = await fs.promises.readFile('./tuned-demos.json', 'utf8')
const demos = JSON.parse(values)
program.setDemos(demos)

// Use the optimized program
const result = await program.forward(ai, {
  question: 'What castle did David Gregory inherit?'
})
console.log(result) // Optimized answer
```

## Advanced Tuning with AxMiPRO v2

While `AxBootstrapFewShot` is powerful, `AxMiPRO` (Model Instruction Program Optimization v2) takes prompt tuning to the next level. This Bayesian optimization framework systematically explores different combinations of instructions, demonstrations, and examples to find the optimal configuration.

### Key Features of MiPRO v2

- **Instruction optimization**: Automatically generates and tests multiple instruction candidates
- **Few-shot example selection**: Finds optimal demonstrations from your dataset
- **Smart Bayesian optimization**: Efficiently explores the configuration space
- **Early stopping**: Halts optimization when improvements plateau to save compute
- **Program and data-aware**: Considers program structure and dataset characteristics

### Example: Sentiment Analysis Optimization

```typescript
import fs from 'node:fs'
import {
  AxAI,
  AxChainOfThought,
  AxMiPRO,
  type AxMetricFn
} from '@ax-llm/ax'

// 1. Create your training data
const trainingData = [
  { productReview: 'This product is amazing!', label: 'positive' },
  { productReview: 'Completely disappointed by the quality.', label: 'negative' },
  { productReview: 'Best purchase ever.', label: 'positive' },
  { productReview: 'I really hate how this turned out.', label: 'negative' },
  // Additional examples...
]

const validationData = [
  { productReview: 'Very happy with the results.', label: 'positive' },
  { productReview: 'Terrible experience, not recommended.', label: 'negative' },
  // Additional validation examples...
]

// 2. Setup AI service
const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY
})

// 3. Create sentiment analysis program
const classifyProgram = new AxChainOfThought<
  { productReview: string },
  { label: string }
>(`productReview -> label:string "positive" or "negative"`)

// 4. Configure MiPRO optimizer
const optimizer = new AxMiPRO({
  ai,
  program: classifyProgram,
  examples: trainingData,
  options: {
    numCandidates: 3,       // Number of instruction candidates
    numTrials: 10,          // Number of optimization trials
    maxBootstrappedDemos: 2, // Maximum demos to bootstrap
    maxLabeledDemos: 3,     // Maximum labeled examples
    earlyStoppingTrials: 3, // Stop after 3 trials with no improvement
    programAwareProposer: true,
    dataAwareProposer: true,
    verbose: true
  }
})

// 5. Define evaluation metric
const metricFn: AxMetricFn = ({ prediction, example }) => {
  return prediction.label === example.label
}

// 6. Run the optimization
const optimizedProgram = await optimizer.compile(metricFn, {
  valset: validationData,
  auto: 'medium'  // Balanced optimization level
})

// 7. Save the optimized configuration
const programConfig = JSON.stringify(optimizedProgram, null, 2)
await fs.promises.writeFile('./mipro-optimized-config.json', programConfig)
```

### MiPRO Configuration Options

MiPRO v2 offers extensive configuration options to tailor the optimization process:

| Option | Description | Default |
|--------|-------------|---------|
| `numCandidates` | Number of instruction candidates to generate | 5 |
| `numTrials` | Number of optimization trials | 30 |
| `maxBootstrappedDemos` | Maximum number of bootstrapped demonstrations | 3 |
| `maxLabeledDemos` | Maximum number of labeled examples | 4 |
| `minibatch` | Use minibatching for faster evaluation | true |
| `minibatchSize` | Size of evaluation minibatches | 25 |
| `earlyStoppingTrials` | Stop if no improvement after N trials | 5 |
| `minImprovementThreshold` | Minimum score improvement threshold | 0.01 |
| `programAwareProposer` | Use program structure for better proposals | true |
| `dataAwareProposer` | Consider dataset characteristics | true |
| `verbose` | Show detailed optimization progress | false |

### Optimization Levels

For convenience, MiPRO offers pre-configured optimization intensities using the `auto` parameter:

```typescript
// 1. Light optimization (faster, less thorough)
const optimizedProgram = await optimizer.compile(metricFn, { auto: 'light' })

// 2. Medium optimization (balanced)
const optimizedProgram = await optimizer.compile(metricFn, { auto: 'medium' })

// 3. Heavy optimization (slower, more thorough)
const optimizedProgram = await optimizer.compile(metricFn, { auto: 'heavy' })
```

## How MiPRO v2 Works

MiPRO v2 optimizes your prompts through a systematic process:

1. **Instruction Generation**: Creates multiple candidate instructions based on program structure and dataset characteristics
2. **Few-Shot Bootstrapping**: Generates high-quality example demonstrations from your data
3. **Example Selection**: Strategically selects labeled examples from your dataset
4. **Bayesian Optimization**: Systematically explores different combinations of instructions and examples
5. **Configuration Application**: Applies the best-performing configuration to your program

This process finds the optimal balance of instructions and examples to maximize your model's effectiveness for your specific task.

## Best Practices for Prompt Tuning

### 1. Prepare Quality Training Data

- **Diversity**: Include examples covering different aspects of your task
- **Balance**: Ensure balanced representation of different classes or categories
- **Size**: Aim for at least 20-100 examples for basic tuning, more for complex tasks
- **Quality**: Manually review examples to ensure they're correct and representative

### 2. Choose the Right Evaluation Metric

Select a metric that truly measures success for your task:

- **Classification**: Accuracy, F1 score, or precision/recall
- **Generation**: BLEU, ROUGE, or semantic similarity scores
- **Question Answering**: Exact match (EM) or F1 scores
- **Custom Metrics**: Design task-specific metrics when standard ones don't apply

### 3. Balance Compute and Quality

- For quick improvements, use `AxBootstrapFewShot` with fewer examples
- For production-critical applications, use `AxMiPRO` with the "heavy" optimization level
- Consider running optimization overnight for complex tasks
- Save and version your optimized configurations for reuse

### 4. Test on Diverse Validation Sets

- Always test your tuned programs on held-out validation data
- Ensure validation examples are representative of real-world use cases
- Compare optimized vs. unoptimized performance to measure improvement

## Conclusion

Prompt tuning is a powerful technique to improve the performance of your language model applications. Ax provides both simple and advanced optimization tools that can significantly enhance your results while potentially reducing costs.

Start with `AxBootstrapFewShot` for quick improvements, then explore `AxMiPRO` for more comprehensive optimization. By following the best practices outlined in this guide, you'll be able to create prompts that maximize the effectiveness of your language models for your specific tasks.



================================================
FILE: src/docs/src/content/docs/03-apidocs/README.md
================================================
---
title: "@ax-llm/ax"
---

## Enumerations

| Enumeration | Description |
| :------ | :------ |
| [AxAIAnthropicModel](/api/#03-apidocs/enumerationaxaianthropicmodel) | - |
| [AxAIAnthropicVertexModel](/api/#03-apidocs/enumerationaxaianthropicvertexmodel) | - |
| [AxAICohereEmbedModel](/api/#03-apidocs/enumerationaxaicohereembedmodel) | Cohere: Models for use in embeddings |
| [AxAICohereModel](/api/#03-apidocs/enumerationaxaicoheremodel) | Cohere: Models for text generation |
| [AxAIDeepSeekModel](/api/#03-apidocs/enumerationaxaideepseekmodel) | DeepSeek: Models for text generation |
| [AxAIGoogleGeminiEmbedModel](/api/#03-apidocs/enumerationaxaigooglegeminiembedmodel) | - |
| [AxAIGoogleGeminiEmbedTypes](/api/#03-apidocs/enumerationaxaigooglegeminiembedtypes) | - |
| [AxAIGoogleGeminiModel](/api/#03-apidocs/enumerationaxaigooglegeminimodel) | - |
| [AxAIGoogleGeminiSafetyCategory](/api/#03-apidocs/enumerationaxaigooglegeminisafetycategory) | - |
| [AxAIGoogleGeminiSafetyThreshold](/api/#03-apidocs/enumerationaxaigooglegeminisafetythreshold) | - |
| [AxAIGrokEmbedModels](/api/#03-apidocs/enumerationaxaigrokembedmodels) | - |
| [AxAIGrokModel](/api/#03-apidocs/enumerationaxaigrokmodel) | - |
| [AxAIGroqModel](/api/#03-apidocs/enumerationaxaigroqmodel) | - |
| [AxAIHuggingFaceModel](/api/#03-apidocs/enumerationaxaihuggingfacemodel) | - |
| [AxAIMistralEmbedModels](/api/#03-apidocs/enumerationaxaimistralembedmodels) | - |
| [AxAIMistralModel](/api/#03-apidocs/enumerationaxaimistralmodel) | - |
| [AxAIOpenAIEmbedModel](/api/#03-apidocs/enumerationaxaiopenaiembedmodel) | - |
| [AxAIOpenAIModel](/api/#03-apidocs/enumerationaxaiopenaimodel) | - |
| [AxAIOpenAIResponsesModel](/api/#03-apidocs/enumerationaxaiopenairesponsesmodel) | - |
| [AxAIRekaModel](/api/#03-apidocs/enumerationaxairekamodel) | - |
| [AxJSInterpreterPermission](/api/#03-apidocs/enumerationaxjsinterpreterpermission) | - |
| [AxLLMRequestTypeValues](/api/#03-apidocs/enumerationaxllmrequesttypevalues) | - |
| [AxSpanKindValues](/api/#03-apidocs/enumerationaxspankindvalues) | - |

## Classes

| Class | Description |
| :------ | :------ |
| [AxAgent](/api/#03-apidocs/classaxagent) | An AI agent that can process inputs using an AI service and coordinate with child agents. Supports features like smart model routing and automatic input field passing to child agents. |
| [AxAI](/api/#03-apidocs/classaxai) | - |
| [AxAIAnthropic](/api/#03-apidocs/classaxaianthropic) | - |
| [AxAIAzureOpenAI](/api/#03-apidocs/classaxaiazureopenai) | - |
| [AxAICohere](/api/#03-apidocs/classaxaicohere) | - |
| [AxAIDeepSeek](/api/#03-apidocs/classaxaideepseek) | - |
| [AxAIGoogleGemini](/api/#03-apidocs/classaxaigooglegemini) | AxAIGoogleGemini: AI Service |
| [AxAIGrok](/api/#03-apidocs/classaxaigrok) | - |
| [AxAIGroq](/api/#03-apidocs/classaxaigroq) | - |
| [AxAIHuggingFace](/api/#03-apidocs/classaxaihuggingface) | - |
| [AxAIMistral](/api/#03-apidocs/classaxaimistral) | - |
| [AxAIOllama](/api/#03-apidocs/classaxaiollama) | OllamaAI: AI Service |
| [AxAIOpenAI](/api/#03-apidocs/classaxaiopenai) | - |
| [AxAIOpenAIBase](/api/#03-apidocs/classaxaiopenaibase) | - |
| [AxAIOpenAIResponses](/api/#03-apidocs/classaxaiopenairesponses) | Base class for OpenAI AI services using the /v1/responses API endpoint |
| [AxAIOpenAIResponsesBase](/api/#03-apidocs/classaxaiopenairesponsesbase) | Base class for OpenAI AI services using the /v1/responses API endpoint |
| [AxAIOpenAIResponsesImpl](/api/#03-apidocs/classaxaiopenairesponsesimpl) | - |
| [AxAIReka](/api/#03-apidocs/classaxaireka) | - |
| [AxAIServiceAbortedError](/api/#03-apidocs/classaxaiserviceabortederror) | - |
| [AxAIServiceAuthenticationError](/api/#03-apidocs/classaxaiserviceauthenticationerror) | - |
| [AxAIServiceError](/api/#03-apidocs/classaxaiserviceerror) | - |
| [AxAIServiceNetworkError](/api/#03-apidocs/classaxaiservicenetworkerror) | - |
| [AxAIServiceResponseError](/api/#03-apidocs/classaxaiserviceresponseerror) | - |
| [AxAIServiceStatusError](/api/#03-apidocs/classaxaiservicestatuserror) | - |
| [AxAIServiceStreamTerminatedError](/api/#03-apidocs/classaxaiservicestreamterminatederror) | - |
| [AxAIServiceTimeoutError](/api/#03-apidocs/classaxaiservicetimeouterror) | - |
| [AxAITogether](/api/#03-apidocs/classaxaitogether) | - |
| [AxApacheTika](/api/#03-apidocs/classaxapachetika) | - |
| [AxAssertionError](/api/#03-apidocs/classaxassertionerror) | - |
| [AxBalancer](/api/#03-apidocs/classaxbalancer) | Balancer that rotates through services. |
| [AxBaseAI](/api/#03-apidocs/classaxbaseai) | - |
| [AxBootstrapFewShot](/api/#03-apidocs/classaxbootstrapfewshot) | - |
| [AxChainOfThought](/api/#03-apidocs/classaxchainofthought) | - |
| [AxDB](/api/#03-apidocs/classaxdb) | - |
| [AxDBBase](/api/#03-apidocs/classaxdbbase) | - |
| [AxDBCloudflare](/api/#03-apidocs/classaxdbcloudflare) | Cloudflare: DB Service |
| [AxDBManager](/api/#03-apidocs/classaxdbmanager) | - |
| [AxDBMemory](/api/#03-apidocs/classaxdbmemory) | MemoryDB: DB Service |
| [AxDBPinecone](/api/#03-apidocs/classaxdbpinecone) | Pinecone: DB Service |
| [AxDBWeaviate](/api/#03-apidocs/classaxdbweaviate) | Weaviate: DB Service |
| [AxDefaultQueryRewriter](/api/#03-apidocs/classaxdefaultqueryrewriter) | - |
| [AxDefaultResultReranker](/api/#03-apidocs/classaxdefaultresultreranker) | - |
| [AxDockerSession](/api/#03-apidocs/classaxdockersession) | - |
| [AxEmbeddingAdapter](/api/#03-apidocs/classaxembeddingadapter) | - |
| [AxFunctionError](/api/#03-apidocs/classaxfunctionerror) | - |
| [AxFunctionProcessor](/api/#03-apidocs/classaxfunctionprocessor) | - |
| [AxGen](/api/#03-apidocs/classaxgen) | - |
| [AxGenerateError](/api/#03-apidocs/classaxgenerateerror) | - |
| [AxHFDataLoader](/api/#03-apidocs/classaxhfdataloader) | - |
| [AxInstanceRegistry](/api/#03-apidocs/classaxinstanceregistry) | - |
| [AxJSInterpreter](/api/#03-apidocs/classaxjsinterpreter) | - |
| [AxMCPClient](/api/#03-apidocs/classaxmcpclient) | - |
| [AxMCPHTTPSSETransport](/api/#03-apidocs/classaxmcphttpssetransport) | - |
| [AxMCPStdioTransport](/api/#03-apidocs/classaxmcpstdiotransport) | - |
| [AxMCPStreambleHTTPTransport](/api/#03-apidocs/classaxmcpstreamblehttptransport) | AxMCPStreambleHTTPTransport implements the 2025-03-26 Streamable HTTP transport specification This transport uses a single HTTP endpoint that supports both POST and GET methods |
| [AxMemory](/api/#03-apidocs/classaxmemory) | - |
| [AxMiPRO](/api/#03-apidocs/classaxmipro) | - |
| [AxMockAIService](/api/#03-apidocs/classaxmockaiservice) | - |
| [AxMultiServiceRouter](/api/#03-apidocs/classaxmultiservicerouter) | - |
| [AxProgram](/api/#03-apidocs/classaxprogram) | - |
| [AxProgramWithSignature](/api/#03-apidocs/classaxprogramwithsignature) | - |
| [AxPromptTemplate](/api/#03-apidocs/classaxprompttemplate) | - |
| [AxRAG](/api/#03-apidocs/classaxrag) | - |
| [AxRateLimiterTokenUsage](/api/#03-apidocs/classaxratelimitertokenusage) | - |
| [AxRewriter](/api/#03-apidocs/classaxrewriter) | - |
| [AxSignature](/api/#03-apidocs/classaxsignature) | - |
| [AxSimpleClassifier](/api/#03-apidocs/classaxsimpleclassifier) | - |
| [AxSimpleClassifierClass](/api/#03-apidocs/classaxsimpleclassifierclass) | - |
| [AxTestPrompt](/api/#03-apidocs/classaxtestprompt) | - |

## Interfaces

| Interface | Description |
| :------ | :------ |
| [AxAgentFeatures](/api/#03-apidocs/interfaceaxagentfeatures) | - |
| [AxAgentic](/api/#03-apidocs/interfaceaxagentic) | Interface for agents that can be used as child agents. Provides methods to get the agent's function definition and features. |
| [AxAIAnthropicArgs](/api/#03-apidocs/interfaceaxaianthropicargs) | - |
| [AxAIAnthropicContentBlockDeltaEvent](/api/#03-apidocs/interfaceaxaianthropiccontentblockdeltaevent) | - |
| [AxAIAnthropicContentBlockStartEvent](/api/#03-apidocs/interfaceaxaianthropiccontentblockstartevent) | - |
| [AxAIAnthropicContentBlockStopEvent](/api/#03-apidocs/interfaceaxaianthropiccontentblockstopevent) | - |
| [AxAIAnthropicErrorEvent](/api/#03-apidocs/interfaceaxaianthropicerrorevent) | - |
| [AxAIAnthropicMessageDeltaEvent](/api/#03-apidocs/interfaceaxaianthropicmessagedeltaevent) | - |
| [AxAIAnthropicMessageStartEvent](/api/#03-apidocs/interfaceaxaianthropicmessagestartevent) | - |
| [AxAIAnthropicMessageStopEvent](/api/#03-apidocs/interfaceaxaianthropicmessagestopevent) | - |
| [AxAIAnthropicPingEvent](/api/#03-apidocs/interfaceaxaianthropicpingevent) | - |
| [AxAICohereArgs](/api/#03-apidocs/interfaceaxaicohereargs) | - |
| [AxAIFeatures](/api/#03-apidocs/interfaceaxaifeatures) | - |
| [AxAIGoogleGeminiArgs](/api/#03-apidocs/interfaceaxaigooglegeminiargs) | - |
| [AxAIGoogleGeminiOptionsTools](/api/#03-apidocs/interfaceaxaigooglegeminioptionstools) | - |
| [AxAIGrokOptionsTools](/api/#03-apidocs/interfaceaxaigrokoptionstools) | - |
| [AxAIGrokSearchSource](/api/#03-apidocs/interfaceaxaigroksearchsource) | - |
| [AxAIHuggingFaceArgs](/api/#03-apidocs/interfaceaxaihuggingfaceargs) | - |
| [AxAIMemory](/api/#03-apidocs/interfaceaxaimemory) | - |
| [AxAIOpenAIArgs](/api/#03-apidocs/interfaceaxaiopenaiargs) | - |
| [AxAIOpenAIBaseArgs](/api/#03-apidocs/interfaceaxaiopenaibaseargs) | - |
| [AxAIOpenAIResponseDelta](/api/#03-apidocs/interfaceaxaiopenairesponsedelta) | - |
| [AxAIOpenAIResponsesArgs](/api/#03-apidocs/interfaceaxaiopenairesponsesargs) | Ready-to-use implementation of the OpenAI Responses API client This class uses OpenAI's /v1/responses API endpoint which supports text, image, and audio inputs |
| [AxAIOpenAIResponsesCodeInterpreterToolCall](/api/#03-apidocs/interfaceaxaiopenairesponsescodeinterpretertoolcall) | - |
| [AxAIOpenAIResponsesComputerToolCall](/api/#03-apidocs/interfaceaxaiopenairesponsescomputertoolcall) | - |
| [AxAIOpenAIResponsesContentPartAddedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsescontentpartaddedevent) | - |
| [AxAIOpenAIResponsesContentPartDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsescontentpartdoneevent) | - |
| [AxAIOpenAIResponsesDefineFunctionTool](/api/#03-apidocs/interfaceaxaiopenairesponsesdefinefunctiontool) | - |
| [AxAIOpenAIResponsesErrorEvent](/api/#03-apidocs/interfaceaxaiopenairesponseserrorevent) | - |
| [AxAIOpenAIResponsesFileSearchCallCompletedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesfilesearchcallcompletedevent) | - |
| [AxAIOpenAIResponsesFileSearchCallInProgressEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesfilesearchcallinprogressevent) | - |
| [AxAIOpenAIResponsesFileSearchCallSearchingEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesfilesearchcallsearchingevent) | - |
| [AxAIOpenAIResponsesFileSearchToolCall](/api/#03-apidocs/interfaceaxaiopenairesponsesfilesearchtoolcall) | - |
| [AxAIOpenAIResponsesFunctionCallArgumentsDeltaEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesfunctioncallargumentsdeltaevent) | - |
| [AxAIOpenAIResponsesFunctionCallArgumentsDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesfunctioncallargumentsdoneevent) | - |
| [AxAIOpenAIResponsesFunctionCallItem](/api/#03-apidocs/interfaceaxaiopenairesponsesfunctioncallitem) | - |
| [AxAIOpenAIResponsesImageGenerationCallCompletedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesimagegenerationcallcompletedevent) | - |
| [AxAIOpenAIResponsesImageGenerationCallGeneratingEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesimagegenerationcallgeneratingevent) | - |
| [AxAIOpenAIResponsesImageGenerationCallInProgressEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesimagegenerationcallinprogressevent) | - |
| [AxAIOpenAIResponsesImageGenerationCallPartialImageEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesimagegenerationcallpartialimageevent) | - |
| [AxAIOpenAIResponsesImageGenerationToolCall](/api/#03-apidocs/interfaceaxaiopenairesponsesimagegenerationtoolcall) | - |
| [AxAIOpenAIResponsesInputAudioContentPart](/api/#03-apidocs/interfaceaxaiopenairesponsesinputaudiocontentpart) | - |
| [AxAIOpenAIResponsesInputFunctionCallItem](/api/#03-apidocs/interfaceaxaiopenairesponsesinputfunctioncallitem) | - |
| [AxAIOpenAIResponsesInputFunctionCallOutputItem](/api/#03-apidocs/interfaceaxaiopenairesponsesinputfunctioncalloutputitem) | - |
| [AxAIOpenAIResponsesInputImageUrlContentPart](/api/#03-apidocs/interfaceaxaiopenairesponsesinputimageurlcontentpart) | - |
| [AxAIOpenAIResponsesInputMessageItem](/api/#03-apidocs/interfaceaxaiopenairesponsesinputmessageitem) | - |
| [AxAIOpenAIResponsesInputTextContentPart](/api/#03-apidocs/interfaceaxaiopenairesponsesinputtextcontentpart) | - |
| [AxAIOpenAIResponsesLocalShellToolCall](/api/#03-apidocs/interfaceaxaiopenairesponseslocalshelltoolcall) | - |
| [AxAIOpenAIResponsesMCPCallArgumentsDeltaEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesmcpcallargumentsdeltaevent) | - |
| [AxAIOpenAIResponsesMCPCallArgumentsDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesmcpcallargumentsdoneevent) | - |
| [AxAIOpenAIResponsesMCPCallCompletedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesmcpcallcompletedevent) | - |
| [AxAIOpenAIResponsesMCPCallFailedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesmcpcallfailedevent) | - |
| [AxAIOpenAIResponsesMCPCallInProgressEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesmcpcallinprogressevent) | - |
| [AxAIOpenAIResponsesMCPListToolsCompletedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesmcplisttoolscompletedevent) | - |
| [AxAIOpenAIResponsesMCPListToolsFailedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesmcplisttoolsfailedevent) | - |
| [AxAIOpenAIResponsesMCPListToolsInProgressEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesmcplisttoolsinprogressevent) | - |
| [AxAIOpenAIResponsesMCPToolCall](/api/#03-apidocs/interfaceaxaiopenairesponsesmcptoolcall) | - |
| [AxAIOpenAIResponsesOutputItemAddedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesoutputitemaddedevent) | - |
| [AxAIOpenAIResponsesOutputItemDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesoutputitemdoneevent) | - |
| [AxAIOpenAIResponsesOutputMessageItem](/api/#03-apidocs/interfaceaxaiopenairesponsesoutputmessageitem) | - |
| [AxAIOpenAIResponsesOutputRefusalContentPart](/api/#03-apidocs/interfaceaxaiopenairesponsesoutputrefusalcontentpart) | - |
| [AxAIOpenAIResponsesOutputTextAnnotationAddedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesoutputtextannotationaddedevent) | - |
| [AxAIOpenAIResponsesOutputTextContentPart](/api/#03-apidocs/interfaceaxaiopenairesponsesoutputtextcontentpart) | - |
| [AxAIOpenAIResponsesOutputTextDeltaEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesoutputtextdeltaevent) | - |
| [AxAIOpenAIResponsesOutputTextDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesoutputtextdoneevent) | - |
| [AxAIOpenAIResponsesReasoningDeltaEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningdeltaevent) | - |
| [AxAIOpenAIResponsesReasoningDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningdoneevent) | - |
| [AxAIOpenAIResponsesReasoningItem](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningitem) | - |
| [AxAIOpenAIResponsesReasoningSummaryDeltaEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningsummarydeltaevent) | - |
| [AxAIOpenAIResponsesReasoningSummaryDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningsummarydoneevent) | - |
| [AxAIOpenAIResponsesReasoningSummaryPart](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningsummarypart) | - |
| [AxAIOpenAIResponsesReasoningSummaryPartAddedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningsummarypartaddedevent) | - |
| [AxAIOpenAIResponsesReasoningSummaryPartDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningsummarypartdoneevent) | - |
| [AxAIOpenAIResponsesReasoningSummaryTextDeltaEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningsummarytextdeltaevent) | - |
| [AxAIOpenAIResponsesReasoningSummaryTextDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesreasoningsummarytextdoneevent) | - |
| [AxAIOpenAIResponsesRefusalDeltaEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesrefusaldeltaevent) | - |
| [AxAIOpenAIResponsesRefusalDoneEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesrefusaldoneevent) | - |
| [AxAIOpenAIResponsesRequest](/api/#03-apidocs/interfaceaxaiopenairesponsesrequest) | - |
| [AxAIOpenAIResponsesResponse](/api/#03-apidocs/interfaceaxaiopenairesponsesresponse) | - |
| [AxAIOpenAIResponsesResponseCompletedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesresponsecompletedevent) | - |
| [AxAIOpenAIResponsesResponseCreatedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesresponsecreatedevent) | - |
| [AxAIOpenAIResponsesResponseDelta](/api/#03-apidocs/interfaceaxaiopenairesponsesresponsedelta) | - |
| [AxAIOpenAIResponsesResponseFailedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesresponsefailedevent) | - |
| [AxAIOpenAIResponsesResponseIncompleteEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesresponseincompleteevent) | - |
| [AxAIOpenAIResponsesResponseInProgressEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesresponseinprogressevent) | - |
| [AxAIOpenAIResponsesResponseQueuedEvent](/api/#03-apidocs/interfaceaxaiopenairesponsesresponsequeuedevent) | - |
| [AxAIOpenAIResponsesStreamEventBase](/api/#03-apidocs/interfaceaxaiopenairesponsesstreameventbase) | - |
| [AxAIOpenAIResponsesToolCallBase](/api/#03-apidocs/interfaceaxaiopenairesponsestoolcallbase) | - |
| [AxAIOpenAIResponsesWebSearchCallCompletedEvent](/api/#03-apidocs/interfaceaxaiopenairesponseswebsearchcallcompletedevent) | - |
| [AxAIOpenAIResponsesWebSearchCallInProgressEvent](/api/#03-apidocs/interfaceaxaiopenairesponseswebsearchcallinprogressevent) | - |
| [AxAIOpenAIResponsesWebSearchCallSearchingEvent](/api/#03-apidocs/interfaceaxaiopenairesponseswebsearchcallsearchingevent) | - |
| [AxAIOpenAIResponsesWebSearchToolCall](/api/#03-apidocs/interfaceaxaiopenairesponseswebsearchtoolcall) | - |
| [AxAIRekaArgs](/api/#03-apidocs/interfaceaxairekaargs) | - |
| [AxAIService](/api/#03-apidocs/interfaceaxaiservice) | - |
| [AxAIServiceImpl](/api/#03-apidocs/interfaceaxaiserviceimpl) | - |
| [AxAIServiceMetrics](/api/#03-apidocs/interfaceaxaiservicemetrics) | - |
| [AxApacheTikaArgs](/api/#03-apidocs/interfaceaxapachetikaargs) | - |
| [AxApacheTikaConvertOptions](/api/#03-apidocs/interfaceaxapachetikaconvertoptions) | - |
| [AxAPI](/api/#03-apidocs/interfaceaxapi) | - |
| [AxAPIConfig](/api/#03-apidocs/interfaceaxapiconfig) | - |
| [AxAssertion](/api/#03-apidocs/interfaceaxassertion) | - |
| [AxBaseAIArgs](/api/#03-apidocs/interfaceaxbaseaiargs) | - |
| [AxDBBaseArgs](/api/#03-apidocs/interfaceaxdbbaseargs) | - |
| [AxDBBaseOpOptions](/api/#03-apidocs/interfaceaxdbbaseopoptions) | - |
| [AxDBCloudflareArgs](/api/#03-apidocs/interfaceaxdbcloudflareargs) | - |
| [AxDBLoaderOptions](/api/#03-apidocs/interfaceaxdbloaderoptions) | - |
| [AxDBManagerArgs](/api/#03-apidocs/interfaceaxdbmanagerargs) | - |
| [AxDBMatch](/api/#03-apidocs/interfaceaxdbmatch) | - |
| [AxDBMemoryArgs](/api/#03-apidocs/interfaceaxdbmemoryargs) | - |
| [AxDBPineconeArgs](/api/#03-apidocs/interfaceaxdbpineconeargs) | - |
| [AxDBQueryService](/api/#03-apidocs/interfaceaxdbqueryservice) | - |
| [AxDBService](/api/#03-apidocs/interfaceaxdbservice) | - |
| [AxDBWeaviateArgs](/api/#03-apidocs/interfaceaxdbweaviateargs) | - |
| [AxDockerContainer](/api/#03-apidocs/interfaceaxdockercontainer) | - |
| [AxField](/api/#03-apidocs/interfaceaxfield) | - |
| [AxFieldDescriptor](/api/#03-apidocs/interfaceaxfielddescriptor) | - |
| [AxFieldProcessor](/api/#03-apidocs/interfaceaxfieldprocessor) | - |
| [AxFieldType](/api/#03-apidocs/interfaceaxfieldtype) | - |
| [AxMCPStreamableHTTPTransportOptions](/api/#03-apidocs/interfaceaxmcpstreamablehttptransportoptions) | - |
| [AxMCPTransport](/api/#03-apidocs/interfaceaxmcptransport) | - |
| [AxMiPROOptions](/api/#03-apidocs/interfaceaxmiprooptions) | - |
| [AxOptimizationStats](/api/#03-apidocs/interfaceaxoptimizationstats) | - |
| [AxProgramWithSignatureOptions](/api/#03-apidocs/interfaceaxprogramwithsignatureoptions) | - |
| [AxPromptTemplateOptions](/api/#03-apidocs/interfaceaxprompttemplateoptions) | - |
| [AxRateLimiterTokenUsageOptions](/api/#03-apidocs/interfaceaxratelimitertokenusageoptions) | - |
| [AxResponseHandlerArgs](/api/#03-apidocs/interfaceaxresponsehandlerargs) | - |
| [AxSimpleClassifierForwardOptions](/api/#03-apidocs/interfaceaxsimpleclassifierforwardoptions) | - |
| [AxStreamingAssertion](/api/#03-apidocs/interfaceaxstreamingassertion) | - |
| [AxStreamingEvent](/api/#03-apidocs/interfaceaxstreamingevent) | - |
| [AxTunable](/api/#03-apidocs/interfaceaxtunable) | - |
| [AxUsable](/api/#03-apidocs/interfaceaxusable) | - |

## Type Aliases

| Type alias | Description |
| :------ | :------ |
| [AxAgentOptions](/api/#03-apidocs/typealiasaxagentoptions) | - |
| [AxAIAnthropicChatError](/api/#03-apidocs/typealiasaxaianthropicchaterror) | - |
| [AxAIAnthropicChatRequest](/api/#03-apidocs/typealiasaxaianthropicchatrequest) | - |
| [AxAIAnthropicChatRequestCacheParam](/api/#03-apidocs/typealiasaxaianthropicchatrequestcacheparam) | - |
| [AxAIAnthropicChatResponse](/api/#03-apidocs/typealiasaxaianthropicchatresponse) | - |
| [AxAIAnthropicChatResponseDelta](/api/#03-apidocs/typealiasaxaianthropicchatresponsedelta) | - |
| [AxAIAnthropicConfig](/api/#03-apidocs/typealiasaxaianthropicconfig) | - |
| [AxAIArgs](/api/#03-apidocs/typealiasaxaiargs) | - |
| [AxAIAzureOpenAIArgs](/api/#03-apidocs/typealiasaxaiazureopenaiargs) | - |
| [AxAIAzureOpenAIConfig](/api/#03-apidocs/typealiasaxaiazureopenaiconfig) | - |
| [AxAICohereChatRequest](/api/#03-apidocs/typealiasaxaicoherechatrequest) | - |
| [AxAICohereChatRequestToolResults](/api/#03-apidocs/typealiasaxaicoherechatrequesttoolresults) | - |
| [AxAICohereChatResponse](/api/#03-apidocs/typealiasaxaicoherechatresponse) | - |
| [AxAICohereChatResponseDelta](/api/#03-apidocs/typealiasaxaicoherechatresponsedelta) | - |
| [AxAICohereChatResponseToolCalls](/api/#03-apidocs/typealiasaxaicoherechatresponsetoolcalls) | - |
| [AxAICohereConfig](/api/#03-apidocs/typealiasaxaicohereconfig) | Cohere: Model options for text generation |
| [AxAICohereEmbedRequest](/api/#03-apidocs/typealiasaxaicohereembedrequest) | - |
| [AxAICohereEmbedResponse](/api/#03-apidocs/typealiasaxaicohereembedresponse) | - |
| [AxAIDeepSeekArgs](/api/#03-apidocs/typealiasaxaideepseekargs) | - |
| [AxAIEmbedModels](/api/#03-apidocs/typealiasaxaiembedmodels) | - |
| [AxAIGoogleGeminiBatchEmbedRequest](/api/#03-apidocs/typealiasaxaigooglegeminibatchembedrequest) | AxAIGoogleGeminiEmbedRequest: Structure for making an embedding request to the Google Gemini API. |
| [AxAIGoogleGeminiBatchEmbedResponse](/api/#03-apidocs/typealiasaxaigooglegeminibatchembedresponse) | AxAIGoogleGeminiEmbedResponse: Structure for handling responses from the Google Gemini API embedding requests. |
| [AxAIGoogleGeminiChatRequest](/api/#03-apidocs/typealiasaxaigooglegeminichatrequest) | - |
| [AxAIGoogleGeminiChatResponse](/api/#03-apidocs/typealiasaxaigooglegeminichatresponse) | - |
| [AxAIGoogleGeminiChatResponseDelta](/api/#03-apidocs/typealiasaxaigooglegeminichatresponsedelta) | - |
| [AxAIGoogleGeminiConfig](/api/#03-apidocs/typealiasaxaigooglegeminiconfig) | AxAIGoogleGeminiConfig: Configuration options for Google Gemini API |
| [AxAIGoogleGeminiContent](/api/#03-apidocs/typealiasaxaigooglegeminicontent) | - |
| [AxAIGoogleGeminiGenerationConfig](/api/#03-apidocs/typealiasaxaigooglegeminigenerationconfig) | - |
| [AxAIGoogleGeminiSafetySettings](/api/#03-apidocs/typealiasaxaigooglegeminisafetysettings) | - |
| [AxAIGoogleGeminiThinkingConfig](/api/#03-apidocs/typealiasaxaigooglegeminithinkingconfig) | - |
| [AxAIGoogleGeminiTool](/api/#03-apidocs/typealiasaxaigooglegeminitool) | - |
| [AxAIGoogleGeminiToolConfig](/api/#03-apidocs/typealiasaxaigooglegeminitoolconfig) | - |
| [AxAIGoogleGeminiToolFunctionDeclaration](/api/#03-apidocs/typealiasaxaigooglegeminitoolfunctiondeclaration) | - |
| [AxAIGoogleGeminiToolGoogleSearchRetrieval](/api/#03-apidocs/typealiasaxaigooglegeminitoolgooglesearchretrieval) | - |
| [AxAIGoogleVertexBatchEmbedRequest](/api/#03-apidocs/typealiasaxaigooglevertexbatchembedrequest) | AxAIGoogleVertexBatchEmbedRequest: Structure for making an embedding request to the Google Vertex API. |
| [AxAIGoogleVertexBatchEmbedResponse](/api/#03-apidocs/typealiasaxaigooglevertexbatchembedresponse) | AxAIGoogleVertexBatchEmbedResponse: Structure for handling responses from the Google Vertex API embedding requests. |
| [AxAIGrokArgs](/api/#03-apidocs/typealiasaxaigrokargs) | - |
| [AxAIGrokChatRequest](/api/#03-apidocs/typealiasaxaigrokchatrequest) | - |
| [AxAIGroqArgs](/api/#03-apidocs/typealiasaxaigroqargs) | - |
| [AxAIHuggingFaceConfig](/api/#03-apidocs/typealiasaxaihuggingfaceconfig) | - |
| [AxAIHuggingFaceRequest](/api/#03-apidocs/typealiasaxaihuggingfacerequest) | - |
| [AxAIHuggingFaceResponse](/api/#03-apidocs/typealiasaxaihuggingfaceresponse) | - |
| [AxAIInputModelList](/api/#03-apidocs/typealiasaxaiinputmodellist) | - |
| [AxAIMistralArgs](/api/#03-apidocs/typealiasaxaimistralargs) | - |
| [AxAIModelList](/api/#03-apidocs/typealiasaxaimodellist) | - |
| [AxAIModelListBase](/api/#03-apidocs/typealiasaxaimodellistbase) | - |
| [AxAIModels](/api/#03-apidocs/typealiasaxaimodels) | - |
| [AxAIOllamaAIConfig](/api/#03-apidocs/typealiasaxaiollamaaiconfig) | - |
| [AxAIOllamaArgs](/api/#03-apidocs/typealiasaxaiollamaargs) | - |
| [AxAIOpenAIChatRequest](/api/#03-apidocs/typealiasaxaiopenaichatrequest) | - |
| [AxAIOpenAIChatResponse](/api/#03-apidocs/typealiasaxaiopenaichatresponse) | - |
| [AxAIOpenAIChatResponseDelta](/api/#03-apidocs/typealiasaxaiopenaichatresponsedelta) | - |
| [AxAIOpenAIConfig](/api/#03-apidocs/typealiasaxaiopenaiconfig) | - |
| [AxAIOpenAIEmbedRequest](/api/#03-apidocs/typealiasaxaiopenaiembedrequest) | - |
| [AxAIOpenAIEmbedResponse](/api/#03-apidocs/typealiasaxaiopenaiembedresponse) | - |
| [AxAIOpenAILogprob](/api/#03-apidocs/typealiasaxaiopenailogprob) | - |
| [AxAIOpenAIResponsesConfig](/api/#03-apidocs/typealiasaxaiopenairesponsesconfig) | - |
| [AxAIOpenAIResponsesInputContentPart](/api/#03-apidocs/typealiasaxaiopenairesponsesinputcontentpart) | - |
| [AxAIOpenAIResponsesInputItem](/api/#03-apidocs/typealiasaxaiopenairesponsesinputitem) | - |
| [AxAIOpenAIResponsesOutputItem](/api/#03-apidocs/typealiasaxaiopenairesponsesoutputitem) | - |
| [AxAIOpenAIResponsesStreamEvent](/api/#03-apidocs/typealiasaxaiopenairesponsesstreamevent) | - |
| [AxAIOpenAIResponsesToolCall](/api/#03-apidocs/typealiasaxaiopenairesponsestoolcall) | - |
| [AxAIOpenAIResponsesToolChoice](/api/#03-apidocs/typealiasaxaiopenairesponsestoolchoice) | - |
| [AxAIOpenAIResponsesToolDefinition](/api/#03-apidocs/typealiasaxaiopenairesponsestooldefinition) | - |
| [AxAIOpenAIUsage](/api/#03-apidocs/typealiasaxaiopenaiusage) | - |
| [AxAIPromptConfig](/api/#03-apidocs/typealiasaxaipromptconfig) | - |
| [AxAIRekaChatRequest](/api/#03-apidocs/typealiasaxairekachatrequest) | - |
| [AxAIRekaChatResponse](/api/#03-apidocs/typealiasaxairekachatresponse) | - |
| [AxAIRekaChatResponseDelta](/api/#03-apidocs/typealiasaxairekachatresponsedelta) | - |
| [AxAIRekaConfig](/api/#03-apidocs/typealiasaxairekaconfig) | - |
| [AxAIRekaUsage](/api/#03-apidocs/typealiasaxairekausage) | - |
| [AxAIServiceActionOptions](/api/#03-apidocs/typealiasaxaiserviceactionoptions) | - |
| [AxAIServiceOptions](/api/#03-apidocs/typealiasaxaiserviceoptions) | - |
| [AxAITogetherArgs](/api/#03-apidocs/typealiasaxaitogetherargs) | - |
| [AxBalancerOptions](/api/#03-apidocs/typealiasaxbalanceroptions) | Options for the balancer. |
| [AxChatRequest](/api/#03-apidocs/typealiasaxchatrequest) | - |
| [AxChatResponse](/api/#03-apidocs/typealiasaxchatresponse) | - |
| [AxChatResponseFunctionCall](/api/#03-apidocs/typealiasaxchatresponsefunctioncall) | - |
| [AxChatResponseResult](/api/#03-apidocs/typealiasaxchatresponseresult) | - |
| [AxDataRow](/api/#03-apidocs/typealiasaxdatarow) | - |
| [AxDBArgs](/api/#03-apidocs/typealiasaxdbargs) | - |
| [AxDBCloudflareOpOptions](/api/#03-apidocs/typealiasaxdbcloudflareopoptions) | - |
| [AxDBMemoryOpOptions](/api/#03-apidocs/typealiasaxdbmemoryopoptions) | - |
| [AxDBPineconeOpOptions](/api/#03-apidocs/typealiasaxdbpineconeopoptions) | - |
| [AxDBQueryRequest](/api/#03-apidocs/typealiasaxdbqueryrequest) | - |
| [AxDBQueryResponse](/api/#03-apidocs/typealiasaxdbqueryresponse) | - |
| [AxDBState](/api/#03-apidocs/typealiasaxdbstate) | - |
| [AxDBUpsertRequest](/api/#03-apidocs/typealiasaxdbupsertrequest) | - |
| [AxDBUpsertResponse](/api/#03-apidocs/typealiasaxdbupsertresponse) | - |
| [AxDBWeaviateOpOptions](/api/#03-apidocs/typealiasaxdbweaviateopoptions) | - |
| [AxEmbedRequest](/api/#03-apidocs/typealiasaxembedrequest) | - |
| [AxEmbedResponse](/api/#03-apidocs/typealiasaxembedresponse) | - |
| [AxEvaluateArgs](/api/#03-apidocs/typealiasaxevaluateargs) | - |
| [AxExample](/api/#03-apidocs/typealiasaxexample) | - |
| [AxFieldProcessorProcess](/api/#03-apidocs/typealiasaxfieldprocessorprocess) | - |
| [AxFieldTemplateFn](/api/#03-apidocs/typealiasaxfieldtemplatefn) | - |
| [AxFieldValue](/api/#03-apidocs/typealiasaxfieldvalue) | - |
| [AxFunction](/api/#03-apidocs/typealiasaxfunction) | - |
| [AxFunctionHandler](/api/#03-apidocs/typealiasaxfunctionhandler) | - |
| [AxFunctionJSONSchema](/api/#03-apidocs/typealiasaxfunctionjsonschema) | - |
| [AxGenDeltaOut](/api/#03-apidocs/typealiasaxgendeltaout) | - |
| [AxGenerateErrorDetails](/api/#03-apidocs/typealiasaxgenerateerrordetails) | - |
| [AxGenerateResult](/api/#03-apidocs/typealiasaxgenerateresult) | - |
| [AxGenIn](/api/#03-apidocs/typealiasaxgenin) | - |
| [AxGenOut](/api/#03-apidocs/typealiasaxgenout) | - |
| [AxGenStreamingOut](/api/#03-apidocs/typealiasaxgenstreamingout) | - |
| [AxIField](/api/#03-apidocs/typealiasaxifield) | - |
| [AxInputFunctionType](/api/#03-apidocs/typealiasaxinputfunctiontype) | - |
| [AxInternalChatRequest](/api/#03-apidocs/typealiasaxinternalchatrequest) | - |
| [AxInternalEmbedRequest](/api/#03-apidocs/typealiasaxinternalembedrequest) | - |
| [AxLoggerFunction](/api/#03-apidocs/typealiasaxloggerfunction) | - |
| [AxLoggerTag](/api/#03-apidocs/typealiasaxloggertag) | - |
| [AxMessage](/api/#03-apidocs/typealiasaxmessage) | - |
| [AxMetricFn](/api/#03-apidocs/typealiasaxmetricfn) | - |
| [AxMetricFnArgs](/api/#03-apidocs/typealiasaxmetricfnargs) | - |
| [AxMockAIServiceConfig](/api/#03-apidocs/typealiasaxmockaiserviceconfig) | - |
| [AxModelConfig](/api/#03-apidocs/typealiasaxmodelconfig) | - |
| [AxModelInfo](/api/#03-apidocs/typealiasaxmodelinfo) | - |
| [AxModelInfoWithProvider](/api/#03-apidocs/typealiasaxmodelinfowithprovider) | - |
| [AxModelUsage](/api/#03-apidocs/typealiasaxmodelusage) | - |
| [AxOptimizerArgs](/api/#03-apidocs/typealiasaxoptimizerargs) | - |
| [AxProgramDemos](/api/#03-apidocs/typealiasaxprogramdemos) | - |
| [AxProgramExamples](/api/#03-apidocs/typealiasaxprogramexamples) | - |
| [AxProgramForwardOptions](/api/#03-apidocs/typealiasaxprogramforwardoptions) | - |
| [AxProgramStreamingForwardOptions](/api/#03-apidocs/typealiasaxprogramstreamingforwardoptions) | - |
| [AxProgramTrace](/api/#03-apidocs/typealiasaxprogramtrace) | - |
| [AxProgramUsage](/api/#03-apidocs/typealiasaxprogramusage) | - |
| [AxRateLimiterFunction](/api/#03-apidocs/typealiasaxratelimiterfunction) | - |
| [AxRerankerIn](/api/#03-apidocs/typealiasaxrerankerin) | - |
| [AxRerankerOut](/api/#03-apidocs/typealiasaxrerankerout) | - |
| [AxRewriteIn](/api/#03-apidocs/typealiasaxrewritein) | - |
| [AxRewriteOut](/api/#03-apidocs/typealiasaxrewriteout) | - |
| [AxSetExamplesOptions](/api/#03-apidocs/typealiasaxsetexamplesoptions) | - |
| [AxSignatureTemplateValue](/api/#03-apidocs/typealiasaxsignaturetemplatevalue) | - |
| [AxStreamingFieldProcessorProcess](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) | - |
| [AxTokenUsage](/api/#03-apidocs/typealiasaxtokenusage) | - |

## Variables

| Variable | Description |
| :------ | :------ |
| [AxEvalUtil](/api/#03-apidocs/variableaxevalutil) | - |
| [axField](/api/#03-apidocs/variableaxfield) | - |
| [axModelInfoAnthropic](/api/#03-apidocs/variableaxmodelinfoanthropic) | - |
| [axModelInfoCohere](/api/#03-apidocs/variableaxmodelinfocohere) | - |
| [axModelInfoDeepSeek](/api/#03-apidocs/variableaxmodelinfodeepseek) | - |
| [axModelInfoGoogleGemini](/api/#03-apidocs/variableaxmodelinfogooglegemini) | AxAIGoogleGemini: Model information |
| [axModelInfoGrok](/api/#03-apidocs/variableaxmodelinfogrok) | - |
| [axModelInfoGroq](/api/#03-apidocs/variableaxmodelinfogroq) | AxAIGroq: Model information |
| [axModelInfoHuggingFace](/api/#03-apidocs/variableaxmodelinfohuggingface) | HuggingFace: Model information |
| [axModelInfoMistral](/api/#03-apidocs/variableaxmodelinfomistral) | - |
| [axModelInfoOpenAI](/api/#03-apidocs/variableaxmodelinfoopenai) | OpenAI: Model information |
| [axModelInfoReka](/api/#03-apidocs/variableaxmodelinforeka) | OpenAI: Model information |
| [axModelInfoTogether](/api/#03-apidocs/variableaxmodelinfotogether) | - |
| [axSpanAttributes](/api/#03-apidocs/variableaxspanattributes) | - |
| [axSpanEvents](/api/#03-apidocs/variableaxspanevents) | - |
| [AxStringUtil](/api/#03-apidocs/variableaxstringutil) | - |

## Functions

| Function | Description |
| :------ | :------ |
| [ax](/api/#03-apidocs/functionax) | - |
| [axAIAnthropicDefaultConfig](/api/#03-apidocs/functionaxaianthropicdefaultconfig) | - |
| [axAIAnthropicVertexDefaultConfig](/api/#03-apidocs/functionaxaianthropicvertexdefaultconfig) | - |
| [axAIAzureOpenAIBestConfig](/api/#03-apidocs/functionaxaiazureopenaibestconfig) | - |
| [axAIAzureOpenAICreativeConfig](/api/#03-apidocs/functionaxaiazureopenaicreativeconfig) | - |
| [axAIAzureOpenAIDefaultConfig](/api/#03-apidocs/functionaxaiazureopenaidefaultconfig) | - |
| [axAIAzureOpenAIFastConfig](/api/#03-apidocs/functionaxaiazureopenaifastconfig) | - |
| [axAICohereCreativeConfig](/api/#03-apidocs/functionaxaicoherecreativeconfig) | - |
| [axAICohereDefaultConfig](/api/#03-apidocs/functionaxaicoheredefaultconfig) | - |
| [axAIDeepSeekCodeConfig](/api/#03-apidocs/functionaxaideepseekcodeconfig) | - |
| [axAIDeepSeekDefaultConfig](/api/#03-apidocs/functionaxaideepseekdefaultconfig) | - |
| [axAIGoogleGeminiDefaultConfig](/api/#03-apidocs/functionaxaigooglegeminidefaultconfig) | AxAIGoogleGemini: Default Model options for text generation |
| [axAIGoogleGeminiDefaultCreativeConfig](/api/#03-apidocs/functionaxaigooglegeminidefaultcreativeconfig) | - |
| [axAIGrokBestConfig](/api/#03-apidocs/functionaxaigrokbestconfig) | - |
| [axAIGrokDefaultConfig](/api/#03-apidocs/functionaxaigrokdefaultconfig) | - |
| [axAIHuggingFaceCreativeConfig](/api/#03-apidocs/functionaxaihuggingfacecreativeconfig) | - |
| [axAIHuggingFaceDefaultConfig](/api/#03-apidocs/functionaxaihuggingfacedefaultconfig) | - |
| [axAIMistralBestConfig](/api/#03-apidocs/functionaxaimistralbestconfig) | - |
| [axAIMistralDefaultConfig](/api/#03-apidocs/functionaxaimistraldefaultconfig) | - |
| [axAIOllamaDefaultConfig](/api/#03-apidocs/functionaxaiollamadefaultconfig) | - |
| [axAIOllamaDefaultCreativeConfig](/api/#03-apidocs/functionaxaiollamadefaultcreativeconfig) | - |
| [axAIOpenAIBestConfig](/api/#03-apidocs/functionaxaiopenaibestconfig) | - |
| [axAIOpenAICreativeConfig](/api/#03-apidocs/functionaxaiopenaicreativeconfig) | - |
| [axAIOpenAIDefaultConfig](/api/#03-apidocs/functionaxaiopenaidefaultconfig) | - |
| [axAIOpenAIFastConfig](/api/#03-apidocs/functionaxaiopenaifastconfig) | - |
| [axAIOpenAIResponsesBestConfig](/api/#03-apidocs/functionaxaiopenairesponsesbestconfig) | - |
| [axAIOpenAIResponsesCreativeConfig](/api/#03-apidocs/functionaxaiopenairesponsescreativeconfig) | - |
| [axAIOpenAIResponsesDefaultConfig](/api/#03-apidocs/functionaxaiopenairesponsesdefaultconfig) | - |
| [axAIRekaBestConfig](/api/#03-apidocs/functionaxairekabestconfig) | - |
| [axAIRekaCreativeConfig](/api/#03-apidocs/functionaxairekacreativeconfig) | - |
| [axAIRekaDefaultConfig](/api/#03-apidocs/functionaxairekadefaultconfig) | - |
| [axAIRekaFastConfig](/api/#03-apidocs/functionaxairekafastconfig) | - |
| [axAITogetherDefaultConfig](/api/#03-apidocs/functionaxaitogetherdefaultconfig) | - |
| [axBaseAIDefaultConfig](/api/#03-apidocs/functionaxbaseaidefaultconfig) | - |
| [axBaseAIDefaultCreativeConfig](/api/#03-apidocs/functionaxbaseaidefaultcreativeconfig) | - |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAgent.md
================================================
---
title: AxAgent
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L158

An AI agent that can process inputs using an AI service and coordinate with child agents.
Supports features like smart model routing and automatic input field passing to child agents.

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `IN` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) | - |
| `OUT` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) | [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |

## Implements

- [`AxAgentic`](/api/#03-apidocs/interfaceaxagentic)

## Constructors

<a id="constructors"></a>

### new AxAgent()

```ts
new AxAgent<IN, OUT>(__namedParameters: Readonly<{
  agents: AxAgentic[];
  ai: Readonly<AxAIService<unknown, unknown>>;
  definition: string;
  description: string;
  functions: AxInputFunctionType;
  name: string;
  signature: string | AxSignature;
}>, options?: Readonly<AxAgentOptions>): AxAgent<IN, OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L173

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<\{ `agents`: [`AxAgentic`](/api/#03-apidocs/interfaceaxagentic)[]; `ai`: `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\>; `definition`: `string`; `description`: `string`; `functions`: [`AxInputFunctionType`](/api/#03-apidocs/typealiasaxinputfunctiontype); `name`: `string`; `signature`: `string` \| [`AxSignature`](/api/#03-apidocs/classaxsignature); \}\> |
| `options`? | `Readonly`\<[`AxAgentOptions`](/api/#03-apidocs/typealiasaxagentoptions)\> |

#### Returns

[`AxAgent`](/api/#03-apidocs/classaxagent)\<`IN`, `OUT`\>

## Methods

<a id="forward"></a>

### forward()

```ts
forward(
   parentAi: Readonly<AxAIService<unknown, unknown>>, 
   values: IN | AxMessage<IN>[], 
options?: Readonly<AxProgramForwardOptions>): Promise<OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L380

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentAi` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`Promise`\<`OUT`\>

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(): AxAgentFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L328

#### Returns

[`AxAgentFeatures`](/api/#03-apidocs/interfaceaxagentfeatures)

#### Implementation of

[`AxAgentic`](/api/#03-apidocs/interfaceaxagentic).[`getFeatures`](/api/#03-apidocs/interfaceaxagenticmdgetfeatures)

***

<a id="getFunction"></a>

### getFunction()

```ts
getFunction(): AxFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L274

#### Returns

[`AxFunction`](/api/#03-apidocs/typealiasaxfunction)

#### Implementation of

[`AxAgentic`](/api/#03-apidocs/interfaceaxagentic).[`getFunction`](/api/#03-apidocs/interfaceaxagenticmdgetfunction)

***

<a id="getTraces"></a>

### getTraces()

```ts
getTraces(): AxProgramTrace[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L258

#### Returns

[`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[]

#### Implementation of

[`AxAgentic`](/api/#03-apidocs/interfaceaxagentic).[`getTraces`](/api/#03-apidocs/interfaceaxagenticmdgettraces)

***

<a id="getUsage"></a>

### getUsage()

```ts
getUsage(): AxModelUsage & object[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L266

#### Returns

[`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[]

#### Implementation of

[`AxAgentic`](/api/#03-apidocs/interfaceaxagentic).[`getUsage`](/api/#03-apidocs/interfaceaxagenticmdgetusage)

***

<a id="resetUsage"></a>

### resetUsage()

```ts
resetUsage(): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L270

#### Returns

`void`

#### Implementation of

[`AxAgentic`](/api/#03-apidocs/interfaceaxagentic).[`resetUsage`](/api/#03-apidocs/interfaceaxagenticmdresetusage)

***

<a id="setDefinition"></a>

### setDefinition()

```ts
setDefinition(definition: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L422

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `definition` | `string` |

#### Returns

`void`

***

<a id="setDemos"></a>

### setDemos()

```ts
setDemos(demos: readonly AxProgramDemos[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L262

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `demos` | readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[] |

#### Returns

`void`

#### Implementation of

[`AxAgentic`](/api/#03-apidocs/interfaceaxagentic).[`setDemos`](/api/#03-apidocs/interfaceaxagenticmdsetdemos)

***

<a id="setDescription"></a>

### setDescription()

```ts
setDescription(description: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L413

Updates the agent's description.
This updates both the stored description and the function's description.

#### Parameters

| Parameter | Type | Description |
| :------ | :------ | :------ |
| `description` | `string` | New description for the agent (must be at least 20 characters) |

#### Returns

`void`

#### Throws

Error if description is too short

***

<a id="setExamples"></a>

### setExamples()

```ts
setExamples(examples: Readonly<AxProgramExamples>, options?: Readonly<AxSetExamplesOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L243

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `examples` | `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\> |
| `options`? | `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\> |

#### Returns

`void`

#### Implementation of

[`AxAgentic`](/api/#03-apidocs/interfaceaxagentic).[`setExamples`](/api/#03-apidocs/interfaceaxagenticmdsetexamples)

***

<a id="setId"></a>

### setId()

```ts
setId(id: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L250

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `id` | `string` |

#### Returns

`void`

#### Implementation of

[`AxAgentic`](/api/#03-apidocs/interfaceaxagentic).[`setId`](/api/#03-apidocs/interfaceaxagenticmdsetid)

***

<a id="setParentId"></a>

### setParentId()

```ts
setParentId(parentId: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L254

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentId` | `string` |

#### Returns

`void`

#### Implementation of

[`AxAgentic`](/api/#03-apidocs/interfaceaxagentic).[`setParentId`](/api/#03-apidocs/interfaceaxagenticmdsetparentid)

***

<a id="streamingForward"></a>

### streamingForward()

```ts
streamingForward(
   parentAi: Readonly<AxAIService<unknown, unknown>>, 
   values: IN | AxMessage<IN>[], 
options?: Readonly<AxProgramStreamingForwardOptions>): AxGenStreamingOut<OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L393

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentAi` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `options`? | `Readonly`\<[`AxProgramStreamingForwardOptions`](/api/#03-apidocs/typealiasaxprogramstreamingforwardoptions)\> |

#### Returns

[`AxGenStreamingOut`](/api/#03-apidocs/typealiasaxgenstreamingout)\<`OUT`\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAI.md
================================================
---
title: AxAI
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L86

## Implements

- [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)

## Constructors

<a id="constructors"></a>

### new AxAI()

```ts
new AxAI(options: Readonly<AxAIArgs>): AxAI
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L89

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIArgs`](/api/#03-apidocs/typealiasaxaiargs)\> |

#### Returns

[`AxAI`](/api/#03-apidocs/classaxai)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L167

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`chat`](/api/#03-apidocs/interfaceaxaiservicemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest>, options?: Readonly<AxAIServiceActionOptions>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L174

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`embed`](/api/#03-apidocs/interfaceaxaiservicemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: string): object
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L143

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | `string` |

#### Returns

`object`

| Name | Type |
| :------ | :------ |
| <a id="functions"></a> `functions` | `boolean` |
| <a id="streaming"></a> `streaming` | `boolean` |

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getFeatures`](/api/#03-apidocs/interfaceaxaiservicemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L139

#### Returns

`string`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getId`](/api/#03-apidocs/interfaceaxaiservicemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): unknown
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L151

#### Returns

`unknown`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLastUsedChatModel`](/api/#03-apidocs/interfaceaxaiservicemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): unknown
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L155

#### Returns

`unknown`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLastUsedEmbedModel`](/api/#03-apidocs/interfaceaxaiservicemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L159

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLastUsedModelConfig`](/api/#03-apidocs/interfaceaxaiservicemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L189

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLogger`](/api/#03-apidocs/interfaceaxaiservicemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L163

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getMetrics`](/api/#03-apidocs/interfaceaxaiservicemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L147

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getModelList`](/api/#03-apidocs/interfaceaxaiservicemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L135

#### Returns

`string`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getName`](/api/#03-apidocs/interfaceaxaiservicemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L185

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getOptions`](/api/#03-apidocs/interfaceaxaiservicemdgetoptions)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L181

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`setOptions`](/api/#03-apidocs/interfaceaxaiservicemdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIAnthropic.md
================================================
---
title: AxAIAnthropic
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/api.ts#L350

## Extends

- [`AxBaseAI`](/api/#03-apidocs/classaxbaseai)\<
  \| [`AxAIAnthropicModel`](/api/#03-apidocs/enumerationaxaianthropicmodel)
  \| [`AxAIAnthropicVertexModel`](/api/#03-apidocs/enumerationaxaianthropicvertexmodel), `unknown`, [`AxAIAnthropicChatRequest`](/api/#03-apidocs/typealiasaxaianthropicchatrequest), `unknown`, [`AxAIAnthropicChatResponse`](/api/#03-apidocs/typealiasaxaianthropicchatresponse), [`AxAIAnthropicChatResponseDelta`](/api/#03-apidocs/typealiasaxaianthropicchatresponsedelta), `unknown`\>

## Constructors

<a id="constructors"></a>

### new AxAIAnthropic()

```ts
new AxAIAnthropic(__namedParameters: Readonly<Omit<AxAIAnthropicArgs, "name">>): AxAIAnthropic
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/api.ts#L359

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIAnthropicArgs`](/api/#03-apidocs/interfaceaxaianthropicargs), `"name"`\>\> |

#### Returns

[`AxAIAnthropic`](/api/#03-apidocs/classaxaianthropic)

#### Overrides

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`constructor`](/api/#03-apidocs/classaxbaseaimdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<
  | AxAIAnthropicModel
  | AxAIAnthropicVertexModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<
  | AxAIAnthropicModel
  | AxAIAnthropicVertexModel, unknown>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\< \| [`AxAIAnthropicModel`](/api/#03-apidocs/enumerationaxaianthropicmodel) \| [`AxAIAnthropicVertexModel`](/api/#03-apidocs/enumerationaxaianthropicvertexmodel)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\< \| [`AxAIAnthropicModel`](/api/#03-apidocs/enumerationaxaianthropicmodel) \| [`AxAIAnthropicVertexModel`](/api/#03-apidocs/enumerationaxaianthropicvertexmodel), `unknown`\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`chat`](/api/#03-apidocs/classaxbaseaimdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<unknown>>, options?: Readonly<AxAIServiceActionOptions<
  | AxAIAnthropicModel
| AxAIAnthropicVertexModel, unknown>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<`unknown`\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\< \| [`AxAIAnthropicModel`](/api/#03-apidocs/enumerationaxaianthropicmodel) \| [`AxAIAnthropicVertexModel`](/api/#03-apidocs/enumerationaxaianthropicvertexmodel), `unknown`\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`embed`](/api/#03-apidocs/classaxbaseaimdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: 
  | AxAIAnthropicModel
  | AxAIAnthropicVertexModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | \| [`AxAIAnthropicModel`](/api/#03-apidocs/enumerationaxaianthropicmodel) \| [`AxAIAnthropicVertexModel`](/api/#03-apidocs/enumerationaxaianthropicvertexmodel) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getFeatures`](/api/#03-apidocs/classaxbaseaimdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getId`](/api/#03-apidocs/classaxbaseaimdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): 
  | undefined
  | AxAIAnthropicModel
  | AxAIAnthropicVertexModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

  \| `undefined`
  \| [`AxAIAnthropicModel`](/api/#03-apidocs/enumerationaxaianthropicmodel)
  \| [`AxAIAnthropicVertexModel`](/api/#03-apidocs/enumerationaxaianthropicvertexmodel)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedChatModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): unknown
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

`unknown`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxbaseaimdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLogger`](/api/#03-apidocs/classaxbaseaimdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getMetrics`](/api/#03-apidocs/classaxbaseaimdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getModelList`](/api/#03-apidocs/classaxbaseaimdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getName`](/api/#03-apidocs/classaxbaseaimdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getOptions`](/api/#03-apidocs/classaxbaseaimdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setAPIURL`](/api/#03-apidocs/classaxbaseaimdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setHeaders`](/api/#03-apidocs/classaxbaseaimdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setName`](/api/#03-apidocs/classaxbaseaimdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setOptions`](/api/#03-apidocs/classaxbaseaimdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIAzureOpenAI.md
================================================
---
title: AxAIAzureOpenAI
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/azure-openai/api.ts#L40

## Extends

- [`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase)\<[`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel), [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)\>

## Constructors

<a id="constructors"></a>

### new AxAIAzureOpenAI()

```ts
new AxAIAzureOpenAI(__namedParameters: Readonly<Omit<AxAIAzureOpenAIArgs, "name">>): AxAIAzureOpenAI
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/azure-openai/api.ts#L44

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIAzureOpenAIArgs`](/api/#03-apidocs/typealiasaxaiazureopenaiargs), `"name"`\>\> |

#### Returns

[`AxAIAzureOpenAI`](/api/#03-apidocs/classaxaiazureopenai)

#### Overrides

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`constructor`](/api/#03-apidocs/classaxaiopenaibasemdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<AxAIOpenAIModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<AxAIOpenAIModel, AxAIOpenAIEmbedModel>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<[`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel), [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`chat`](/api/#03-apidocs/classaxaiopenaibasemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<AxAIOpenAIEmbedModel>>, options?: Readonly<AxAIServiceActionOptions<AxAIOpenAIModel, AxAIOpenAIEmbedModel>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<[`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel), [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`embed`](/api/#03-apidocs/classaxaiopenaibasemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: AxAIOpenAIModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | [`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getFeatures`](/api/#03-apidocs/classaxaiopenaibasemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getId`](/api/#03-apidocs/classaxaiopenaibasemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | AxAIOpenAIModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| [`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedChatModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): 
  | undefined
  | AxAIOpenAIEmbedModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

  \| `undefined`
  \| [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLogger`](/api/#03-apidocs/classaxaiopenaibasemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getMetrics`](/api/#03-apidocs/classaxaiopenaibasemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getModelList`](/api/#03-apidocs/classaxaiopenaibasemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getName`](/api/#03-apidocs/classaxaiopenaibasemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getOptions`](/api/#03-apidocs/classaxaiopenaibasemdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setAPIURL`](/api/#03-apidocs/classaxaiopenaibasemdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setHeaders`](/api/#03-apidocs/classaxaiopenaibasemdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setName`](/api/#03-apidocs/classaxaiopenaibasemdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setOptions`](/api/#03-apidocs/classaxaiopenaibasemdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAICohere.md
================================================
---
title: AxAICohere
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/api.ts#L298

## Extends

- [`AxBaseAI`](/api/#03-apidocs/classaxbaseai)\<[`AxAICohereModel`](/api/#03-apidocs/enumerationaxaicoheremodel), [`AxAICohereEmbedModel`](/api/#03-apidocs/enumerationaxaicohereembedmodel), [`AxAICohereChatRequest`](/api/#03-apidocs/typealiasaxaicoherechatrequest), [`AxAICohereEmbedRequest`](/api/#03-apidocs/typealiasaxaicohereembedrequest), [`AxAICohereChatResponse`](/api/#03-apidocs/typealiasaxaicoherechatresponse), [`AxAICohereChatResponseDelta`](/api/#03-apidocs/typealiasaxaicoherechatresponsedelta), [`AxAICohereEmbedResponse`](/api/#03-apidocs/typealiasaxaicohereembedresponse)\>

## Constructors

<a id="constructors"></a>

### new AxAICohere()

```ts
new AxAICohere(__namedParameters: Readonly<Omit<AxAICohereArgs, "name">>): AxAICohere
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/api.ts#L307

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAICohereArgs`](/api/#03-apidocs/interfaceaxaicohereargs), `"name"`\>\> |

#### Returns

[`AxAICohere`](/api/#03-apidocs/classaxaicohere)

#### Overrides

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`constructor`](/api/#03-apidocs/classaxbaseaimdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<AxAICohereModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<AxAICohereModel, AxAICohereEmbedModel>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<[`AxAICohereModel`](/api/#03-apidocs/enumerationaxaicoheremodel)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAICohereModel`](/api/#03-apidocs/enumerationaxaicoheremodel), [`AxAICohereEmbedModel`](/api/#03-apidocs/enumerationaxaicohereembedmodel)\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`chat`](/api/#03-apidocs/classaxbaseaimdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<AxAICohereEmbedModel>>, options?: Readonly<AxAIServiceActionOptions<AxAICohereModel, AxAICohereEmbedModel>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<[`AxAICohereEmbedModel`](/api/#03-apidocs/enumerationaxaicohereembedmodel)\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAICohereModel`](/api/#03-apidocs/enumerationaxaicoheremodel), [`AxAICohereEmbedModel`](/api/#03-apidocs/enumerationaxaicohereembedmodel)\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`embed`](/api/#03-apidocs/classaxbaseaimdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: AxAICohereModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | [`AxAICohereModel`](/api/#03-apidocs/enumerationaxaicoheremodel) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getFeatures`](/api/#03-apidocs/classaxbaseaimdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getId`](/api/#03-apidocs/classaxbaseaimdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | AxAICohereModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| [`AxAICohereModel`](/api/#03-apidocs/enumerationaxaicoheremodel)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedChatModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): 
  | undefined
  | AxAICohereEmbedModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

  \| `undefined`
  \| [`AxAICohereEmbedModel`](/api/#03-apidocs/enumerationaxaicohereembedmodel)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxbaseaimdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLogger`](/api/#03-apidocs/classaxbaseaimdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getMetrics`](/api/#03-apidocs/classaxbaseaimdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getModelList`](/api/#03-apidocs/classaxbaseaimdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getName`](/api/#03-apidocs/classaxbaseaimdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getOptions`](/api/#03-apidocs/classaxbaseaimdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setAPIURL`](/api/#03-apidocs/classaxbaseaimdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setHeaders`](/api/#03-apidocs/classaxbaseaimdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setName`](/api/#03-apidocs/classaxbaseaimdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setOptions`](/api/#03-apidocs/classaxbaseaimdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIDeepSeek.md
================================================
---
title: AxAIDeepSeek
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/deepseek/api.ts#L31

## Extends

- [`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase)\<[`AxAIDeepSeekModel`](/api/#03-apidocs/enumerationaxaideepseekmodel), `undefined`\>

## Constructors

<a id="constructors"></a>

### new AxAIDeepSeek()

```ts
new AxAIDeepSeek(__namedParameters: Readonly<Omit<AxAIDeepSeekArgs, "name">>): AxAIDeepSeek
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/deepseek/api.ts#L32

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIDeepSeekArgs`](/api/#03-apidocs/typealiasaxaideepseekargs), `"name"`\>\> |

#### Returns

[`AxAIDeepSeek`](/api/#03-apidocs/classaxaideepseek)

#### Overrides

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`constructor`](/api/#03-apidocs/classaxaiopenaibasemdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<AxAIDeepSeekModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<AxAIDeepSeekModel, undefined>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<[`AxAIDeepSeekModel`](/api/#03-apidocs/enumerationaxaideepseekmodel)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIDeepSeekModel`](/api/#03-apidocs/enumerationaxaideepseekmodel), `undefined`\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`chat`](/api/#03-apidocs/classaxaiopenaibasemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<undefined>>, options?: Readonly<AxAIServiceActionOptions<AxAIDeepSeekModel, undefined>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<`undefined`\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIDeepSeekModel`](/api/#03-apidocs/enumerationaxaideepseekmodel), `undefined`\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`embed`](/api/#03-apidocs/classaxaiopenaibasemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: AxAIDeepSeekModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | [`AxAIDeepSeekModel`](/api/#03-apidocs/enumerationaxaideepseekmodel) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getFeatures`](/api/#03-apidocs/classaxaiopenaibasemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getId`](/api/#03-apidocs/classaxaiopenaibasemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | AxAIDeepSeekModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| [`AxAIDeepSeekModel`](/api/#03-apidocs/enumerationaxaideepseekmodel)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedChatModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): undefined
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

`undefined`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLogger`](/api/#03-apidocs/classaxaiopenaibasemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getMetrics`](/api/#03-apidocs/classaxaiopenaibasemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getModelList`](/api/#03-apidocs/classaxaiopenaibasemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getName`](/api/#03-apidocs/classaxaiopenaibasemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getOptions`](/api/#03-apidocs/classaxaiopenaibasemdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setAPIURL`](/api/#03-apidocs/classaxaiopenaibasemdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setHeaders`](/api/#03-apidocs/classaxaiopenaibasemdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setName`](/api/#03-apidocs/classaxaiopenaibasemdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setOptions`](/api/#03-apidocs/classaxaiopenaibasemdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIGoogleGemini.md
================================================
---
title: AxAIGoogleGemini
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/api.ts#L574

AxAIGoogleGemini: AI Service

## Extends

- [`AxBaseAI`](/api/#03-apidocs/classaxbaseai)\<[`AxAIGoogleGeminiModel`](/api/#03-apidocs/enumerationaxaigooglegeminimodel), [`AxAIGoogleGeminiEmbedModel`](/api/#03-apidocs/enumerationaxaigooglegeminiembedmodel), [`AxAIGoogleGeminiChatRequest`](/api/#03-apidocs/typealiasaxaigooglegeminichatrequest), 
  \| [`AxAIGoogleGeminiBatchEmbedRequest`](/api/#03-apidocs/typealiasaxaigooglegeminibatchembedrequest)
  \| [`AxAIGoogleVertexBatchEmbedRequest`](/api/#03-apidocs/typealiasaxaigooglevertexbatchembedrequest), [`AxAIGoogleGeminiChatResponse`](/api/#03-apidocs/typealiasaxaigooglegeminichatresponse), [`AxAIGoogleGeminiChatResponseDelta`](/api/#03-apidocs/typealiasaxaigooglegeminichatresponsedelta), 
  \| [`AxAIGoogleGeminiBatchEmbedResponse`](/api/#03-apidocs/typealiasaxaigooglegeminibatchembedresponse)
  \| [`AxAIGoogleVertexBatchEmbedResponse`](/api/#03-apidocs/typealiasaxaigooglevertexbatchembedresponse)\>

## Constructors

<a id="constructors"></a>

### new AxAIGoogleGemini()

```ts
new AxAIGoogleGemini(__namedParameters: Readonly<Omit<AxAIGoogleGeminiArgs, "name">>): AxAIGoogleGemini
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/api.ts#L583

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIGoogleGeminiArgs`](/api/#03-apidocs/interfaceaxaigooglegeminiargs), `"name"`\>\> |

#### Returns

[`AxAIGoogleGemini`](/api/#03-apidocs/classaxaigooglegemini)

#### Overrides

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`constructor`](/api/#03-apidocs/classaxbaseaimdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<AxAIGoogleGeminiModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<AxAIGoogleGeminiModel, AxAIGoogleGeminiEmbedModel>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<[`AxAIGoogleGeminiModel`](/api/#03-apidocs/enumerationaxaigooglegeminimodel)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIGoogleGeminiModel`](/api/#03-apidocs/enumerationaxaigooglegeminimodel), [`AxAIGoogleGeminiEmbedModel`](/api/#03-apidocs/enumerationaxaigooglegeminiembedmodel)\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`chat`](/api/#03-apidocs/classaxbaseaimdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<AxAIGoogleGeminiEmbedModel>>, options?: Readonly<AxAIServiceActionOptions<AxAIGoogleGeminiModel, AxAIGoogleGeminiEmbedModel>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<[`AxAIGoogleGeminiEmbedModel`](/api/#03-apidocs/enumerationaxaigooglegeminiembedmodel)\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIGoogleGeminiModel`](/api/#03-apidocs/enumerationaxaigooglegeminimodel), [`AxAIGoogleGeminiEmbedModel`](/api/#03-apidocs/enumerationaxaigooglegeminiembedmodel)\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`embed`](/api/#03-apidocs/classaxbaseaimdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: AxAIGoogleGeminiModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | [`AxAIGoogleGeminiModel`](/api/#03-apidocs/enumerationaxaigooglegeminimodel) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getFeatures`](/api/#03-apidocs/classaxbaseaimdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getId`](/api/#03-apidocs/classaxbaseaimdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): 
  | undefined
  | AxAIGoogleGeminiModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

  \| `undefined`
  \| [`AxAIGoogleGeminiModel`](/api/#03-apidocs/enumerationaxaigooglegeminimodel)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedChatModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): 
  | undefined
  | AxAIGoogleGeminiEmbedModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

  \| `undefined`
  \| [`AxAIGoogleGeminiEmbedModel`](/api/#03-apidocs/enumerationaxaigooglegeminiembedmodel)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxbaseaimdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLogger`](/api/#03-apidocs/classaxbaseaimdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getMetrics`](/api/#03-apidocs/classaxbaseaimdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getModelList`](/api/#03-apidocs/classaxbaseaimdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getName`](/api/#03-apidocs/classaxbaseaimdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getOptions`](/api/#03-apidocs/classaxbaseaimdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setAPIURL`](/api/#03-apidocs/classaxbaseaimdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setHeaders`](/api/#03-apidocs/classaxbaseaimdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setName`](/api/#03-apidocs/classaxbaseaimdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setOptions`](/api/#03-apidocs/classaxbaseaimdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIGroq.md
================================================
---
title: AxAIGroq
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/groq/api.ts#L27

## Extends

- [`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase)\<[`AxAIGroqModel`](/api/#03-apidocs/enumerationaxaigroqmodel), `undefined`\>

## Constructors

<a id="constructors"></a>

### new AxAIGroq()

```ts
new AxAIGroq(__namedParameters: Readonly<Omit<AxAIGroqArgs, "name">>): AxAIGroq
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/groq/api.ts#L28

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIGroqArgs`](/api/#03-apidocs/typealiasaxaigroqargs), `"name"`\>\> |

#### Returns

[`AxAIGroq`](/api/#03-apidocs/classaxaigroq)

#### Overrides

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`constructor`](/api/#03-apidocs/classaxaiopenaibasemdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<AxAIGroqModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<AxAIGroqModel, undefined>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<[`AxAIGroqModel`](/api/#03-apidocs/enumerationaxaigroqmodel)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIGroqModel`](/api/#03-apidocs/enumerationaxaigroqmodel), `undefined`\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`chat`](/api/#03-apidocs/classaxaiopenaibasemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<undefined>>, options?: Readonly<AxAIServiceActionOptions<AxAIGroqModel, undefined>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<`undefined`\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIGroqModel`](/api/#03-apidocs/enumerationaxaigroqmodel), `undefined`\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`embed`](/api/#03-apidocs/classaxaiopenaibasemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: AxAIGroqModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | [`AxAIGroqModel`](/api/#03-apidocs/enumerationaxaigroqmodel) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getFeatures`](/api/#03-apidocs/classaxaiopenaibasemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getId`](/api/#03-apidocs/classaxaiopenaibasemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | AxAIGroqModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| [`AxAIGroqModel`](/api/#03-apidocs/enumerationaxaigroqmodel)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedChatModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): undefined
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

`undefined`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLogger`](/api/#03-apidocs/classaxaiopenaibasemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getMetrics`](/api/#03-apidocs/classaxaiopenaibasemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getModelList`](/api/#03-apidocs/classaxaiopenaibasemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getName`](/api/#03-apidocs/classaxaiopenaibasemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getOptions`](/api/#03-apidocs/classaxaiopenaibasemdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setAPIURL`](/api/#03-apidocs/classaxaiopenaibasemdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setHeaders`](/api/#03-apidocs/classaxaiopenaibasemdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setName`](/api/#03-apidocs/classaxaiopenaibasemdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/groq/api.ts#L71

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Overrides

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setOptions`](/api/#03-apidocs/classaxaiopenaibasemdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIHuggingFace.md
================================================
---
title: AxAIHuggingFace
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/huggingface/api.ts#L165

## Extends

- [`AxBaseAI`](/api/#03-apidocs/classaxbaseai)\<[`AxAIHuggingFaceModel`](/api/#03-apidocs/enumerationaxaihuggingfacemodel), `unknown`, [`AxAIHuggingFaceRequest`](/api/#03-apidocs/typealiasaxaihuggingfacerequest), `unknown`, [`AxAIHuggingFaceResponse`](/api/#03-apidocs/typealiasaxaihuggingfaceresponse), `unknown`, `unknown`\>

## Constructors

<a id="constructors"></a>

### new AxAIHuggingFace()

```ts
new AxAIHuggingFace(__namedParameters: Readonly<Omit<AxAIHuggingFaceArgs, "name">>): AxAIHuggingFace
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/huggingface/api.ts#L174

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIHuggingFaceArgs`](/api/#03-apidocs/interfaceaxaihuggingfaceargs), `"name"`\>\> |

#### Returns

[`AxAIHuggingFace`](/api/#03-apidocs/classaxaihuggingface)

#### Overrides

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`constructor`](/api/#03-apidocs/classaxbaseaimdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<MetaLlama270BChatHF>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<MetaLlama270BChatHF, unknown>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<[`MetaLlama270BChatHF`](/api/#03-apidocs/enumerationaxaihuggingfacemodelmdmetallama270bchathf)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`MetaLlama270BChatHF`](/api/#03-apidocs/enumerationaxaihuggingfacemodelmdmetallama270bchathf), `unknown`\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`chat`](/api/#03-apidocs/classaxbaseaimdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<unknown>>, options?: Readonly<AxAIServiceActionOptions<MetaLlama270BChatHF, unknown>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<`unknown`\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`MetaLlama270BChatHF`](/api/#03-apidocs/enumerationaxaihuggingfacemodelmdmetallama270bchathf), `unknown`\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`embed`](/api/#03-apidocs/classaxbaseaimdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: MetaLlama270BChatHF): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | [`MetaLlama270BChatHF`](/api/#03-apidocs/enumerationaxaihuggingfacemodelmdmetallama270bchathf) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getFeatures`](/api/#03-apidocs/classaxbaseaimdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getId`](/api/#03-apidocs/classaxbaseaimdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): 
  | undefined
  | MetaLlama270BChatHF
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

  \| `undefined`
  \| [`MetaLlama270BChatHF`](/api/#03-apidocs/enumerationaxaihuggingfacemodelmdmetallama270bchathf)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedChatModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): unknown
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

`unknown`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxbaseaimdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLogger`](/api/#03-apidocs/classaxbaseaimdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getMetrics`](/api/#03-apidocs/classaxbaseaimdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getModelList`](/api/#03-apidocs/classaxbaseaimdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getName`](/api/#03-apidocs/classaxbaseaimdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getOptions`](/api/#03-apidocs/classaxbaseaimdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setAPIURL`](/api/#03-apidocs/classaxbaseaimdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setHeaders`](/api/#03-apidocs/classaxbaseaimdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setName`](/api/#03-apidocs/classaxbaseaimdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setOptions`](/api/#03-apidocs/classaxbaseaimdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIMistral.md
================================================
---
title: AxAIMistral
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/mistral/api.ts#L35

## Extends

- [`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase)\<[`AxAIMistralModel`](/api/#03-apidocs/enumerationaxaimistralmodel), [`AxAIMistralEmbedModels`](/api/#03-apidocs/enumerationaxaimistralembedmodels)\>

## Constructors

<a id="constructors"></a>

### new AxAIMistral()

```ts
new AxAIMistral(__namedParameters: Readonly<Omit<AxAIMistralArgs, "name">>): AxAIMistral
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/mistral/api.ts#L39

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIMistralArgs`](/api/#03-apidocs/typealiasaxaimistralargs), `"name"`\>\> |

#### Returns

[`AxAIMistral`](/api/#03-apidocs/classaxaimistral)

#### Overrides

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`constructor`](/api/#03-apidocs/classaxaiopenaibasemdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<AxAIMistralModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<AxAIMistralModel, MistralEmbed>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<[`AxAIMistralModel`](/api/#03-apidocs/enumerationaxaimistralmodel)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIMistralModel`](/api/#03-apidocs/enumerationaxaimistralmodel), [`MistralEmbed`](/api/#03-apidocs/enumerationaxaimistralembedmodelsmdmistralembed)\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`chat`](/api/#03-apidocs/classaxaiopenaibasemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<MistralEmbed>>, options?: Readonly<AxAIServiceActionOptions<AxAIMistralModel, MistralEmbed>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<[`MistralEmbed`](/api/#03-apidocs/enumerationaxaimistralembedmodelsmdmistralembed)\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIMistralModel`](/api/#03-apidocs/enumerationaxaimistralmodel), [`MistralEmbed`](/api/#03-apidocs/enumerationaxaimistralembedmodelsmdmistralembed)\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`embed`](/api/#03-apidocs/classaxaiopenaibasemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: AxAIMistralModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | [`AxAIMistralModel`](/api/#03-apidocs/enumerationaxaimistralmodel) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getFeatures`](/api/#03-apidocs/classaxaiopenaibasemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getId`](/api/#03-apidocs/classaxaiopenaibasemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | AxAIMistralModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| [`AxAIMistralModel`](/api/#03-apidocs/enumerationaxaimistralmodel)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedChatModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): 
  | undefined
  | MistralEmbed
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

  \| `undefined`
  \| [`MistralEmbed`](/api/#03-apidocs/enumerationaxaimistralembedmodelsmdmistralembed)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLogger`](/api/#03-apidocs/classaxaiopenaibasemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getMetrics`](/api/#03-apidocs/classaxaiopenaibasemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getModelList`](/api/#03-apidocs/classaxaiopenaibasemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getName`](/api/#03-apidocs/classaxaiopenaibasemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getOptions`](/api/#03-apidocs/classaxaiopenaibasemdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setAPIURL`](/api/#03-apidocs/classaxaiopenaibasemdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setHeaders`](/api/#03-apidocs/classaxaiopenaibasemdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setName`](/api/#03-apidocs/classaxaiopenaibasemdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setOptions`](/api/#03-apidocs/classaxaiopenaibasemdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIOllama.md
================================================
---
title: AxAIOllama
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/ollama/api.ts#L33

OllamaAI: AI Service

## Extends

- [`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase)\<`string`, `string`\>

## Constructors

<a id="constructors"></a>

### new AxAIOllama()

```ts
new AxAIOllama(__namedParameters: Readonly<Omit<AxAIOllamaArgs, "name">>): AxAIOllama
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/ollama/api.ts#L34

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIOllamaArgs`](/api/#03-apidocs/typealiasaxaiollamaargs), `"name"`\>\> |

#### Returns

[`AxAIOllama`](/api/#03-apidocs/classaxaiollama)

#### Overrides

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`constructor`](/api/#03-apidocs/classaxaiopenaibasemdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<string>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<string, string>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<`string`\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<`string`, `string`\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`chat`](/api/#03-apidocs/classaxaiopenaibasemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<string>>, options?: Readonly<AxAIServiceActionOptions<string, string>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<`string`\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<`string`, `string`\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`embed`](/api/#03-apidocs/classaxaiopenaibasemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: string): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | `string` |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getFeatures`](/api/#03-apidocs/classaxaiopenaibasemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getId`](/api/#03-apidocs/classaxaiopenaibasemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| `string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedChatModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): undefined | string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

`undefined` \| `string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLogger`](/api/#03-apidocs/classaxaiopenaibasemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getMetrics`](/api/#03-apidocs/classaxaiopenaibasemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getModelList`](/api/#03-apidocs/classaxaiopenaibasemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getName`](/api/#03-apidocs/classaxaiopenaibasemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getOptions`](/api/#03-apidocs/classaxaiopenaibasemdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setAPIURL`](/api/#03-apidocs/classaxaiopenaibasemdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setHeaders`](/api/#03-apidocs/classaxaiopenaibasemdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setName`](/api/#03-apidocs/classaxaiopenaibasemdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setOptions`](/api/#03-apidocs/classaxaiopenaibasemdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIOpenAI.md
================================================
---
title: AxAIOpenAI
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/api.ts#L574

## Extends

- [`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase)\<[`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel), [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)\>

## Constructors

<a id="constructors"></a>

### new AxAIOpenAI()

```ts
new AxAIOpenAI(__namedParameters: Readonly<Omit<AxAIOpenAIArgs<"openai", AxAIOpenAIModel, AxAIOpenAIEmbedModel, AxAIOpenAIChatRequest<AxAIOpenAIModel>>, "name">>): AxAIOpenAI
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/api.ts#L578

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIOpenAIArgs`](/api/#03-apidocs/interfaceaxaiopenaiargs)\<`"openai"`, [`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel), [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel), [`AxAIOpenAIChatRequest`](/api/#03-apidocs/typealiasaxaiopenaichatrequest)\<[`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel)\>\>, `"name"`\>\> |

#### Returns

[`AxAIOpenAI`](/api/#03-apidocs/classaxaiopenai)

#### Overrides

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`constructor`](/api/#03-apidocs/classaxaiopenaibasemdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<AxAIOpenAIModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<AxAIOpenAIModel, AxAIOpenAIEmbedModel>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<[`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel), [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`chat`](/api/#03-apidocs/classaxaiopenaibasemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<AxAIOpenAIEmbedModel>>, options?: Readonly<AxAIServiceActionOptions<AxAIOpenAIModel, AxAIOpenAIEmbedModel>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<[`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel), [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`embed`](/api/#03-apidocs/classaxaiopenaibasemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: AxAIOpenAIModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | [`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getFeatures`](/api/#03-apidocs/classaxaiopenaibasemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getId`](/api/#03-apidocs/classaxaiopenaibasemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | AxAIOpenAIModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| [`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedChatModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): 
  | undefined
  | AxAIOpenAIEmbedModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

  \| `undefined`
  \| [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLogger`](/api/#03-apidocs/classaxaiopenaibasemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getMetrics`](/api/#03-apidocs/classaxaiopenaibasemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getModelList`](/api/#03-apidocs/classaxaiopenaibasemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getName`](/api/#03-apidocs/classaxaiopenaibasemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getOptions`](/api/#03-apidocs/classaxaiopenaibasemdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setAPIURL`](/api/#03-apidocs/classaxaiopenaibasemdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setHeaders`](/api/#03-apidocs/classaxaiopenaibasemdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setName`](/api/#03-apidocs/classaxaiopenaibasemdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setOptions`](/api/#03-apidocs/classaxaiopenaibasemdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAIReka.md
================================================
---
title: AxAIReka
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/reka/api.ts#L266

## Extends

- [`AxBaseAI`](/api/#03-apidocs/classaxbaseai)\<[`AxAIRekaModel`](/api/#03-apidocs/enumerationaxairekamodel), `undefined`, [`AxAIRekaChatRequest`](/api/#03-apidocs/typealiasaxairekachatrequest), `unknown`, [`AxAIRekaChatResponse`](/api/#03-apidocs/typealiasaxairekachatresponse), [`AxAIRekaChatResponseDelta`](/api/#03-apidocs/typealiasaxairekachatresponsedelta), `unknown`\>

## Constructors

<a id="constructors"></a>

### new AxAIReka()

```ts
new AxAIReka(__namedParameters: Readonly<Omit<AxAIRekaArgs, "name">>): AxAIReka
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/reka/api.ts#L275

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAIRekaArgs`](/api/#03-apidocs/interfaceaxairekaargs), `"name"`\>\> |

#### Returns

[`AxAIReka`](/api/#03-apidocs/classaxaireka)

#### Overrides

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`constructor`](/api/#03-apidocs/classaxbaseaimdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<AxAIRekaModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<AxAIRekaModel, undefined>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<[`AxAIRekaModel`](/api/#03-apidocs/enumerationaxairekamodel)\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIRekaModel`](/api/#03-apidocs/enumerationaxairekamodel), `undefined`\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`chat`](/api/#03-apidocs/classaxbaseaimdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<undefined>>, options?: Readonly<AxAIServiceActionOptions<AxAIRekaModel, undefined>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<`undefined`\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<[`AxAIRekaModel`](/api/#03-apidocs/enumerationaxairekamodel), `undefined`\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`embed`](/api/#03-apidocs/classaxbaseaimdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: AxAIRekaModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | [`AxAIRekaModel`](/api/#03-apidocs/enumerationaxairekamodel) |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getFeatures`](/api/#03-apidocs/classaxbaseaimdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getId`](/api/#03-apidocs/classaxbaseaimdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | AxAIRekaModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| [`AxAIRekaModel`](/api/#03-apidocs/enumerationaxairekamodel)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedChatModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): undefined
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

`undefined`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxbaseaimdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxbaseaimdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getLogger`](/api/#03-apidocs/classaxbaseaimdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getMetrics`](/api/#03-apidocs/classaxbaseaimdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getModelList`](/api/#03-apidocs/classaxbaseaimdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getName`](/api/#03-apidocs/classaxbaseaimdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`getOptions`](/api/#03-apidocs/classaxbaseaimdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setAPIURL`](/api/#03-apidocs/classaxbaseaimdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setHeaders`](/api/#03-apidocs/classaxbaseaimdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setName`](/api/#03-apidocs/classaxbaseaimdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai).[`setOptions`](/api/#03-apidocs/classaxbaseaimdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAITogether.md
================================================
---
title: AxAITogether
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/together/api.ts#L18

## Extends

- [`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase)\<`string`, `unknown`\>

## Constructors

<a id="constructors"></a>

### new AxAITogether()

```ts
new AxAITogether(__namedParameters: Readonly<Omit<AxAITogetherArgs, "name">>): AxAITogether
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/together/api.ts#L19

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxAITogetherArgs`](/api/#03-apidocs/typealiasaxaitogetherargs), `"name"`\>\> |

#### Returns

[`AxAITogether`](/api/#03-apidocs/classaxaitogether)

#### Overrides

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`constructor`](/api/#03-apidocs/classaxaiopenaibasemdconstructors)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<string>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<string, unknown>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<`string`\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<`string`, `unknown`\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`chat`](/api/#03-apidocs/classaxaiopenaibasemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<unknown>>, options?: Readonly<AxAIServiceActionOptions<string, unknown>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<`unknown`\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<`string`, `unknown`\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`embed`](/api/#03-apidocs/classaxaiopenaibasemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: string): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | `string` |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getFeatures`](/api/#03-apidocs/classaxaiopenaibasemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getId`](/api/#03-apidocs/classaxaiopenaibasemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| `string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedChatModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): unknown
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

`unknown`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedEmbedModel`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLastUsedModelConfig`](/api/#03-apidocs/classaxaiopenaibasemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getLogger`](/api/#03-apidocs/classaxaiopenaibasemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getMetrics`](/api/#03-apidocs/classaxaiopenaibasemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getModelList`](/api/#03-apidocs/classaxaiopenaibasemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getName`](/api/#03-apidocs/classaxaiopenaibasemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`getOptions`](/api/#03-apidocs/classaxaiopenaibasemdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setAPIURL`](/api/#03-apidocs/classaxaiopenaibasemdsetapiurl)

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setHeaders`](/api/#03-apidocs/classaxaiopenaibasemdsetheaders)

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setName`](/api/#03-apidocs/classaxaiopenaibasemdsetname)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase).[`setOptions`](/api/#03-apidocs/classaxaiopenaibasemdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxApacheTika.md
================================================
---
title: AxApacheTika
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/tika.ts#L12

## Constructors

<a id="constructors"></a>

### new AxApacheTika()

```ts
new AxApacheTika(args?: Readonly<AxApacheTikaArgs>): AxApacheTika
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/tika.ts#L16

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `args`? | `Readonly`\<[`AxApacheTikaArgs`](/api/#03-apidocs/interfaceaxapachetikaargs)\> |

#### Returns

[`AxApacheTika`](/api/#03-apidocs/classaxapachetika)

## Methods

<a id="convert"></a>

### convert()

```ts
convert(files: Readonly<string[] | Blob[]>, options?: Readonly<{
  batchSize: number;
  format: "text" | "html";
}>): Promise<string[]>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/tika.ts#L54

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `files` | `Readonly`\<`string`[] \| `Blob`[]\> |
| `options`? | `Readonly`\<\{ `batchSize`: `number`; `format`: `"text"` \| `"html"`; \}\> |

#### Returns

`Promise`\<`string`[]\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxAssertionError.md
================================================
---
title: AxAssertionError
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/asserts.ts#L16

## Extends

- `Error`

## Constructors

<a id="constructors"></a>

### new AxAssertionError()

```ts
new AxAssertionError(__namedParameters: Readonly<{
  message: string;
 }>): AxAssertionError
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/asserts.ts#L17

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<\{ `message`: `string`; \}\> |

#### Returns

[`AxAssertionError`](/api/#03-apidocs/classaxassertionerror)

#### Overrides

```ts
Error.constructor
```

## Properties

| Property | Modifier | Type | Description | Inherited from |
| :------ | :------ | :------ | :------ | :------ |
| <a id="cause"></a> `cause?` | `public` | `unknown` | - | `Error.cause` |
| <a id="message"></a> `message` | `public` | `string` | - | `Error.message` |
| <a id="name"></a> `name` | `public` | `string` | - | `Error.name` |
| <a id="stack"></a> `stack?` | `public` | `string` | - | `Error.stack` |
| <a id="prepareStackTrace"></a> `prepareStackTrace?` | `static` | (`err`: `Error`, `stackTraces`: `CallSite`[]) => `any` | Optional override for formatting stack traces **See** https://v8.dev/docs/stack-trace-api#customizing-stack-traces | `Error.prepareStackTrace` |
| <a id="stackTraceLimit"></a> `stackTraceLimit` | `static` | `number` | - | `Error.stackTraceLimit` |

## Methods

<a id="getFixingInstructions"></a>

### getFixingInstructions()

```ts
getFixingInstructions(): object[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/asserts.ts#L26

#### Returns

`object`[]

***

<a id="toString"></a>

### toString()

```ts
toString(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/asserts.ts#L39

Returns a string representation of an object.

#### Returns

`string`

***

<a id="captureStackTrace"></a>

### captureStackTrace()

```ts
static captureStackTrace(targetObject: object, constructorOpt?: Function): void
```

Defined in: node\_modules/@types/node/globals.d.ts:136

Create .stack property on a target object

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `targetObject` | `object` |
| `constructorOpt`? | `Function` |

#### Returns

`void`

#### Inherited from

```ts
Error.captureStackTrace
```



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxBalancer.md
================================================
---
title: AxBalancer
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L42

Balancer that rotates through services.

## Implements

- [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>

## Constructors

<a id="constructors"></a>

### new AxBalancer()

```ts
new AxBalancer(services: readonly AxAIService<unknown, unknown>[], options?: AxBalancerOptions): AxBalancer
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L55

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `services` | readonly [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>[] |
| `options`? | [`AxBalancerOptions`](/api/#03-apidocs/typealiasaxbalanceroptions) |

#### Returns

[`AxBalancer`](/api/#03-apidocs/classaxbalancer)

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L201

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`chat`](/api/#03-apidocs/interfaceaxaiservicemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest>, options?: Readonly<AxAIServiceActionOptions>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L261

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`embed`](/api/#03-apidocs/interfaceaxaiservicemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: string): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L147

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | `string` |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getFeatures`](/api/#03-apidocs/interfaceaxaiservicemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L143

#### Returns

`string`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getId`](/api/#03-apidocs/interfaceaxaiservicemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): unknown
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L76

#### Returns

`unknown`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLastUsedChatModel`](/api/#03-apidocs/interfaceaxaiservicemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): unknown
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L79

#### Returns

`unknown`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLastUsedEmbedModel`](/api/#03-apidocs/interfaceaxaiservicemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L82

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLastUsedModelConfig`](/api/#03-apidocs/interfaceaxaiservicemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L295

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLogger`](/api/#03-apidocs/interfaceaxaiservicemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L151

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getMetrics`](/api/#03-apidocs/interfaceaxaiservicemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L117

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getModelList`](/api/#03-apidocs/interfaceaxaiservicemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L139

#### Returns

`string`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getName`](/api/#03-apidocs/interfaceaxaiservicemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L291

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getOptions`](/api/#03-apidocs/interfaceaxaiservicemdgetoptions)

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L287

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`setOptions`](/api/#03-apidocs/interfaceaxaiservicemdsetoptions)

***

<a id="inputOrderComparator"></a>

### inputOrderComparator()

```ts
static inputOrderComparator(): number
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L89

Service comparator that respects the input order of services.

#### Returns

`number`

***

<a id="metricComparator"></a>

### metricComparator()

```ts
static metricComparator(a: AxAIService, b: AxAIService): number
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L110

Service comparator that sorts services by cost.

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `a` | [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice) |
| `b` | [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice) |

#### Returns

`number`



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxBaseAI.md
================================================
---
title: AxBaseAI
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L72

## Extended by

- [`AxAIAnthropic`](/api/#03-apidocs/classaxaianthropic)
- [`AxAICohere`](/api/#03-apidocs/classaxaicohere)
- [`AxAIGoogleGemini`](/api/#03-apidocs/classaxaigooglegemini)
- [`AxAIHuggingFace`](/api/#03-apidocs/classaxaihuggingface)
- [`AxAIOpenAIBase`](/api/#03-apidocs/classaxaiopenaibase)
- [`AxAIOpenAIResponsesBase`](/api/#03-apidocs/classaxaiopenairesponsesbase)
- [`AxAIReka`](/api/#03-apidocs/classaxaireka)

## Type Parameters

| Type Parameter |
| :------ |
| `TModel` |
| `TEmbedModel` |
| `TChatRequest` |
| `TEmbedRequest` |
| `TChatResponse` |
| `TChatResponseDelta` |
| `TEmbedResponse` |

## Implements

- [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`TModel`, `TEmbedModel`\>

## Constructors

<a id="constructors"></a>

### new AxBaseAI()

```ts
new AxBaseAI<TModel, TEmbedModel, TChatRequest, TEmbedRequest, TChatResponse, TChatResponseDelta, TEmbedResponse>(aiImpl: Readonly<AxAIServiceImpl<TModel, TEmbedModel, TChatRequest, TEmbedRequest, TChatResponse, TChatResponseDelta, TEmbedResponse>>, __namedParameters: Readonly<AxBaseAIArgs<TModel, TEmbedModel>>): AxBaseAI<TModel, TEmbedModel, TChatRequest, TEmbedRequest, TChatResponse, TChatResponseDelta, TEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L137

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `aiImpl` | `Readonly`\<[`AxAIServiceImpl`](/api/#03-apidocs/interfaceaxaiserviceimpl)\<`TModel`, `TEmbedModel`, `TChatRequest`, `TEmbedRequest`, `TChatResponse`, `TChatResponseDelta`, `TEmbedResponse`\>\> |
| `__namedParameters` | `Readonly`\<[`AxBaseAIArgs`](/api/#03-apidocs/interfaceaxbaseaiargs)\<`TModel`, `TEmbedModel`\>\> |

#### Returns

[`AxBaseAI`](/api/#03-apidocs/classaxbaseai)\<`TModel`, `TEmbedModel`, `TChatRequest`, `TEmbedRequest`, `TChatResponse`, `TChatResponseDelta`, `TEmbedResponse`\>

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<TModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<TModel, TEmbedModel>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L326

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<`TModel`\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<`TModel`, `TEmbedModel`\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`chat`](/api/#03-apidocs/interfaceaxaiservicemdchat)

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<TEmbedModel>>, options?: Readonly<AxAIServiceActionOptions<TModel, TEmbedModel>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L614

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<`TEmbedModel`\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<`TModel`, `TEmbedModel`\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`embed`](/api/#03-apidocs/interfaceaxaiservicemdembed)

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: TModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L265

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | `TModel` |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getFeatures`](/api/#03-apidocs/interfaceaxaiservicemdgetfeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L194

#### Returns

`string`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getId`](/api/#03-apidocs/interfaceaxaiservicemdgetid)

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | TModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L271

#### Returns

`undefined` \| `TModel`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLastUsedChatModel`](/api/#03-apidocs/interfaceaxaiservicemdgetlastusedchatmodel)

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): undefined | TEmbedModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L275

#### Returns

`undefined` \| `TEmbedModel`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLastUsedEmbedModel`](/api/#03-apidocs/interfaceaxaiservicemdgetlastusedembedmodel)

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L279

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLastUsedModelConfig`](/api/#03-apidocs/interfaceaxaiservicemdgetlastusedmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L230

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getLogger`](/api/#03-apidocs/interfaceaxaiservicemdgetlogger)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L322

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getMetrics`](/api/#03-apidocs/interfaceaxaiservicemdgetmetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L234

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getModelList`](/api/#03-apidocs/interfaceaxaiservicemdgetmodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L261

#### Returns

`string`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getName`](/api/#03-apidocs/interfaceaxaiservicemdgetname)

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L217

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`getOptions`](/api/#03-apidocs/interfaceaxaiservicemdgetoptions)

***

<a id="setAPIURL"></a>

### setAPIURL()

```ts
setAPIURL(apiURL: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `apiURL` | `string` |

#### Returns

`void`

***

<a id="setHeaders"></a>

### setHeaders()

```ts
setHeaders(headers: () => Promise<Record<string, string>>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L202

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |

#### Returns

`void`

***

<a id="setName"></a>

### setName()

```ts
setName(name: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L190

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |

#### Returns

`void`

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`

#### Implementation of

[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice).[`setOptions`](/api/#03-apidocs/interfaceaxaiservicemdsetoptions)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxBootstrapFewShot.md
================================================
---
title: AxBootstrapFewShot
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/optimize.ts#L51

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `IN` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) | [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) |
| `OUT` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) | [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |

## Constructors

<a id="constructors"></a>

### new AxBootstrapFewShot()

```ts
new AxBootstrapFewShot<IN, OUT>(__namedParameters: Readonly<AxOptimizerArgs<IN, OUT>>): AxBootstrapFewShot<IN, OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/optimize.ts#L76

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<[`AxOptimizerArgs`](/api/#03-apidocs/typealiasaxoptimizerargs)\<`IN`, `OUT`\>\> |

#### Returns

[`AxBootstrapFewShot`](/api/#03-apidocs/classaxbootstrapfewshot)\<`IN`, `OUT`\>

## Methods

<a id="compile"></a>

### compile()

```ts
compile(metricFn: AxMetricFn, options?: Readonly<
  | undefined
  | {
  batchSize: number;
  costMonitoring: boolean;
  debugMode: boolean;
  earlyStoppingPatience: number;
  maxDemos: number;
  maxExamples: number;
  maxRounds: number;
  maxTokensPerGeneration: number;
  teacherAI: AxAIService<unknown, unknown>;
  verboseMode: boolean;
 }>): Promise<{
  demos: AxProgramDemos[];
  stats: AxOptimizationStats;
}>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/optimize.ts#L244

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `metricFn` | [`AxMetricFn`](/api/#03-apidocs/typealiasaxmetricfn) |
| `options`? | `Readonly`\< \| `undefined` \| \{ `batchSize`: `number`; `costMonitoring`: `boolean`; `debugMode`: `boolean`; `earlyStoppingPatience`: `number`; `maxDemos`: `number`; `maxExamples`: `number`; `maxRounds`: `number`; `maxTokensPerGeneration`: `number`; `teacherAI`: [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>; `verboseMode`: `boolean`; \}\> |

#### Returns

`Promise`\<\{
  `demos`: [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[];
  `stats`: [`AxOptimizationStats`](/api/#03-apidocs/interfaceaxoptimizationstats);
 \}\>

***

<a id="getStats"></a>

### getStats()

```ts
getStats(): AxOptimizationStats
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/optimize.ts#L281

#### Returns

[`AxOptimizationStats`](/api/#03-apidocs/interfaceaxoptimizationstats)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxChainOfThought.md
================================================
---
title: AxChainOfThought
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/cot.ts#L6

## Extends

- [`AxGen`](/api/#03-apidocs/classaxgen)\<`IN`, `OUT`\>

## Extended by

- [`AxRAG`](/api/#03-apidocs/classaxrag)

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `IN` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) | [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) |
| `OUT` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) | [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |

## Constructors

<a id="constructors"></a>

### new AxChainOfThought()

```ts
new AxChainOfThought<IN, OUT>(signature: Readonly<string | AxSignature>, options?: Readonly<AxProgramForwardOptions & object>): AxChainOfThought<IN, OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/cot.ts#L10

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `signature` | `Readonly`\<`string` \| [`AxSignature`](/api/#03-apidocs/classaxsignature)\> |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions) & `object`\> |

#### Returns

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought)\<`IN`, `OUT`\>

#### Overrides

[`AxGen`](/api/#03-apidocs/classaxgen).[`constructor`](/api/#03-apidocs/classaxgenmdconstructors)

## Methods

<a id="_forward1"></a>

### \_forward1()

```ts
_forward1(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: IN | AxMessage<IN>[], 
   options: Readonly<AxProgramForwardOptions>): AsyncGenerator<{
  delta: Partial<OUT>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L746

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `options` | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<`OUT`\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`_forward1`](/api/#03-apidocs/classaxgenmdforward1)

***

<a id="addAssert"></a>

### addAssert()

```ts
addAssert(fn: (values: Record<string, unknown>) => undefined | boolean | Promise<undefined | boolean>, message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L136

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fn` | (`values`: `Record`\<`string`, `unknown`\>) => `undefined` \| `boolean` \| `Promise`\<`undefined` \| `boolean`\> |
| `message`? | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addAssert`](/api/#03-apidocs/classaxgenmdaddassert)

***

<a id="addFieldProcessor"></a>

### addFieldProcessor()

```ts
addFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L183

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addFieldProcessor`](/api/#03-apidocs/classaxgenmdaddfieldprocessor)

***

<a id="addStreamingAssert"></a>

### addStreamingAssert()

```ts
addStreamingAssert(
   fieldName: string, 
   fn: (content: string, done?: boolean) => undefined | boolean, 
   message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L140

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | (`content`: `string`, `done`?: `boolean`) => `undefined` \| `boolean` |
| `message`? | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addStreamingAssert`](/api/#03-apidocs/classaxgenmdaddstreamingassert)

***

<a id="addStreamingFieldProcessor"></a>

### addStreamingFieldProcessor()

```ts
addStreamingFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L176

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addStreamingFieldProcessor`](/api/#03-apidocs/classaxgenmdaddstreamingfieldprocessor)

***

<a id="forward"></a>

### forward()

```ts
forward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: IN | AxMessage<IN>[], 
options?: Readonly<AxProgramForwardOptions>): Promise<OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L823

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`Promise`\<`OUT`\>

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`forward`](/api/#03-apidocs/classaxgenmdforward)

***

<a id="getSignature"></a>

### getSignature()

```ts
getSignature(): AxSignature
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L165

#### Returns

[`AxSignature`](/api/#03-apidocs/classaxsignature)

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`getSignature`](/api/#03-apidocs/classaxgenmdgetsignature)

***

<a id="getTraces"></a>

### getTraces()

```ts
getTraces(): AxProgramTrace[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L262

#### Returns

[`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[]

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`getTraces`](/api/#03-apidocs/classaxgenmdgettraces)

***

<a id="getUsage"></a>

### getUsage()

```ts
getUsage(): AxModelUsage & object[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L276

#### Returns

[`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[]

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`getUsage`](/api/#03-apidocs/classaxgenmdgetusage)

***

<a id="register"></a>

### register()

```ts
register(prog: Readonly<AxTunable & AxUsable>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L169

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `prog` | `Readonly`\<[`AxTunable`](/api/#03-apidocs/interfaceaxtunable) & [`AxUsable`](/api/#03-apidocs/interfaceaxusable)\> |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`register`](/api/#03-apidocs/classaxgenmdregister)

***

<a id="resetUsage"></a>

### resetUsage()

```ts
resetUsage(): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L286

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`resetUsage`](/api/#03-apidocs/classaxgenmdresetusage)

***

<a id="setDemos"></a>

### setDemos()

```ts
setDemos(demos: readonly AxProgramDemos[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L293

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `demos` | readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[] |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setDemos`](/api/#03-apidocs/classaxgenmdsetdemos)

***

<a id="setExamples"></a>

### setExamples()

```ts
setExamples(examples: Readonly<AxProgramExamples>, options?: Readonly<AxSetExamplesOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L856

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `examples` | `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\> |
| `options`? | `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setExamples`](/api/#03-apidocs/classaxgenmdsetexamples)

***

<a id="setId"></a>

### setId()

```ts
setId(id: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L199

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `id` | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setId`](/api/#03-apidocs/classaxgenmdsetid)

***

<a id="setParentId"></a>

### setParentId()

```ts
setParentId(parentId: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentId` | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setParentId`](/api/#03-apidocs/classaxgenmdsetparentid)

***

<a id="streamingForward"></a>

### streamingForward()

```ts
streamingForward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: IN | AxMessage<IN>[], 
   options?: Readonly<AxProgramStreamingForwardOptions>): AsyncGenerator<{
  delta: Partial<OUT>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L845

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `options`? | `Readonly`\<[`AxProgramStreamingForwardOptions`](/api/#03-apidocs/typealiasaxprogramstreamingforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<`OUT`\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`streamingForward`](/api/#03-apidocs/classaxgenmdstreamingforward)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDB.md
================================================
---
title: AxDB
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/wrap.ts#L19

## Implements

- [`AxDBService`](/api/#03-apidocs/interfaceaxdbservice)

## Constructors

<a id="constructors"></a>

### new AxDB()

```ts
new AxDB(args: Readonly<AxDBArgs>): AxDB
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/wrap.ts#L21

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `args` | `Readonly`\<[`AxDBArgs`](/api/#03-apidocs/typealiasaxdbargs)\> |

#### Returns

[`AxDB`](/api/#03-apidocs/classaxdb)

## Methods

<a id="batchUpsert"></a>

### batchUpsert()

```ts
batchUpsert(batchReq: readonly AxDBUpsertRequest[], update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/wrap.ts#L46

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `batchReq` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Implementation of

[`AxDBService`](/api/#03-apidocs/interfaceaxdbservice).[`batchUpsert`](/api/#03-apidocs/interfaceaxdbservicemdbatchupsert)

***

<a id="query"></a>

### query()

```ts
query(req: Readonly<AxDBQueryRequest>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/wrap.ts#L53

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>

#### Implementation of

[`AxDBService`](/api/#03-apidocs/interfaceaxdbservice).[`query`](/api/#03-apidocs/interfaceaxdbservicemdquery)

***

<a id="upsert"></a>

### upsert()

```ts
upsert(req: Readonly<AxDBUpsertRequest>, update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/wrap.ts#L39

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Implementation of

[`AxDBService`](/api/#03-apidocs/interfaceaxdbservice).[`upsert`](/api/#03-apidocs/interfaceaxdbservicemdupsert)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDBBase.md
================================================
---
title: AxDBBase
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L22

## Extended by

- [`AxDBCloudflare`](/api/#03-apidocs/classaxdbcloudflare)
- [`AxDBMemory`](/api/#03-apidocs/classaxdbmemory)
- [`AxDBPinecone`](/api/#03-apidocs/classaxdbpinecone)
- [`AxDBWeaviate`](/api/#03-apidocs/classaxdbweaviate)

## Implements

- [`AxDBService`](/api/#03-apidocs/interfaceaxdbservice)

## Constructors

<a id="constructors"></a>

### new AxDBBase()

```ts
new AxDBBase(__namedParameters: Readonly<AxDBBaseArgs & object>): AxDBBase
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L44

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<[`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs) & `object`\> |

#### Returns

[`AxDBBase`](/api/#03-apidocs/classaxdbbase)

## Properties

| Property | Type |
| :------ | :------ |
| <a id="_batchUpsert"></a> `_batchUpsert?` | (`batchReq`: readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[], `update`?: `boolean`, `options`?: `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\>) => `Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\> |
| <a id="_query"></a> `_query?` | (`req`: `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\>, `options`?: `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\>) => `Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\> |
| <a id="_upsert"></a> `_upsert?` | (`req`: `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\>, `update`?: `boolean`, `options`?: `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\>) => `Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\> |

## Methods

<a id="batchUpsert"></a>

### batchUpsert()

```ts
batchUpsert(req: readonly AxDBUpsertRequest[], update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L88

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Implementation of

[`AxDBService`](/api/#03-apidocs/interfaceaxdbservice).[`batchUpsert`](/api/#03-apidocs/interfaceaxdbservicemdbatchupsert)

***

<a id="query"></a>

### query()

```ts
query(req: Readonly<AxDBQueryRequest>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L128

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>

#### Implementation of

[`AxDBService`](/api/#03-apidocs/interfaceaxdbservice).[`query`](/api/#03-apidocs/interfaceaxdbservicemdquery)

***

<a id="upsert"></a>

### upsert()

```ts
upsert(req: Readonly<AxDBUpsertRequest>, update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L54

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Implementation of

[`AxDBService`](/api/#03-apidocs/interfaceaxdbservice).[`upsert`](/api/#03-apidocs/interfaceaxdbservicemdupsert)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDBCloudflare.md
================================================
---
title: AxDBCloudflare
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/cloudflare.ts#L44

Cloudflare: DB Service

## Extends

- [`AxDBBase`](/api/#03-apidocs/classaxdbbase)

## Constructors

<a id="constructors"></a>

### new AxDBCloudflare()

```ts
new AxDBCloudflare(__namedParameters: Readonly<Omit<AxDBCloudflareArgs, "name">>): AxDBCloudflare
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/cloudflare.ts#L48

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxDBCloudflareArgs`](/api/#03-apidocs/interfaceaxdbcloudflareargs), `"name"`\>\> |

#### Returns

[`AxDBCloudflare`](/api/#03-apidocs/classaxdbcloudflare)

#### Overrides

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`constructor`](/api/#03-apidocs/classaxdbbasemdconstructors)

## Properties

| Property | Type | Inherited from |
| :------ | :------ | :------ |
| <a id="_batchUpsert"></a> `_batchUpsert?` | (`batchReq`: readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[], `update`?: `boolean`, `options`?: `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\>) => `Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\> | [`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`_batchUpsert`](/api/#03-apidocs/classaxdbbasemdbatchupsert) |
| <a id="_query"></a> `_query?` | (`req`: `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\>, `options`?: `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\>) => `Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\> | [`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`_query`](/api/#03-apidocs/classaxdbbasemdquery) |

## Methods

<a id="_upsert"></a>

### \_upsert()

```ts
_upsert(
   req: Readonly<AxDBUpsertRequest>, 
   _update?: boolean, 
options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/cloudflare.ts#L62

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `_update`? | `boolean` |
| `options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Overrides

```ts
AxDBBase._upsert
```

***

<a id="batchUpsert"></a>

### batchUpsert()

```ts
batchUpsert(
   batchReq: readonly AxDBUpsertRequest[], 
   update?: boolean, 
options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/cloudflare.ts#L98

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `batchReq` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `update`? | `boolean` |
| `options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Overrides

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`batchUpsert`](/api/#03-apidocs/classaxdbbasemdbatchupsert)

***

<a id="query"></a>

### query()

```ts
query(req: Readonly<AxDBQueryRequest>, options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/cloudflare.ts#L147

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |
| `options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>

#### Overrides

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`query`](/api/#03-apidocs/classaxdbbasemdquery)

***

<a id="upsert"></a>

### upsert()

```ts
upsert(req: Readonly<AxDBUpsertRequest>, update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L54

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Inherited from

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`upsert`](/api/#03-apidocs/classaxdbbasemdupsert)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDBManager.md
================================================
---
title: AxDBManager
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L30

## Constructors

<a id="constructors"></a>

### new AxDBManager()

```ts
new AxDBManager(__namedParameters: Readonly<AxDBManagerArgs>): AxDBManager
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L37

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<[`AxDBManagerArgs`](/api/#03-apidocs/interfaceaxdbmanagerargs)\> |

#### Returns

[`AxDBManager`](/api/#03-apidocs/classaxdbmanager)

## Methods

<a id="insert"></a>

### insert()

```ts
insert(text: Readonly<string | string[]>, options?: Readonly<{
  abortSignal: AbortSignal;
  batchSize: number;
  maxWordsPerChunk: number;
  minWordsPerChunk: number;
}>): Promise<void>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L50

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `text` | `Readonly`\<`string` \| `string`[]\> |
| `options`? | `Readonly`\<\{ `abortSignal`: `AbortSignal`; `batchSize`: `number`; `maxWordsPerChunk`: `number`; `minWordsPerChunk`: `number`; \}\> |

#### Returns

`Promise`\<`void`\>

***

<a id="query"></a>

### query()

```ts
query(query: Readonly<string | number | string[] | number[]>, __namedParameters: 
  | undefined
  | Readonly<{
  abortSignal: AbortSignal;
  topPercent: number;
}>): Promise<AxDBMatch[][]>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L112

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `query` | `Readonly`\<`string` \| `number` \| `string`[] \| `number`[]\> |
| `__namedParameters` | \| `undefined` \| `Readonly`\<\{ `abortSignal`: `AbortSignal`; `topPercent`: `number`; \}\> |

#### Returns

`Promise`\<[`AxDBMatch`](/api/#03-apidocs/interfaceaxdbmatch)[][]\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDBMemory.md
================================================
---
title: AxDBMemory
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L20

MemoryDB: DB Service

## Extends

- [`AxDBBase`](/api/#03-apidocs/classaxdbbase)

## Constructors

<a id="constructors"></a>

### new AxDBMemory()

```ts
new AxDBMemory(__namedParameters: Readonly<Omit<AxDBMemoryArgs, "name">>): AxDBMemory
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L23

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxDBMemoryArgs`](/api/#03-apidocs/interfaceaxdbmemoryargs), `"name"`\>\> |

#### Returns

[`AxDBMemory`](/api/#03-apidocs/classaxdbmemory)

#### Overrides

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`constructor`](/api/#03-apidocs/classaxdbbasemdconstructors)

## Methods

<a id="_batchUpsert"></a>

### \_batchUpsert()

```ts
_batchUpsert(
   batchReq: readonly AxDBUpsertRequest[], 
   update?: boolean, 
_options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L50

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `batchReq` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `update`? | `boolean` |
| `_options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Overrides

```ts
AxDBBase._batchUpsert
```

***

<a id="_query"></a>

### \_query()

```ts
_query(req: Readonly<AxDBQueryRequest>, _options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L65

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |
| `_options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>

#### Overrides

```ts
AxDBBase._query
```

***

<a id="_upsert"></a>

### \_upsert()

```ts
_upsert(
   req: Readonly<AxDBUpsertRequest>, 
   _update?: boolean, 
_options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L28

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `_update`? | `boolean` |
| `_options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Overrides

```ts
AxDBBase._upsert
```

***

<a id="batchUpsert"></a>

### batchUpsert()

```ts
batchUpsert(req: readonly AxDBUpsertRequest[], update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L88

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Inherited from

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`batchUpsert`](/api/#03-apidocs/classaxdbbasemdbatchupsert)

***

<a id="clearDB"></a>

### clearDB()

```ts
clearDB(): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L100

#### Returns

`void`

***

<a id="getDB"></a>

### getDB()

```ts
getDB(): AxDBState
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L92

#### Returns

[`AxDBState`](/api/#03-apidocs/typealiasaxdbstate)

***

<a id="query"></a>

### query()

```ts
query(req: Readonly<AxDBQueryRequest>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L128

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>

#### Inherited from

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`query`](/api/#03-apidocs/classaxdbbasemdquery)

***

<a id="setDB"></a>

### setDB()

```ts
setDB(state: AxDBState): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L96

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `state` | [`AxDBState`](/api/#03-apidocs/typealiasaxdbstate) |

#### Returns

`void`

***

<a id="upsert"></a>

### upsert()

```ts
upsert(req: Readonly<AxDBUpsertRequest>, update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L54

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Inherited from

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`upsert`](/api/#03-apidocs/classaxdbbasemdupsert)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDBPinecone.md
================================================
---
title: AxDBPinecone
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/pinecone.ts#L58

Pinecone: DB Service

## Extends

- [`AxDBBase`](/api/#03-apidocs/classaxdbbase)

## Constructors

<a id="constructors"></a>

### new AxDBPinecone()

```ts
new AxDBPinecone(__namedParameters: Readonly<Omit<AxDBPineconeArgs, "name">>): AxDBPinecone
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/pinecone.ts#L62

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxDBPineconeArgs`](/api/#03-apidocs/interfaceaxdbpineconeargs), `"name"`\>\> |

#### Returns

[`AxDBPinecone`](/api/#03-apidocs/classaxdbpinecone)

#### Overrides

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`constructor`](/api/#03-apidocs/classaxdbbasemdconstructors)

## Properties

| Property | Type | Inherited from |
| :------ | :------ | :------ |
| <a id="_query"></a> `_query?` | (`req`: `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\>, `options`?: `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\>) => `Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\> | [`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`_query`](/api/#03-apidocs/classaxdbbasemdquery) |

## Methods

<a id="_batchUpsert"></a>

### \_batchUpsert()

```ts
_batchUpsert(
   batchReq: readonly AxDBUpsertRequest[], 
   _update?: boolean, 
options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/pinecone.ts#L85

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `batchReq` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `_update`? | `boolean` |
| `options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Overrides

```ts
AxDBBase._batchUpsert
```

***

<a id="_upsert"></a>

### \_upsert()

```ts
_upsert(
   req: Readonly<AxDBUpsertRequest>, 
   update?: boolean, 
options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/pinecone.ts#L76

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `update`? | `boolean` |
| `options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Overrides

```ts
AxDBBase._upsert
```

***

<a id="batchUpsert"></a>

### batchUpsert()

```ts
batchUpsert(req: readonly AxDBUpsertRequest[], update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L88

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Inherited from

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`batchUpsert`](/api/#03-apidocs/classaxdbbasemdbatchupsert)

***

<a id="query"></a>

### query()

```ts
query(req: Readonly<AxDBQueryRequest>, options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/pinecone.ts#L111

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |
| `options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>

#### Overrides

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`query`](/api/#03-apidocs/classaxdbbasemdquery)

***

<a id="upsert"></a>

### upsert()

```ts
upsert(req: Readonly<AxDBUpsertRequest>, update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L54

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Inherited from

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`upsert`](/api/#03-apidocs/classaxdbbasemdupsert)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDBWeaviate.md
================================================
---
title: AxDBWeaviate
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/weaviate.ts#L39

Weaviate: DB Service

## Extends

- [`AxDBBase`](/api/#03-apidocs/classaxdbbase)

## Constructors

<a id="constructors"></a>

### new AxDBWeaviate()

```ts
new AxDBWeaviate(__namedParameters: Readonly<Omit<AxDBWeaviateArgs, "name">>): AxDBWeaviate
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/weaviate.ts#L43

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<`Omit`\<[`AxDBWeaviateArgs`](/api/#03-apidocs/interfaceaxdbweaviateargs), `"name"`\>\> |

#### Returns

[`AxDBWeaviate`](/api/#03-apidocs/classaxdbweaviate)

#### Overrides

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`constructor`](/api/#03-apidocs/classaxdbbasemdconstructors)

## Methods

<a id="_batchUpsert"></a>

### \_batchUpsert()

```ts
_batchUpsert(
   batchReq: readonly AxDBUpsertRequest[], 
   update?: boolean, 
options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/weaviate.ts#L93

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `batchReq` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `update`? | `boolean` |
| `options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Overrides

```ts
AxDBBase._batchUpsert
```

***

<a id="_query"></a>

### \_query()

```ts
_query(req: Readonly<AxDBQueryRequest>, options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/weaviate.ts#L138

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |
| `options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>

#### Overrides

```ts
AxDBBase._query
```

***

<a id="_upsert"></a>

### \_upsert()

```ts
_upsert(
   req: Readonly<AxDBUpsertRequest>, 
   update?: boolean, 
options?: Readonly<AxDBBaseOpOptions>): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/weaviate.ts#L57

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `update`? | `boolean` |
| `options`? | `Readonly`\<[`AxDBBaseOpOptions`](/api/#03-apidocs/interfaceaxdbbaseopoptions)\> |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Overrides

```ts
AxDBBase._upsert
```

***

<a id="batchUpsert"></a>

### batchUpsert()

```ts
batchUpsert(req: readonly AxDBUpsertRequest[], update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L88

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Inherited from

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`batchUpsert`](/api/#03-apidocs/classaxdbbasemdbatchupsert)

***

<a id="query"></a>

### query()

```ts
query(req: Readonly<AxDBQueryRequest>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L128

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>

#### Inherited from

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`query`](/api/#03-apidocs/classaxdbbasemdquery)

***

<a id="upsert"></a>

### upsert()

```ts
upsert(req: Readonly<AxDBUpsertRequest>, update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L54

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

#### Inherited from

[`AxDBBase`](/api/#03-apidocs/classaxdbbase).[`upsert`](/api/#03-apidocs/classaxdbbasemdupsert)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDefaultQueryRewriter.md
================================================
---
title: AxDefaultQueryRewriter
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/rewriter.ts#L6

## Extends

- [`AxGen`](/api/#03-apidocs/classaxgen)\<[`AxRewriteIn`](/api/#03-apidocs/typealiasaxrewritein), [`AxRewriteOut`](/api/#03-apidocs/typealiasaxrewriteout)\>

## Constructors

<a id="constructors"></a>

### new AxDefaultQueryRewriter()

```ts
new AxDefaultQueryRewriter(options?: Readonly<AxProgramForwardOptions>): AxDefaultQueryRewriter
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/rewriter.ts#L7

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

[`AxDefaultQueryRewriter`](/api/#03-apidocs/classaxdefaultqueryrewriter)

#### Overrides

[`AxGen`](/api/#03-apidocs/classaxgen).[`constructor`](/api/#03-apidocs/classaxgenmdconstructors)

## Methods

<a id="_forward1"></a>

### \_forward1()

```ts
_forward1(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: 
  | AxRewriteIn
  | AxMessage<AxRewriteIn>[], 
   options: Readonly<AxProgramForwardOptions>): AsyncGenerator<{
  delta: Partial<AxRewriteOut>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L746

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | \| [`AxRewriteIn`](/api/#03-apidocs/typealiasaxrewritein) \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<[`AxRewriteIn`](/api/#03-apidocs/typealiasaxrewritein)\>[] |
| `options` | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<[`AxRewriteOut`](/api/#03-apidocs/typealiasaxrewriteout)\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`_forward1`](/api/#03-apidocs/classaxgenmdforward1)

***

<a id="addAssert"></a>

### addAssert()

```ts
addAssert(fn: (values: Record<string, unknown>) => undefined | boolean | Promise<undefined | boolean>, message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L136

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fn` | (`values`: `Record`\<`string`, `unknown`\>) => `undefined` \| `boolean` \| `Promise`\<`undefined` \| `boolean`\> |
| `message`? | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addAssert`](/api/#03-apidocs/classaxgenmdaddassert)

***

<a id="addFieldProcessor"></a>

### addFieldProcessor()

```ts
addFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L183

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addFieldProcessor`](/api/#03-apidocs/classaxgenmdaddfieldprocessor)

***

<a id="addStreamingAssert"></a>

### addStreamingAssert()

```ts
addStreamingAssert(
   fieldName: string, 
   fn: (content: string, done?: boolean) => undefined | boolean, 
   message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L140

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | (`content`: `string`, `done`?: `boolean`) => `undefined` \| `boolean` |
| `message`? | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addStreamingAssert`](/api/#03-apidocs/classaxgenmdaddstreamingassert)

***

<a id="addStreamingFieldProcessor"></a>

### addStreamingFieldProcessor()

```ts
addStreamingFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L176

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addStreamingFieldProcessor`](/api/#03-apidocs/classaxgenmdaddstreamingfieldprocessor)

***

<a id="forward"></a>

### forward()

```ts
forward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: 
  | AxRewriteIn
  | AxMessage<AxRewriteIn>[], 
options?: Readonly<AxProgramForwardOptions>): Promise<AxRewriteOut>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L823

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | \| [`AxRewriteIn`](/api/#03-apidocs/typealiasaxrewritein) \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<[`AxRewriteIn`](/api/#03-apidocs/typealiasaxrewritein)\>[] |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`Promise`\<[`AxRewriteOut`](/api/#03-apidocs/typealiasaxrewriteout)\>

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`forward`](/api/#03-apidocs/classaxgenmdforward)

***

<a id="getSignature"></a>

### getSignature()

```ts
getSignature(): AxSignature
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L165

#### Returns

[`AxSignature`](/api/#03-apidocs/classaxsignature)

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`getSignature`](/api/#03-apidocs/classaxgenmdgetsignature)

***

<a id="getTraces"></a>

### getTraces()

```ts
getTraces(): AxProgramTrace[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L262

#### Returns

[`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[]

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`getTraces`](/api/#03-apidocs/classaxgenmdgettraces)

***

<a id="getUsage"></a>

### getUsage()

```ts
getUsage(): AxModelUsage & object[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L276

#### Returns

[`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[]

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`getUsage`](/api/#03-apidocs/classaxgenmdgetusage)

***

<a id="register"></a>

### register()

```ts
register(prog: Readonly<AxTunable & AxUsable>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L169

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `prog` | `Readonly`\<[`AxTunable`](/api/#03-apidocs/interfaceaxtunable) & [`AxUsable`](/api/#03-apidocs/interfaceaxusable)\> |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`register`](/api/#03-apidocs/classaxgenmdregister)

***

<a id="resetUsage"></a>

### resetUsage()

```ts
resetUsage(): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L286

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`resetUsage`](/api/#03-apidocs/classaxgenmdresetusage)

***

<a id="setDemos"></a>

### setDemos()

```ts
setDemos(demos: readonly AxProgramDemos[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L293

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `demos` | readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[] |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setDemos`](/api/#03-apidocs/classaxgenmdsetdemos)

***

<a id="setExamples"></a>

### setExamples()

```ts
setExamples(examples: Readonly<AxProgramExamples>, options?: Readonly<AxSetExamplesOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L856

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `examples` | `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\> |
| `options`? | `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setExamples`](/api/#03-apidocs/classaxgenmdsetexamples)

***

<a id="setId"></a>

### setId()

```ts
setId(id: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L199

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `id` | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setId`](/api/#03-apidocs/classaxgenmdsetid)

***

<a id="setParentId"></a>

### setParentId()

```ts
setParentId(parentId: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentId` | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setParentId`](/api/#03-apidocs/classaxgenmdsetparentid)

***

<a id="streamingForward"></a>

### streamingForward()

```ts
streamingForward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: 
  | AxRewriteIn
  | AxMessage<AxRewriteIn>[], 
   options?: Readonly<AxProgramStreamingForwardOptions>): AsyncGenerator<{
  delta: Partial<AxRewriteOut>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L845

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | \| [`AxRewriteIn`](/api/#03-apidocs/typealiasaxrewritein) \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<[`AxRewriteIn`](/api/#03-apidocs/typealiasaxrewritein)\>[] |
| `options`? | `Readonly`\<[`AxProgramStreamingForwardOptions`](/api/#03-apidocs/typealiasaxprogramstreamingforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<[`AxRewriteOut`](/api/#03-apidocs/typealiasaxrewriteout)\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`streamingForward`](/api/#03-apidocs/classaxgenmdstreamingforward)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDefaultResultReranker.md
================================================
---
title: AxDefaultResultReranker
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/reranker.ts#L8

## Extends

- [`AxGen`](/api/#03-apidocs/classaxgen)\<[`AxRerankerIn`](/api/#03-apidocs/typealiasaxrerankerin), [`AxRerankerOut`](/api/#03-apidocs/typealiasaxrerankerout)\>

## Constructors

<a id="constructors"></a>

### new AxDefaultResultReranker()

```ts
new AxDefaultResultReranker(options?: Readonly<AxProgramForwardOptions>): AxDefaultResultReranker
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/reranker.ts#L12

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

[`AxDefaultResultReranker`](/api/#03-apidocs/classaxdefaultresultreranker)

#### Overrides

[`AxGen`](/api/#03-apidocs/classaxgen).[`constructor`](/api/#03-apidocs/classaxgenmdconstructors)

## Methods

<a id="_forward1"></a>

### \_forward1()

```ts
_forward1(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: 
  | AxRerankerIn
  | AxMessage<AxRerankerIn>[], 
   options: Readonly<AxProgramForwardOptions>): AsyncGenerator<{
  delta: Partial<AxRerankerOut>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L746

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | \| [`AxRerankerIn`](/api/#03-apidocs/typealiasaxrerankerin) \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<[`AxRerankerIn`](/api/#03-apidocs/typealiasaxrerankerin)\>[] |
| `options` | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<[`AxRerankerOut`](/api/#03-apidocs/typealiasaxrerankerout)\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`_forward1`](/api/#03-apidocs/classaxgenmdforward1)

***

<a id="addAssert"></a>

### addAssert()

```ts
addAssert(fn: (values: Record<string, unknown>) => undefined | boolean | Promise<undefined | boolean>, message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L136

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fn` | (`values`: `Record`\<`string`, `unknown`\>) => `undefined` \| `boolean` \| `Promise`\<`undefined` \| `boolean`\> |
| `message`? | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addAssert`](/api/#03-apidocs/classaxgenmdaddassert)

***

<a id="addFieldProcessor"></a>

### addFieldProcessor()

```ts
addFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L183

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addFieldProcessor`](/api/#03-apidocs/classaxgenmdaddfieldprocessor)

***

<a id="addStreamingAssert"></a>

### addStreamingAssert()

```ts
addStreamingAssert(
   fieldName: string, 
   fn: (content: string, done?: boolean) => undefined | boolean, 
   message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L140

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | (`content`: `string`, `done`?: `boolean`) => `undefined` \| `boolean` |
| `message`? | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addStreamingAssert`](/api/#03-apidocs/classaxgenmdaddstreamingassert)

***

<a id="addStreamingFieldProcessor"></a>

### addStreamingFieldProcessor()

```ts
addStreamingFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L176

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`addStreamingFieldProcessor`](/api/#03-apidocs/classaxgenmdaddstreamingfieldprocessor)

***

<a id="forward"></a>

### forward()

```ts
forward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   input: Readonly<AxRerankerIn>, 
options?: Readonly<AxProgramForwardOptions>): Promise<AxRerankerOut>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/reranker.ts#L19

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `input` | `Readonly`\<[`AxRerankerIn`](/api/#03-apidocs/typealiasaxrerankerin)\> |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`Promise`\<[`AxRerankerOut`](/api/#03-apidocs/typealiasaxrerankerout)\>

#### Overrides

[`AxGen`](/api/#03-apidocs/classaxgen).[`forward`](/api/#03-apidocs/classaxgenmdforward)

***

<a id="getSignature"></a>

### getSignature()

```ts
getSignature(): AxSignature
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L165

#### Returns

[`AxSignature`](/api/#03-apidocs/classaxsignature)

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`getSignature`](/api/#03-apidocs/classaxgenmdgetsignature)

***

<a id="getTraces"></a>

### getTraces()

```ts
getTraces(): AxProgramTrace[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L262

#### Returns

[`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[]

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`getTraces`](/api/#03-apidocs/classaxgenmdgettraces)

***

<a id="getUsage"></a>

### getUsage()

```ts
getUsage(): AxModelUsage & object[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L276

#### Returns

[`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[]

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`getUsage`](/api/#03-apidocs/classaxgenmdgetusage)

***

<a id="register"></a>

### register()

```ts
register(prog: Readonly<AxTunable & AxUsable>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L169

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `prog` | `Readonly`\<[`AxTunable`](/api/#03-apidocs/interfaceaxtunable) & [`AxUsable`](/api/#03-apidocs/interfaceaxusable)\> |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`register`](/api/#03-apidocs/classaxgenmdregister)

***

<a id="resetUsage"></a>

### resetUsage()

```ts
resetUsage(): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L286

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`resetUsage`](/api/#03-apidocs/classaxgenmdresetusage)

***

<a id="setDemos"></a>

### setDemos()

```ts
setDemos(demos: readonly AxProgramDemos[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L293

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `demos` | readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[] |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setDemos`](/api/#03-apidocs/classaxgenmdsetdemos)

***

<a id="setExamples"></a>

### setExamples()

```ts
setExamples(examples: Readonly<AxProgramExamples>, options?: Readonly<AxSetExamplesOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L856

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `examples` | `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\> |
| `options`? | `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setExamples`](/api/#03-apidocs/classaxgenmdsetexamples)

***

<a id="setId"></a>

### setId()

```ts
setId(id: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L199

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `id` | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setId`](/api/#03-apidocs/classaxgenmdsetid)

***

<a id="setParentId"></a>

### setParentId()

```ts
setParentId(parentId: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentId` | `string` |

#### Returns

`void`

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`setParentId`](/api/#03-apidocs/classaxgenmdsetparentid)

***

<a id="streamingForward"></a>

### streamingForward()

```ts
streamingForward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: 
  | AxRerankerIn
  | AxMessage<AxRerankerIn>[], 
   options?: Readonly<AxProgramStreamingForwardOptions>): AsyncGenerator<{
  delta: Partial<AxRerankerOut>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L845

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | \| [`AxRerankerIn`](/api/#03-apidocs/typealiasaxrerankerin) \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<[`AxRerankerIn`](/api/#03-apidocs/typealiasaxrerankerin)\>[] |
| `options`? | `Readonly`\<[`AxProgramStreamingForwardOptions`](/api/#03-apidocs/typealiasaxprogramstreamingforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<[`AxRerankerOut`](/api/#03-apidocs/typealiasaxrerankerout)\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

#### Inherited from

[`AxGen`](/api/#03-apidocs/classaxgen).[`streamingForward`](/api/#03-apidocs/classaxgenmdstreamingforward)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxDockerSession.md
================================================
---
title: AxDockerSession
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L56

## Constructors

<a id="constructors"></a>

### new AxDockerSession()

```ts
new AxDockerSession(apiUrl: string): AxDockerSession
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L60

#### Parameters

| Parameter | Type | Default value |
| :------ | :------ | :------ |
| `apiUrl` | `string` | `'http://localhost:2375'` |

#### Returns

[`AxDockerSession`](/api/#03-apidocs/classaxdockersession)

## Methods

<a id="connectToContainer"></a>

### connectToContainer()

```ts
connectToContainer(containerId: string): Promise<void>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L186

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `containerId` | `string` |

#### Returns

`Promise`\<`void`\>

***

<a id="createContainer"></a>

### createContainer()

```ts
createContainer(__namedParameters: Readonly<{
  doNotPullImage: boolean;
  imageName: string;
  tag: string;
  volumes: object[];
 }>): Promise<{
  Id: string;
}>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L80

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<\{ `doNotPullImage`: `boolean`; `imageName`: `string`; `tag`: `string`; `volumes`: `object`[]; \}\> |

#### Returns

`Promise`\<\{
  `Id`: `string`;
 \}\>

***

<a id="executeCommand"></a>

### executeCommand()

```ts
executeCommand(command: string): Promise<string>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L274

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `command` | `string` |

#### Returns

`Promise`\<`string`\>

***

<a id="findOrCreateContainer"></a>

### findOrCreateContainer()

```ts
findOrCreateContainer(__namedParameters: Readonly<{
  doNotPullImage: boolean;
  imageName: string;
  tag: string;
  volumes: object[];
 }>): Promise<{
  Id: string;
  isNew: boolean;
}>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L128

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<\{ `doNotPullImage`: `boolean`; `imageName`: `string`; `tag`: `string`; `volumes`: `object`[]; \}\> |

#### Returns

`Promise`\<\{
  `Id`: `string`;
  `isNew`: `boolean`;
 \}\>

***

<a id="getContainerLogs"></a>

### getContainerLogs()

```ts
getContainerLogs(): Promise<string>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L263

#### Returns

`Promise`\<`string`\>

***

<a id="listContainers"></a>

### listContainers()

```ts
listContainers(all: boolean): Promise<AxDockerContainer[]>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L256

#### Parameters

| Parameter | Type | Default value |
| :------ | :------ | :------ |
| `all` | `boolean` | `false` |

#### Returns

`Promise`\<[`AxDockerContainer`](/api/#03-apidocs/interfaceaxdockercontainer)[]\>

***

<a id="pullImage"></a>

### pullImage()

```ts
pullImage(imageName: string): Promise<void>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L64

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `imageName` | `string` |

#### Returns

`Promise`\<`void`\>

***

<a id="startContainer"></a>

### startContainer()

```ts
startContainer(): Promise<void>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L169

#### Returns

`Promise`\<`void`\>

***

<a id="stopContainers"></a>

### stopContainers()

```ts
stopContainers(__namedParameters: Readonly<{
  remove: boolean;
  tag: string;
  timeout: number;
}>): Promise<object[]>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L198

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<\{ `remove`: `boolean`; `tag`: `string`; `timeout`: `number`; \}\> |

#### Returns

`Promise`\<`object`[]\>

***

<a id="toFunction"></a>

### toFunction()

```ts
toFunction(): AxFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L373

#### Returns

[`AxFunction`](/api/#03-apidocs/typealiasaxfunction)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxEmbeddingAdapter.md
================================================
---
title: AxEmbeddingAdapter
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/embed.ts#L7

## Constructors

<a id="constructors"></a>

### new AxEmbeddingAdapter()

```ts
new AxEmbeddingAdapter(__namedParameters: Readonly<{
  ai: AxAIService;
  func: (args: readonly number[], extra?: Readonly<AxAIServiceActionOptions>) => Promise<unknown>;
  info: Readonly<{
     argumentDescription: string;
     description: string;
     name: string;
    }>;
 }>): AxEmbeddingAdapter
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/embed.ts#L19

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<\{ `ai`: [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice); `func`: (`args`: readonly `number`[], `extra`?: `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\>) => `Promise`\<`unknown`\>; `info`: `Readonly`\<\{ `argumentDescription`: `string`; `description`: `string`; `name`: `string`; \}\>; \}\> |

#### Returns

[`AxEmbeddingAdapter`](/api/#03-apidocs/classaxembeddingadapter)

## Methods

<a id="toFunction"></a>

### toFunction()

```ts
toFunction(): AxFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/embed.ts#L60

#### Returns

[`AxFunction`](/api/#03-apidocs/typealiasaxfunction)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxFunctionProcessor.md
================================================
---
title: AxFunctionProcessor
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/functions.ts#L106

## Constructors

<a id="constructors"></a>

### new AxFunctionProcessor()

```ts
new AxFunctionProcessor(funcList: readonly AxFunction[]): AxFunctionProcessor
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/functions.ts#L109

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `funcList` | readonly [`AxFunction`](/api/#03-apidocs/typealiasaxfunction)[] |

#### Returns

[`AxFunctionProcessor`](/api/#03-apidocs/classaxfunctionprocessor)

## Methods

<a id="execute"></a>

### execute()

```ts
execute(func: Readonly<AxChatResponseFunctionCall>, options?: Readonly<AxAIServiceActionOptions>): Promise<string>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/functions.ts#L149

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `func` | `Readonly`\<[`AxChatResponseFunctionCall`](/api/#03-apidocs/typealiasaxchatresponsefunctioncall)\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\> |

#### Returns

`Promise`\<`string`\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxGen.md
================================================
---
title: AxGen
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L92

## Extends

- [`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature)\<`IN`, `OUT`\>

## Extended by

- [`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought)
- [`AxDefaultQueryRewriter`](/api/#03-apidocs/classaxdefaultqueryrewriter)
- [`AxDefaultResultReranker`](/api/#03-apidocs/classaxdefaultresultreranker)
- [`AxRewriter`](/api/#03-apidocs/classaxrewriter)

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `IN` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) | - |
| `OUT` *extends* [`AxGenerateResult`](/api/#03-apidocs/typealiasaxgenerateresult)\<[`AxGenOut`](/api/#03-apidocs/typealiasaxgenout)\> | [`AxGenerateResult`](/api/#03-apidocs/typealiasaxgenerateresult)\<[`AxGenOut`](/api/#03-apidocs/typealiasaxgenout)\> |

## Constructors

<a id="constructors"></a>

### new AxGen()

```ts
new AxGen<IN, OUT>(signature: Readonly<string | AxSignature>, options?: Readonly<AxProgramForwardOptions>): AxGen<IN, OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L109

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `signature` | `Readonly`\<`string` \| [`AxSignature`](/api/#03-apidocs/classaxsignature)\> |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

[`AxGen`](/api/#03-apidocs/classaxgen)\<`IN`, `OUT`\>

#### Overrides

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`constructor`](/api/#03-apidocs/classaxprogramwithsignaturemdconstructors)

## Methods

<a id="_forward1"></a>

### \_forward1()

```ts
_forward1(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: IN | AxMessage<IN>[], 
   options: Readonly<AxProgramForwardOptions>): AsyncGenerator<{
  delta: Partial<OUT>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L746

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `options` | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<`OUT`\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

***

<a id="addAssert"></a>

### addAssert()

```ts
addAssert(fn: (values: Record<string, unknown>) => undefined | boolean | Promise<undefined | boolean>, message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L136

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fn` | (`values`: `Record`\<`string`, `unknown`\>) => `undefined` \| `boolean` \| `Promise`\<`undefined` \| `boolean`\> |
| `message`? | `string` |

#### Returns

`void`

***

<a id="addFieldProcessor"></a>

### addFieldProcessor()

```ts
addFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L183

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

***

<a id="addStreamingAssert"></a>

### addStreamingAssert()

```ts
addStreamingAssert(
   fieldName: string, 
   fn: (content: string, done?: boolean) => undefined | boolean, 
   message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L140

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | (`content`: `string`, `done`?: `boolean`) => `undefined` \| `boolean` |
| `message`? | `string` |

#### Returns

`void`

***

<a id="addStreamingFieldProcessor"></a>

### addStreamingFieldProcessor()

```ts
addStreamingFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L176

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

***

<a id="forward"></a>

### forward()

```ts
forward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: IN | AxMessage<IN>[], 
options?: Readonly<AxProgramForwardOptions>): Promise<OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L823

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`Promise`\<`OUT`\>

#### Overrides

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`forward`](/api/#03-apidocs/classaxprogramwithsignaturemdforward)

***

<a id="getSignature"></a>

### getSignature()

```ts
getSignature(): AxSignature
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L165

#### Returns

[`AxSignature`](/api/#03-apidocs/classaxsignature)

#### Inherited from

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`getSignature`](/api/#03-apidocs/classaxprogramwithsignaturemdgetsignature)

***

<a id="getTraces"></a>

### getTraces()

```ts
getTraces(): AxProgramTrace[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L262

#### Returns

[`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[]

#### Inherited from

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`getTraces`](/api/#03-apidocs/classaxprogramwithsignaturemdgettraces)

***

<a id="getUsage"></a>

### getUsage()

```ts
getUsage(): AxModelUsage & object[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L276

#### Returns

[`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[]

#### Inherited from

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`getUsage`](/api/#03-apidocs/classaxprogramwithsignaturemdgetusage)

***

<a id="register"></a>

### register()

```ts
register(prog: Readonly<AxTunable & AxUsable>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L169

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `prog` | `Readonly`\<[`AxTunable`](/api/#03-apidocs/interfaceaxtunable) & [`AxUsable`](/api/#03-apidocs/interfaceaxusable)\> |

#### Returns

`void`

#### Inherited from

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`register`](/api/#03-apidocs/classaxprogramwithsignaturemdregister)

***

<a id="resetUsage"></a>

### resetUsage()

```ts
resetUsage(): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L286

#### Returns

`void`

#### Inherited from

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`resetUsage`](/api/#03-apidocs/classaxprogramwithsignaturemdresetusage)

***

<a id="setDemos"></a>

### setDemos()

```ts
setDemos(demos: readonly AxProgramDemos[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L293

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `demos` | readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[] |

#### Returns

`void`

#### Inherited from

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`setDemos`](/api/#03-apidocs/classaxprogramwithsignaturemdsetdemos)

***

<a id="setExamples"></a>

### setExamples()

```ts
setExamples(examples: Readonly<AxProgramExamples>, options?: Readonly<AxSetExamplesOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L856

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `examples` | `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\> |
| `options`? | `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\> |

#### Returns

`void`

#### Overrides

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`setExamples`](/api/#03-apidocs/classaxprogramwithsignaturemdsetexamples)

***

<a id="setId"></a>

### setId()

```ts
setId(id: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L199

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `id` | `string` |

#### Returns

`void`

#### Inherited from

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`setId`](/api/#03-apidocs/classaxprogramwithsignaturemdsetid)

***

<a id="setParentId"></a>

### setParentId()

```ts
setParentId(parentId: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentId` | `string` |

#### Returns

`void`

#### Inherited from

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`setParentId`](/api/#03-apidocs/classaxprogramwithsignaturemdsetparentid)

***

<a id="streamingForward"></a>

### streamingForward()

```ts
streamingForward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: IN | AxMessage<IN>[], 
   options?: Readonly<AxProgramStreamingForwardOptions>): AsyncGenerator<{
  delta: Partial<OUT>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L845

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `options`? | `Readonly`\<[`AxProgramStreamingForwardOptions`](/api/#03-apidocs/typealiasaxprogramstreamingforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<`OUT`\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

#### Overrides

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature).[`streamingForward`](/api/#03-apidocs/classaxprogramwithsignaturemdstreamingforward)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxHFDataLoader.md
================================================
---
title: AxHFDataLoader
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/loader.ts#L5

## Constructors

<a id="constructors"></a>

### new AxHFDataLoader()

```ts
new AxHFDataLoader(__namedParameters: Readonly<{
  config: string;
  dataset: string;
  options: Readonly<{
     length: number;
     offset: number;
    }>;
  split: string;
 }>): AxHFDataLoader
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/loader.ts#L14

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<\{ `config`: `string`; `dataset`: `string`; `options`: `Readonly`\<\{ `length`: `number`; `offset`: `number`; \}\>; `split`: `string`; \}\> |

#### Returns

[`AxHFDataLoader`](/api/#03-apidocs/classaxhfdataloader)

## Methods

<a id="getData"></a>

### getData()

```ts
getData(): AxDataRow[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/loader.ts#L67

#### Returns

[`AxDataRow`](/api/#03-apidocs/typealiasaxdatarow)[]

***

<a id="getRows"></a>

### getRows()

```ts
getRows<T>(__namedParameters: Readonly<{
  count: number;
  fields: readonly string[];
  renameMap: Record<string, string>;
}>): Promise<T[]>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/loader.ts#L71

#### Type Parameters

| Type Parameter |
| :------ |
| `T` |

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<\{ `count`: `number`; `fields`: readonly `string`[]; `renameMap`: `Record`\<`string`, `string`\>; \}\> |

#### Returns

`Promise`\<`T`[]\>

***

<a id="loadData"></a>

### loadData()

```ts
loadData(): Promise<AxDataRow[]>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/loader.ts#L51

#### Returns

`Promise`\<[`AxDataRow`](/api/#03-apidocs/typealiasaxdatarow)[]\>

***

<a id="setData"></a>

### setData()

```ts
setData(rows: AxDataRow[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/loader.ts#L63

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `rows` | [`AxDataRow`](/api/#03-apidocs/typealiasaxdatarow)[] |

#### Returns

`void`



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxInstanceRegistry.md
================================================
---
title: AxInstanceRegistry
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/registry.ts#L1

## Type Parameters

| Type Parameter |
| :------ |
| `T` |

## Constructors

<a id="constructors"></a>

### new AxInstanceRegistry()

```ts
new AxInstanceRegistry<T>(): AxInstanceRegistry<T>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/registry.ts#L4

#### Returns

[`AxInstanceRegistry`](/api/#03-apidocs/classaxinstanceregistry)\<`T`\>

## Methods

<a id="iterator"></a>

### \[iterator\]()

```ts
iterator: Generator<T, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/registry.ts#L12

#### Returns

`Generator`\<`T`, `void`, `unknown`\>

***

<a id="register"></a>

### register()

```ts
register(instance: T): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/registry.ts#L8

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `instance` | `T` |

#### Returns

`void`



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxJSInterpreter.md
================================================
---
title: AxJSInterpreter
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/code.ts#L29

## Constructors

<a id="constructors"></a>

### new AxJSInterpreter()

```ts
new AxJSInterpreter(__namedParameters: 
  | undefined
  | Readonly<{
  permissions: readonly AxJSInterpreterPermission[];
 }>): AxJSInterpreter
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/code.ts#L32

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | \| `undefined` \| `Readonly`\<\{ `permissions`: readonly [`AxJSInterpreterPermission`](/api/#03-apidocs/enumerationaxjsinterpreterpermission)[]; \}\> |

#### Returns

[`AxJSInterpreter`](/api/#03-apidocs/classaxjsinterpreter)

## Methods

<a id="toFunction"></a>

### toFunction()

```ts
toFunction(): AxFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/code.ts#L67

#### Returns

[`AxFunction`](/api/#03-apidocs/typealiasaxfunction)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxMemory.md
================================================
---
title: AxMemory
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L180

## Implements

- [`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory)

## Constructors

<a id="constructors"></a>

### new AxMemory()

```ts
new AxMemory(limit: number, options?: object): AxMemory
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L184

#### Parameters

| Parameter | Type | Default value |
| :------ | :------ | :------ |
| `limit` | `number` | `defaultLimit` |
| `options`? | \{ `debug`: `boolean`; `debugHideSystemPrompt`: `boolean`; \} | `undefined` |
| `options.debug`? | `boolean` | `undefined` |
| `options.debugHideSystemPrompt`? | `boolean` | `undefined` |

#### Returns

[`AxMemory`](/api/#03-apidocs/classaxmemory)

## Methods

<a id="add"></a>

### add()

```ts
add(value: 
  | {
  cache: boolean;
  content: string;
  role: "system";
 }
  | {
  content:   | string
     | (
     | {
     cache: boolean;
     text: string;
     type: "text";
    }
     | {
     cache: boolean;
     details: "high" | "low" | "auto";
     image: string;
     mimeType: string;
     type: "image";
    }
     | {
     cache: boolean;
     data: string;
     format: "wav";
     type: "audio";
    })[];
  name: string;
  role: "user";
 }
  | {
  cache: boolean;
  content: string;
  functionCalls: object[];
  name: string;
  role: "assistant";
 }
  | {
  cache: boolean;
  functionId: string;
  isError: boolean;
  result: string;
  role: "function";
 }
  | (
  | {
  cache: boolean;
  content: string;
  role: "system";
 }
  | {
  content:   | string
     | (
     | {
     cache: boolean;
     text: string;
     type: "text";
    }
     | {
     cache: boolean;
     details: "high" | "low" | "auto";
     image: string;
     mimeType: string;
     type: "image";
    }
     | {
     cache: boolean;
     data: string;
     format: "wav";
     type: "audio";
    })[];
  name: string;
  role: "user";
 }
  | {
  cache: boolean;
  content: string;
  functionCalls: object[];
  name: string;
  role: "assistant";
 }
  | {
  cache: boolean;
  functionId: string;
  isError: boolean;
  result: string;
  role: "function";
 })[], sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `value` | \| \{ `cache`: `boolean`; `content`: `string`; `role`: `"system"`; \} \| \{ `content`: \| `string` \| ( \| \{ `cache`: `boolean`; `text`: `string`; `type`: `"text"`; \} \| \{ `cache`: `boolean`; `details`: `"high"` \| `"low"` \| `"auto"`; `image`: `string`; `mimeType`: `string`; `type`: `"image"`; \} \| \{ `cache`: `boolean`; `data`: `string`; `format`: `"wav"`; `type`: `"audio"`; \})[]; `name`: `string`; `role`: `"user"`; \} \| \{ `cache`: `boolean`; `content`: `string`; `functionCalls`: `object`[]; `name`: `string`; `role`: `"assistant"`; \} \| \{ `cache`: `boolean`; `functionId`: `string`; `isError`: `boolean`; `result`: `string`; `role`: `"function"`; \} \| ( \| \{ `cache`: `boolean`; `content`: `string`; `role`: `"system"`; \} \| \{ `content`: \| `string` \| ( \| \{ `cache`: `boolean`; `text`: `string`; `type`: `"text"`; \} \| \{ `cache`: `boolean`; `details`: `"high"` \| `"low"` \| `"auto"`; `image`: `string`; `mimeType`: `string`; `type`: `"image"`; \} \| \{ `cache`: `boolean`; `data`: `string`; `format`: `"wav"`; `type`: `"audio"`; \})[]; `name`: `string`; `role`: `"user"`; \} \| \{ `cache`: `boolean`; `content`: `string`; `functionCalls`: `object`[]; `name`: `string`; `role`: `"assistant"`; \} \| \{ `cache`: `boolean`; `functionId`: `string`; `isError`: `boolean`; `result`: `string`; `role`: `"function"`; \})[] |
| `sessionId`? | `string` |

#### Returns

`void`

#### Implementation of

[`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory).[`add`](/api/#03-apidocs/interfaceaxaimemorymdadd)

***

<a id="addResult"></a>

### addResult()

```ts
addResult(result: Readonly<AxChatResponseResult>, sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L213

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `result` | `Readonly`\<[`AxChatResponseResult`](/api/#03-apidocs/typealiasaxchatresponseresult)\> |
| `sessionId`? | `string` |

#### Returns

`void`

#### Implementation of

[`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory).[`addResult`](/api/#03-apidocs/interfaceaxaimemorymdaddresult)

***

<a id="addTag"></a>

### addTag()

```ts
addTag(name: string, sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L224

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |
| `sessionId`? | `string` |

#### Returns

`void`

#### Implementation of

[`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory).[`addTag`](/api/#03-apidocs/interfaceaxaimemorymdaddtag)

***

<a id="getLast"></a>

### getLast()

```ts
getLast(sessionId?: string): 
  | undefined
  | {
  chat:   | {
     cache: boolean;
     content: string;
     role: "system";
    }
     | {
     content:   | string
        | (
        | {
        cache: boolean;
        text: string;
        type: "text";
       }
        | {
        cache: boolean;
        details: "high" | "low" | "auto";
        image: string;
        mimeType: string;
        type: "image";
       }
        | {
        cache: boolean;
        data: string;
        format: "wav";
        type: "audio";
       })[];
     name: string;
     role: "user";
    }
     | {
     cache: boolean;
     content: string;
     functionCalls: object[];
     name: string;
     role: "assistant";
    }
     | {
     cache: boolean;
     functionId: string;
     isError: boolean;
     result: string;
     role: "function";
    };
  tags: string[];
}
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L236

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `sessionId`? | `string` |

#### Returns

  \| `undefined`
  \| \{
  `chat`:   \| \{
     `cache`: `boolean`;
     `content`: `string`;
     `role`: `"system"`;
    \}
     \| \{
     `content`:   \| `string`
        \| (
        \| \{
        `cache`: `boolean`;
        `text`: `string`;
        `type`: `"text"`;
       \}
        \| \{
        `cache`: `boolean`;
        `details`: `"high"` \| `"low"` \| `"auto"`;
        `image`: `string`;
        `mimeType`: `string`;
        `type`: `"image"`;
       \}
        \| \{
        `cache`: `boolean`;
        `data`: `string`;
        `format`: `"wav"`;
        `type`: `"audio"`;
       \})[];
     `name`: `string`;
     `role`: `"user"`;
    \}
     \| \{
     `cache`: `boolean`;
     `content`: `string`;
     `functionCalls`: `object`[];
     `name`: `string`;
     `role`: `"assistant"`;
    \}
     \| \{
     `cache`: `boolean`;
     `functionId`: `string`;
     `isError`: `boolean`;
     `result`: `string`;
     `role`: `"function"`;
    \};
  `tags`: `string`[];
 \}

#### Implementation of

[`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory).[`getLast`](/api/#03-apidocs/interfaceaxaimemorymdgetlast)

***

<a id="history"></a>

### history()

```ts
history(sessionId?: string): (
  | {
  cache: boolean;
  content: string;
  role: "system";
 }
  | {
  content:   | string
     | (
     | {
     cache: boolean;
     text: string;
     type: "text";
    }
     | {
     cache: boolean;
     details: "high" | "low" | "auto";
     image: string;
     mimeType: string;
     type: "image";
    }
     | {
     cache: boolean;
     data: string;
     format: "wav";
     type: "audio";
    })[];
  name: string;
  role: "user";
 }
  | {
  cache: boolean;
  content: string;
  functionCalls: object[];
  name: string;
  role: "assistant";
 }
  | {
  cache: boolean;
  functionId: string;
  isError: boolean;
  result: string;
  role: "function";
 })[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L232

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `sessionId`? | `string` |

#### Returns

(
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `role`: `"system"`;
 \}
  \| \{
  `content`:   \| `string`
     \| (
     \| \{
     `cache`: `boolean`;
     `text`: `string`;
     `type`: `"text"`;
    \}
     \| \{
     `cache`: `boolean`;
     `details`: `"high"` \| `"low"` \| `"auto"`;
     `image`: `string`;
     `mimeType`: `string`;
     `type`: `"image"`;
    \}
     \| \{
     `cache`: `boolean`;
     `data`: `string`;
     `format`: `"wav"`;
     `type`: `"audio"`;
    \})[];
  `name`: `string`;
  `role`: `"user"`;
 \}
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `functionCalls`: `object`[];
  `name`: `string`;
  `role`: `"assistant"`;
 \}
  \| \{
  `cache`: `boolean`;
  `functionId`: `string`;
  `isError`: `boolean`;
  `result`: `string`;
  `role`: `"function"`;
 \})[]

#### Implementation of

[`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory).[`history`](/api/#03-apidocs/interfaceaxaimemorymdhistory)

***

<a id="reset"></a>

### reset()

```ts
reset(sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L240

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `sessionId`? | `string` |

#### Returns

`void`

#### Implementation of

[`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory).[`reset`](/api/#03-apidocs/interfaceaxaimemorymdreset)

***

<a id="rewindToTag"></a>

### rewindToTag()

```ts
rewindToTag(name: string, sessionId?: string): (
  | {
  cache: boolean;
  content: string;
  role: "system";
 }
  | {
  content:   | string
     | (
     | {
     cache: boolean;
     text: string;
     type: "text";
    }
     | {
     cache: boolean;
     details: "high" | "low" | "auto";
     image: string;
     mimeType: string;
     type: "image";
    }
     | {
     cache: boolean;
     data: string;
     format: "wav";
     type: "audio";
    })[];
  name: string;
  role: "user";
 }
  | {
  cache: boolean;
  content: string;
  functionCalls: object[];
  name: string;
  role: "assistant";
 }
  | {
  cache: boolean;
  functionId: string;
  isError: boolean;
  result: string;
  role: "function";
 })[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L228

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |
| `sessionId`? | `string` |

#### Returns

(
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `role`: `"system"`;
 \}
  \| \{
  `content`:   \| `string`
     \| (
     \| \{
     `cache`: `boolean`;
     `text`: `string`;
     `type`: `"text"`;
    \}
     \| \{
     `cache`: `boolean`;
     `details`: `"high"` \| `"low"` \| `"auto"`;
     `image`: `string`;
     `mimeType`: `string`;
     `type`: `"image"`;
    \}
     \| \{
     `cache`: `boolean`;
     `data`: `string`;
     `format`: `"wav"`;
     `type`: `"audio"`;
    \})[];
  `name`: `string`;
  `role`: `"user"`;
 \}
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `functionCalls`: `object`[];
  `name`: `string`;
  `role`: `"assistant"`;
 \}
  \| \{
  `cache`: `boolean`;
  `functionId`: `string`;
  `isError`: `boolean`;
  `result`: `string`;
  `role`: `"function"`;
 \})[]

#### Implementation of

[`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory).[`rewindToTag`](/api/#03-apidocs/interfaceaxaimemorymdrewindtotag)

***

<a id="updateResult"></a>

### updateResult()

```ts
updateResult(result: Readonly<AxChatResponseResult>, sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/memory.ts#L217

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `result` | `Readonly`\<[`AxChatResponseResult`](/api/#03-apidocs/typealiasaxchatresponseresult)\> |
| `sessionId`? | `string` |

#### Returns

`void`

#### Implementation of

[`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory).[`updateResult`](/api/#03-apidocs/interfaceaxaimemorymdupdateresult)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxProgram.md
================================================
---
title: AxProgram
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L306

## Type Parameters

| Type Parameter |
| :------ |
| `IN` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) |
| `OUT` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |

## Implements

- [`AxTunable`](/api/#03-apidocs/interfaceaxtunable)
- [`AxUsable`](/api/#03-apidocs/interfaceaxusable)

## Constructors

<a id="constructors"></a>

### new AxProgram()

```ts
new AxProgram<IN, OUT>(): AxProgram<IN, OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L315

#### Returns

[`AxProgram`](/api/#03-apidocs/classaxprogram)\<`IN`, `OUT`\>

## Methods

<a id="forward"></a>

### forward()

```ts
forward(
   _ai: Readonly<AxAIService<unknown, unknown>>, 
   _values: IN | AxMessage<IN>[], 
_options?: Readonly<AxProgramForwardOptions>): Promise<OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L327

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `_ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `_values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `_options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`Promise`\<`OUT`\>

***

<a id="getTraces"></a>

### getTraces()

```ts
getTraces(): AxProgramTrace[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L376

#### Returns

[`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[]

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`getTraces`](/api/#03-apidocs/interfaceaxtunablemdgettraces)

***

<a id="getUsage"></a>

### getUsage()

```ts
getUsage(): AxModelUsage & object[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L390

#### Returns

[`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[]

#### Implementation of

[`AxUsable`](/api/#03-apidocs/interfaceaxusable).[`getUsage`](/api/#03-apidocs/interfaceaxusablemdgetusage)

***

<a id="register"></a>

### register()

```ts
register(prog: Readonly<AxTunable & AxUsable>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L320

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `prog` | `Readonly`\<[`AxTunable`](/api/#03-apidocs/interfaceaxtunable) & [`AxUsable`](/api/#03-apidocs/interfaceaxusable)\> |

#### Returns

`void`

***

<a id="resetUsage"></a>

### resetUsage()

```ts
resetUsage(): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L400

#### Returns

`void`

#### Implementation of

[`AxUsable`](/api/#03-apidocs/interfaceaxusable).[`resetUsage`](/api/#03-apidocs/interfaceaxusablemdresetusage)

***

<a id="setDemos"></a>

### setDemos()

```ts
setDemos(demos: readonly AxProgramDemos[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L407

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `demos` | readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[] |

#### Returns

`void`

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setDemos`](/api/#03-apidocs/interfaceaxtunablemdsetdemos)

***

<a id="setExamples"></a>

### setExamples()

```ts
setExamples(examples: Readonly<AxProgramExamples>, options?: Readonly<AxSetExamplesOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L363

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `examples` | `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\> |
| `options`? | `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\> |

#### Returns

`void`

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setExamples`](/api/#03-apidocs/interfaceaxtunablemdsetexamples)

***

<a id="setId"></a>

### setId()

```ts
setId(id: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L350

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `id` | `string` |

#### Returns

`void`

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setId`](/api/#03-apidocs/interfaceaxtunablemdsetid)

***

<a id="setParentId"></a>

### setParentId()

```ts
setParentId(parentId: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L357

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentId` | `string` |

#### Returns

`void`

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setParentId`](/api/#03-apidocs/interfaceaxtunablemdsetparentid)

***

<a id="streamingForward"></a>

### streamingForward()

```ts
streamingForward(
   _ai: Readonly<AxAIService<unknown, unknown>>, 
   _values: IN | AxMessage<IN>[], 
_options?: Readonly<AxProgramStreamingForwardOptions>): AxGenStreamingOut<OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L339

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `_ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `_values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `_options`? | `Readonly`\<[`AxProgramStreamingForwardOptions`](/api/#03-apidocs/typealiasaxprogramstreamingforwardoptions)\> |

#### Returns

[`AxGenStreamingOut`](/api/#03-apidocs/typealiasaxgenstreamingout)\<`OUT`\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxProgramWithSignature.md
================================================
---
title: AxProgramWithSignature
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L136

## Extended by

- [`AxGen`](/api/#03-apidocs/classaxgen)

## Type Parameters

| Type Parameter |
| :------ |
| `IN` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) |
| `OUT` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |

## Implements

- [`AxTunable`](/api/#03-apidocs/interfaceaxtunable)
- [`AxUsable`](/api/#03-apidocs/interfaceaxusable)

## Constructors

<a id="constructors"></a>

### new AxProgramWithSignature()

```ts
new AxProgramWithSignature<IN, OUT>(signature: Readonly<string | AxSignature>, options?: Readonly<AxProgramWithSignatureOptions>): AxProgramWithSignature<IN, OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L151

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `signature` | `Readonly`\<`string` \| [`AxSignature`](/api/#03-apidocs/classaxsignature)\> |
| `options`? | `Readonly`\<[`AxProgramWithSignatureOptions`](/api/#03-apidocs/interfaceaxprogramwithsignatureoptions)\> |

#### Returns

[`AxProgramWithSignature`](/api/#03-apidocs/classaxprogramwithsignature)\<`IN`, `OUT`\>

## Methods

<a id="forward"></a>

### forward()

```ts
forward(
   _ai: Readonly<AxAIService<unknown, unknown>>, 
   _values: IN | AxMessage<IN>[], 
_options?: Readonly<AxProgramForwardOptions>): Promise<OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L176

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `_ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `_values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `_options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`Promise`\<`OUT`\>

***

<a id="getSignature"></a>

### getSignature()

```ts
getSignature(): AxSignature
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L165

#### Returns

[`AxSignature`](/api/#03-apidocs/classaxsignature)

***

<a id="getTraces"></a>

### getTraces()

```ts
getTraces(): AxProgramTrace[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L262

#### Returns

[`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[]

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`getTraces`](/api/#03-apidocs/interfaceaxtunablemdgettraces)

***

<a id="getUsage"></a>

### getUsage()

```ts
getUsage(): AxModelUsage & object[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L276

#### Returns

[`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[]

#### Implementation of

[`AxUsable`](/api/#03-apidocs/interfaceaxusable).[`getUsage`](/api/#03-apidocs/interfaceaxusablemdgetusage)

***

<a id="register"></a>

### register()

```ts
register(prog: Readonly<AxTunable & AxUsable>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L169

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `prog` | `Readonly`\<[`AxTunable`](/api/#03-apidocs/interfaceaxtunable) & [`AxUsable`](/api/#03-apidocs/interfaceaxusable)\> |

#### Returns

`void`

***

<a id="resetUsage"></a>

### resetUsage()

```ts
resetUsage(): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L286

#### Returns

`void`

#### Implementation of

[`AxUsable`](/api/#03-apidocs/interfaceaxusable).[`resetUsage`](/api/#03-apidocs/interfaceaxusablemdresetusage)

***

<a id="setDemos"></a>

### setDemos()

```ts
setDemos(demos: readonly AxProgramDemos[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L293

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `demos` | readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[] |

#### Returns

`void`

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setDemos`](/api/#03-apidocs/interfaceaxtunablemdsetdemos)

***

<a id="setExamples"></a>

### setExamples()

```ts
setExamples(examples: Readonly<AxProgramExamples>, options?: Readonly<AxSetExamplesOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L212

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `examples` | `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\> |
| `options`? | `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\> |

#### Returns

`void`

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setExamples`](/api/#03-apidocs/interfaceaxtunablemdsetexamples)

***

<a id="setId"></a>

### setId()

```ts
setId(id: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L199

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `id` | `string` |

#### Returns

`void`

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setId`](/api/#03-apidocs/interfaceaxtunablemdsetid)

***

<a id="setParentId"></a>

### setParentId()

```ts
setParentId(parentId: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentId` | `string` |

#### Returns

`void`

#### Implementation of

[`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setParentId`](/api/#03-apidocs/interfaceaxtunablemdsetparentid)

***

<a id="streamingForward"></a>

### streamingForward()

```ts
streamingForward(
   _ai: Readonly<AxAIService<unknown, unknown>>, 
   _values: IN | AxMessage<IN>[], 
_options?: Readonly<AxProgramStreamingForwardOptions>): AxGenStreamingOut<OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L188

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `_ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `_values` | `IN` \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`IN`\>[] |
| `_options`? | `Readonly`\<[`AxProgramStreamingForwardOptions`](/api/#03-apidocs/typealiasaxprogramstreamingforwardoptions)\> |

#### Returns

[`AxGenStreamingOut`](/api/#03-apidocs/typealiasaxgenstreamingout)\<`OUT`\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxPromptTemplate.md
================================================
---
title: AxPromptTemplate
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/prompt.ts#L41

## Constructors

<a id="constructors"></a>

### new AxPromptTemplate()

```ts
new AxPromptTemplate(
   sig: Readonly<AxSignature>, 
   options?: Readonly<AxPromptTemplateOptions>, 
   fieldTemplates?: Record<string, AxFieldTemplateFn>): AxPromptTemplate
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/prompt.ts#L48

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `sig` | `Readonly`\<[`AxSignature`](/api/#03-apidocs/classaxsignature)\> |
| `options`? | `Readonly`\<[`AxPromptTemplateOptions`](/api/#03-apidocs/interfaceaxprompttemplateoptions)\> |
| `fieldTemplates`? | `Record`\<`string`, [`AxFieldTemplateFn`](/api/#03-apidocs/typealiasaxfieldtemplatefn)\> |

#### Returns

[`AxPromptTemplate`](/api/#03-apidocs/classaxprompttemplate)

## Methods

<a id="render"></a>

### render()

```ts
render<T>(values: T | readonly AxMessage<T>[], __namedParameters: Readonly<{
  demos: Record<string, AxFieldValue>[];
  examples: Record<string, AxFieldValue>[];
  skipSystemPrompt: boolean;
 }>): (
  | {
  cache: boolean;
  content: string;
  role: "system";
 }
  | {
  content:   | string
     | (
     | {
     cache: boolean;
     text: string;
     type: "text";
    }
     | {
     cache: boolean;
     details: "high" | "low" | "auto";
     image: string;
     mimeType: string;
     type: "image";
    }
     | {
     cache: boolean;
     data: string;
     format: "wav";
     type: "audio";
    })[];
  name: string;
  role: "user";
 }
  | {
  cache: boolean;
  content: string;
  functionCalls: object[];
  name: string;
  role: "assistant";
 }
  | {
  cache: boolean;
  functionId: string;
  isError: boolean;
  result: string;
  role: "function";
 })[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/prompt.ts#L103

#### Type Parameters

| Type Parameter |
| :------ |
| `T` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) |

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `values` | `T` \| readonly [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<`T`\>[] |
| `__namedParameters` | `Readonly`\<\{ `demos`: `Record`\<`string`, [`AxFieldValue`](/api/#03-apidocs/typealiasaxfieldvalue)\>[]; `examples`: `Record`\<`string`, [`AxFieldValue`](/api/#03-apidocs/typealiasaxfieldvalue)\>[]; `skipSystemPrompt`: `boolean`; \}\> |

#### Returns

(
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `role`: `"system"`;
 \}
  \| \{
  `content`:   \| `string`
     \| (
     \| \{
     `cache`: `boolean`;
     `text`: `string`;
     `type`: `"text"`;
    \}
     \| \{
     `cache`: `boolean`;
     `details`: `"high"` \| `"low"` \| `"auto"`;
     `image`: `string`;
     `mimeType`: `string`;
     `type`: `"image"`;
    \}
     \| \{
     `cache`: `boolean`;
     `data`: `string`;
     `format`: `"wav"`;
     `type`: `"audio"`;
    \})[];
  `name`: `string`;
  `role`: `"user"`;
 \}
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `functionCalls`: `object`[];
  `name`: `string`;
  `role`: `"assistant"`;
 \}
  \| \{
  `cache`: `boolean`;
  `functionId`: `string`;
  `isError`: `boolean`;
  `result`: `string`;
  `role`: `"function"`;
 \})[]

***

<a id="renderExtraFields"></a>

### renderExtraFields()

```ts
renderExtraFields(extraFields: readonly AxIField[]): (
  | {
  cache: boolean;
  text: string;
  type: "text";
 }
  | {
  cache: boolean;
  details: "high" | "low" | "auto";
  image: string;
  mimeType: string;
  type: "image";
 }
  | {
  cache: boolean;
  data: string;
  format: "wav";
  type: "audio";
 })[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/prompt.ts#L232

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `extraFields` | readonly [`AxIField`](/api/#03-apidocs/typealiasaxifield)[] |

#### Returns

(
  \| \{
  `cache`: `boolean`;
  `text`: `string`;
  `type`: `"text"`;
 \}
  \| \{
  `cache`: `boolean`;
  `details`: `"high"` \| `"low"` \| `"auto"`;
  `image`: `string`;
  `mimeType`: `string`;
  `type`: `"image"`;
 \}
  \| \{
  `cache`: `boolean`;
  `data`: `string`;
  `format`: `"wav"`;
  `type`: `"audio"`;
 \})[]



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxRAG.md
================================================
---
title: AxRAG
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/rag.ts#L8

## Extends

- [`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought)\<\{
  `context`: `string`[];
  `question`: `string`;
 \}, \{
  `answer`: `string`;
 \}\>

## Constructors

<a id="constructors"></a>

### new AxRAG()

```ts
new AxRAG(queryFn: (query: string) => Promise<string>, options: Readonly<AxProgramForwardOptions & object>): AxRAG
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/rag.ts#L19

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `queryFn` | (`query`: `string`) => `Promise`\<`string`\> |
| `options` | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions) & `object`\> |

#### Returns

[`AxRAG`](/api/#03-apidocs/classaxrag)

#### Overrides

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`constructor`](/api/#03-apidocs/classaxchainofthoughtmdconstructors)

## Methods

<a id="_forward1"></a>

### \_forward1()

```ts
_forward1(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: 
  | {
  context: string[];
  question: string;
 }
  | AxMessage<{
  context: string[];
  question: string;
 }>[], 
   options: Readonly<AxProgramForwardOptions>): AsyncGenerator<{
  delta: Partial<{
     answer: string;
    }>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L746

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | \| \{ `context`: `string`[]; `question`: `string`; \} \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<\{ `context`: `string`[]; `question`: `string`; \}\>[] |
| `options` | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<\{
     `answer`: `string`;
    \}\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`_forward1`](/api/#03-apidocs/classaxchainofthoughtmdforward1)

***

<a id="addAssert"></a>

### addAssert()

```ts
addAssert(fn: (values: Record<string, unknown>) => undefined | boolean | Promise<undefined | boolean>, message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L136

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fn` | (`values`: `Record`\<`string`, `unknown`\>) => `undefined` \| `boolean` \| `Promise`\<`undefined` \| `boolean`\> |
| `message`? | `string` |

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`addAssert`](/api/#03-apidocs/classaxchainofthoughtmdaddassert)

***

<a id="addFieldProcessor"></a>

### addFieldProcessor()

```ts
addFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L183

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`addFieldProcessor`](/api/#03-apidocs/classaxchainofthoughtmdaddfieldprocessor)

***

<a id="addStreamingAssert"></a>

### addStreamingAssert()

```ts
addStreamingAssert(
   fieldName: string, 
   fn: (content: string, done?: boolean) => undefined | boolean, 
   message?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L140

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | (`content`: `string`, `done`?: `boolean`) => `undefined` \| `boolean` |
| `message`? | `string` |

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`addStreamingAssert`](/api/#03-apidocs/classaxchainofthoughtmdaddstreamingassert)

***

<a id="addStreamingFieldProcessor"></a>

### addStreamingFieldProcessor()

```ts
addStreamingFieldProcessor(fieldName: string, fn: 
  | AxFieldProcessorProcess
  | AxStreamingFieldProcessorProcess): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L176

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fieldName` | `string` |
| `fn` | \| [`AxFieldProcessorProcess`](/api/#03-apidocs/typealiasaxfieldprocessorprocess) \| [`AxStreamingFieldProcessorProcess`](/api/#03-apidocs/typealiasaxstreamingfieldprocessorprocess) |

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`addStreamingFieldProcessor`](/api/#03-apidocs/classaxchainofthoughtmdaddstreamingfieldprocessor)

***

<a id="forward"></a>

### forward()

```ts
forward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: 
  | {
  context: string[];
  question: string;
 }
  | AxMessage<{
  context: string[];
  question: string;
 }>[], 
   options?: Readonly<AxProgramForwardOptions>): Promise<{
  answer: string;
}>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/rag.ts#L40

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | \| \{ `context`: `string`[]; `question`: `string`; \} \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<\{ `context`: `string`[]; `question`: `string`; \}\>[] |
| `options`? | `Readonly`\<[`AxProgramForwardOptions`](/api/#03-apidocs/typealiasaxprogramforwardoptions)\> |

#### Returns

`Promise`\<\{
  `answer`: `string`;
 \}\>

#### Overrides

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`forward`](/api/#03-apidocs/classaxchainofthoughtmdforward)

***

<a id="getSignature"></a>

### getSignature()

```ts
getSignature(): AxSignature
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L165

#### Returns

[`AxSignature`](/api/#03-apidocs/classaxsignature)

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`getSignature`](/api/#03-apidocs/classaxchainofthoughtmdgetsignature)

***

<a id="getTraces"></a>

### getTraces()

```ts
getTraces(): AxProgramTrace[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L262

#### Returns

[`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[]

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`getTraces`](/api/#03-apidocs/classaxchainofthoughtmdgettraces)

***

<a id="getUsage"></a>

### getUsage()

```ts
getUsage(): AxModelUsage & object[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L276

#### Returns

[`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[]

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`getUsage`](/api/#03-apidocs/classaxchainofthoughtmdgetusage)

***

<a id="register"></a>

### register()

```ts
register(prog: Readonly<AxTunable & AxUsable>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L169

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `prog` | `Readonly`\<[`AxTunable`](/api/#03-apidocs/interfaceaxtunable) & [`AxUsable`](/api/#03-apidocs/interfaceaxusable)\> |

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`register`](/api/#03-apidocs/classaxchainofthoughtmdregister)

***

<a id="resetUsage"></a>

### resetUsage()

```ts
resetUsage(): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L286

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`resetUsage`](/api/#03-apidocs/classaxchainofthoughtmdresetusage)

***

<a id="setDemos"></a>

### setDemos()

```ts
setDemos(demos: readonly AxProgramDemos[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L293

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `demos` | readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[] |

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`setDemos`](/api/#03-apidocs/classaxchainofthoughtmdsetdemos)

***

<a id="setExamples"></a>

### setExamples()

```ts
setExamples(examples: Readonly<AxProgramExamples>, options?: Readonly<AxSetExamplesOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L856

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `examples` | `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\> |
| `options`? | `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\> |

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`setExamples`](/api/#03-apidocs/classaxchainofthoughtmdsetexamples)

***

<a id="setId"></a>

### setId()

```ts
setId(id: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L199

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `id` | `string` |

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`setId`](/api/#03-apidocs/classaxchainofthoughtmdsetid)

***

<a id="setParentId"></a>

### setParentId()

```ts
setParentId(parentId: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L206

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `parentId` | `string` |

#### Returns

`void`

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`setParentId`](/api/#03-apidocs/classaxchainofthoughtmdsetparentid)

***

<a id="streamingForward"></a>

### streamingForward()

```ts
streamingForward(
   ai: Readonly<AxAIService<unknown, unknown>>, 
   values: 
  | {
  context: string[];
  question: string;
 }
  | AxMessage<{
  context: string[];
  question: string;
 }>[], 
   options?: Readonly<AxProgramStreamingForwardOptions>): AsyncGenerator<{
  delta: Partial<{
     answer: string;
    }>;
  version: number;
}, void, unknown>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L845

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| `values` | \| \{ `context`: `string`[]; `question`: `string`; \} \| [`AxMessage`](/api/#03-apidocs/typealiasaxmessage)\<\{ `context`: `string`[]; `question`: `string`; \}\>[] |
| `options`? | `Readonly`\<[`AxProgramStreamingForwardOptions`](/api/#03-apidocs/typealiasaxprogramstreamingforwardoptions)\> |

#### Returns

`AsyncGenerator`\<\{
  `delta`: `Partial`\<\{
     `answer`: `string`;
    \}\>;
  `version`: `number`;
 \}, `void`, `unknown`\>

#### Inherited from

[`AxChainOfThought`](/api/#03-apidocs/classaxchainofthought).[`streamingForward`](/api/#03-apidocs/classaxchainofthoughtmdstreamingforward)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxRateLimiterTokenUsage.md
================================================
---
title: AxRateLimiterTokenUsage
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/util/rate-limit.ts#L9

## Constructors

<a id="constructors"></a>

### new AxRateLimiterTokenUsage()

```ts
new AxRateLimiterTokenUsage(
   maxTokens: number, 
   refillRate: number, 
   options?: Readonly<AxRateLimiterTokenUsageOptions>): AxRateLimiterTokenUsage
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/util/rate-limit.ts#L16

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `maxTokens` | `number` |
| `refillRate` | `number` |
| `options`? | `Readonly`\<[`AxRateLimiterTokenUsageOptions`](/api/#03-apidocs/interfaceaxratelimitertokenusageoptions)\> |

#### Returns

[`AxRateLimiterTokenUsage`](/api/#03-apidocs/classaxratelimitertokenusage)

## Methods

<a id="acquire"></a>

### acquire()

```ts
acquire(tokens: number): Promise<void>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/util/rate-limit.ts#L56

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `tokens` | `number` |

#### Returns

`Promise`\<`void`\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxSignature.md
================================================
---
title: AxSignature
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L37

## Constructors

<a id="constructors"></a>

### new AxSignature()

```ts
new AxSignature(signature?: Readonly<string | AxSignature>): AxSignature
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L45

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `signature`? | `Readonly`\<`string` \| [`AxSignature`](/api/#03-apidocs/classaxsignature)\> |

#### Returns

[`AxSignature`](/api/#03-apidocs/classaxsignature)

## Methods

<a id="addInputField"></a>

### addInputField()

```ts
addInputField(field: Readonly<AxField>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L118

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `field` | `Readonly`\<[`AxField`](/api/#03-apidocs/interfaceaxfield)\> |

#### Returns

`void`

***

<a id="addOutputField"></a>

### addOutputField()

```ts
addOutputField(field: Readonly<AxField>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L123

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `field` | `Readonly`\<[`AxField`](/api/#03-apidocs/interfaceaxfield)\> |

#### Returns

`void`

***

<a id="getDescription"></a>

### getDescription()

```ts
getDescription(): undefined | string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L140

#### Returns

`undefined` \| `string`

***

<a id="getInputFields"></a>

### getInputFields()

```ts
getInputFields(): readonly AxIField[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L138

#### Returns

readonly [`AxIField`](/api/#03-apidocs/typealiasaxifield)[]

***

<a id="getOutputFields"></a>

### getOutputFields()

```ts
getOutputFields(): readonly AxIField[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L139

#### Returns

readonly [`AxIField`](/api/#03-apidocs/typealiasaxifield)[]

***

<a id="hash"></a>

### hash()

```ts
hash(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L210

#### Returns

`string`

***

<a id="setDescription"></a>

### setDescription()

```ts
setDescription(desc: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L113

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `desc` | `string` |

#### Returns

`void`

***

<a id="setInputFields"></a>

### setInputFields()

```ts
setInputFields(fields: readonly AxField[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L128

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fields` | readonly [`AxField`](/api/#03-apidocs/interfaceaxfield)[] |

#### Returns

`void`

***

<a id="setOutputFields"></a>

### setOutputFields()

```ts
setOutputFields(fields: readonly AxField[]): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L133

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `fields` | readonly [`AxField`](/api/#03-apidocs/interfaceaxfield)[] |

#### Returns

`void`

***

<a id="toJSON"></a>

### toJSON()

```ts
toJSON(): object
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L214

#### Returns

`object`

| Name | Type |
| :------ | :------ |
| <a id="description"></a> `description` | `undefined` \| `string` |
| <a id="id"></a> `id` | `string` |
| <a id="inputFields"></a> `inputFields` | [`AxIField`](/api/#03-apidocs/typealiasaxifield)[] |
| <a id="outputFields"></a> `outputFields` | [`AxIField`](/api/#03-apidocs/typealiasaxifield)[] |

***

<a id="toJSONSchema"></a>

### toJSONSchema()

```ts
toJSONSchema(): AxFunctionJSONSchema
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L148

#### Returns

[`AxFunctionJSONSchema`](/api/#03-apidocs/typealiasaxfunctionjsonschema)

***

<a id="toString"></a>

### toString()

```ts
toString(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L212

#### Returns

`string`



================================================
FILE: src/docs/src/content/docs/03-apidocs/Class.AxTestPrompt.md
================================================
---
title: AxTestPrompt
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/evaluate.ts#L14

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `IN` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) | [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) |
| `OUT` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) | [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |

## Constructors

<a id="constructors"></a>

### new AxTestPrompt()

```ts
new AxTestPrompt<IN, OUT>(__namedParameters: Readonly<AxEvaluateArgs<IN, OUT>>): AxTestPrompt<IN, OUT>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/evaluate.ts#L22

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `__namedParameters` | `Readonly`\<[`AxEvaluateArgs`](/api/#03-apidocs/typealiasaxevaluateargs)\<`IN`, `OUT`\>\> |

#### Returns

[`AxTestPrompt`](/api/#03-apidocs/classaxtestprompt)\<`IN`, `OUT`\>

## Methods

<a id="run"></a>

### run()

```ts
run(metricFn: AxMetricFn): Promise<void>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/evaluate.ts#L35

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `metricFn` | [`AxMetricFn`](/api/#03-apidocs/typealiasaxmetricfn) |

#### Returns

`Promise`\<`void`\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIAnthropicModel.md
================================================
---
title: AxAIAnthropicModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L3

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="Claude21"></a> `Claude21` | `"claude-2.1"` |
| <a id="Claude35Haiku"></a> `Claude35Haiku` | `"claude-3-5-haiku-latest"` |
| <a id="Claude35Sonnet"></a> `Claude35Sonnet` | `"claude-3-5-sonnet-latest"` |
| <a id="Claude37Sonnet"></a> `Claude37Sonnet` | `"claude-3-7-sonnet-latest"` |
| <a id="Claude3Haiku"></a> `Claude3Haiku` | `"claude-3-haiku-20240307"` |
| <a id="Claude3Opus"></a> `Claude3Opus` | `"claude-3-opus-latest"` |
| <a id="Claude3Sonnet"></a> `Claude3Sonnet` | `"claude-3-sonnet-20240229"` |
| <a id="Claude4Opus"></a> `Claude4Opus` | `"claude-opus-4-20250514"` |
| <a id="Claude4Sonnet"></a> `Claude4Sonnet` | `"claude-sonnet-4-20250514"` |
| <a id="ClaudeInstant12"></a> `ClaudeInstant12` | `"claude-instant-1.2"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAICohereEmbedModel.md
================================================
---
title: AxAICohereEmbedModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L16

Cohere: Models for use in embeddings

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="EmbedEnglishLightV30"></a> `EmbedEnglishLightV30` | `"embed-english-light-v3.0"` |
| <a id="EmbedEnglishV30"></a> `EmbedEnglishV30` | `"embed-english-v3.0"` |
| <a id="EmbedMultiLingualLightV30"></a> `EmbedMultiLingualLightV30` | `"embed-multilingual-light-v3.0"` |
| <a id="EmbedMultiLingualV30"></a> `EmbedMultiLingualV30` | `"embed-multilingual-v3.0"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAICohereModel.md
================================================
---
title: AxAICohereModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L6

Cohere: Models for text generation

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="Command"></a> `Command` | `"command"` |
| <a id="CommandLight"></a> `CommandLight` | `"command-light"` |
| <a id="CommandR"></a> `CommandR` | `"command-r"` |
| <a id="CommandRPlus"></a> `CommandRPlus` | `"command-r-plus"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIDeepSeekModel.md
================================================
---
title: AxAIDeepSeekModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/deepseek/types.ts#L4

DeepSeek: Models for text generation

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="DeepSeekChat"></a> `DeepSeekChat` | `"deepseek-chat"` |
| <a id="DeepSeekCoder"></a> `DeepSeekCoder` | `"deepseek-coder"` |
| <a id="DeepSeekReasoner"></a> `DeepSeekReasoner` | `"deepseek-reasoner"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIGoogleGeminiEmbedModel.md
================================================
---
title: AxAIGoogleGeminiEmbedModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L15

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="GeminiEmbedding"></a> `GeminiEmbedding` | `"gemini-embedding-exp-03-07"` |
| <a id="TextEmbedding004"></a> `TextEmbedding004` | `"text-embedding-004"` |
| <a id="TextEmbedding005"></a> `TextEmbedding005` | `"text-embedding-005"` |
| <a id="TextEmbeddingLarge"></a> `TextEmbeddingLarge` | `"text-embedding-large-exp-03-07"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIGoogleGeminiModel.md
================================================
---
title: AxAIGoogleGeminiModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L3

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="Gemini15Flash"></a> `Gemini15Flash` | `"gemini-1.5-flash"` |
| <a id="Gemini15Flash002"></a> `Gemini15Flash002` | `"gemini-1.5-flash-002"` |
| <a id="Gemini15Flash8B"></a> `Gemini15Flash8B` | `"gemini-1.5-flash-8b"` |
| <a id="Gemini15Pro"></a> `Gemini15Pro` | `"gemini-1.5-pro"` |
| <a id="Gemini1Pro"></a> `Gemini1Pro` | `"gemini-1.0-pro"` |
| <a id="Gemini20Flash"></a> `Gemini20Flash` | `"gemini-2.0-flash"` |
| <a id="Gemini20FlashLite"></a> `Gemini20FlashLite` | `"gemini-2.0-flash-lite-preview-02-05"` |
| <a id="Gemini25Flash"></a> `Gemini25Flash` | `"gemini-2.5-flash-preview-04-17"` |
| <a id="Gemini25Pro"></a> `Gemini25Pro` | `"gemini-2.5-pro-preview-05-06"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIGoogleGeminiSafetyCategory.md
================================================
---
title: AxAIGoogleGeminiSafetyCategory
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L22

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="HarmCategoryDangerousContent"></a> `HarmCategoryDangerousContent` | `"HARM_CATEGORY_DANGEROUS_CONTENT"` |
| <a id="HarmCategoryHarassment"></a> `HarmCategoryHarassment` | `"HARM_CATEGORY_HARASSMENT"` |
| <a id="HarmCategoryHateSpeech"></a> `HarmCategoryHateSpeech` | `"HARM_CATEGORY_HATE_SPEECH"` |
| <a id="HarmCategorySexuallyExplicit"></a> `HarmCategorySexuallyExplicit` | `"HARM_CATEGORY_SEXUALLY_EXPLICIT"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIGoogleGeminiSafetyThreshold.md
================================================
---
title: AxAIGoogleGeminiSafetyThreshold
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L29

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="BlockDefault"></a> `BlockDefault` | `"HARM_BLOCK_THRESHOLD_UNSPECIFIED"` |
| <a id="BlockLowAndAbove"></a> `BlockLowAndAbove` | `"BLOCK_LOW_AND_ABOVE"` |
| <a id="BlockMediumAndAbove"></a> `BlockMediumAndAbove` | `"BLOCK_MEDIUM_AND_ABOVE"` |
| <a id="BlockNone"></a> `BlockNone` | `"BLOCK_NONE"` |
| <a id="BlockOnlyHigh"></a> `BlockOnlyHigh` | `"BLOCK_ONLY_HIGH"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIGroqModel.md
================================================
---
title: AxAIGroqModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/groq/types.ts#L1

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="Gemma2_9B"></a> `Gemma2_9B` | `"gemma2-9b-it"` |
| <a id="Llama3_8B"></a> `Llama3_8B` | `"llama3-8b-8192"` |
| <a id="Llama33_70B"></a> `Llama33_70B` | `"llama-3.3-70b-versatile"` |
| <a id="Mixtral_8x7B"></a> `Mixtral_8x7B` | `"mixtral-8x7b-32768"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIHuggingFaceModel.md
================================================
---
title: AxAIHuggingFaceModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/huggingface/types.ts#L3

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="MetaLlama270BChatHF"></a> `MetaLlama270BChatHF` | `"meta-llama/Llama-2-70b-chat-hf"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIMistralEmbedModels.md
================================================
---
title: AxAIMistralEmbedModels
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/mistral/types.ts#L14

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="MistralEmbed"></a> `MistralEmbed` | `"mistral-embed"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIMistralModel.md
================================================
---
title: AxAIMistralModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/mistral/types.ts#L3

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="Codestral"></a> `Codestral` | `"codestral-latest"` |
| <a id="Mistral7B"></a> `Mistral7B` | `"open-mistral-7b"` |
| <a id="Mistral8x7B"></a> `Mistral8x7B` | `"open-mixtral-8x7b"` |
| <a id="MistralLarge"></a> `MistralLarge` | `"mistral-large-latest"` |
| <a id="MistralNemo"></a> `MistralNemo` | `"mistral-nemo-latest"` |
| <a id="MistralSmall"></a> `MistralSmall` | `"mistral-small-latest"` |
| <a id="OpenCodestralMamba"></a> `OpenCodestralMamba` | `"open-codestral-mamba"` |
| <a id="OpenMistralNemo"></a> `OpenMistralNemo` | `"open-mistral-nemo-latest"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIOpenAIEmbedModel.md
================================================
---
title: AxAIOpenAIEmbedModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L20

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="TextEmbedding3Large"></a> `TextEmbedding3Large` | `"text-embedding-3-large"` |
| <a id="TextEmbedding3Small"></a> `TextEmbedding3Small` | `"text-embedding-3-small"` |
| <a id="TextEmbeddingAda002"></a> `TextEmbeddingAda002` | `"text-embedding-ada-002"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIOpenAIModel.md
================================================
---
title: AxAIOpenAIModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L3

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="GPT35TextDavinci002"></a> `GPT35TextDavinci002` | `"text-davinci-002"` |
| <a id="GPT35Turbo"></a> `GPT35Turbo` | `"gpt-3.5-turbo"` |
| <a id="GPT35TurboInstruct"></a> `GPT35TurboInstruct` | `"gpt-3.5-turbo-instruct"` |
| <a id="GPT3TextAda001"></a> `GPT3TextAda001` | `"text-ada-001"` |
| <a id="GPT3TextBabbage002"></a> `GPT3TextBabbage002` | `"text-babbage-002"` |
| <a id="GPT4"></a> `GPT4` | `"gpt-4"` |
| <a id="GPT41"></a> `GPT41` | `"gpt-4.1"` |
| <a id="GPT41Mini"></a> `GPT41Mini` | `"gpt-4.1-mini"` |
| <a id="GPT4ChatGPT4O"></a> `GPT4ChatGPT4O` | `"chatgpt-4o-latest"` |
| <a id="GPT4O"></a> `GPT4O` | `"gpt-4o"` |
| <a id="GPT4OMini"></a> `GPT4OMini` | `"gpt-4o-mini"` |
| <a id="GPT4Turbo"></a> `GPT4Turbo` | `"gpt-4-turbo"` |
| <a id="O1"></a> `O1` | `"o1"` |
| <a id="O1Mini"></a> `O1Mini` | `"o1-mini"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxAIRekaModel.md
================================================
---
title: AxAIRekaModel
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/reka/types.ts#L3

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="RekaCore"></a> `RekaCore` | `"reka-core"` |
| <a id="RekaEdge"></a> `RekaEdge` | `"reka-edge"` |
| <a id="RekaFlash"></a> `RekaFlash` | `"reka-flash"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxJSInterpreterPermission.md
================================================
---
title: AxJSInterpreterPermission
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/code.ts#L11

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="CRYPTO"></a> `CRYPTO` | `"crypto"` |
| <a id="FS"></a> `FS` | `"node:fs"` |
| <a id="NET"></a> `NET` | `"net"` |
| <a id="OS"></a> `OS` | `"os"` |
| <a id="PROCESS"></a> `PROCESS` | `"process"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxLLMRequestTypeValues.md
================================================
---
title: AxLLMRequestTypeValues
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/trace/trace.ts#L54

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="CHAT"></a> `CHAT` | `"chat"` |
| <a id="COMPLETION"></a> `COMPLETION` | `"completion"` |
| <a id="RERANK"></a> `RERANK` | `"rerank"` |
| <a id="UNKNOWN"></a> `UNKNOWN` | `"unknown"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Enumeration.AxSpanKindValues.md
================================================
---
title: AxSpanKindValues
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/trace/trace.ts#L61

## Enumeration Members

| Enumeration Member | Value |
| :------ | :------ |
| <a id="AGENT"></a> `AGENT` | `"agent"` |
| <a id="TASK"></a> `TASK` | `"task"` |
| <a id="TOOL"></a> `TOOL` | `"tool"` |
| <a id="UNKNOWN"></a> `UNKNOWN` | `"unknown"` |
| <a id="WORKFLOW"></a> `WORKFLOW` | `"workflow"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAgentic.md
================================================
---
title: AxAgentic
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L28

Interface for agents that can be used as child agents.
Provides methods to get the agent's function definition and features.

## Extends

- [`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`AxUsable`](/api/#03-apidocs/interfaceaxusable)

## Properties

| Property | Type | Inherited from |
| :------ | :------ | :------ |
| <a id="getTraces"></a> `getTraces` | () => [`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[] | [`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`getTraces`](/api/#03-apidocs/interfaceaxtunablemdgettraces) |
| <a id="getUsage"></a> `getUsage` | () => [`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[] | [`AxUsable`](/api/#03-apidocs/interfaceaxusable).[`getUsage`](/api/#03-apidocs/interfaceaxusablemdgetusage) |
| <a id="resetUsage"></a> `resetUsage` | () => `void` | [`AxUsable`](/api/#03-apidocs/interfaceaxusable).[`resetUsage`](/api/#03-apidocs/interfaceaxusablemdresetusage) |
| <a id="setDemos"></a> `setDemos` | (`demos`: readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[]) => `void` | [`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setDemos`](/api/#03-apidocs/interfaceaxtunablemdsetdemos) |
| <a id="setExamples"></a> `setExamples` | (`examples`: `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\>, `options`?: `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\>) => `void` | [`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setExamples`](/api/#03-apidocs/interfaceaxtunablemdsetexamples) |
| <a id="setId"></a> `setId` | (`id`: `string`) => `void` | [`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setId`](/api/#03-apidocs/interfaceaxtunablemdsetid) |
| <a id="setParentId"></a> `setParentId` | (`parentId`: `string`) => `void` | [`AxTunable`](/api/#03-apidocs/interfaceaxtunable).[`setParentId`](/api/#03-apidocs/interfaceaxtunablemdsetparentid) |

## Methods

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(): AxAgentFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L30

#### Returns

[`AxAgentFeatures`](/api/#03-apidocs/interfaceaxagentfeatures)

***

<a id="getFunction"></a>

### getFunction()

```ts
getFunction(): AxFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L29

#### Returns

[`AxFunction`](/api/#03-apidocs/typealiasaxfunction)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIAnthropicArgs.md
================================================
---
title: AxAIAnthropicArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/api.ts#L44

## Properties

| Property | Type |
| :------ | :------ |
| <a id="apiKey"></a> `apiKey?` | `string` |
| <a id="config"></a> `config?` | `Readonly`\<`Partial`\<[`AxAIAnthropicConfig`](/api/#03-apidocs/typealiasaxaianthropicconfig)\>\> |
| <a id="models"></a> `models?` | [`AxAIInputModelList`](/api/#03-apidocs/typealiasaxaiinputmodellist)\< \| [`AxAIAnthropicModel`](/api/#03-apidocs/enumerationaxaianthropicmodel) \| [`AxAIAnthropicVertexModel`](/api/#03-apidocs/enumerationaxaianthropicvertexmodel), `undefined`\> |
| <a id="name"></a> `name` | `"anthropic"` |
| <a id="options"></a> `options?` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |
| <a id="projectId"></a> `projectId?` | `string` |
| <a id="region"></a> `region?` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIAnthropicContentBlockDeltaEvent.md
================================================
---
title: AxAIAnthropicContentBlockDeltaEvent
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L180

## Properties

| Property | Type |
| :------ | :------ |
| <a id="delta"></a> `delta` | \| \{ `text`: `string`; `type`: `"text_delta"`; \} \| \{ `partial_json`: `string`; `type`: `"input_json_delta"`; \} |
| <a id="index"></a> `index` | `number` |
| <a id="type"></a> `type` | `"content_block_delta"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIAnthropicContentBlockStartEvent.md
================================================
---
title: AxAIAnthropicContentBlockStartEvent
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L163

## Properties

| Property | Type |
| :------ | :------ |
| <a id="content_block"></a> `content_block` | \| \{ `text`: `string`; `type`: `"text"`; \} \| \{ `id`: `string`; `input`: `object`; `name`: `string`; `type`: `"tool_use"`; \} |
| <a id="index"></a> `index` | `number` |
| <a id="type"></a> `type` | `"content_block_start"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIAnthropicContentBlockStopEvent.md
================================================
---
title: AxAIAnthropicContentBlockStopEvent
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L195

## Properties

| Property | Type |
| :------ | :------ |
| <a id="index"></a> `index` | `number` |
| <a id="type"></a> `type` | `"content_block_stop"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIAnthropicErrorEvent.md
================================================
---
title: AxAIAnthropicErrorEvent
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L223

## Properties

| Property | Type |
| :------ | :------ |
| <a id="error"></a> `error` | `object` |
| `error.message` | `string` |
| `error.type` | `"overloaded_error"` |
| <a id="type"></a> `type` | `"error"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIAnthropicMessageDeltaEvent.md
================================================
---
title: AxAIAnthropicMessageDeltaEvent
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L201

## Properties

| Property | Type |
| :------ | :------ |
| <a id="delta"></a> `delta` | `object` |
| `delta.stop_reason` | `null` \| `"end_turn"` \| `"max_tokens"` \| `"stop_sequence"` |
| `delta.stop_sequence` | `null` \| `string` |
| <a id="type"></a> `type` | `"message_delta"` |
| <a id="usage"></a> `usage` | `object` |
| `usage.output_tokens` | `number` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIAnthropicMessageStartEvent.md
================================================
---
title: AxAIAnthropicMessageStartEvent
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L145

## Properties

| Property | Type |
| :------ | :------ |
| <a id="message"></a> `message` | `object` |
| `message.content` | \[\] |
| `message.id` | `string` |
| `message.model` | `string` |
| `message.role` | `"assistant"` |
| `message.stop_reason` | `null` \| `string` |
| `message.stop_sequence` | `null` \| `string` |
| `message.type` | `"message"` |
| `message.usage` | `object` |
| `message.usage.input_tokens` | `number` |
| `message.usage.output_tokens` | `number` |
| <a id="type"></a> `type` | `"message_start"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIAnthropicMessageStopEvent.md
================================================
---
title: AxAIAnthropicMessageStopEvent
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L213

## Properties

| Property | Type |
| :------ | :------ |
| <a id="type"></a> `type` | `"message_stop"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIAnthropicPingEvent.md
================================================
---
title: AxAIAnthropicPingEvent
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L218

## Properties

| Property | Type |
| :------ | :------ |
| <a id="type"></a> `type` | `"ping"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAICohereArgs.md
================================================
---
title: AxAICohereArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/api.ts#L47

## Properties

| Property | Type |
| :------ | :------ |
| <a id="apiKey"></a> `apiKey` | `string` |
| <a id="config"></a> `config?` | `Readonly`\<`Partial`\<[`AxAICohereConfig`](/api/#03-apidocs/typealiasaxaicohereconfig)\>\> |
| <a id="models"></a> `models?` | [`AxAIInputModelList`](/api/#03-apidocs/typealiasaxaiinputmodellist)\<[`AxAICohereModel`](/api/#03-apidocs/enumerationaxaicoheremodel), [`AxAICohereEmbedModel`](/api/#03-apidocs/enumerationaxaicohereembedmodel)\> |
| <a id="name"></a> `name` | `"cohere"` |
| <a id="options"></a> `options?` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIGoogleGeminiArgs.md
================================================
---
title: AxAIGoogleGeminiArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/api.ts#L92

## Properties

| Property | Type |
| :------ | :------ |
| <a id="apiKey"></a> `apiKey?` | `string` |
| <a id="config"></a> `config?` | `Readonly`\<`Partial`\<[`AxAIGoogleGeminiConfig`](/api/#03-apidocs/typealiasaxaigooglegeminiconfig)\>\> |
| <a id="endpointId"></a> `endpointId?` | `string` |
| <a id="modelInfo"></a> `modelInfo?` | [`AxModelInfo`](/api/#03-apidocs/typealiasaxmodelinfo)[] |
| <a id="models"></a> `models?` | [`AxAIInputModelList`](/api/#03-apidocs/typealiasaxaiinputmodellist)\<[`AxAIGoogleGeminiModel`](/api/#03-apidocs/enumerationaxaigooglegeminimodel), [`AxAIGoogleGeminiEmbedModel`](/api/#03-apidocs/enumerationaxaigooglegeminiembedmodel)\> |
| <a id="name"></a> `name` | `"google-gemini"` |
| <a id="options"></a> `options?` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions) & [`AxAIGoogleGeminiOptionsTools`](/api/#03-apidocs/interfaceaxaigooglegeminioptionstools)\> |
| <a id="projectId"></a> `projectId?` | `string` |
| <a id="region"></a> `region?` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIGoogleGeminiOptionsTools.md
================================================
---
title: AxAIGoogleGeminiOptionsTools
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/api.ts#L82

## Properties

| Property | Type |
| :------ | :------ |
| <a id="codeExecution"></a> `codeExecution?` | `boolean` |
| <a id="googleSearch"></a> `googleSearch?` | `boolean` |
| <a id="googleSearchRetrieval"></a> `googleSearchRetrieval?` | `object` |
| `googleSearchRetrieval.dynamicThreshold?` | `number` |
| `googleSearchRetrieval.mode?` | `"MODE_DYNAMIC"` |
| <a id="urlContext"></a> `urlContext?` | `boolean` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIHuggingFaceArgs.md
================================================
---
title: AxAIHuggingFaceArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/huggingface/api.ts#L38

## Properties

| Property | Type |
| :------ | :------ |
| <a id="apiKey"></a> `apiKey` | `string` |
| <a id="config"></a> `config?` | `Readonly`\<`Partial`\<[`AxAIHuggingFaceConfig`](/api/#03-apidocs/typealiasaxaihuggingfaceconfig)\>\> |
| <a id="models"></a> `models?` | [`AxAIInputModelList`](/api/#03-apidocs/typealiasaxaiinputmodellist)\<[`MetaLlama270BChatHF`](/api/#03-apidocs/enumerationaxaihuggingfacemodelmdmetallama270bchathf), `undefined`\> |
| <a id="name"></a> `name` | `"huggingface"` |
| <a id="options"></a> `options?` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIMemory.md
================================================
---
title: AxAIMemory
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/types.ts#L3

## Methods

<a id="add"></a>

### add()

```ts
add(result: 
  | readonly (
  | {
  cache: boolean;
  content: string;
  role: "system";
 }
  | {
  content:   | string
     | (
     | {
     cache: boolean;
     text: string;
     type: "text";
    }
     | {
     cache: boolean;
     details: "high" | "low" | "auto";
     image: string;
     mimeType: string;
     type: "image";
    }
     | {
     cache: boolean;
     data: string;
     format: "wav";
     type: "audio";
    })[];
  name: string;
  role: "user";
 }
  | {
  cache: boolean;
  content: string;
  functionCalls: object[];
  name: string;
  role: "assistant";
 }
  | {
  cache: boolean;
  functionId: string;
  isError: boolean;
  result: string;
  role: "function";
 })[]
  | Readonly<
  | {
  cache: boolean;
  content: string;
  role: "system";
 }
  | {
  content:   | string
     | (
     | {
     cache: boolean;
     text: string;
     type: "text";
    }
     | {
     cache: boolean;
     details: "high" | "low" | "auto";
     image: string;
     mimeType: string;
     type: "image";
    }
     | {
     cache: boolean;
     data: string;
     format: "wav";
     type: "audio";
    })[];
  name: string;
  role: "user";
 }
  | {
  cache: boolean;
  content: string;
  functionCalls: object[];
  name: string;
  role: "assistant";
 }
  | {
  cache: boolean;
  functionId: string;
  isError: boolean;
  result: string;
  role: "function";
 }>, sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/types.ts#L4

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `result` | \| readonly ( \| \{ `cache`: `boolean`; `content`: `string`; `role`: `"system"`; \} \| \{ `content`: \| `string` \| ( \| \{ `cache`: `boolean`; `text`: `string`; `type`: `"text"`; \} \| \{ `cache`: `boolean`; `details`: `"high"` \| `"low"` \| `"auto"`; `image`: `string`; `mimeType`: `string`; `type`: `"image"`; \} \| \{ `cache`: `boolean`; `data`: `string`; `format`: `"wav"`; `type`: `"audio"`; \})[]; `name`: `string`; `role`: `"user"`; \} \| \{ `cache`: `boolean`; `content`: `string`; `functionCalls`: `object`[]; `name`: `string`; `role`: `"assistant"`; \} \| \{ `cache`: `boolean`; `functionId`: `string`; `isError`: `boolean`; `result`: `string`; `role`: `"function"`; \})[] \| `Readonly`\< \| \{ `cache`: `boolean`; `content`: `string`; `role`: `"system"`; \} \| \{ `content`: \| `string` \| ( \| \{ `cache`: `boolean`; `text`: `string`; `type`: `"text"`; \} \| \{ `cache`: `boolean`; `details`: `"high"` \| `"low"` \| `"auto"`; `image`: `string`; `mimeType`: `string`; `type`: `"image"`; \} \| \{ `cache`: `boolean`; `data`: `string`; `format`: `"wav"`; `type`: `"audio"`; \})[]; `name`: `string`; `role`: `"user"`; \} \| \{ `cache`: `boolean`; `content`: `string`; `functionCalls`: `object`[]; `name`: `string`; `role`: `"assistant"`; \} \| \{ `cache`: `boolean`; `functionId`: `string`; `isError`: `boolean`; `result`: `string`; `role`: `"function"`; \}\> |
| `sessionId`? | `string` |

#### Returns

`void`

***

<a id="addResult"></a>

### addResult()

```ts
addResult(result: Readonly<AxChatResponseResult>, sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/types.ts#L10

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `result` | `Readonly`\<[`AxChatResponseResult`](/api/#03-apidocs/typealiasaxchatresponseresult)\> |
| `sessionId`? | `string` |

#### Returns

`void`

***

<a id="addTag"></a>

### addTag()

```ts
addTag(name: string, sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/types.ts#L25

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |
| `sessionId`? | `string` |

#### Returns

`void`

***

<a id="getLast"></a>

### getLast()

```ts
getLast(sessionId?: string): 
  | undefined
  | {
  chat:   | {
     cache: boolean;
     content: string;
     role: "system";
    }
     | {
     content:   | string
        | (
        | {
        cache: boolean;
        text: string;
        type: "text";
       }
        | {
        cache: boolean;
        details: "high" | "low" | "auto";
        image: string;
        mimeType: string;
        type: "image";
       }
        | {
        cache: boolean;
        data: string;
        format: "wav";
        type: "audio";
       })[];
     name: string;
     role: "user";
    }
     | {
     cache: boolean;
     content: string;
     functionCalls: object[];
     name: string;
     role: "assistant";
    }
     | {
     cache: boolean;
     functionId: string;
     isError: boolean;
     result: string;
     role: "function";
    };
  tags: string[];
}
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/types.ts#L21

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `sessionId`? | `string` |

#### Returns

  \| `undefined`
  \| \{
  `chat`:   \| \{
     `cache`: `boolean`;
     `content`: `string`;
     `role`: `"system"`;
    \}
     \| \{
     `content`:   \| `string`
        \| (
        \| \{
        `cache`: `boolean`;
        `text`: `string`;
        `type`: `"text"`;
       \}
        \| \{
        `cache`: `boolean`;
        `details`: `"high"` \| `"low"` \| `"auto"`;
        `image`: `string`;
        `mimeType`: `string`;
        `type`: `"image"`;
       \}
        \| \{
        `cache`: `boolean`;
        `data`: `string`;
        `format`: `"wav"`;
        `type`: `"audio"`;
       \})[];
     `name`: `string`;
     `role`: `"user"`;
    \}
     \| \{
     `cache`: `boolean`;
     `content`: `string`;
     `functionCalls`: `object`[];
     `name`: `string`;
     `role`: `"assistant"`;
    \}
     \| \{
     `cache`: `boolean`;
     `functionId`: `string`;
     `isError`: `boolean`;
     `result`: `string`;
     `role`: `"function"`;
    \};
  `tags`: `string`[];
 \}

***

<a id="history"></a>

### history()

```ts
history(sessionId?: string): (
  | {
  cache: boolean;
  content: string;
  role: "system";
 }
  | {
  content:   | string
     | (
     | {
     cache: boolean;
     text: string;
     type: "text";
    }
     | {
     cache: boolean;
     details: "high" | "low" | "auto";
     image: string;
     mimeType: string;
     type: "image";
    }
     | {
     cache: boolean;
     data: string;
     format: "wav";
     type: "audio";
    })[];
  name: string;
  role: "user";
 }
  | {
  cache: boolean;
  content: string;
  functionCalls: object[];
  name: string;
  role: "assistant";
 }
  | {
  cache: boolean;
  functionId: string;
  isError: boolean;
  result: string;
  role: "function";
 })[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/types.ts#L18

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `sessionId`? | `string` |

#### Returns

(
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `role`: `"system"`;
 \}
  \| \{
  `content`:   \| `string`
     \| (
     \| \{
     `cache`: `boolean`;
     `text`: `string`;
     `type`: `"text"`;
    \}
     \| \{
     `cache`: `boolean`;
     `details`: `"high"` \| `"low"` \| `"auto"`;
     `image`: `string`;
     `mimeType`: `string`;
     `type`: `"image"`;
    \}
     \| \{
     `cache`: `boolean`;
     `data`: `string`;
     `format`: `"wav"`;
     `type`: `"audio"`;
    \})[];
  `name`: `string`;
  `role`: `"user"`;
 \}
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `functionCalls`: `object`[];
  `name`: `string`;
  `role`: `"assistant"`;
 \}
  \| \{
  `cache`: `boolean`;
  `functionId`: `string`;
  `isError`: `boolean`;
  `result`: `string`;
  `role`: `"function"`;
 \})[]

***

<a id="reset"></a>

### reset()

```ts
reset(sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/types.ts#L19

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `sessionId`? | `string` |

#### Returns

`void`

***

<a id="rewindToTag"></a>

### rewindToTag()

```ts
rewindToTag(name: string, sessionId?: string): (
  | {
  cache: boolean;
  content: string;
  role: "system";
 }
  | {
  content:   | string
     | (
     | {
     cache: boolean;
     text: string;
     type: "text";
    }
     | {
     cache: boolean;
     details: "high" | "low" | "auto";
     image: string;
     mimeType: string;
     type: "image";
    }
     | {
     cache: boolean;
     data: string;
     format: "wav";
     type: "audio";
    })[];
  name: string;
  role: "user";
 }
  | {
  cache: boolean;
  content: string;
  functionCalls: object[];
  name: string;
  role: "assistant";
 }
  | {
  cache: boolean;
  functionId: string;
  isError: boolean;
  result: string;
  role: "function";
 })[]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/types.ts#L26

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `name` | `string` |
| `sessionId`? | `string` |

#### Returns

(
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `role`: `"system"`;
 \}
  \| \{
  `content`:   \| `string`
     \| (
     \| \{
     `cache`: `boolean`;
     `text`: `string`;
     `type`: `"text"`;
    \}
     \| \{
     `cache`: `boolean`;
     `details`: `"high"` \| `"low"` \| `"auto"`;
     `image`: `string`;
     `mimeType`: `string`;
     `type`: `"image"`;
    \}
     \| \{
     `cache`: `boolean`;
     `data`: `string`;
     `format`: `"wav"`;
     `type`: `"audio"`;
    \})[];
  `name`: `string`;
  `role`: `"user"`;
 \}
  \| \{
  `cache`: `boolean`;
  `content`: `string`;
  `functionCalls`: `object`[];
  `name`: `string`;
  `role`: `"assistant"`;
 \}
  \| \{
  `cache`: `boolean`;
  `functionId`: `string`;
  `isError`: `boolean`;
  `result`: `string`;
  `role`: `"function"`;
 \})[]

***

<a id="updateResult"></a>

### updateResult()

```ts
updateResult(result: Readonly<AxChatResponseResult> & object, sessionId?: string): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/mem/types.ts#L11

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `result` | `Readonly`\<[`AxChatResponseResult`](/api/#03-apidocs/typealiasaxchatresponseresult)\> & `object` |
| `sessionId`? | `string` |

#### Returns

`void`



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIOpenAIArgs.md
================================================
---
title: AxAIOpenAIArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/api.ts#L74

## Extends

- `Omit`\<[`AxAIOpenAIBaseArgs`](/api/#03-apidocs/interfaceaxaiopenaibaseargs)\<`TModel`, `TEmbedModel`, `TChatReq`\>, `"config"` \| `"supportFor"` \| `"modelInfo"`\>

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `TName` | `"openai"` |
| `TModel` | [`AxAIOpenAIModel`](/api/#03-apidocs/enumerationaxaiopenaimodel) |
| `TEmbedModel` | [`AxAIOpenAIEmbedModel`](/api/#03-apidocs/enumerationaxaiopenaiembedmodel) |
| `TChatReq` *extends* [`AxAIOpenAIChatRequest`](/api/#03-apidocs/typealiasaxaiopenaichatrequest)\<`TModel`\> | [`AxAIOpenAIChatRequest`](/api/#03-apidocs/typealiasaxaiopenaichatrequest)\<`TModel`\> |

## Properties

| Property | Type | Inherited from |
| :------ | :------ | :------ |
| <a id="apiKey"></a> `apiKey` | `string` | `Omit.apiKey` |
| <a id="apiURL"></a> `apiURL?` | `string` | `Omit.apiURL` |
| <a id="chatReqUpdater"></a> `chatReqUpdater?` | `ChatReqUpdater`\<`TModel`, `TChatReq`\> | `Omit.chatReqUpdater` |
| <a id="config"></a> `config?` | `Partial`\<`Readonly`\<[`AxAIOpenAIConfig`](/api/#03-apidocs/typealiasaxaiopenaiconfig)\<`TModel`, `TEmbedModel`\>\>\> | - |
| <a id="modelInfo"></a> `modelInfo?` | [`AxModelInfo`](/api/#03-apidocs/typealiasaxmodelinfo)[] | - |
| <a id="models"></a> `models?` | [`AxAIInputModelList`](/api/#03-apidocs/typealiasaxaiinputmodellist)\<`TModel`, `TEmbedModel`\> | `Omit.models` |
| <a id="name"></a> `name` | `TName` | - |
| <a id="options"></a> `options?` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions) & `object`\> | `Omit.options` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIOpenAIResponseDelta.md
================================================
---
title: AxAIOpenAIResponseDelta
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L71

## Type Parameters

| Type Parameter |
| :------ |
| `T` |

## Properties

| Property | Type |
| :------ | :------ |
| <a id="choices"></a> `choices` | `object`[] |
| <a id="created"></a> `created` | `number` |
| <a id="id"></a> `id` | `string` |
| <a id="model"></a> `model` | `string` |
| <a id="object"></a> `object` | `string` |
| <a id="system_fingerprint"></a> `system_fingerprint` | `string` |
| <a id="usage"></a> `usage?` | [`AxAIOpenAIUsage`](/api/#03-apidocs/typealiasaxaiopenaiusage) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIRekaArgs.md
================================================
---
title: AxAIRekaArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/reka/api.ts#L53

## Properties

| Property | Type |
| :------ | :------ |
| <a id="apiKey"></a> `apiKey` | `string` |
| <a id="apiURL"></a> `apiURL?` | `string` |
| <a id="config"></a> `config?` | `Readonly`\<`Partial`\<[`AxAIRekaConfig`](/api/#03-apidocs/typealiasaxairekaconfig)\>\> |
| <a id="modelInfo"></a> `modelInfo?` | readonly [`AxModelInfo`](/api/#03-apidocs/typealiasaxmodelinfo)[] |
| <a id="models"></a> `models?` | [`AxAIInputModelList`](/api/#03-apidocs/typealiasaxaiinputmodellist)\<[`AxAIRekaModel`](/api/#03-apidocs/enumerationaxairekamodel), `undefined`\> |
| <a id="name"></a> `name` | `"reka"` |
| <a id="options"></a> `options?` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions) & `object`\> |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIService.md
================================================
---
title: AxAIService
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L302

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `TModel` | `unknown` |
| `TEmbedModel` | `unknown` |

## Methods

<a id="chat"></a>

### chat()

```ts
chat(req: Readonly<AxChatRequest<TModel>>, options?: Readonly<AxAIPromptConfig & AxAIServiceActionOptions<TModel, TEmbedModel>>): Promise<
  | AxChatResponse
| ReadableStream<AxChatResponse>>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L314

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\<`TModel`\>\> |
| `options`? | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig) & [`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<`TModel`, `TEmbedModel`\>\> |

#### Returns

`Promise`\<
  \| [`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)
  \| `ReadableStream`\<[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)\>\>

***

<a id="embed"></a>

### embed()

```ts
embed(req: Readonly<AxEmbedRequest<TEmbedModel>>, options?: Readonly<AxAIServiceActionOptions<TModel, TEmbedModel>>): Promise<AxEmbedResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L320

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxEmbedRequest`](/api/#03-apidocs/typealiasaxembedrequest)\<`TEmbedModel`\>\> |
| `options`? | `Readonly`\<[`AxAIServiceActionOptions`](/api/#03-apidocs/typealiasaxaiserviceactionoptions)\<`TModel`, `TEmbedModel`\>\> |

#### Returns

`Promise`\<[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)\>

***

<a id="getFeatures"></a>

### getFeatures()

```ts
getFeatures(model?: TModel): AxAIFeatures
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L305

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `model`? | `TModel` |

#### Returns

[`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures)

***

<a id="getId"></a>

### getId()

```ts
getId(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L303

#### Returns

`string`

***

<a id="getLastUsedChatModel"></a>

### getLastUsedChatModel()

```ts
getLastUsedChatModel(): undefined | TModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L310

#### Returns

`undefined` \| `TModel`

***

<a id="getLastUsedEmbedModel"></a>

### getLastUsedEmbedModel()

```ts
getLastUsedEmbedModel(): undefined | TEmbedModel
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L311

#### Returns

`undefined` \| `TEmbedModel`

***

<a id="getLastUsedModelConfig"></a>

### getLastUsedModelConfig()

```ts
getLastUsedModelConfig(): undefined | AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L312

#### Returns

`undefined` \| [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

***

<a id="getLogger"></a>

### getLogger()

```ts
getLogger(): AxLoggerFunction
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L308

#### Returns

[`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction)

***

<a id="getMetrics"></a>

### getMetrics()

```ts
getMetrics(): AxAIServiceMetrics
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L307

#### Returns

[`AxAIServiceMetrics`](/api/#03-apidocs/interfaceaxaiservicemetrics)

***

<a id="getModelList"></a>

### getModelList()

```ts
getModelList(): undefined | AxAIModelList
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L306

#### Returns

`undefined` \| [`AxAIModelList`](/api/#03-apidocs/typealiasaxaimodellist)

***

<a id="getName"></a>

### getName()

```ts
getName(): string
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L304

#### Returns

`string`

***

<a id="getOptions"></a>

### getOptions()

```ts
getOptions(): Readonly<AxAIServiceOptions>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L326

#### Returns

`Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\>

***

<a id="setOptions"></a>

### setOptions()

```ts
setOptions(options: Readonly<AxAIServiceOptions>): void
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L325

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `options` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |

#### Returns

`void`



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIServiceImpl.md
================================================
---
title: AxAIServiceImpl
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L329

## Type Parameters

| Type Parameter |
| :------ |
| `TModel` |
| `TEmbedModel` |
| `TChatRequest` |
| `TEmbedRequest` |
| `TChatResponse` |
| `TChatResponseDelta` |
| `TEmbedResponse` |

## Methods

<a id="createChatReq"></a>

### createChatReq()

```ts
createChatReq(req: Readonly<AxInternalChatRequest<TModel>>, config: Readonly<AxAIPromptConfig>): [AxAPI, TChatRequest]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L338

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxInternalChatRequest`](/api/#03-apidocs/typealiasaxinternalchatrequest)\<`TModel`\>\> |
| `config` | `Readonly`\<[`AxAIPromptConfig`](/api/#03-apidocs/typealiasaxaipromptconfig)\> |

#### Returns

\[[`AxAPI`](/api/#03-apidocs/interfaceaxapi), `TChatRequest`\]

***

<a id="createChatResp"></a>

### createChatResp()

```ts
createChatResp(resp: Readonly<TChatResponse>): AxChatResponse
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L343

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `resp` | `Readonly`\<`TChatResponse`\> |

#### Returns

[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)

***

<a id="createChatStreamResp"></a>

### createChatStreamResp()?

```ts
optional createChatStreamResp(resp: Readonly<TChatResponseDelta>, state: object): AxChatResponse
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L345

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `resp` | `Readonly`\<`TChatResponseDelta`\> |
| `state` | `object` |

#### Returns

[`AxChatResponse`](/api/#03-apidocs/typealiasaxchatresponse)

***

<a id="createEmbedReq"></a>

### createEmbedReq()?

```ts
optional createEmbedReq(req: Readonly<AxInternalEmbedRequest<TEmbedModel>>): [AxAPI, TEmbedRequest]
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L350

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxInternalEmbedRequest`](/api/#03-apidocs/typealiasaxinternalembedrequest)\<`TEmbedModel`\>\> |

#### Returns

\[[`AxAPI`](/api/#03-apidocs/interfaceaxapi), `TEmbedRequest`\]

***

<a id="createEmbedResp"></a>

### createEmbedResp()?

```ts
optional createEmbedResp(resp: Readonly<TEmbedResponse>): AxEmbedResponse
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L354

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `resp` | `Readonly`\<`TEmbedResponse`\> |

#### Returns

[`AxEmbedResponse`](/api/#03-apidocs/typealiasaxembedresponse)

***

<a id="getModelConfig"></a>

### getModelConfig()

```ts
getModelConfig(): AxModelConfig
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L356

#### Returns

[`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig)

***

<a id="getTokenUsage"></a>

### getTokenUsage()

```ts
getTokenUsage(): undefined | AxTokenUsage
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L358

#### Returns

`undefined` \| [`AxTokenUsage`](/api/#03-apidocs/typealiasaxtokenusage)



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAIServiceMetrics.md
================================================
---
title: AxAIServiceMetrics
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L186

## Properties

| Property | Type |
| :------ | :------ |
| <a id="errors"></a> `errors` | `object` |
| `errors.chat` | `object` |
| `errors.chat.count` | `number` |
| `errors.chat.rate` | `number` |
| `errors.chat.total` | `number` |
| `errors.embed` | `object` |
| `errors.embed.count` | `number` |
| `errors.embed.rate` | `number` |
| `errors.embed.total` | `number` |
| <a id="latency"></a> `latency` | `object` |
| `latency.chat` | `object` |
| `latency.chat.mean` | `number` |
| `latency.chat.p95` | `number` |
| `latency.chat.p99` | `number` |
| `latency.chat.samples` | `number`[] |
| `latency.embed` | `object` |
| `latency.embed.mean` | `number` |
| `latency.embed.p95` | `number` |
| `latency.embed.p99` | `number` |
| `latency.embed.samples` | `number`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxApacheTikaArgs.md
================================================
---
title: AxApacheTikaArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/tika.ts#L3

## Properties

| Property | Type |
| :------ | :------ |
| <a id="fetch"></a> `fetch?` | (`input`: `string` \| `URL` \| `Request`, `init`?: `RequestInit`) => `Promise`\<`Response`\> |
| <a id="url"></a> `url?` | `string` \| `URL` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxApacheTikaConvertOptions.md
================================================
---
title: AxApacheTikaConvertOptions
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/tika.ts#L8

## Properties

| Property | Type |
| :------ | :------ |
| <a id="format"></a> `format?` | `"text"` \| `"html"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxAssertion.md
================================================
---
title: AxAssertion
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/asserts.ts#L3

## Properties

| Property | Type |
| :------ | :------ |
| <a id="message"></a> `message?` | `string` |

## Methods

<a id="fn"></a>

### fn()

```ts
fn(values: Record<string, unknown>): undefined | boolean | Promise<undefined | boolean>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/asserts.ts#L4

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `values` | `Record`\<`string`, `unknown`\> |

#### Returns

`undefined` \| `boolean` \| `Promise`\<`undefined` \| `boolean`\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxBaseAIArgs.md
================================================
---
title: AxBaseAIArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/base.ts#L38

## Type Parameters

| Type Parameter |
| :------ |
| `TModel` |
| `TEmbedModel` |

## Properties

| Property | Type |
| :------ | :------ |
| <a id="apiURL"></a> `apiURL` | `string` |
| <a id="defaults"></a> `defaults` | `Readonly`\<\{ `embedModel`: `TEmbedModel`; `model`: `TModel`; \}\> |
| <a id="headers"></a> `headers` | () => `Promise`\<`Record`\<`string`, `string`\>\> |
| <a id="modelInfo"></a> `modelInfo` | readonly [`AxModelInfo`](/api/#03-apidocs/typealiasaxmodelinfo)[] |
| <a id="models"></a> `models?` | [`AxAIInputModelList`](/api/#03-apidocs/typealiasaxaiinputmodellist)\<`TModel`, `TEmbedModel`\> |
| <a id="name"></a> `name` | `string` |
| <a id="options"></a> `options?` | `Readonly`\<[`AxAIServiceOptions`](/api/#03-apidocs/typealiasaxaiserviceoptions)\> |
| <a id="supportFor"></a> `supportFor` | \| [`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures) \| (`model`: `TModel`) => [`AxAIFeatures`](/api/#03-apidocs/interfaceaxaifeatures) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBBaseArgs.md
================================================
---
title: AxDBBaseArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L13

## Extended by

- [`AxDBCloudflareArgs`](/api/#03-apidocs/interfaceaxdbcloudflareargs)
- [`AxDBMemoryArgs`](/api/#03-apidocs/interfaceaxdbmemoryargs)
- [`AxDBPineconeArgs`](/api/#03-apidocs/interfaceaxdbpineconeargs)
- [`AxDBWeaviateArgs`](/api/#03-apidocs/interfaceaxdbweaviateargs)

## Properties

| Property | Type |
| :------ | :------ |
| <a id="fetch"></a> `fetch?` | (`input`: `string` \| `URL` \| `Request`, `init`?: `RequestInit`) => `Promise`\<`Response`\> |
| <a id="tracer"></a> `tracer?` | `Tracer` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBBaseOpOptions.md
================================================
---
title: AxDBBaseOpOptions
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/base.ts#L18

## Properties

| Property | Type |
| :------ | :------ |
| <a id="span"></a> `span?` | `Span` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBCloudflareArgs.md
================================================
---
title: AxDBCloudflareArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/cloudflare.ts#L34

## Extends

- [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs)

## Properties

| Property | Type | Overrides | Inherited from |
| :------ | :------ | :------ | :------ |
| <a id="accountId"></a> `accountId` | `string` | - | - |
| <a id="apiKey"></a> `apiKey` | `string` | - | - |
| <a id="fetch"></a> `fetch?` | (`input`: `string` \| `URL` \| `Request`, `init`?: `RequestInit`) => `Promise`\<`Response`\> | [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs).[`fetch`](/api/#03-apidocs/interfaceaxdbbaseargsmdfetch) | - |
| <a id="name"></a> `name` | `"cloudflare"` | - | - |
| <a id="tracer"></a> `tracer?` | `Tracer` | - | [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs).[`tracer`](/api/#03-apidocs/interfaceaxdbbaseargsmdtracer) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBLoaderOptions.md
================================================
---
title: AxDBLoaderOptions
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L11

## Properties

| Property | Type |
| :------ | :------ |
| <a id="chunker"></a> `chunker?` | (`text`: `string`) => `string`[] |
| <a id="reranker"></a> `reranker?` | [`AxProgram`](/api/#03-apidocs/classaxprogram)\<[`AxRerankerIn`](/api/#03-apidocs/typealiasaxrerankerin), [`AxRerankerOut`](/api/#03-apidocs/typealiasaxrerankerout)\> |
| <a id="rewriter"></a> `rewriter?` | [`AxProgram`](/api/#03-apidocs/classaxprogram)\<[`AxRewriteIn`](/api/#03-apidocs/typealiasaxrewritein), [`AxRewriteOut`](/api/#03-apidocs/typealiasaxrewriteout)\> |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBManagerArgs.md
================================================
---
title: AxDBManagerArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L17

## Properties

| Property | Type |
| :------ | :------ |
| <a id="ai"></a> `ai` | [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice) |
| <a id="config"></a> `config?` | [`AxDBLoaderOptions`](/api/#03-apidocs/interfaceaxdbloaderoptions) |
| <a id="db"></a> `db` | [`AxDBService`](/api/#03-apidocs/interfaceaxdbservice) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBMatch.md
================================================
---
title: AxDBMatch
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L23

## Properties

| Property | Type |
| :------ | :------ |
| <a id="score"></a> `score` | `number` |
| <a id="text"></a> `text` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBMemoryArgs.md
================================================
---
title: AxDBMemoryArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L11

## Extends

- [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs)

## Properties

| Property | Type | Inherited from |
| :------ | :------ | :------ |
| <a id="fetch"></a> `fetch?` | (`input`: `string` \| `URL` \| `Request`, `init`?: `RequestInit`) => `Promise`\<`Response`\> | [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs).[`fetch`](/api/#03-apidocs/interfaceaxdbbaseargsmdfetch) |
| <a id="name"></a> `name` | `"memory"` | - |
| <a id="tracer"></a> `tracer?` | `Tracer` | [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs).[`tracer`](/api/#03-apidocs/interfaceaxdbbaseargsmdtracer) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBPineconeArgs.md
================================================
---
title: AxDBPineconeArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/pinecone.ts#L48

## Extends

- [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs)

## Properties

| Property | Type | Overrides | Inherited from |
| :------ | :------ | :------ | :------ |
| <a id="apiKey"></a> `apiKey` | `string` | - | - |
| <a id="fetch"></a> `fetch?` | (`input`: `string` \| `URL` \| `Request`, `init`?: `RequestInit`) => `Promise`\<`Response`\> | [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs).[`fetch`](/api/#03-apidocs/interfaceaxdbbaseargsmdfetch) | - |
| <a id="host"></a> `host` | `string` | - | - |
| <a id="name"></a> `name` | `"pinecone"` | - | - |
| <a id="tracer"></a> `tracer?` | `Tracer` | - | [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs).[`tracer`](/api/#03-apidocs/interfaceaxdbbaseargsmdtracer) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBQueryService.md
================================================
---
title: AxDBQueryService
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L48

## Extended by

- [`AxDBService`](/api/#03-apidocs/interfaceaxdbservice)

## Methods

<a id="query"></a>

### query()

```ts
query(req: Readonly<AxDBQueryRequest>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L49

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBService.md
================================================
---
title: AxDBService
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L36

## Extends

- [`AxDBQueryService`](/api/#03-apidocs/interfaceaxdbqueryservice)

## Methods

<a id="batchUpsert"></a>

### batchUpsert()

```ts
batchUpsert(batchReq: readonly AxDBUpsertRequest[], update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L42

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `batchReq` | readonly [`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)[] |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>

***

<a id="query"></a>

### query()

```ts
query(req: Readonly<AxDBQueryRequest>): Promise<AxDBQueryResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L49

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBQueryRequest`](/api/#03-apidocs/typealiasaxdbqueryrequest)\> |

#### Returns

`Promise`\<[`AxDBQueryResponse`](/api/#03-apidocs/typealiasaxdbqueryresponse)\>

#### Inherited from

[`AxDBQueryService`](/api/#03-apidocs/interfaceaxdbqueryservice).[`query`](/api/#03-apidocs/interfaceaxdbqueryservicemdquery)

***

<a id="upsert"></a>

### upsert()

```ts
upsert(req: Readonly<AxDBUpsertRequest>, update?: boolean): Promise<AxDBUpsertResponse>
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L37

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `req` | `Readonly`\<[`AxDBUpsertRequest`](/api/#03-apidocs/typealiasaxdbupsertrequest)\> |
| `update`? | `boolean` |

#### Returns

`Promise`\<[`AxDBUpsertResponse`](/api/#03-apidocs/typealiasaxdbupsertresponse)\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDBWeaviateArgs.md
================================================
---
title: AxDBWeaviateArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/weaviate.ts#L29

## Extends

- [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs)

## Properties

| Property | Type | Overrides | Inherited from |
| :------ | :------ | :------ | :------ |
| <a id="apiKey"></a> `apiKey` | `string` | - | - |
| <a id="fetch"></a> `fetch?` | (`input`: `string` \| `URL` \| `Request`, `init`?: `RequestInit`) => `Promise`\<`Response`\> | [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs).[`fetch`](/api/#03-apidocs/interfaceaxdbbaseargsmdfetch) | - |
| <a id="host"></a> `host` | `string` | - | - |
| <a id="name"></a> `name` | `"weaviate"` | - | - |
| <a id="tracer"></a> `tracer?` | `Tracer` | - | [`AxDBBaseArgs`](/api/#03-apidocs/interfaceaxdbbaseargs).[`tracer`](/api/#03-apidocs/interfaceaxdbbaseargsmdtracer) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxDockerContainer.md
================================================
---
title: AxDockerContainer
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/funcs/docker.ts#L3

## Properties

| Property | Type |
| :------ | :------ |
| <a id="Command"></a> `Command` | `string` |
| <a id="Created"></a> `Created` | `number` |
| <a id="HostConfig"></a> `HostConfig` | `object` |
| `HostConfig.NetworkMode` | `string` |
| <a id="Id"></a> `Id` | `string` |
| <a id="Image"></a> `Image` | `string` |
| <a id="ImageID"></a> `ImageID` | `string` |
| <a id="Labels"></a> `Labels` | `object` |
| <a id="Mounts"></a> `Mounts` | `object`[] |
| <a id="Names"></a> `Names` | `string`[] |
| <a id="NetworkSettings"></a> `NetworkSettings` | `object` |
| `NetworkSettings.Networks` | `object` |
| <a id="Ports"></a> `Ports` | `object`[] |
| <a id="SizeRootFs"></a> `SizeRootFs` | `number` |
| <a id="SizeRw"></a> `SizeRw` | `number` |
| <a id="State"></a> `State` | `object` |
| `State.Dead` | `boolean` |
| `State.Error` | `string` |
| `State.ExitCode` | `number` |
| `State.FinishedAt` | `Date` |
| `State.OOMKilled` | `boolean` |
| `State.Paused` | `boolean` |
| `State.Pid` | `number` |
| `State.Restarting` | `boolean` |
| `State.Running` | `boolean` |
| `State.StartedAt` | `Date` |
| `State.Status` | `string` |
| <a id="Status"></a> `Status` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxField.md
================================================
---
title: AxField
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L12

## Properties

| Property | Type |
| :------ | :------ |
| <a id="description"></a> `description?` | `string` |
| <a id="isInternal"></a> `isInternal?` | `boolean` |
| <a id="isOptional"></a> `isOptional?` | `boolean` |
| <a id="name"></a> `name` | `string` |
| <a id="title"></a> `title?` | `string` |
| <a id="type"></a> `type?` | `object` |
| `type.isArray` | `boolean` |
| `type.name` | \| `"string"` \| `"number"` \| `"boolean"` \| `"image"` \| `"audio"` \| `"code"` \| `"json"` \| `"datetime"` \| `"date"` \| `"class"` |
| `type.options?` | `string`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxProgramWithSignatureOptions.md
================================================
---
title: AxProgramWithSignatureOptions
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L132

## Properties

| Property | Type |
| :------ | :------ |
| <a id="description"></a> `description?` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxRateLimiterTokenUsageOptions.md
================================================
---
title: AxRateLimiterTokenUsageOptions
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/util/rate-limit.ts#L5

## Properties

| Property | Type |
| :------ | :------ |
| <a id="debug"></a> `debug?` | `boolean` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxResponseHandlerArgs.md
================================================
---
title: AxResponseHandlerArgs
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L70

## Type Parameters

| Type Parameter |
| :------ |
| `T` |

## Properties

| Property | Type |
| :------ | :------ |
| <a id="ai"></a> `ai` | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`unknown`, `unknown`\>\> |
| <a id="fastFail"></a> `fastFail?` | `boolean` |
| <a id="functions"></a> `functions?` | readonly [`AxFunction`](/api/#03-apidocs/typealiasaxfunction)[] |
| <a id="mem"></a> `mem` | [`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory) |
| <a id="model"></a> `model?` | `string` |
| <a id="res"></a> `res` | `T` |
| <a id="sessionId"></a> `sessionId?` | `string` |
| <a id="span"></a> `span?` | `Span` |
| <a id="traceId"></a> `traceId?` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxStreamingAssertion.md
================================================
---
title: AxStreamingAssertion
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/asserts.ts#L10

## Properties

| Property | Type |
| :------ | :------ |
| <a id="fieldName"></a> `fieldName` | `string` |
| <a id="message"></a> `message?` | `string` |

## Methods

<a id="fn"></a>

### fn()

```ts
fn(content: string, done?: boolean): undefined | boolean
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/asserts.ts#L12

#### Parameters

| Parameter | Type |
| :------ | :------ |
| `content` | `string` |
| `done`? | `boolean` |

#### Returns

`undefined` \| `boolean`



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxTunable.md
================================================
---
title: AxTunable
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L111

## Extended by

- [`AxAgentic`](/api/#03-apidocs/interfaceaxagentic)

## Properties

| Property | Type |
| :------ | :------ |
| <a id="getTraces"></a> `getTraces` | () => [`AxProgramTrace`](/api/#03-apidocs/typealiasaxprogramtrace)[] |
| <a id="setDemos"></a> `setDemos` | (`demos`: readonly [`AxProgramDemos`](/api/#03-apidocs/typealiasaxprogramdemos)[]) => `void` |
| <a id="setExamples"></a> `setExamples` | (`examples`: `Readonly`\<[`AxProgramExamples`](/api/#03-apidocs/typealiasaxprogramexamples)\>, `options`?: `Readonly`\<[`AxSetExamplesOptions`](/api/#03-apidocs/typealiasaxsetexamplesoptions)\>) => `void` |
| <a id="setId"></a> `setId` | (`id`: `string`) => `void` |
| <a id="setParentId"></a> `setParentId` | (`parentId`: `string`) => `void` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/Interface.AxUsable.md
================================================
---
title: AxUsable
---

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L122

## Extended by

- [`AxAgentic`](/api/#03-apidocs/interfaceaxagentic)

## Properties

| Property | Type |
| :------ | :------ |
| <a id="getUsage"></a> `getUsage` | () => [`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) & `object`[] |
| <a id="resetUsage"></a> `resetUsage` | () => `void` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAgentOptions.md
================================================
---
title: AxAgentOptions
---

```ts
type AxAgentOptions = Omit<AxProgramForwardOptions, "functions"> & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/prompts/agent.ts#L33

## Type declaration

| Name | Type | Description |
| :------ | :------ | :------ |
| `debug`? | `boolean` | - |
| `disableSmartModelRouting`? | `boolean` | - |
| `excludeFieldsFromPassthrough`? | `string`[] | List of field names that should not be automatically passed from parent to child agents |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIAnthropicChatError.md
================================================
---
title: AxAIAnthropicChatError
---

```ts
type AxAIAnthropicChatError = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L136

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="error"></a> `error` | \{ `message`: `string`; `type`: `"authentication_error"`; \} |
| <a id="type"></a> `type` | `"error"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIAnthropicChatRequest.md
================================================
---
title: AxAIAnthropicChatRequest
---

```ts
type AxAIAnthropicChatRequest = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L37

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="anthropic_version"></a> `anthropic_version`? | `string` |
| <a id="max_tokens"></a> `max_tokens`? | `number` |
| <a id="messages"></a> `messages` | ( \| \{ `content`: \| `string` \| ( \| ... & ... \| ... & ... \| \{ `content`: ... \| ...; `is_error`: `boolean`; `tool_use_id`: `string`; `type`: `"tool_result"`; \})[]; `role`: `"user"`; \} \| \{ `content`: \| `string` \| ( \| \{ `text`: `string`; `type`: `"text"`; \} \| \{ `id`: `string`; `input`: `object`; `name`: `string`; `type`: `"tool_use"`; \})[]; `role`: `"assistant"`; \})[] |
| <a id="metadata"></a> `metadata`? | \{ `user_id`: `string`; \} |
| <a id="model"></a> `model`? | `string` |
| <a id="stop_sequences"></a> `stop_sequences`? | `string`[] |
| <a id="stream"></a> `stream`? | `boolean` |
| <a id="system"></a> `system`? | \| `string` \| `object` & [`AxAIAnthropicChatRequestCacheParam`](/api/#03-apidocs/typealiasaxaianthropicchatrequestcacheparam)[] |
| <a id="temperature"></a> `temperature`? | `number` |
| <a id="tool_choice"></a> `tool_choice`? | \| \{ `type`: `"auto"` \| `"any"`; \} \| \{ `name`: `string`; `type`: `"tool"`; \} |
| <a id="tools"></a> `tools`? | `object` & [`AxAIAnthropicChatRequestCacheParam`](/api/#03-apidocs/typealiasaxaianthropicchatrequestcacheparam)[] |
| <a id="top_k"></a> `top_k`? | `number` |
| <a id="top_p"></a> `top_p`? | `number` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIAnthropicChatRequestCacheParam.md
================================================
---
title: AxAIAnthropicChatRequestCacheParam
---

```ts
type AxAIAnthropicChatRequestCacheParam = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L32

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="cache_control"></a> `cache_control`? | \{ `type`: `"ephemeral"`; \} |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIAnthropicChatResponse.md
================================================
---
title: AxAIAnthropicChatResponse
---

```ts
type AxAIAnthropicChatResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L111

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="content"></a> `content` | ( \| \{ `text`: `string`; `type`: `"text"`; \} \| \{ `id`: `string`; `input`: `string`; `name`: `string`; `type`: `"tool_use"`; \})[] |
| <a id="id"></a> `id` | `string` |
| <a id="model"></a> `model` | `string` |
| <a id="role"></a> `role` | `"assistant"` |
| <a id="stop_reason"></a> `stop_reason` | `"end_turn"` \| `"max_tokens"` \| `"stop_sequence"` \| `"tool_use"` |
| <a id="stop_sequence"></a> `stop_sequence`? | `string` |
| <a id="type"></a> `type` | `"message"` |
| <a id="usage"></a> `usage` | \{ `input_tokens`: `number`; `output_tokens`: `number`; \} |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIAnthropicChatResponseDelta.md
================================================
---
title: AxAIAnthropicChatResponseDelta
---

```ts
type AxAIAnthropicChatResponseDelta = 
  | AxAIAnthropicMessageStartEvent
  | AxAIAnthropicContentBlockStartEvent
  | AxAIAnthropicContentBlockDeltaEvent
  | AxAIAnthropicContentBlockStopEvent
  | AxAIAnthropicMessageDeltaEvent
  | AxAIAnthropicMessageStopEvent
  | AxAIAnthropicPingEvent
  | AxAIAnthropicErrorEvent;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L232



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIAnthropicConfig.md
================================================
---
title: AxAIAnthropicConfig
---

```ts
type AxAIAnthropicConfig = AxModelConfig & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/anthropic/types.ts#L28

## Type declaration

| Name | Type |
| :------ | :------ |
| `model` | \| [`AxAIAnthropicModel`](/api/#03-apidocs/enumerationaxaianthropicmodel) \| [`AxAIAnthropicVertexModel`](/api/#03-apidocs/enumerationaxaianthropicvertexmodel) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIArgs.md
================================================
---
title: AxAIArgs
---

```ts
type AxAIArgs = 
  | AxAIOpenAIArgs
  | AxAIOpenAIResponsesArgs
  | AxAIAzureOpenAIArgs
  | AxAITogetherArgs
  | AxAIAnthropicArgs
  | AxAIGroqArgs
  | AxAIGoogleGeminiArgs
  | AxAICohereArgs
  | AxAIHuggingFaceArgs
  | AxAIMistralArgs
  | AxAIDeepSeekArgs
  | AxAIOllamaArgs
  | AxAIRekaArgs;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L56



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAICohereChatRequest.md
================================================
---
title: AxAICohereChatRequest
---

```ts
type AxAICohereChatRequest = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L41

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="chat_history"></a> `chat_history` | ( \| \{ `message`: `string`; `role`: `"CHATBOT"`; `tool_calls`: [`AxAICohereChatResponseToolCalls`](/api/#03-apidocs/typealiasaxaicoherechatresponsetoolcalls); \} \| \{ `message`: `string`; `role`: `"SYSTEM"`; \} \| \{ `message`: `string`; `role`: `"USER"`; \} \| \{ `message`: `string`; `role`: `"TOOL"`; `tool_results`: [`AxAICohereChatRequestToolResults`](/api/#03-apidocs/typealiasaxaicoherechatrequesttoolresults); \})[] |
| <a id="end_sequences"></a> `end_sequences`? | readonly `string`[] |
| <a id="frequency_penalty"></a> `frequency_penalty`? | `number` |
| <a id="k"></a> `k`? | `number` |
| <a id="max_tokens"></a> `max_tokens`? | `number` |
| <a id="message"></a> `message`? | `string` |
| <a id="model"></a> `model` | [`AxAICohereModel`](/api/#03-apidocs/enumerationaxaicoheremodel) |
| <a id="p"></a> `p`? | `number` |
| <a id="preamble"></a> `preamble`? | `string` |
| <a id="presence_penalty"></a> `presence_penalty`? | `number` |
| <a id="stop_sequences"></a> `stop_sequences`? | `string`[] |
| <a id="temperature"></a> `temperature`? | `number` |
| <a id="tool_results"></a> `tool_results`? | [`AxAICohereChatRequestToolResults`](/api/#03-apidocs/typealiasaxaicoherechatrequesttoolresults) |
| <a id="tools"></a> `tools`? | `object`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAICohereChatRequestToolResults.md
================================================
---
title: AxAICohereChatRequestToolResults
---

```ts
type AxAICohereChatRequestToolResults = object[];
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L36

## Type declaration

| Name | Type |
| :------ | :------ |
| `call` | [`AxAICohereChatResponseToolCalls`](/api/#03-apidocs/typealiasaxaicoherechatresponsetoolcalls)\[`0`\] |
| `outputs` | `object`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAICohereChatResponse.md
================================================
---
title: AxAICohereChatResponse
---

```ts
type AxAICohereChatResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L89

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="finish_reason"></a> `finish_reason` | \| `"COMPLETE"` \| `"ERROR"` \| `"ERROR_TOXIC"` \| `"ERROR_LIMIT"` \| `"USER_CANCEL"` \| `"MAX_TOKENS"` |
| <a id="generation_id"></a> `generation_id` | `string` |
| <a id="meta"></a> `meta` | \{ `billed_units`: \{ `input_tokens`: `number`; `output_tokens`: `number`; \}; \} |
| <a id="response_id"></a> `response_id` | `string` |
| <a id="text"></a> `text` | `string` |
| <a id="tool_calls"></a> `tool_calls` | [`AxAICohereChatResponseToolCalls`](/api/#03-apidocs/typealiasaxaicoherechatresponsetoolcalls) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAICohereChatResponseDelta.md
================================================
---
title: AxAICohereChatResponseDelta
---

```ts
type AxAICohereChatResponseDelta = AxAICohereChatResponse & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L109

## Type declaration

| Name | Type |
| :------ | :------ |
| `event_type` | \| `"stream-start"` \| `"text-generation"` \| `"tool-calls-generation"` \| `"stream-end"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAICohereChatResponseToolCalls.md
================================================
---
title: AxAICohereChatResponseToolCalls
---

```ts
type AxAICohereChatResponseToolCalls = object[];
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L31

## Type declaration

| Name | Type |
| :------ | :------ |
| `name` | `string` |
| `parameters`? | `object` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAICohereConfig.md
================================================
---
title: AxAICohereConfig
---

```ts
type AxAICohereConfig = AxModelConfig & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L26

Cohere: Model options for text generation

## Type declaration

| Name | Type |
| :------ | :------ |
| `embedModel`? | [`AxAICohereEmbedModel`](/api/#03-apidocs/enumerationaxaicohereembedmodel) |
| `model` | [`AxAICohereModel`](/api/#03-apidocs/enumerationaxaicoheremodel) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAICohereEmbedRequest.md
================================================
---
title: AxAICohereEmbedRequest
---

```ts
type AxAICohereEmbedRequest = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L117

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="model"></a> `model` | [`AxAICohereEmbedModel`](/api/#03-apidocs/enumerationaxaicohereembedmodel) |
| <a id="texts"></a> `texts` | readonly `string`[] |
| <a id="truncate"></a> `truncate` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAICohereEmbedResponse.md
================================================
---
title: AxAICohereEmbedResponse
---

```ts
type AxAICohereEmbedResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/cohere/types.ts#L123

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="embeddings"></a> `embeddings` | `number`[][] |
| <a id="id"></a> `id` | `string` |
| <a id="model"></a> `model` | [`AxAICohereEmbedModel`](/api/#03-apidocs/enumerationaxaicohereembedmodel) |
| <a id="texts"></a> `texts` | `string`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIEmbedModels.md
================================================
---
title: AxAIEmbedModels
---

```ts
type AxAIEmbedModels = 
  | AxAIOpenAIEmbedModel
  | AxAIGoogleGeminiEmbedModel
  | AxAICohereEmbedModel;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L81



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiBatchEmbedRequest.md
================================================
---
title: AxAIGoogleGeminiBatchEmbedRequest
---

```ts
type AxAIGoogleGeminiBatchEmbedRequest = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L208

AxAIGoogleGeminiEmbedRequest: Structure for making an embedding request to the Google Gemini API.

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="requests"></a> `requests` | `object`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiBatchEmbedResponse.md
================================================
---
title: AxAIGoogleGeminiBatchEmbedResponse
---

```ts
type AxAIGoogleGeminiBatchEmbedResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L220

AxAIGoogleGeminiEmbedResponse: Structure for handling responses from the Google Gemini API embedding requests.

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="embeddings"></a> `embeddings` | `object`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiChatRequest.md
================================================
---
title: AxAIGoogleGeminiChatRequest
---

```ts
type AxAIGoogleGeminiChatRequest = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L141

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="contents"></a> `contents` | [`AxAIGoogleGeminiContent`](/api/#03-apidocs/typealiasaxaigooglegeminicontent)[] |
| <a id="generationConfig"></a> `generationConfig` | [`AxAIGoogleGeminiGenerationConfig`](/api/#03-apidocs/typealiasaxaigooglegeminigenerationconfig) |
| <a id="safetySettings"></a> `safetySettings`? | [`AxAIGoogleGeminiSafetySettings`](/api/#03-apidocs/typealiasaxaigooglegeminisafetysettings) |
| <a id="systemInstruction"></a> `systemInstruction`? | [`AxAIGoogleGeminiContent`](/api/#03-apidocs/typealiasaxaigooglegeminicontent) |
| <a id="toolConfig"></a> `toolConfig`? | [`AxAIGoogleGeminiToolConfig`](/api/#03-apidocs/typealiasaxaigooglegeminitoolconfig) |
| <a id="tools"></a> `tools`? | [`AxAIGoogleGeminiTool`](/api/#03-apidocs/typealiasaxaigooglegeminitool)[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiChatResponse.md
================================================
---
title: AxAIGoogleGeminiChatResponse
---

```ts
type AxAIGoogleGeminiChatResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L150

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="candidates"></a> `candidates` | `object`[] |
| <a id="usageMetadata"></a> `usageMetadata` | \{ `candidatesTokenCount`: `number`; `promptTokenCount`: `number`; `thoughtsTokenCount`: `number`; `totalTokenCount`: `number`; \} |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiChatResponseDelta.md
================================================
---
title: AxAIGoogleGeminiChatResponseDelta
---

```ts
type AxAIGoogleGeminiChatResponseDelta = AxAIGoogleGeminiChatResponse;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L184



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiConfig.md
================================================
---
title: AxAIGoogleGeminiConfig
---

```ts
type AxAIGoogleGeminiConfig = AxModelConfig & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L194

AxAIGoogleGeminiConfig: Configuration options for Google Gemini API

## Type declaration

| Name | Type |
| :------ | :------ |
| `autoTruncate`? | `boolean` |
| `dimensions`? | `number` |
| `embedModel`? | [`AxAIGoogleGeminiEmbedModel`](/api/#03-apidocs/enumerationaxaigooglegeminiembedmodel) |
| `embedType`? | [`AxAIGoogleGeminiEmbedTypes`](/api/#03-apidocs/enumerationaxaigooglegeminiembedtypes) |
| `model` | [`AxAIGoogleGeminiModel`](/api/#03-apidocs/enumerationaxaigooglegeminimodel) |
| `safetySettings`? | [`AxAIGoogleGeminiSafetySettings`](/api/#03-apidocs/typealiasaxaigooglegeminisafetysettings) |
| `thinking`? | [`AxAIGoogleGeminiThinkingConfig`](/api/#03-apidocs/typealiasaxaigooglegeminithinkingconfig) |
| `urlContext`? | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiContent.md
================================================
---
title: AxAIGoogleGeminiContent
---

```ts
type AxAIGoogleGeminiContent = 
  | {
  parts: (
     | {
     text: string;
     thought: string;
    }
     | {
     inlineData: {
        data: string;
        mimeType: string;
       };
    }
     | {
     fileData: {
        fileUri: string;
        mimeType: string;
       };
    })[];
  role: "user";
 }
  | {
  parts: object[] | object[];
  role: "model";
 }
  | {
  parts: object[];
  role: "function";
};
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L48



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiGenerationConfig.md
================================================
---
title: AxAIGoogleGeminiGenerationConfig
---

```ts
type AxAIGoogleGeminiGenerationConfig = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L121

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="candidateCount"></a> `candidateCount`? | `number` |
| <a id="frequencyPenalty"></a> `frequencyPenalty`? | `number` |
| <a id="maxOutputTokens"></a> `maxOutputTokens`? | `number` |
| <a id="responseMimeType"></a> `responseMimeType`? | `string` |
| <a id="stopSequences"></a> `stopSequences`? | readonly `string`[] |
| <a id="temperature"></a> `temperature`? | `number` |
| <a id="thinkingConfig"></a> `thinkingConfig`? | \{ `includeThoughts`: `boolean`; `thinkingBudget`: `number`; \} |
| <a id="topK"></a> `topK`? | `number` |
| <a id="topP"></a> `topP`? | `number` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiSafetySettings.md
================================================
---
title: AxAIGoogleGeminiSafetySettings
---

```ts
type AxAIGoogleGeminiSafetySettings = object[];
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L136

## Type declaration

| Name | Type |
| :------ | :------ |
| `category` | [`AxAIGoogleGeminiSafetyCategory`](/api/#03-apidocs/enumerationaxaigooglegeminisafetycategory) |
| `threshold` | [`AxAIGoogleGeminiSafetyThreshold`](/api/#03-apidocs/enumerationaxaigooglegeminisafetythreshold) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiTool.md
================================================
---
title: AxAIGoogleGeminiTool
---

```ts
type AxAIGoogleGeminiTool = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L106

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="code_execution"></a> `code_execution`? | `object` |
| <a id="function_declarations"></a> `function_declarations`? | [`AxAIGoogleGeminiToolFunctionDeclaration`](/api/#03-apidocs/typealiasaxaigooglegeminitoolfunctiondeclaration)[] |
| <a id="google_search"></a> `google_search`? | `object` |
| <a id="google_search_retrieval"></a> `google_search_retrieval`? | [`AxAIGoogleGeminiToolGoogleSearchRetrieval`](/api/#03-apidocs/typealiasaxaigooglegeminitoolgooglesearchretrieval) |
| <a id="url_context"></a> `url_context`? | `object` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiToolConfig.md
================================================
---
title: AxAIGoogleGeminiToolConfig
---

```ts
type AxAIGoogleGeminiToolConfig = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L114

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="function_calling_config"></a> `function_calling_config` | \{ `allowed_function_names`: `string`[]; `mode`: `"ANY"` \| `"NONE"` \| `"AUTO"`; \} |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiToolFunctionDeclaration.md
================================================
---
title: AxAIGoogleGeminiToolFunctionDeclaration
---

```ts
type AxAIGoogleGeminiToolFunctionDeclaration = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L93

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="description"></a> `description`? | `string` |
| <a id="name"></a> `name` | `string` |
| <a id="parameters"></a> `parameters`? | `object` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIGoogleGeminiToolGoogleSearchRetrieval.md
================================================
---
title: AxAIGoogleGeminiToolGoogleSearchRetrieval
---

```ts
type AxAIGoogleGeminiToolGoogleSearchRetrieval = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/google-gemini/types.ts#L99

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="dynamic_retrieval_config"></a> `dynamic_retrieval_config` | \{ `dynamic_threshold`: `number`; `mode`: `"MODE_DYNAMIC"`; \} |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIHuggingFaceConfig.md
================================================
---
title: AxAIHuggingFaceConfig
---

```ts
type AxAIHuggingFaceConfig = AxModelConfig & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/huggingface/types.ts#L7

## Type declaration

| Name | Type |
| :------ | :------ |
| `doSample`? | `boolean` |
| `maxTime`? | `number` |
| `model` | [`AxAIHuggingFaceModel`](/api/#03-apidocs/enumerationaxaihuggingfacemodel) |
| `returnFullText`? | `boolean` |
| `useCache`? | `boolean` |
| `waitForModel`? | `boolean` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIHuggingFaceRequest.md
================================================
---
title: AxAIHuggingFaceRequest
---

```ts
type AxAIHuggingFaceRequest = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/huggingface/types.ts#L16

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="inputs"></a> `inputs` | `string` |
| <a id="model"></a> `model` | [`AxAIHuggingFaceModel`](/api/#03-apidocs/enumerationaxaihuggingfacemodel) |
| <a id="options"></a> `options`? | \{ `use_cache`: `boolean`; `wait_for_model`: `boolean`; \} |
| <a id="parameters"></a> `parameters` | \{ `do_sample`: `boolean`; `max_new_tokens`: `number`; `max_time`: `number`; `num_return_sequences`: `number`; `repetition_penalty`: `number`; `return_full_text`: `boolean`; `temperature`: `number`; `top_k`: `number`; `top_p`: `number`; \} |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIHuggingFaceResponse.md
================================================
---
title: AxAIHuggingFaceResponse
---

```ts
type AxAIHuggingFaceResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/huggingface/types.ts#L36

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="generated_text"></a> `generated_text` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIModels.md
================================================
---
title: AxAIModels
---

```ts
type AxAIModels = 
  | AxAIOpenAIModel
  | AxAIAnthropicModel
  | AxAIGroqModel
  | AxAIGoogleGeminiModel
  | AxAICohereModel
  | AxAIHuggingFaceModel
  | AxAIMistralModel
  | AxAIDeepSeekModel;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/wrap.ts#L71



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOllamaAIConfig.md
================================================
---
title: AxAIOllamaAIConfig
---

```ts
type AxAIOllamaAIConfig = AxAIOpenAIConfig<string, string>;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/ollama/api.ts#L8



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOllamaArgs.md
================================================
---
title: AxAIOllamaArgs
---

```ts
type AxAIOllamaArgs = AxAIOpenAIArgs<"ollama", string, string> & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/ollama/api.ts#L24

## Type declaration

| Name | Type |
| :------ | :------ |
| `embedModel`? | `string` |
| `model`? | `string` |
| `url`? | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOpenAIChatRequest.md
================================================
---
title: AxAIOpenAIChatRequest
---

```ts
type AxAIOpenAIChatRequest<TModel> = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L85

## Type Parameters

| Type Parameter |
| :------ |
| `TModel` |

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="frequency_penalty"></a> `frequency_penalty`? | `number` |
| <a id="logit_bias"></a> `logit_bias`? | `Map`\<`string`, `number`\> |
| <a id="max_completion_tokens"></a> `max_completion_tokens`? | `number` |
| <a id="messages"></a> `messages` | ( \| \{ `content`: `string`; `role`: `"system"`; \} \| \{ `content`: \| `string` \| ( \| \{ `text`: `string`; `type`: `"text"`; \} \| \{ `image_url`: \{ `details`: ...; `url`: ...; \}; `type`: `"image_url"`; \} \| \{ `input_audio`: \{ `data`: ...; `format`: ...; \}; `type`: `"input_audio"`; \})[]; `name`: `string`; `role`: `"user"`; \} \| \{ `content`: `string`; `name`: `string`; `role`: `"assistant"`; `tool_calls`: `object`[]; \} \| \{ `content`: `string`; `role`: `"tool"`; `tool_call_id`: `string`; \})[] |
| <a id="model"></a> `model` | `TModel` |
| <a id="n"></a> `n`? | `number` |
| <a id="organization"></a> `organization`? | `string` |
| <a id="presence_penalty"></a> `presence_penalty`? | `number` |
| <a id="reasoning_effort"></a> `reasoning_effort`? | `"low"` \| `"medium"` \| `"high"` |
| <a id="response_format"></a> `response_format`? | \{ `type`: `string`; \} |
| <a id="stop"></a> `stop`? | readonly `string`[] |
| <a id="store"></a> `store`? | `boolean` |
| <a id="stream"></a> `stream`? | `boolean` |
| <a id="temperature"></a> `temperature`? | `number` |
| <a id="tool_choice"></a> `tool_choice`? | \| `"none"` \| `"auto"` \| `"required"` \| \{ `function`: \{ `name`: `string`; \}; `type`: `"function"`; \} |
| <a id="tools"></a> `tools`? | `object`[] |
| <a id="top_p"></a> `top_p`? | `number` |
| <a id="user"></a> `user`? | `string` |
| <a id="web_search_options"></a> `web_search_options`? | \{ `search_context_size`: `"low"` \| `"medium"` \| `"high"`; `user_location`: \| \{ `approximate`: \{ `city`: `string`; `country`: `string`; `region`: `string`; `timezone`: `string`; `type`: `"approximate"`; \}; \} \| `null`; \} |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOpenAIChatResponse.md
================================================
---
title: AxAIOpenAIChatResponse
---

```ts
type AxAIOpenAIChatResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L165

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="choices"></a> `choices` | `object`[] |
| <a id="created"></a> `created` | `number` |
| <a id="error"></a> `error`? | \{ `code`: `number`; `message`: `string`; `param`: `string`; `type`: `string`; \} |
| <a id="id"></a> `id` | `string` |
| <a id="model"></a> `model` | `string` |
| <a id="object"></a> `object` | `"chat.completion"` |
| <a id="system_fingerprint"></a> `system_fingerprint` | `string` |
| <a id="usage"></a> `usage`? | [`AxAIOpenAIUsage`](/api/#03-apidocs/typealiasaxaiopenaiusage) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOpenAIChatResponseDelta.md
================================================
---
title: AxAIOpenAIChatResponseDelta
---

```ts
type AxAIOpenAIChatResponseDelta = AxAIOpenAIResponseDelta<{
  content: string;
  reasoning_content: string;
  role: string;
  tool_calls: NonNullable<...[...][0]["message"]["tool_calls"]>[0] & object[];
}>;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L195



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOpenAIConfig.md
================================================
---
title: AxAIOpenAIConfig
---

```ts
type AxAIOpenAIConfig<TModel, TEmbedModel> = Omit<AxModelConfig, "topK"> & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L26

## Type declaration

| Name | Type |
| :------ | :------ |
| `bestOf`? | `number` |
| `dimensions`? | `number` |
| `echo`? | `boolean` |
| `embedModel`? | `TEmbedModel` |
| `logitBias`? | `Map`\<`string`, `number`\> |
| `logprobs`? | `number` |
| `model` | `TModel` |
| `reasoningEffort`? | `"low"` \| `"medium"` \| `"high"` |
| `responseFormat`? | `"json_object"` |
| `serviceTier`? | `"auto"` \| `"default"` \| `"flex"` |
| `stop`? | `string`[] |
| `store`? | `boolean` |
| `suffix`? | `string` \| `null` |
| `user`? | `string` |
| `webSearchOptions`? | \{ `searchContextSize`: `"low"` \| `"medium"` \| `"high"`; `userLocation`: \| \{ `approximate`: \{ `city`: `string`; `country`: `string`; `region`: `string`; `timezone`: `string`; `type`: `"approximate"`; \}; \} \| `null`; \} |

## Type Parameters

| Type Parameter |
| :------ |
| `TModel` |
| `TEmbedModel` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOpenAIEmbedRequest.md
================================================
---
title: AxAIOpenAIEmbedRequest
---

```ts
type AxAIOpenAIEmbedRequest<TEmbedModel> = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L206

## Type Parameters

| Type Parameter |
| :------ |
| `TEmbedModel` |

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="dimensions"></a> `dimensions`? | `number` |
| <a id="input"></a> `input` | readonly `string`[] |
| <a id="model"></a> `model` | `TEmbedModel` |
| <a id="user"></a> `user`? | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOpenAIEmbedResponse.md
================================================
---
title: AxAIOpenAIEmbedResponse
---

```ts
type AxAIOpenAIEmbedResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L213

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="data"></a> `data` | `object`[] |
| <a id="model"></a> `model` | `string` |
| <a id="usage"></a> `usage` | [`AxAIOpenAIUsage`](/api/#03-apidocs/typealiasaxaiopenaiusage) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOpenAILogprob.md
================================================
---
title: AxAIOpenAILogprob
---

```ts
type AxAIOpenAILogprob = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L58

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="text_offset"></a> `text_offset` | `number`[] |
| <a id="token_logprobs"></a> `token_logprobs` | `number`[] |
| <a id="tokens"></a> `tokens` | `string`[] |
| <a id="top_logprobs"></a> `top_logprobs` | `Map`\<`string`, `number`\> |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIOpenAIUsage.md
================================================
---
title: AxAIOpenAIUsage
---

```ts
type AxAIOpenAIUsage = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/openai/chat_types.ts#L65

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="completion_tokens"></a> `completion_tokens` | `number` |
| <a id="prompt_tokens"></a> `prompt_tokens` | `number` |
| <a id="total_tokens"></a> `total_tokens` | `number` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIPromptConfig.md
================================================
---
title: AxAIPromptConfig
---

```ts
type AxAIPromptConfig = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L263

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="showThoughts"></a> `showThoughts`? | `boolean` |
| <a id="stream"></a> `stream`? | `boolean` |
| <a id="thinkingTokenBudget"></a> `thinkingTokenBudget`? | `"minimal"` \| `"low"` \| `"medium"` \| `"high"` \| `"highest"` \| `"none"` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIRekaChatRequest.md
================================================
---
title: AxAIRekaChatRequest
---

```ts
type AxAIRekaChatRequest = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/reka/types.ts#L20

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="frequency_penalty"></a> `frequency_penalty`? | `number` |
| <a id="max_tokens"></a> `max_tokens`? | `number` |
| <a id="messages"></a> `messages` | ( \| \{ `content`: `string` \| `object`[]; `role`: `"user"`; \} \| \{ `content`: `string` \| `object`[]; `role`: `"assistant"`; \})[] |
| <a id="model"></a> `model` | `string` |
| <a id="presence_penalty"></a> `presence_penalty`? | `number` |
| <a id="response_format"></a> `response_format`? | \{ `type`: `string`; \} |
| <a id="stop"></a> `stop`? | readonly `string`[] |
| <a id="stream"></a> `stream`? | `boolean` |
| <a id="temperature"></a> `temperature`? | `number` |
| <a id="top_k"></a> `top_k`? | `number` |
| <a id="top_p"></a> `top_p`? | `number` |
| <a id="usage"></a> `usage`? | [`AxAIRekaUsage`](/api/#03-apidocs/typealiasaxairekausage) |
| <a id="use_search_engine"></a> `use_search_engine`? | `boolean` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIRekaChatResponse.md
================================================
---
title: AxAIRekaChatResponse
---

```ts
type AxAIRekaChatResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/reka/types.ts#L55

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="id"></a> `id` | `string` |
| <a id="model"></a> `model` | `string` |
| <a id="responses"></a> `responses` | `object`[] |
| <a id="usage"></a> `usage`? | [`AxAIRekaUsage`](/api/#03-apidocs/typealiasaxairekausage) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIRekaChatResponseDelta.md
================================================
---
title: AxAIRekaChatResponseDelta
---

```ts
type AxAIRekaChatResponseDelta = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/reka/types.ts#L72

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="id"></a> `id` | `string` |
| <a id="model"></a> `model` | `string` |
| <a id="responses"></a> `responses` | `object`[] |
| <a id="usage"></a> `usage`? | [`AxAIRekaUsage`](/api/#03-apidocs/typealiasaxairekausage) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIRekaConfig.md
================================================
---
title: AxAIRekaConfig
---

```ts
type AxAIRekaConfig = Omit<AxModelConfig, "topK"> & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/reka/types.ts#L9

## Type declaration

| Name | Type |
| :------ | :------ |
| `model` | [`AxAIRekaModel`](/api/#03-apidocs/enumerationaxairekamodel) |
| `stop`? | readonly `string`[] |
| `useSearchEngine`? | `boolean` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIRekaUsage.md
================================================
---
title: AxAIRekaUsage
---

```ts
type AxAIRekaUsage = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/reka/types.ts#L15

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="input_tokens"></a> `input_tokens` | `number` |
| <a id="output_tokens"></a> `output_tokens` | `number` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIServiceActionOptions.md
================================================
---
title: AxAIServiceActionOptions
---

```ts
type AxAIServiceActionOptions<TModel, TEmbedModel> = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L286

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `TModel` | `unknown` |
| `TEmbedModel` | `unknown` |

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="abortSignal"></a> `abortSignal`? | `AbortSignal` |
| <a id="ai"></a> `ai`? | `Readonly`\<[`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)\<`TModel`, `TEmbedModel`\>\> |
| <a id="debug"></a> `debug`? | `boolean` |
| <a id="debugHideSystemPrompt"></a> `debugHideSystemPrompt`? | `boolean` |
| <a id="logger"></a> `logger`? | [`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction) |
| <a id="rateLimiter"></a> `rateLimiter`? | [`AxRateLimiterFunction`](/api/#03-apidocs/typealiasaxratelimiterfunction) |
| <a id="sessionId"></a> `sessionId`? | `string` |
| <a id="timeout"></a> `timeout`? | `number` |
| <a id="traceContext"></a> `traceContext`? | `Context` |
| <a id="traceId"></a> `traceId`? | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxAIServiceOptions.md
================================================
---
title: AxAIServiceOptions
---

```ts
type AxAIServiceOptions = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L275

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="abortSignal"></a> `abortSignal`? | `AbortSignal` |
| <a id="debug"></a> `debug`? | `boolean` |
| <a id="excludeContentFromTrace"></a> `excludeContentFromTrace`? | `boolean` |
| <a id="fetch"></a> `fetch`? | *typeof* [`__type`](/api/#03-apidocs/interfaceaxapiconfig) |
| <a id="logger"></a> `logger`? | [`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction) |
| <a id="rateLimiter"></a> `rateLimiter`? | [`AxRateLimiterFunction`](/api/#03-apidocs/typealiasaxratelimiterfunction) |
| <a id="timeout"></a> `timeout`? | `number` |
| <a id="tracer"></a> `tracer`? | `Tracer` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxBalancerOptions.md
================================================
---
title: AxBalancerOptions
---

```ts
type AxBalancerOptions = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/balance.ts#L31

Options for the balancer.

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="comparator"></a> `comparator`? | (`a`: [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice), `b`: [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice)) => `number` |
| <a id="debug"></a> `debug`? | `boolean` |
| <a id="initialBackoffMs"></a> `initialBackoffMs`? | `number` |
| <a id="maxBackoffMs"></a> `maxBackoffMs`? | `number` |
| <a id="maxRetries"></a> `maxRetries`? | `number` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxChatRequest.md
================================================
---
title: AxChatRequest
---

```ts
type AxChatRequest<TModel> = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L124

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `TModel` | `string` |

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="chatPrompt"></a> `chatPrompt` | ( \| \{ `cache`: `boolean`; `content`: `string`; `role`: `"system"`; \} \| \{ `content`: \| `string` \| ( \| \{ `cache`: `boolean`; `text`: `string`; `type`: `"text"`; \} \| \{ `cache`: `boolean`; `details`: ... \| ... \| ...; `image`: `string`; `mimeType`: `string`; `type`: `"image"`; \} \| \{ `cache`: `boolean`; `data`: `string`; `format`: `"wav"`; `type`: `"audio"`; \})[]; `name`: `string`; `role`: `"user"`; \} \| \{ `cache`: `boolean`; `content`: `string`; `functionCalls`: `object`[]; `name`: `string`; `role`: `"assistant"`; \} \| \{ `cache`: `boolean`; `functionId`: `string`; `isError`: `boolean`; `result`: `string`; `role`: `"function"`; \})[] |
| <a id="functionCall"></a> `functionCall`? | \| `"none"` \| `"auto"` \| `"required"` \| \{ `function`: \{ `name`: `string`; \}; `type`: `"function"`; \} |
| <a id="functions"></a> `functions`? | `Readonly`\<\{ `description`: `string`; `name`: `string`; `parameters`: [`AxFunctionJSONSchema`](/api/#03-apidocs/typealiasaxfunctionjsonschema); \}\>[] |
| <a id="model"></a> `model`? | `TModel` |
| <a id="modelConfig"></a> `modelConfig`? | [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxChatResponse.md
================================================
---
title: AxChatResponse
---

```ts
type AxChatResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L108

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="modelUsage"></a> `modelUsage`? | [`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) |
| <a id="remoteId"></a> `remoteId`? | `string` |
| <a id="results"></a> `results` | readonly [`AxChatResponseResult`](/api/#03-apidocs/typealiasaxchatresponseresult)[] |
| <a id="sessionId"></a> `sessionId`? | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxChatResponseFunctionCall.md
================================================
---
title: AxChatResponseFunctionCall
---

```ts
type AxChatResponseFunctionCall = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/functions.ts#L100

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="args"></a> `args` | `string` |
| <a id="id"></a> `id` | `string` |
| <a id="name"></a> `name` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxChatResponseResult.md
================================================
---
title: AxChatResponseResult
---

```ts
type AxChatResponseResult = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L84

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="content"></a> `content`? | `string` |
| <a id="finishReason"></a> `finishReason`? | `"stop"` \| `"length"` \| `"function_call"` \| `"content_filter"` \| `"error"` |
| <a id="functionCalls"></a> `functionCalls`? | `object`[] |
| <a id="id"></a> `id`? | `string` |
| <a id="name"></a> `name`? | `string` |
| <a id="thought"></a> `thought`? | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDataRow.md
================================================
---
title: AxDataRow
---

```ts
type AxDataRow = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/loader.ts#L3

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="row"></a> `row` | `Record`\<`string`, [`AxFieldValue`](/api/#03-apidocs/typealiasaxfieldvalue)\> |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBArgs.md
================================================
---
title: AxDBArgs
---

```ts
type AxDBArgs = 
  | AxDBCloudflareArgs
  | AxDBPineconeArgs
  | AxDBWeaviateArgs
  | AxDBMemoryArgs;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/wrap.ts#L13



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBCloudflareOpOptions.md
================================================
---
title: AxDBCloudflareOpOptions
---

```ts
type AxDBCloudflareOpOptions = AxDBBaseOpOptions;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/cloudflare.ts#L13



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBMemoryOpOptions.md
================================================
---
title: AxDBMemoryOpOptions
---

```ts
type AxDBMemoryOpOptions = AxDBBaseOpOptions;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L9



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBPineconeOpOptions.md
================================================
---
title: AxDBPineconeOpOptions
---

```ts
type AxDBPineconeOpOptions = AxDBBaseOpOptions;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/pinecone.ts#L11



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBQueryRequest.md
================================================
---
title: AxDBQueryRequest
---

```ts
type AxDBQueryRequest = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L17

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="columns"></a> `columns`? | `string`[] |
| <a id="id"></a> `id`? | `string` |
| <a id="limit"></a> `limit`? | `number` |
| <a id="namespace"></a> `namespace`? | `string` |
| <a id="table"></a> `table` | `string` |
| <a id="text"></a> `text`? | `string` |
| <a id="values"></a> `values`? | readonly `number`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBQueryResponse.md
================================================
---
title: AxDBQueryResponse
---

```ts
type AxDBQueryResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L27

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="matches"></a> `matches` | `object`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBState.md
================================================
---
title: AxDBState
---

```ts
type AxDBState = Record<string, Record<string, AxDBUpsertRequest>>;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/memory.ts#L15



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBUpsertRequest.md
================================================
---
title: AxDBUpsertRequest
---

```ts
type AxDBUpsertRequest = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L3

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="id"></a> `id` | `string` |
| <a id="metadata"></a> `metadata`? | `Record`\<`string`, `string`\> |
| <a id="namespace"></a> `namespace`? | `string` |
| <a id="table"></a> `table` | `string` |
| <a id="text"></a> `text`? | `string` |
| <a id="values"></a> `values`? | readonly `number`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBUpsertResponse.md
================================================
---
title: AxDBUpsertResponse
---

```ts
type AxDBUpsertResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/types.ts#L12

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="ids"></a> `ids` | `string`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxDBWeaviateOpOptions.md
================================================
---
title: AxDBWeaviateOpOptions
---

```ts
type AxDBWeaviateOpOptions = AxDBBaseOpOptions;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/db/weaviate.ts#L11



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxEmbedRequest.md
================================================
---
title: AxEmbedRequest
---

```ts
type AxEmbedRequest<TEmbedModel> = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L218

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `TEmbedModel` | `string` |

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="embedModel"></a> `embedModel`? | `TEmbedModel` |
| <a id="texts"></a> `texts`? | readonly `string`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxEmbedResponse.md
================================================
---
title: AxEmbedResponse
---

```ts
type AxEmbedResponse = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L115

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="embeddings"></a> `embeddings` | readonly readonly `number`[][] |
| <a id="modelUsage"></a> `modelUsage`? | [`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage) |
| <a id="remoteId"></a> `remoteId`? | `string` |
| <a id="sessionId"></a> `sessionId`? | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxEvaluateArgs.md
================================================
---
title: AxEvaluateArgs
---

```ts
type AxEvaluateArgs<IN, OUT> = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/evaluate.ts#L8

## Type Parameters

| Type Parameter |
| :------ |
| `IN` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) |
| `OUT` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="ai"></a> `ai` | [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice) |
| <a id="examples"></a> `examples` | `Readonly`\<[`AxExample`](/api/#03-apidocs/typealiasaxexample)[]\> |
| <a id="program"></a> `program` | `Readonly`\<[`AxProgram`](/api/#03-apidocs/classaxprogram)\<`IN`, `OUT`\>\> |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxExample.md
================================================
---
title: AxExample
---

```ts
type AxExample = Record<string, AxFieldValue>;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/optimize.ts#L14



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxFieldTemplateFn.md
================================================
---
title: AxFieldTemplateFn
---

```ts
type AxFieldTemplateFn = (field: Readonly<AxField>, value: Readonly<AxFieldValue>) => any[];
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/prompt.ts#L36

## Parameters

| Parameter | Type |
| :------ | :------ |
| `field` | `Readonly`\<[`AxField`](/api/#03-apidocs/interfaceaxfield)\> |
| `value` | `Readonly`\<[`AxFieldValue`](/api/#03-apidocs/typealiasaxfieldvalue)\> |

## Returns

`any`[]



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxFieldValue.md
================================================
---
title: AxFieldValue
---

```ts
type AxFieldValue = 
  | string
  | string[]
  | number
  | boolean
  | object
  | null
  | undefined
  | {
  data: string;
  mimeType: string;
 }
  | object[]
  | {
  data: string;
  format: "wav";
 }
  | object[];
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/types.ts#L1



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxFunction.md
================================================
---
title: AxFunction
---

```ts
type AxFunction = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L77

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="description"></a> `description` | `string` |
| <a id="func"></a> `func` | [`AxFunctionHandler`](/api/#03-apidocs/typealiasaxfunctionhandler) |
| <a id="name"></a> `name` | `string` |
| <a id="parameters"></a> `parameters`? | [`AxFunctionJSONSchema`](/api/#03-apidocs/typealiasaxfunctionjsonschema) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxFunctionHandler.md
================================================
---
title: AxFunctionHandler
---

```ts
type AxFunctionHandler = (args?: any, extra?: Readonly<{
  ai: AxAIService;
  debug: boolean;
  sessionId: string;
  traceId: string;
 }>) => unknown;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L53

## Parameters

| Parameter | Type |
| :------ | :------ |
| `args`? | `any` |
| `extra`? | `Readonly`\<\{ `ai`: [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice); `debug`: `boolean`; `sessionId`: `string`; `traceId`: `string`; \}\> |

## Returns

`unknown`



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxFunctionJSONSchema.md
================================================
---
title: AxFunctionJSONSchema
---

```ts
type AxFunctionJSONSchema = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L64

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="items"></a> `items`? | [`AxFunctionJSONSchema`](/api/#03-apidocs/typealiasaxfunctionjsonschema) |
| <a id="properties"></a> `properties`? | `Record`\<`string`, [`AxFunctionJSONSchema`](/api/#03-apidocs/typealiasaxfunctionjsonschema) & `object`\> |
| <a id="required"></a> `required`? | `string`[] |
| <a id="type"></a> `type` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxGenerateResult.md
================================================
---
title: AxGenerateResult
---

```ts
type AxGenerateResult<OUT> = OUT & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/generate.ts#L66

## Type declaration

| Name | Type |
| :------ | :------ |
| `thought`? | `string` |

## Type Parameters

| Type Parameter |
| :------ |
| `OUT` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxGenIn.md
================================================
---
title: AxGenIn
---

```ts
type AxGenIn = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/types.ts#L14

## Index Signature

```ts
[key: string]: AxFieldValue
```



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxGenOut.md
================================================
---
title: AxGenOut
---

```ts
type AxGenOut = Record<string, AxFieldValue>;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/types.ts#L16



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxIField.md
================================================
---
title: AxIField
---

```ts
type AxIField = Omit<AxField, "title"> & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/sig.ts#L35

## Type declaration

| Name | Type |
| :------ | :------ |
| `title` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxInputFunctionType.md
================================================
---
title: AxInputFunctionType
---

```ts
type AxInputFunctionType = (
  | AxFunction
  | {
  toFunction: () => 
     | AxFunction
     | AxFunction[];
 })[];
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/functions.ts#L175



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxInternalChatRequest.md
================================================
---
title: AxInternalChatRequest
---

```ts
type AxInternalChatRequest<TModel> = Omit<AxChatRequest, "model"> & Required<Pick<AxChatRequest<TModel>, "model">>;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L215

## Type Parameters

| Type Parameter |
| :------ |
| `TModel` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxInternalEmbedRequest.md
================================================
---
title: AxInternalEmbedRequest
---

```ts
type AxInternalEmbedRequest<TEmbedModel> = Omit<AxEmbedRequest, "embedModel"> & Required<Pick<AxEmbedRequest<TEmbedModel>, "embedModel">>;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L223

## Type Parameters

| Type Parameter |
| :------ |
| `TEmbedModel` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxMetricFn.md
================================================
---
title: AxMetricFn
---

```ts
type AxMetricFn = <T>(arg0: Readonly<{
  example: AxExample;
  prediction: T;
 }>) => number;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/optimize.ts#L16

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `T` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) | [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |

## Parameters

| Parameter | Type |
| :------ | :------ |
| `arg0` | `Readonly`\<\{ `example`: [`AxExample`](/api/#03-apidocs/typealiasaxexample); `prediction`: `T`; \}\> |

## Returns

`number`



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxMetricFnArgs.md
================================================
---
title: AxMetricFnArgs
---

```ts
type AxMetricFnArgs = Parameters<AxMetricFn>[0];
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/optimize.ts#L20



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxModelConfig.md
================================================
---
title: AxModelConfig
---

```ts
type AxModelConfig = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L40

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="endSequences"></a> `endSequences`? | `string`[] |
| <a id="frequencyPenalty"></a> `frequencyPenalty`? | `number` |
| <a id="maxTokens"></a> `maxTokens`? | `number` |
| <a id="n"></a> `n`? | `number` |
| <a id="presencePenalty"></a> `presencePenalty`? | `number` |
| <a id="stopSequences"></a> `stopSequences`? | `string`[] |
| <a id="stream"></a> `stream`? | `boolean` |
| <a id="temperature"></a> `temperature`? | `number` |
| <a id="topK"></a> `topK`? | `number` |
| <a id="topP"></a> `topP`? | `number` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxModelInfo.md
================================================
---
title: AxModelInfo
---

```ts
type AxModelInfo = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L21

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="aliases"></a> `aliases`? | `string`[] |
| <a id="characterIsToken"></a> `characterIsToken`? | `boolean` |
| <a id="completionTokenCostPer1M"></a> `completionTokenCostPer1M`? | `number` |
| <a id="currency"></a> `currency`? | `string` |
| <a id="hasShowThoughts"></a> `hasShowThoughts`? | `boolean` |
| <a id="hasThinkingBudget"></a> `hasThinkingBudget`? | `boolean` |
| <a id="maxTokens"></a> `maxTokens`? | `number` |
| <a id="name"></a> `name` | `string` |
| <a id="promptTokenCostPer1M"></a> `promptTokenCostPer1M`? | `number` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxModelInfoWithProvider.md
================================================
---
title: AxModelInfoWithProvider
---

```ts
type AxModelInfoWithProvider = AxModelInfo & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L122

## Type declaration

| Name | Type |
| :------ | :------ |
| `provider` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxOptimizerArgs.md
================================================
---
title: AxOptimizerArgs
---

```ts
type AxOptimizerArgs<IN, OUT> = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/optimize.ts#L22

## Type Parameters

| Type Parameter |
| :------ |
| `IN` *extends* [`AxGenIn`](/api/#03-apidocs/typealiasaxgenin) |
| `OUT` *extends* [`AxGenOut`](/api/#03-apidocs/typealiasaxgenout) |

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="ai"></a> `ai` | [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice) |
| <a id="examples"></a> `examples` | `Readonly`\<[`AxExample`](/api/#03-apidocs/typealiasaxexample)[]\> |
| <a id="options"></a> `options`? | \{ `batchSize`: `number`; `costMonitoring`: `boolean`; `debugMode`: `boolean`; `earlyStoppingPatience`: `number`; `maxDemos`: `number`; `maxExamples`: `number`; `maxRounds`: `number`; `maxTokensPerGeneration`: `number`; `teacherAI`: [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice); `verboseMode`: `boolean`; \} |
| <a id="program"></a> `program` | `Readonly`\<[`AxProgram`](/api/#03-apidocs/classaxprogram)\<`IN`, `OUT`\>\> |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxProgramDemos.md
================================================
---
title: AxProgramDemos
---

```ts
type AxProgramDemos = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L27

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="programId"></a> `programId` | `string` |
| <a id="traces"></a> `traces` | `Record`\<`string`, [`AxFieldValue`](/api/#03-apidocs/typealiasaxfieldvalue)\>[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxProgramExamples.md
================================================
---
title: AxProgramExamples
---

```ts
type AxProgramExamples = 
  | AxProgramDemos
  | AxProgramDemos["traces"];
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L33



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxProgramForwardOptions.md
================================================
---
title: AxProgramForwardOptions
---

```ts
type AxProgramForwardOptions = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L35

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="abortSignal"></a> `abortSignal`? | `AbortSignal` |
| <a id="ai"></a> `ai`? | [`AxAIService`](/api/#03-apidocs/interfaceaxaiservice) |
| <a id="asserts"></a> `asserts`? | [`AxAssertion`](/api/#03-apidocs/interfaceaxassertion)[] |
| <a id="debug"></a> `debug`? | `boolean` |
| <a id="debugHideSystemPrompt"></a> `debugHideSystemPrompt`? | `boolean` |
| <a id="description"></a> `description`? | `string` |
| <a id="excludeContentFromTrace"></a> `excludeContentFromTrace`? | `boolean` |
| <a id="fastFail"></a> `fastFail`? | `boolean` |
| <a id="functionCall"></a> `functionCall`? | [`AxChatRequest`](/api/#03-apidocs/typealiasaxchatrequest)\[`"functionCall"`\] |
| <a id="functions"></a> `functions`? | [`AxInputFunctionType`](/api/#03-apidocs/typealiasaxinputfunctiontype) |
| <a id="logger"></a> `logger`? | [`AxLoggerFunction`](/api/#03-apidocs/typealiasaxloggerfunction) |
| <a id="maxRetries"></a> `maxRetries`? | `number` |
| <a id="maxSteps"></a> `maxSteps`? | `number` |
| <a id="mem"></a> `mem`? | [`AxAIMemory`](/api/#03-apidocs/interfaceaxaimemory) |
| <a id="model"></a> `model`? | `string` |
| <a id="modelConfig"></a> `modelConfig`? | [`AxModelConfig`](/api/#03-apidocs/typealiasaxmodelconfig) |
| <a id="promptTemplate"></a> `promptTemplate`? | *typeof* [`AxPromptTemplate`](/api/#03-apidocs/classaxprompttemplate) |
| <a id="rateLimiter"></a> `rateLimiter`? | [`AxRateLimiterFunction`](/api/#03-apidocs/typealiasaxratelimiterfunction) |
| <a id="sessionId"></a> `sessionId`? | `string` |
| <a id="showThoughts"></a> `showThoughts`? | `boolean` |
| <a id="stopFunction"></a> `stopFunction`? | `string` |
| <a id="stream"></a> `stream`? | `boolean` |
| <a id="streamingAsserts"></a> `streamingAsserts`? | [`AxStreamingAssertion`](/api/#03-apidocs/interfaceaxstreamingassertion)[] |
| <a id="thinkingTokenBudget"></a> `thinkingTokenBudget`? | `"minimal"` \| `"low"` \| `"medium"` \| `"high"` \| `"highest"` \| `"none"` |
| <a id="thoughtFieldName"></a> `thoughtFieldName`? | `string` |
| <a id="traceId"></a> `traceId`? | `string` |
| <a id="traceLabel"></a> `traceLabel`? | `string` |
| <a id="tracer"></a> `tracer`? | `Tracer` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxProgramTrace.md
================================================
---
title: AxProgramTrace
---

```ts
type AxProgramTrace = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L21

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="programId"></a> `programId` | `string` |
| <a id="trace"></a> `trace` | `Record`\<`string`, [`AxFieldValue`](/api/#03-apidocs/typealiasaxfieldvalue)\> |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxProgramUsage.md
================================================
---
title: AxProgramUsage
---

```ts
type AxProgramUsage = AxChatResponse["modelUsage"] & object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/dsp/program.ts#L127

## Type declaration

| Name | Type |
| :------ | :------ |
| `ai` | `string` |
| `model` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxRateLimiterFunction.md
================================================
---
title: AxRateLimiterFunction
---

```ts
type AxRateLimiterFunction = <T>(reqFunc: () => Promise<T | ReadableStream<T>>, info: Readonly<{
  modelUsage: AxModelUsage;
}>) => Promise<T | ReadableStream<T>>;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L229

## Type Parameters

| Type Parameter | Default type |
| :------ | :------ |
| `T` | `unknown` |

## Parameters

| Parameter | Type |
| :------ | :------ |
| `reqFunc` | () => `Promise`\<`T` \| `ReadableStream`\<`T`\>\> |
| `info` | `Readonly`\<\{ `modelUsage`: [`AxModelUsage`](/api/#03-apidocs/typealiasaxmodelusage); \}\> |

## Returns

`Promise`\<`T` \| `ReadableStream`\<`T`\>\>



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxRerankerIn.md
================================================
---
title: AxRerankerIn
---

```ts
type AxRerankerIn = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L8

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="items"></a> `items` | `string`[] |
| <a id="query"></a> `query` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxRerankerOut.md
================================================
---
title: AxRerankerOut
---

```ts
type AxRerankerOut = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L9

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="rankedItems"></a> `rankedItems` | `string`[] |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxRewriteIn.md
================================================
---
title: AxRewriteIn
---

```ts
type AxRewriteIn = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L5

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="query"></a> `query` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxRewriteOut.md
================================================
---
title: AxRewriteOut
---

```ts
type AxRewriteOut = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/docs/manager.ts#L6

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="rewrittenQuery"></a> `rewrittenQuery` | `string` |



================================================
FILE: src/docs/src/content/docs/03-apidocs/TypeAlias.AxTokenUsage.md
================================================
---
title: AxTokenUsage
---

```ts
type AxTokenUsage = object;
```

Defined in: https://github.com/ax-llm/ax/blob/5d189b5efb1a6d8f9665c1966845f7a5ac21c3f1/src/ax/ai/types.ts#L33

## Type declaration

| Name | Type |
| :------ | :------ |
| <a id="completionTokens"></a> `completionTokens` | `number` |
| <a id="promptTokens"></a> `promptTokens` | `number` |
| <a id="thoughtsTokens"></a> `thoughtsTokens`? | `number` |
| <a id="totalTokens"></a> `totalTokens` | `number` |



================================================
FILE: src/docs/src/pages/api.astro
================================================
---
// src/pages/api.astro
import { getCollection } from 'astro:content'
import Navigation from '../components/Navigation.astro'
import Header from '../components/Header.astro'
import Footer from '../components/Footer.astro'
import '../styles/shared.css'

function getOrderFromPath(path: string): number[] {
  // Split path into segments
  const segments = path.split('/')

  // Map each segment to its order number
  return segments.map((segment) => {
    // Extract number from start of segment (e.g., "01-introduction" => 1)
    const match = segment.match(/^(\d+)-/)
    // If there's no match or no capture group, return a high number
    if (!match || !match[1]) {
      return Number.MAX_SAFE_INTEGER
    }
    return parseInt(match[1], 10)
  })
}

function compareOrderedPaths(a: string, b: string): number {
  const aOrders = getOrderFromPath(a)
  const bOrders = getOrderFromPath(b)

  // Compare each segment's order number
  const minLength = Math.min(aOrders.length, bOrders.length)

  for (let i = 0; i < minLength; i++) {
    const aOrder = aOrders[i] ?? Number.MAX_SAFE_INTEGER
    const bOrder = bOrders[i] ?? Number.MAX_SAFE_INTEGER

    if (aOrder !== bOrder) {
      return aOrder - bOrder
    }
  }

  // If all segments match, shorter paths come first
  return aOrders.length - bOrders.length
}

// Get all markdown files from content/docs
const allDocs = await getCollection('docs')

// Sort by the number prefix in filename
const sortedDocs = allDocs.sort((a, b) => compareOrderedPaths(a.slug, b.slug))

// Render all markdown content
const renderedDocs = await Promise.all(
  sortedDocs
    .filter((doc) => doc.filePath?.includes('apidocs'))
    .map(async (doc) => {
      const { Content } = await doc.render()
      return { ...doc, Content }
    })
)
---

<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>API Documentation</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
  </head>

  <body>
    <Navigation />
    <div class="container">
      <Header />

      <!-- Main Content - Rendered Markdown Sections -->
      <main class="prose">
        {
          renderedDocs.map(({ Content, slug, data }) => (
            <section id={slug} class="api-section">
              <h2>{data.title}</h2>
              {data.description && (
                <p class="description">{data.description}</p>
              )}
              <div class="prose">
                <Content />
              </div>
            </section>
          ))
        }
      </main>

      <Footer />
    </div>
  </body>
</html>



================================================
FILE: src/docs/src/pages/index.astro
================================================
---
// src/pages/index.astro
import fs from 'fs'
import path from 'path'
import { marked } from 'marked'
import Navigation from '../components/Navigation.astro'
import Header from '../components/Header.astro'
import Footer from '../components/Footer.astro'
import '../styles/shared.css'

// Read README.md from the root of the project
const readmePath = path.join(process.cwd(), '..', '..', 'README.md')
const readmeRawContent = fs.readFileSync(readmePath, 'utf-8')

// Strip content above <!-- header --> comment
const headerIndex = readmeRawContent.indexOf('<!-- header -->')
const readmeContent =
  headerIndex !== -1
    ? readmeRawContent.substring(headerIndex)
    : readmeRawContent

// Parse markdown to HTML
const htmlContent = marked(readmeContent)
---

<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Ax Documentation</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
  </head>

  <body>
    <Navigation />
    <div class="container">
      <Header />

      <!-- Main Content from README.md -->
      <main class="prose">
        <Fragment set:html={htmlContent} />
      </main>

      <Footer />
    </div>
  </body>
</html>



================================================
FILE: src/docs/src/pages/optimize.astro
================================================
---
// src/pages/optimize.astro
import fs from 'fs'
import path from 'path'
import { marked } from 'marked'
import Navigation from '../components/Navigation.astro'
import Header from '../components/Header.astro'
import Footer from '../components/Footer.astro'
import '../styles/shared.css'

// Read OPTIMIZE.md from the root of the project
const optimizePath = path.join(process.cwd(), '..', '..', 'OPTIMIZE.md')
const optimizeRawContent = fs.readFileSync(optimizePath, 'utf-8')

// Parse markdown to HTML
const htmlContent = marked(optimizeRawContent)
---

<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Ax Optimization Guide</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
  </head>

  <body>
    <Navigation />
    <div class="container">
      <Header />

      <!-- Main Content from OPTIMIZE.md -->
      <main class="prose">
        <Fragment set:html={htmlContent} />
      </main>

      <Footer />
    </div>
  </body>
</html> 


================================================
FILE: src/docs/src/styles/custom.css
================================================
/* :root {
    --sl-font: 'JetBrains Mono Variable', serif;
} */

:root {
    font-size: 22px !important;

    --sl-font: 'Roboto', sans-serif;
}

/* Dark mode colors. */
:root {
	--sl-color-accent-low: rgb(0, 0, 0);
	--sl-color-accent: #000000;
	--sl-color-accent-high: #21c800;
	--sl-color-white: #ffffff;
	--sl-color-gray-1: #eceef2;
	--sl-color-gray-2: #c0c2c7;
	--sl-color-gray-3: #888b96;
	--sl-color-gray-4: #545861;
	--sl-color-gray-5: #353841;
	--sl-color-gray-6: #24272f;
	--sl-color-black: #17181c;
}
/* Light mode colors. */
:root[data-theme='light'] {
	--sl-color-accent-low: #96ff82;
	--sl-color-accent: #21c800;
	--sl-color-accent-high: #182775;
	--sl-color-white: #17181c;
	--sl-color-gray-1: #24272f;
	--sl-color-gray-2: #353841;
	--sl-color-gray-3: #545861;
	--sl-color-gray-4: #888b96;
	--sl-color-gray-5: #c0c2c7;
	--sl-color-gray-6: #eceef2;
	--sl-color-gray-7: #f5f6f8;
	--sl-color-black: #ffffff;
}


================================================
FILE: src/docs/src/styles/shared.css
================================================
/* Shared styles for documentation pages */

* {
    box-sizing: border-box;
    margin: 0;
    padding: 0;
}

body {
    font-family:
        'Inter',
        -apple-system,
        BlinkMacSystemFont,
        sans-serif;
    background: #ffffff;
    color: #1a1a1a;
    line-height: 1.6;
    font-size: 16px;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 0 24px;
}

@media (max-width: 768px) {
    .container {
        padding: 0 16px;
    }
}

/* Hide the first H1 from markdown content */
/* .prose h1:first-of-type,
main.prose > h1:first-child,
main.prose h1:first-of-type {
  display: none !important;
} */

/* Typography inspired by Humming design */
.prose h1 {
    font-size: 48px;
    font-weight: 700;
    line-height: 1.1;
    color: #000000;
    margin: 80px 0 24px 0;
    letter-spacing: -0.02em;
}

.prose h2 {
    font-size: 32px;
    font-weight: 600;
    line-height: 1.2;
    color: #000000;
    margin: 64px 0 16px 0;
    letter-spacing: -0.01em;
}

.prose h3 {
    font-size: 24px;
    font-weight: 600;
    line-height: 1.3;
    color: #000000;
    margin: 48px 0 12px 0;
}

.prose h4,
.prose h5,
.prose h6 {
    font-size: 18px;
    font-weight: 600;
    line-height: 1.4;
    color: #000000;
    margin: 32px 0 8px 0;
}

.prose p {
    font-size: 16px;
    line-height: 1.7;
    color: #4a4a4a;
    margin: 16px 0;
    max-width: 720px;
}

.prose ul,
.prose ol {
    margin: 24px 0;
    padding-left: 24px;
    max-width: 720px;
}

.prose li {
    margin: 8px 0;
    color: #4a4a4a;
    line-height: 1.6;
}

.prose li>ul,
.prose li>ol {
    margin: 8px 0;
}

/* Links */
.prose a {
    color: #0066cc;
    text-decoration: none;
    border-bottom: 1px solid transparent;
    transition: all 0.2s ease;
}

.prose a:hover {
    border-bottom-color: #0066cc;
}

/* Code styles */
.prose code {
    font-family:
        'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas,
        'Courier New', monospace;
    background: #f8f9fa;
    padding: 2px 6px;
    border-radius: 4px;
    font-size: 14px;
    color: #e83e8c;
    border: 1px solid #e9ecef;
}

.prose pre {
    background: #f8f9fa;
    border: 1px solid #e9ecef;
    border-radius: 8px;
    padding: 24px;
    margin: 32px 0;
    overflow-x: auto;
    font-family:
        'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas,
        'Courier New', monospace;
    font-size: 14px;
    line-height: 1.5;
}

.prose pre code {
    background: none;
    border: none;
    padding: 0;
    color: #24292f;
    font-size: inherit;
}

/* Tables */
.prose table {
    width: 100%;
    border-collapse: collapse;
    margin: 32px 0;
    border: 1px solid #e9ecef;
    border-radius: 8px;
    overflow: hidden;
}

.prose th {
    background: #f8f9fa;
    padding: 16px;
    text-align: left;
    font-weight: 600;
    color: #1a1a1a;
    border-bottom: 1px solid #e9ecef;
    font-size: 14px;
}

.prose td {
    padding: 16px;
    border-bottom: 1px solid #f1f3f4;
    color: #4a4a4a;
    font-size: 14px;
    vertical-align: top;
}

.prose tr:last-child td {
    border-bottom: none;
}

/* Images */
.prose img {
    max-width: 100%;
    height: auto;
    border-radius: 8px;
    margin: 32px 0;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
}

/* Badges */
.prose img[src*='shields.io'],
.prose img[src*='badge'],
.prose img[src*='dcbadge'] {
    display: inline;
    margin: 0 4px;
    vertical-align: middle;
    box-shadow: none;
    border-radius: 4px;
}

/* Blockquotes */
.prose blockquote {
    border-left: 4px solid #e9ecef;
    margin: 32px 0;
    padding: 16px 24px;
    background: #f8f9fa;
    border-radius: 0 8px 8px 0;
    font-style: italic;
    color: #6c757d;
}

/* Horizontal rules */
.prose hr {
    border: none;
    border-top: 1px solid #e9ecef;
    margin: 64px 0;
}

/* API Documentation specific styles */
.api-section {
    border-radius: 12px;
    padding: 32px;
    margin: 32px 0;
}

.api-section h2 {
    font-size: 24px;
    font-weight: 600;
    color: #000000;
    margin: 0 0 16px 0;
    display: flex;
    align-items: center;
    gap: 8px;
}

.api-section h2::before {
    content: '>';
    color: #0066cc;
    font-weight: 700;
}

.api-section .description {
    color: #6c757d;
    font-size: 14px;
    margin-bottom: 24px;
    font-style: italic;
}

/* Mobile responsive */
@media (max-width: 768px) {
    .prose h1 {
        font-size: 36px;
        margin: 48px 0 16px 0;
    }

    .prose h2 {
        font-size: 28px;
        margin: 40px 0 12px 0;
    }

    .prose h3 {
        font-size: 22px;
        margin: 32px 0 8px 0;
    }

    .prose p,
    .prose ul,
    .prose ol {
        font-size: 15px;
    }

    .prose pre {
        padding: 16px;
        margin: 24px 0;
        border-radius: 6px;
    }

    .prose table {
        font-size: 13px;
    }

    .prose th,
    .prose td {
        padding: 12px 8px;
    }

    .api-section {
        padding: 24px 16px;
        margin: 24px 0;
    }
}

@media (max-width: 480px) {

    .prose table,
    .prose thead,
    .prose tbody,
    .prose th,
    .prose td,
    .prose tr {
        display: block;
    }

    .prose thead tr {
        position: absolute;
        top: -9999px;
        left: -9999px;
    }

    .prose tr {
        border: 1px solid #e9ecef;
        margin-bottom: 16px;
        padding: 16px;
        border-radius: 8px;
        background: #f8f9fa;
    }

    .prose td {
        border: none;
        position: relative;
        padding-left: 40%;
        padding-top: 8px;
        padding-bottom: 8px;
    }

    .prose td:before {
        content: attr(data-label) ': ';
        position: absolute;
        left: 6px;
        width: 35%;
        font-weight: 600;
        color: #1a1a1a;
    }
}


================================================
FILE: src/docs/.vscode/extensions.json
================================================
{
  "recommendations": ["astro-build.astro-vscode"],
  "unwantedRecommendations": []
}



================================================
FILE: src/docs/.vscode/launch.json
================================================
{
  "version": "0.2.0",
  "configurations": [
    {
      "command": "./node_modules/.bin/astro dev",
      "name": "Development server",
      "request": "launch",
      "type": "node-terminal"
    }
  ]
}



================================================
FILE: src/examples/abort-patterns.ts
================================================
#!/usr/bin/env tsx

/**
 * Comprehensive example demonstrating various abort patterns with AbortController
 * Shows best practices for different use cases
 */

import { AxAI, AxAIServiceAbortedError } from '@ax-llm/ax'

async function basicAbortPattern() {
  console.log('\n🚨 Basic Abort Pattern')
  console.log('=====================================')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  // Start a request
  const requestPromise = ai.chat(
    {
      chatPrompt: [
        {
          role: 'user',
          content: 'Write a detailed essay about artificial intelligence.',
        },
      ],
    },
    {
      abortSignal: abortController.signal,
    }
  )

  // Simulate user cancellation after 2 seconds
  setTimeout(() => {
    console.log('🛑 User clicked cancel - aborting request...')
    abortController.abort('User cancelled the request')
  }, 2000)

  try {
    const response = await requestPromise
    if (response instanceof ReadableStream) {
      console.log('✅ Stream response received')
    } else {
      console.log(
        '✅ Response received:',
        response.results[0]?.content?.slice(0, 100) + '...'
      )
    }
  } catch (error) {
    if (error instanceof AxAIServiceAbortedError) {
      console.log('❌ Request was aborted:', error.message)
      console.log('📝 Abort reason:', error.context.abortReason)
    } else {
      console.log('❌ Other error:', error)
    }
  }
}

async function timeoutAbortPattern() {
  console.log('\n⏰ Timeout Abort Pattern')
  console.log('=====================================')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  // Set up automatic timeout
  const timeoutMs = 3000
  const timeoutId = setTimeout(() => {
    console.log(`⏰ Request timed out after ${timeoutMs}ms`)
    abortController.abort(`Request timeout after ${timeoutMs}ms`)
  }, timeoutMs)

  const requestPromise = ai.chat(
    {
      chatPrompt: [
        { role: 'user', content: 'Explain quantum computing in simple terms.' },
      ],
    },
    {
      abortSignal: abortController.signal,
    }
  )

  try {
    const response = await requestPromise
    clearTimeout(timeoutId) // Important: clear timeout on success
    if (response instanceof ReadableStream) {
      console.log('✅ Stream response received within timeout')
    } else {
      console.log(
        '✅ Response received within timeout:',
        response.results[0]?.content?.slice(0, 100) + '...'
      )
    }
  } catch (error) {
    clearTimeout(timeoutId) // Important: always clean up
    if (error instanceof AxAIServiceAbortedError) {
      console.log('❌ Request timed out:', error.message)
    } else {
      console.log('❌ Other error:', error)
    }
  }
}

async function multipleRequestsPattern() {
  console.log('\n🔄 Multiple Requests Pattern')
  console.log('=====================================')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  // Start multiple related requests
  const requests = [
    ai.chat(
      {
        chatPrompt: [{ role: 'user', content: 'What is machine learning?' }],
      },
      { abortSignal: abortController.signal }
    ),

    ai.chat(
      {
        chatPrompt: [{ role: 'user', content: 'What is deep learning?' }],
      },
      { abortSignal: abortController.signal }
    ),

    ai.embed(
      {
        texts: ['Machine learning overview', 'Deep learning concepts'],
      },
      { abortSignal: abortController.signal }
    ),
  ]

  // Abort all requests after 4 seconds
  setTimeout(() => {
    console.log('🛑 Aborting all batch requests...')
    abortController.abort('Batch operation cancelled')
  }, 4000)

  // Handle all requests with Promise.allSettled
  const results = await Promise.allSettled(requests)

  results.forEach((result, index) => {
    const requestType = index < 2 ? 'Chat' : 'Embed'
    if (result.status === 'fulfilled') {
      console.log(`✅ ${requestType} request ${index + 1} completed`)
    } else {
      console.log(
        `❌ ${requestType} request ${index + 1} failed:`,
        result.reason.message
      )
    }
  })
}

async function streamingAbortPattern() {
  console.log('\n🌊 Streaming Abort Pattern')
  console.log('=====================================')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  try {
    const stream = await ai.chat(
      {
        chatPrompt: [
          { role: 'user', content: 'Tell me a story about space exploration.' },
        ],
      },
      {
        stream: true,
        abortSignal: abortController.signal,
      }
    )

    // Abort streaming after 3 seconds
    const timeoutId = setTimeout(() => {
      console.log('🛑 Aborting stream after 3 seconds...')
      abortController.abort('Stream timeout')
    }, 3000)

    if (stream instanceof ReadableStream) {
      const reader = stream.getReader()
      let chunkCount = 0

      try {
        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          chunkCount++
          const content = value.results[0]?.content || ''
          console.log(`📦 Chunk ${chunkCount}:`, content.slice(0, 50) + '...')
        }
        clearTimeout(timeoutId)
        console.log('✅ Stream completed naturally')
      } catch {
        console.log('❌ Stream was aborted after', chunkCount, 'chunks')
      } finally {
        clearTimeout(timeoutId)
        reader.releaseLock()
      }
    }
  } catch (error) {
    if (error instanceof AxAIServiceAbortedError) {
      console.log('❌ Stream request failed to start:', error.message)
    }
  }
}

async function eventHandlerPattern() {
  console.log('\n📡 Event Handler Pattern')
  console.log('=====================================')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  // Set up abort event listeners
  abortController.signal.addEventListener('abort', () => {
    console.log('🔔 Abort event fired!')
    console.log('📝 Reason:', abortController.signal.reason)
    console.log('🧹 Cleaning up resources...')
    // Here you would clean up any resources, update UI, etc.
  })

  const requestPromise = ai.chat(
    {
      chatPrompt: [{ role: 'user', content: 'Explain the concept of time.' }],
    },
    {
      abortSignal: abortController.signal,
    }
  )

  // Check if already aborted before starting
  if (abortController.signal.aborted) {
    console.log('❌ Already aborted, not starting request')
    return
  }

  // Trigger abort after 2.5 seconds
  setTimeout(() => {
    abortController.abort('Event handler demo completed')
  }, 2500)

  try {
    const response = await requestPromise
    if (response instanceof ReadableStream) {
      console.log('✅ Stream response received')
    } else {
      console.log(
        '✅ Response received:',
        response.results[0]?.content?.slice(0, 100) + '...'
      )
    }
  } catch (error) {
    if (error instanceof AxAIServiceAbortedError) {
      console.log('❌ Request was aborted through event handler')
    }
  }
}

async function conditionalAbortPattern() {
  console.log('\n🎯 Conditional Abort Pattern')
  console.log('=====================================')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()
  let responseStarted = false

  // Start request
  const requestPromise = ai
    .chat(
      {
        chatPrompt: [
          { role: 'user', content: 'Write a short poem about coding.' },
        ],
      },
      {
        abortSignal: abortController.signal,
      }
    )
    .then((response) => {
      responseStarted = true
      return response
    })

  // Conditional abort logic
  setTimeout(() => {
    if (!responseStarted) {
      console.log('🛑 Request taking too long, aborting...')
      abortController.abort('Conditional timeout - no response started')
    } else {
      console.log('✅ Response already started, letting it complete')
    }
  }, 2000)

  try {
    const response = await requestPromise
    if (response instanceof ReadableStream) {
      console.log('✅ Stream response received')
    } else {
      console.log(
        '✅ Response received:',
        response.results[0]?.content?.slice(0, 100) + '...'
      )
    }
  } catch (error) {
    if (error instanceof AxAIServiceAbortedError) {
      console.log('❌ Request was conditionally aborted:', error.message)
    }
  }
}

// Utility function for racing promises against abort
async function raceWithAbort<T>(
  requestPromise: Promise<T>,
  abortSignal: AbortSignal
): Promise<T> {
  if (abortSignal.aborted) {
    throw new Error(
      `Request aborted: ${abortSignal.reason || 'Unknown reason'}`
    )
  }

  return new Promise<T>((resolve, reject) => {
    const abortHandler = () => {
      reject(
        new Error(`Request aborted: ${abortSignal.reason || 'Unknown reason'}`)
      )
    }

    abortSignal.addEventListener('abort', abortHandler, { once: true })

    requestPromise
      .then((result) => {
        abortSignal.removeEventListener('abort', abortHandler)
        resolve(result)
      })
      .catch((error) => {
        abortSignal.removeEventListener('abort', abortHandler)
        reject(error)
      })
  })
}

async function utilityRacePattern() {
  console.log('\n🏁 Utility Race Pattern')
  console.log('=====================================')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  // Use the utility function to race against abort
  const requestPromise = ai.chat({
    chatPrompt: [{ role: 'user', content: 'What is the meaning of life?' }],
  })

  // Abort after 2 seconds
  setTimeout(() => {
    console.log('🛑 Racing timeout reached, aborting...')
    abortController.abort('Race timeout')
  }, 2000)

  try {
    const response = await raceWithAbort(requestPromise, abortController.signal)
    if (response instanceof ReadableStream) {
      console.log('✅ Stream response won the race')
    } else {
      console.log(
        '✅ Response won the race:',
        response.results[0]?.content?.slice(0, 100) + '...'
      )
    }
  } catch (error) {
    console.log('❌ Abort won the race:', (error as Error).message)
  }
}

// Main execution
async function main() {
  console.log('🚀 Ax Abort Patterns Demo')
  console.log('Demonstrating various AbortController patterns with Ax')
  console.log('Note: Using demo mode if no OpenAI API key is provided\n')

  try {
    await basicAbortPattern()
    await timeoutAbortPattern()
    await multipleRequestsPattern()
    await streamingAbortPattern()
    await eventHandlerPattern()
    await conditionalAbortPattern()
    await utilityRacePattern()
  } catch (error) {
    console.error('❌ Demo execution failed:', error)
  }

  console.log('\n✅ All abort pattern demos completed!')
  console.log('\n📚 Key takeaways:')
  console.log('• Use AbortController directly for maximum flexibility')
  console.log('• Always clean up timeouts to prevent memory leaks')
  console.log('• Use Promise.allSettled for multiple abortable requests')
  console.log('• Set up abort event listeners for resource cleanup')
  console.log('• Check signal.aborted before starting operations')
  console.log('• Implement custom racing utilities when needed')
}

if (import.meta.url.endsWith(process.argv[1] ?? '')) {
  main().catch(console.error)
}



================================================
FILE: src/examples/abort-simple.ts
================================================
#!/usr/bin/env tsx

/**
 * Simple example demonstrating request abortion in Ax using AbortController
 */

import { AxAI } from '@ax-llm/ax'

async function basicAbortExample() {
  console.log('\n=== Basic Abort Example ===')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  // Start a chat request with abort support
  const requestPromise = ai.chat(
    {
      chatPrompt: [
        {
          role: 'user',
          content: 'Tell me a very long story about space exploration.',
        },
      ],
    },
    {
      abortSignal: abortController.signal,
    }
  )

  // Abort after 2 seconds
  setTimeout(() => {
    console.log('Aborting request...')
    abortController.abort('Request took too long')
  }, 2000)

  try {
    const response = await requestPromise
    console.log('Response received:', response)
  } catch (error) {
    console.log('✅ Request was aborted:', (error as Error).message)
  }
}

async function timeoutAbortExample() {
  console.log('\n=== Timeout Abort Example ===')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  // Create a timeout that automatically aborts
  const timeoutMs = 1500
  const timeoutId = setTimeout(() => {
    console.log(`Aborting after ${timeoutMs}ms timeout...`)
    abortController.abort(`Request timeout after ${timeoutMs}ms`)
  }, timeoutMs)

  // Start a request
  const requestPromise = ai.chat(
    {
      chatPrompt: [
        { role: 'user', content: 'Explain quantum computing in detail.' },
      ],
    },
    {
      abortSignal: abortController.signal,
    }
  )

  try {
    const response = await requestPromise
    clearTimeout(timeoutId) // Clear timeout if request completes
    console.log('Response received:', response)
  } catch (error) {
    clearTimeout(timeoutId) // Clean up timeout
    console.log('✅ Request was aborted:', (error as Error).message)
  }
}

async function embedAbortExample() {
  console.log('\n=== Embed Abort Example ===')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  // Start an embed request with abort support
  const embedPromise = ai.embed(
    {
      texts: ['This is a text to embed', 'Another text to embed'],
    },
    {
      abortSignal: abortController.signal,
    }
  )

  // Abort after 1 second
  setTimeout(() => {
    console.log('Aborting embed request...')
    abortController.abort('Embed took too long')
  }, 1000)

  try {
    const embedResponse = await embedPromise
    console.log(
      'Embed response received:',
      embedResponse.embeddings.length,
      'embeddings'
    )
  } catch (error) {
    console.log('✅ Embed request was aborted:', (error as Error).message)
  }
}

async function multipleRequestsExample() {
  console.log('\n=== Multiple Requests with Shared AbortController ===')

  const ai = new AxAI({
    name: 'openai',
    apiKey: process.env.OPENAI_APIKEY || 'demo',
  })

  const abortController = new AbortController()

  // Start multiple requests that share the same abort controller
  const requests = [
    ai.chat(
      {
        chatPrompt: [{ role: 'user', content: 'What is machine learning?' }],
      },
      { abortSignal: abortController.signal }
    ),

    ai.chat(
      {
        chatPrompt: [{ role: 'user', content: 'What is deep learning?' }],
      },
      { abortSignal: abortController.signal }
    ),

    ai.embed(
      {
        texts: ['Machine learning', 'Deep learning'],
      },
      { abortSignal: abortController.signal }
    ),
  ]

  // Abort all requests after 2 seconds
  setTimeout(() => {
    console.log('Aborting all requests...')
    abortController.abort('Batch abort after timeout')
  }, 2000)

  // Handle all requests
  const results = await Promise.allSettled(requests)

  results.forEach((result, index) => {
    if (result.status === 'fulfilled') {
      console.log(`✅ Request ${index + 1} completed`)
    } else {
      console.log(`❌ Request ${index + 1} failed:`, result.reason.message)
    }
  })
}

// Main execution
async function main() {
  console.log('🚀 Ax Request Abortion Examples')
  console.log('Note: These examples use demo mode if no API key is provided')

  try {
    await basicAbortExample()
    await timeoutAbortExample()
    await embedAbortExample()
    await multipleRequestsExample()
  } catch (error) {
    console.error('Example execution failed:', error)
  }

  console.log('\n✅ All abort examples completed!')
  console.log('\nKey patterns demonstrated:')
  console.log('• Use AbortController directly for simple cases')
  console.log('• Combine with setTimeout for timeout-based abortion')
  console.log('• Share AbortController across multiple requests')
  console.log('• Always clean up timeouts to prevent memory leaks')
  console.log(
    '• Use Promise.allSettled for handling multiple abortable requests'
  )
}

if (import.meta.url.endsWith(process.argv[1] ?? '')) {
  main().catch(console.error)
}



================================================
FILE: src/examples/agent.ts
================================================
import { AxAgent, AxAI, AxAIOpenAIModel } from '@ax-llm/ax'

const researcher = new AxAgent({
  name: 'Physics Researcher',
  description:
    'Researcher for physics questions can answer questions about advanced physics',
  signature: `question, physicsQuestion "physics questions" -> answer "reply in bullet points"`,
})

const summarizer = new AxAgent({
  name: 'Science Summarizer',
  description:
    'Summarizer can write short summaries of advanced science topics',
  definition:
    'You are a science summarizer. You can write short summaries of advanced science topics. Use numbered bullet points to summarize the answer in order of importance.',
  signature: `answer "bullet points to summarize" -> shortSummary "summarize in 10 to 20 words"`,
})

const agent = new AxAgent({
  name: 'Scientist',
  description: 'An agent that can answer advanced science questions',
  signature: 'question -> answer',
  agents: [researcher, summarizer],
})

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
  models: [
    {
      key: 'dumb',
      model: AxAIOpenAIModel.GPT35Turbo,
      description: 'Use the dumb model for very simple questions',
    },
    {
      key: 'smart',
      model: AxAIOpenAIModel.GPT4OMini,
      description: 'Use the smart model for advanced questions',
    },
    {
      key: 'smartest',
      model: AxAIOpenAIModel.GPT4O,
      description: 'Use the smartest model for the most advanced questions',
    },
  ],
})
ai.setOptions({ debug: true })

// const ai = new AxAI({
//   name: 'google-gemini',
//   apiKey: process.env.GOOGLE_APIKEY as string
// });

// const ai = new AxAI({
//   name: 'groq',
//   apiKey: process.env.GROQ_APIKEY as string
// });

// const question = `What is a cat?`
const question = 'Why is gravity not a real force?'

const res = await agent.forward(ai, { question })
console.log('>', res)



================================================
FILE: src/examples/ax-template.ts
================================================
import { ax, AxAI, AxGen, f } from '@ax-llm/ax'

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

console.log('=== Ax Tagged Template Literals Demo ===\n')

// Example 1: Basic AxGen creation
console.log('1. Basic AxGen creation:')
const basicGen = ax`userQuestion:string -> responseText:string`
console.log('Created AxGen with signature:', basicGen.getSignature().toString())
console.log()

// Example 2: Using field builders with AxGen
console.log('2. Using field builders with AxGen:')
const sentimentGen = ax`
  inputText:${f.string('Text to analyze')} -> 
  sentiment:${f.class(['positive', 'negative', 'neutral'], 'Sentiment classification')},
  confidence:${f.number('Confidence score 0-1')}
`
console.log(
  'Sentiment AxGen signature:',
  sentimentGen.getSignature().toString()
)
console.log()

// Example 3: Complex AxGen with arrays and modifiers
console.log('3. Complex AxGen with arrays and modifiers:')
const complexGen = ax`
  "Extract structured information from customer feedback"
  customerFeedback:${f.string('Customer feedback text')} ->
  topics:${f.array(f.string())},
  urgency:${f.class(['low', 'medium', 'high'])},
  actionItems:${f.array(f.string())},
  reasoning:${f.internal(f.string('Internal reasoning process'))},
  followUpRequired:${f.optional(f.boolean('Whether follow-up is needed'))}
`
console.log('Complex AxGen signature:', complexGen.getSignature().toString())
console.log('Description:', complexGen.getSignature().getDescription())
console.log()

// Example 4: Direct usage with AI - sentiment analysis
console.log('4. Direct usage with AI - sentiment analysis:')
try {
  const result = await sentimentGen.forward(ai, {
    inputText:
      'I absolutely love this new product! It works perfectly and saved me so much time.',
  })

  console.log('Sentiment analysis result:')
  console.log('- Sentiment:', result.sentiment)
  console.log('- Confidence:', result.confidence)
} catch {
  console.log('Sentiment analysis (simulated):', {
    sentiment: 'positive',
    confidence: 0.95,
  })
}
console.log()

// Example 5: Comparison with traditional AxGen constructor
console.log('5. Comparison with traditional AxGen constructor:')
const traditionalGen = new AxGen(
  'userQuestion:string -> responseText:string, confidenceScore:number'
)
const templateGen = ax`userQuestion:string -> responseText:string, confidenceScore:number`

console.log(
  'Traditional constructor signature:',
  traditionalGen.getSignature().toString()
)
console.log(
  'Template literal signature:',
  templateGen.getSignature().toString()
)
console.log(
  'Are equivalent:',
  traditionalGen.getSignature().toString() ===
    templateGen.getSignature().toString()
)
console.log()

// Example 6: Code generation AxGen
console.log('6. Code generation AxGen:')
const codeGen = ax`
  problemDescription:${f.string('Programming problem description')} ->
  pythonSolution:${f.code('python', 'Python code solution')},
  solutionExplanation:${f.string('Explanation of the solution')},
  timeComplexity:${f.class(['O(1)', 'O(log n)', 'O(n)', 'O(n log n)', 'O(n²)'], 'Time complexity')}
`
console.log(
  'Code generation AxGen signature:',
  codeGen.getSignature().toString()
)
console.log()

console.log('=== Ax Tagged Template Literals Demo Complete ===')
console.log('')
console.log('Usage examples:')
console.log('- const gen = ax`userQuery:string -> responseText:string`')
console.log(
  '- const gen = ax`inputText:${f.string("Input")} -> categoryType:${f.class(["A", "B"])}`'
)
console.log('- const result = await gen.forward(ai, { userInput: "test" })')



================================================
FILE: src/examples/balancer.ts
================================================
import {
  AxAI,
  AxAIAnthropicModel,
  AxAIOpenAIModel,
  AxBalancer,
  AxChainOfThought,
} from '@ax-llm/ax'

const textToSummarize = `The technological singularity—or simply the singularity[1]—is a hypothetical future point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization.[2][3] According to the most popular version of the singularity hypothesis, I.J. Good's intelligence explosion model, an upgradable intelligent agent will eventually enter a "runaway reaction" of self-improvement cycles, each new and more intelligent generation appearing more and more rapidly, causing an "explosion" in intelligence and resulting in a powerful superintelligence that qualitatively far surpasses all human intelligence.[4]`

// models and embedModelList allows you to use common names for models across different AI services
// is works without the balancer as well.

const ai1 = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
  models: [
    {
      key: 'chill',
      model: AxAIOpenAIModel.GPT4OMini,
      description: 'A model that is good for simple tasks',
    },
    {
      key: 'genius',
      model: AxAIOpenAIModel.GPT4Turbo,
      description: 'A model that is good for more complex tasks',
    },
  ],
})

const ai2 = new AxAI({
  name: 'anthropic',
  apiKey: process.env.ANTHROPIC_APIKEY as string,
  models: [
    {
      key: 'chill',
      model: AxAIAnthropicModel.Claude3Haiku,
      description: 'A model that is good for simple tasks',
    },
    {
      key: 'genius',
      model: AxAIAnthropicModel.Claude35Sonnet,
      description: 'A model that is good for more complex tasks',
    },
  ],
})

const gen = new AxChainOfThought<{ textToSummarize: string }>(
  `textToSummarize -> shortSummary "summarize in 5 to 10 words"`
)

const ai = new AxBalancer([ai1, ai2])
const res = await gen.forward(ai, { textToSummarize }, { model: 'chill' })
console.log('>', res)



================================================
FILE: src/examples/chain-of-thought.ts
================================================
import { AxAI, AxChainOfThought } from '@ax-llm/ax'

const cot = new AxChainOfThought(
  `
  context:string[] "Information to answer the question",
  question:string
  ->
  answer:string[]`
)

const values = {
  question: 'What is the capital of France?',
  context: [
    'Paris is the capital and most populous city of France. Situated on the Seine River, in the north of the country, it is in the centre of the Île-de-France region, also known as the région parisienne, "Paris Region"',
    'France is a unitary semi-presidential republic with its capital in Paris, the countrys largest city and main cultural and commercial centre; other major ',
  ],
}

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

// const ai = new AxAI({
//   name: 'ollama',
//   config: { stream: false }
// });

// const ai = new AxAI({
//   name: 'google-gemini',
//   apiKey: process.env.GOOGLE_APIKEY as string,
//   config: { model: AxAIGoogleGeminiModel.Gemini15Flash8B, stream: false },
// })

ai.setOptions({ debug: true })

const res = await cot.forward(ai, values)
console.log(res)

console.log(ai.getMetrics())



================================================
FILE: src/examples/chat.ts
================================================
import {
  ax,
  AxAI,
  AxAIGoogleGeminiModel,
  type AxFunction,
  type AxMessage,
  f,
} from '@ax-llm/ax'

// Weather function for testing function calls
const getCurrentWeather = async (
  args: Readonly<{ location: string; units?: string }>
) => {
  // Simulate weather API call
  const weatherData = {
    tokyo: { temp: 22, condition: 'Sunny', humidity: 65 },
    'new york': { temp: 18, condition: 'Cloudy', humidity: 70 },
    london: { temp: 15, condition: 'Rainy', humidity: 85 },
    default: { temp: 20, condition: 'Pleasant', humidity: 60 },
  }

  const location = args.location.toLowerCase()
  const weather =
    weatherData[location as keyof typeof weatherData] || weatherData.default
  const unit = args.units === 'metric' ? '°C' : '°F'

  return `The weather in ${args.location} is ${weather.temp}${unit} and ${weather.condition} with ${weather.humidity}% humidity.`
}

// Define available functions
const functions: AxFunction[] = [
  {
    name: 'getCurrentWeather',
    description: 'Get current weather information for a specific location',
    parameters: {
      type: 'object',
      properties: {
        location: {
          type: 'string',
          description: 'The city or location to get weather for',
        },
        units: {
          type: 'string',
          enum: ['metric', 'imperial'],
          description:
            'Temperature units (metric for Celsius, imperial for Fahrenheit)',
        },
      },
      required: ['location'],
    },
    func: getCurrentWeather,
  },
]

// Initialize Gemini AI
const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string,
  config: {
    model: AxAIGoogleGeminiModel.Gemini25Flash,
  },
  options: {
    debug: true,
  },
})

// Create a chat assistant with function calling capability using modern template literals
const chatBot = ax`
  message:${f.string('A casual message from the user')} -> 
  reply:${f.string('A friendly, casual response that can include weather information when requested')}
`

console.log('🤖 Starting casual chat with Gemini (with function calling)...\n')

// Start a casual conversation
const chat: AxMessage<{ message: string }>[] = [
  {
    role: 'user',
    values: { message: 'Hi! How are you doing today?' },
  },
]

console.log('👤 User: Hi! How are you doing today?\n')

// Get first response
let response = await chatBot.forward(ai, chat, { functions })
console.log(`🤖 Bot: ${response.reply}\n`)

// Add response to chat history
chat.push({ role: 'assistant', values: { message: response.reply as string } })

// Test function calling with weather request
chat.push({
  role: 'user',
  values: {
    message: "That's great! What's the weather like in Tokyo right now?",
  },
})

console.log(
  "👤 User: That's great! What's the weather like in Tokyo right now?\n"
)

response = await chatBot.forward(ai, chat, {
  functions,
  functionCall: 'required',
})
console.log(`🤖 Bot: ${response.reply}\n`)

// Add response and continue
chat.push({ role: 'assistant', values: { message: response.reply as string } })

chat.push({
  role: 'user',
  values: {
    message:
      'How about the weather in New York? And can you tell me a fun fact?',
  },
})

console.log(
  '👤 User: How about the weather in New York? And can you tell me a fun fact?\n'
)

response = await chatBot.forward(ai, chat, {
  functions,
  functionCall: 'required',
})
console.log(`🤖 Bot: ${response.reply}\n`)



================================================
FILE: src/examples/checkpoint-recovery.ts
================================================
import {
  ax,
  AxAI,
  AxAIOpenAIModel,
  type AxCheckpointLoadFn,
  type AxCheckpointSaveFn,
  type AxMetricFn,
  AxMiPRO,
  type AxOptimizationCheckpoint,
  f,
} from '@ax-llm/ax'

// Example checkpoint functions for different storage systems
const createMemoryCheckpoint = () => {
  const storage = new Map<string, AxOptimizationCheckpoint>()

  const save: AxCheckpointSaveFn = async (checkpoint) => {
    const id = `checkpoint_${checkpoint.timestamp}_${checkpoint.optimizerType}`
    storage.set(id, checkpoint)
    console.log(`💾 Memory: Saved checkpoint ${id}`)
    return id
  }

  const load: AxCheckpointLoadFn = async (id) => {
    return storage.get(id) || null
  }

  const list = () => Array.from(storage.keys()).sort()
  const size = () => storage.size

  return { save, load, list, size }
}

// Example: localStorage checkpoint functions (for browsers)
// eslint-disable-next-line @typescript-eslint/no-unused-vars
const createBrowserCheckpoint = () => {
  const storageKey = 'ax-checkpoints'

  const save: AxCheckpointSaveFn = async (checkpoint) => {
    const id = `checkpoint_${checkpoint.timestamp}_${checkpoint.optimizerType}`
    const storage = JSON.parse(localStorage.getItem(storageKey) || '{}')
    storage[id] = checkpoint
    localStorage.setItem(storageKey, JSON.stringify(storage))
    console.log(`💾 Browser: Saved checkpoint ${id}`)
    return id
  }

  const load: AxCheckpointLoadFn = async (id) => {
    const storage = JSON.parse(localStorage.getItem(storageKey) || '{}')
    return storage[id] || null
  }

  return { save, load }
}

// Example: Mock database checkpoint functions
// eslint-disable-next-line @typescript-eslint/no-unused-vars
const createDatabaseCheckpoint = () => {
  // Mock database storage
  const mockDB = new Map<string, AxOptimizationCheckpoint>()

  const save: AxCheckpointSaveFn = async (checkpoint) => {
    const id = `checkpoint_${checkpoint.timestamp}_${checkpoint.optimizerType}`
    // In real implementation: await db.checkpoints.create({ id, data: checkpoint })
    mockDB.set(id, checkpoint)
    console.log(`💾 Database: Saved checkpoint ${id}`)
    return id
  }

  const load: AxCheckpointLoadFn = async (id) => {
    // In real implementation: const result = await db.checkpoints.findUnique({ where: { id } })
    return mockDB.get(id) || null
  }

  return { save, load }
}

// Simple sentiment analysis program
export const sentimentAnalyzer = ax`
  reviewText:${f.string('Customer review text')} -> 
  sentiment:${f.class(['positive', 'negative', 'neutral'], 'Overall sentiment')},
  confidence:${f.number('Confidence score 0-1')}
`

// Training examples
const examples = [
  {
    reviewText: 'I absolutely love this product!',
    sentiment: 'positive',
    confidence: 0.9,
  },
  {
    reviewText: 'This is terrible quality, waste of money',
    sentiment: 'negative',
    confidence: 0.8,
  },
  {
    reviewText: 'It works fine, nothing special',
    sentiment: 'neutral',
    confidence: 0.6,
  },
  {
    reviewText: 'Best purchase I ever made!',
    sentiment: 'positive',
    confidence: 0.95,
  },
  {
    reviewText: 'Completely useless, returned immediately',
    sentiment: 'negative',
    confidence: 0.9,
  },
  {
    reviewText: 'Average product, does what it says',
    sentiment: 'neutral',
    confidence: 0.7,
  },
  {
    reviewText: 'Exceeded my expectations, highly recommend!',
    sentiment: 'positive',
    confidence: 0.85,
  },
  {
    reviewText: 'Poor build quality, broke after one week',
    sentiment: 'negative',
    confidence: 0.8,
  },
]

// Metric function
const metric: AxMetricFn = ({ prediction, example }) => {
  let score = 0
  if (prediction.sentiment === example.sentiment) score += 0.7

  // Bonus for confidence alignment
  const predConfidence = prediction.confidence as number
  const expectedConfidence = example.confidence as number
  const confidenceDiff = Math.abs(predConfidence - expectedConfidence)
  if (confidenceDiff < 0.2) score += 0.3

  return score
}

// AI setup
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: {
    model: AxAIOpenAIModel.GPT4OMini,
    maxTokens: 200,
    temperature: 0.1,
  },
})

console.log('=== Simple Function-Based Checkpointing Demo ===')

// Demonstrate different checkpoint implementations
console.log('\n📦 Available checkpoint implementations:')
console.log('1. Memory storage (Map)')
console.log('2. Browser storage (localStorage)')
console.log('3. Database storage (mock)')

// Create checkpoint functions - choose your storage
const memoryCheckpoint = createMemoryCheckpoint()
// const browserCheckpoint = createBrowserCheckpoint()
// const databaseCheckpoint = createDatabaseCheckpoint()

// For this demo, we'll use memory storage
const {
  save: checkpointSave,
  load: checkpointLoad,
  list,
  size,
} = memoryCheckpoint

// Check for existing checkpoints
const existingCheckpoints = list()
console.log(`\nFound ${existingCheckpoints.length} existing checkpoints`)

let resumeFromCheckpoint: string | undefined

if (existingCheckpoints.length > 0) {
  // Find the most recent checkpoint
  const sortedCheckpoints = existingCheckpoints.sort().reverse()
  resumeFromCheckpoint = sortedCheckpoints[0]
  console.log(`Will resume from: ${resumeFromCheckpoint}`)

  // Load and display checkpoint info
  const checkpoint = await checkpointLoad(resumeFromCheckpoint!)
  if (checkpoint) {
    console.log(`Checkpoint details:`)
    console.log(
      `  - Round: ${checkpoint.currentRound}/${checkpoint.totalRounds}`
    )
    console.log(`  - Best Score: ${checkpoint.bestScore.toFixed(3)}`)
    console.log(
      `  - Timestamp: ${new Date(checkpoint.timestamp).toLocaleString()}`
    )
  }
} else {
  console.log('No existing checkpoints found, starting fresh optimization')
}

// Create optimizer with simple checkpoint functions
const optimizer = new AxMiPRO({
  studentAI: ai,
  examples,
  checkpointSave,
  checkpointLoad,
  checkpointInterval: 3, // Save every 3 rounds
  resumeFromCheckpoint, // Resume from checkpoint if available
  options: {
    numCandidates: 4,
    numTrials: 15, // Longer run to demonstrate checkpointing
    verbose: true,
    earlyStoppingTrials: 5,
  },
})

console.log('\nStarting optimization...')
console.log('💡 Tip: This shows how simple checkpoint functions can be!')

try {
  const result = await optimizer.compile(sentimentAnalyzer, metric, {
    verbose: true,
    saveCheckpointOnComplete: true, // Save final checkpoint
  })

  console.log(`\n✅ Optimization complete!`)
  console.log(`Final score: ${(result.bestScore * 100).toFixed(1)}%`)

  // Apply the optimized configuration
  if (result.demos) {
    sentimentAnalyzer.setDemos(result.demos)
  }

  // Test the optimized model
  console.log('\n🧪 Testing optimized model:')
  const testReviews = [
    'This product changed my life, absolutely incredible!',
    'Mediocre at best, nothing to write home about',
    'Worst purchase ever, complete garbage',
  ]

  for (const review of testReviews) {
    const analysis = await sentimentAnalyzer.forward(ai, { reviewText: review })
    console.log(`Review: "${review}"`)
    console.log(
      `Analysis: ${analysis.sentiment} (confidence: ${analysis.confidence})`
    )
    console.log('')
  }
} catch (error) {
  console.error('Optimization failed:', error)
  console.log("💡 Don't worry! Your progress has been saved in checkpoints.")
  console.log('You can restart this script to resume from the last checkpoint.')
}

// Show final stats
console.log(`\n📊 Final checkpoint stats:`)
console.log(`  - Total checkpoints: ${size()}`)
console.log(`  - Checkpoint IDs: ${list().join(', ')}`)

console.log('\n🎯 Key Takeaways:')
console.log('1. Just two simple functions: save and load')
console.log('2. Works with any storage: memory, localStorage, databases, cloud')
console.log('3. No complex interfaces or classes needed')
console.log('4. Easy to implement for your specific storage needs')
console.log('5. Checkpoints contain complete optimization state')

console.log('\n💡 Implementation Examples:')
console.log('- Memory: Map<string, checkpoint>')
console.log('- Browser: localStorage.setItem(id, JSON.stringify(checkpoint))')
console.log('- Database: await db.checkpoints.create({ id, data: checkpoint })')
console.log(
  '- Cloud: await s3.putObject({ Key: id, Body: JSON.stringify(checkpoint) })'
)
console.log(
  '- File: fs.writeFileSync(`${id}.json`, JSON.stringify(checkpoint))'
)



================================================
FILE: src/examples/customer-support.ts
================================================
import { AxAI, AxAIGoogleGeminiModel, AxGen } from '@ax-llm/ax'

const gen = new AxGen<
  {
    customerEmail: string
  },
  {
    productName: string
    issueDescription: string
    issueSummary: string
    paymentMethod: string
  }
>(
  `customerEmail:string  -> productName:string "The name of the product",
issueDescription:string "A description of the issue",
issueSummary:string "A summary of the issue",
paymentMethod:string "The method of payment"
`
)

const customerMessage = `
Hello Support Team,

I am writing to report an issue with my recent order #12345. I received the package yesterday, but unfortunately, the product that I paid for with cash (XYZ Smartwatch) is not functioning properly. When I tried to turn it on, the screen remained blank, and I couldn't get it to respond to any of the buttons.

I have already tried resetting the device multiple times, but the issue persists. I believe there may be a defect with the product, and I would like to request a replacement or refund. Please let me know what steps I should take to proceed with the return or exchange process. I have attached a copy of the order confirmation and shipping confirmation for your reference.

Thank you for your attention to this matter.

Best regards,
John Doe.
  `

// const ai = new AxAI({
//   name: 'openai',
//   apiKey: process.env.OPENAI_APIKEY as string
// });

const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string,
  config: { model: AxAIGoogleGeminiModel.Gemini15Flash8B },
})

ai.setOptions({ debug: true })

const res = await gen.forward(ai, { customerEmail: customerMessage })

console.log('Traces:\n', gen.getTraces())

console.log('Result:\n', res)



================================================
FILE: src/examples/debug-logging.ts
================================================
import { AxAI, AxChainOfThought, AxGen } from '@ax-llm/ax'

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

// 1. Basic debug logging (default colored output)
ai.setOptions({ debug: true })

const basicGen = new AxChainOfThought<
  { question: string },
  { answer: string; reasoning: string }
>(
  `question:string "A question to answer" -> 
   answer:string "The answer to the question",
   reasoning:string "Step by step reasoning"`
)

const basicResult = await basicGen.forward(ai, {
  question: 'What is the capital of Japan?',
})
console.log('Result:', basicResult)

// 2. Custom logger with timestamps
const timestampLogger = (message: string): void => {
  const timestamp = new Date().toISOString()
  process.stdout.write(`[${timestamp}] ${message}`)
}

const customGen = new AxGen<
  { textToClassify: string },
  { category: string; confidence: number }
>(
  `textToClassify:string "Text to classify" ->
   category:class "tech, business, sports, entertainment" "The category",
   confidence:number "Confidence score 0-1"`
)

const customResult = await customGen.forward(
  ai,
  { textToClassify: 'Apple announces new iPhone with AI features' },
  { logger: timestampLogger }
)
console.log('Result:', customResult)

// 3. Text-only logger (no colors)
const textLogger = (message: string): void => {
  process.stdout.write(message)
}

ai.setOptions({ debug: true, logger: textLogger })

const textGen = new AxChainOfThought<
  { problem: string },
  { solution: string; steps: string[] }
>(
  `problem:string "A problem to solve" ->
   solution:string "The solution",
   steps:string[] "List of solution steps"`
)

const textResult = await textGen.forward(ai, {
  problem: 'How to make a paper airplane?',
})
console.log('Result:', textResult)



================================================
FILE: src/examples/docker.ts
================================================
import { AxAI, AxDockerSession, AxGen } from '@ax-llm/ax'

// Initialize Docker session
const dockerSession = new AxDockerSession()

// Create a Docker container and execute the command sequence
await dockerSession.findOrCreateContainer({
  imageName: 'ubuntu:latest',
  tag: 'ax:example',
})

// Define the task for generating a command sequence
const prompt = new AxGen(
  `"Find requested file and display top 3 lines of its content and a hash of the file."
  fileQuery:string -> content:string, hash:string`,
  { functions: [dockerSession] }
)

// Initialize the AI instance with your API key
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})
ai.setOptions({
  debug: true,
})

// Execute the task
const res = await prompt.forward(ai, {
  fileQuery: 'config file for current shell',
})

console.log(res)

// await dockerSession.stopContainers({ remove: true, tag: 'ax:example' });



================================================
FILE: src/examples/dope-or-nope.ts
================================================
import fs from 'fs'

import {
  AxAI,
  AxBootstrapFewShot,
  AxChainOfThought,
  AxHFDataLoader,
  type AxMetricFn,
} from '@ax-llm/ax'

const hf = new AxHFDataLoader({
  dataset: 'llm-wizard/dope_or_nope_v2',
  split: 'train',
  config: 'default',
})

await hf.loadData()

const examples = await hf.getRows<{ question: string; answer: number }>({
  count: 5,
  fields: ['Sentence', 'Rating'],
  renameMap: { Sentence: 'question', Rating: 'answer' },
})

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

// Setup the program to tune
const program = new AxChainOfThought<{ question: string }, { answer: string }>(
  `question -> answer:number "numerical rating from 1 to 4"`
)

// use examples if you have separate examples and tuning data sets without overlap.
// program.setExamples(examples);

const optimize = new AxBootstrapFewShot<
  { question: string },
  { answer: string }
>({
  studentAI: ai,
  examples,
})

// Setup a evaluation metric em, f1 scores are a popular way measure retrieval performance.
const metricFn: AxMetricFn = ({ prediction, example }) => {
  return prediction.answer === example.answer ? 1 : 0
}

// Run the optimizer
const result = await optimize.compile(program, metricFn)

// save the resulting demonstrations to use later
const values = JSON.stringify(result, null, 2)
await fs.promises.writeFile('./dope-or-nope-demos.json', values)

console.log('> done. test with dope-or-nope.ts')



================================================
FILE: src/examples/embed.ts
================================================
import { AxAI } from '@ax-llm/ax'

// Initialize the AI service with your API key
const ai = new AxAI({
  name: 'openai', // You can use 'anthropic', 'google-gemini', etc.
  apiKey: process.env.OPENAI_APIKEY as string,
})

try {
  console.log('Generating embeddings for example text...')

  // Simple example: embedding a single string
  const result = await ai.embed({
    texts: ['This is a sample text to embed.'],
  })

  console.log('\nEmbedding results:')
  console.log(`- Number of embeddings: ${result.embeddings.length}`)

  // Check if we have a valid embedding
  if (result.embeddings.length > 0 && result.embeddings[0]) {
    const embedding = result.embeddings[0]
    console.log(`- Embedding dimensions: ${embedding.length}`)
    console.log(`- First few values: [${embedding.slice(0, 3).join(', ')}...]`)
  }

  // Display model usage information if available
  if (result.modelUsage) {
    console.log('\nModel usage information:')
    console.log(`- AI provider: ${result.modelUsage.ai}`)
    console.log(`- Model used: ${result.modelUsage.model}`)

    if (result.modelUsage.tokens) {
      console.log(`- Tokens used: ${JSON.stringify(result.modelUsage.tokens)}`)
    }
  }

  console.log('\nEmbeddings can be used for:')
  console.log('- Semantic search')
  console.log('- Document similarity comparison')
  console.log('- Clustering related content')
  console.log('- Building knowledge retrieval systems')
} catch (error) {
  console.error('Error generating embeddings:', error)
}



================================================
FILE: src/examples/extract-test.ts
================================================
import { AxAIGoogleGeminiModel, AxGen } from '@ax-llm/ax'
import { AxAI } from '@ax-llm/ax'

// Define the signature with the specific field names
const signature =
  'story:string -> intent:string, dogColors:string[], dogName:string, dogAge:string, dogBreed:string'

// Create the generator
const gen = new AxGen<
  { story: string },
  {
    intent: string
    dogColors: string[]
    dogName: string
    dogAge: string
    dogBreed: string
  }
>(signature)

// Create AI instance
const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string,
  config: { model: AxAIGoogleGeminiModel.Gemini15Flash8B },
})

// Test input
const input = {
  story:
    'Once upon a time, there was a dog named Luki. Luki was a golden retriever. Luki was 2 months old. The colors of his fur are golden, white and brown.',
}

// Run the test with streamingForward
console.log('Testing streamingForward with dog info fields...\n')

const generator = gen.streamingForward(ai, input)

try {
  for await (const res of generator) {
    console.log('Streaming delta:', res)
  }
} catch (error) {
  console.error('Error during streaming:', error)
}

try {
  const result = await gen.forward(ai, input)
  console.log('Result:', result)
} catch (error) {
  console.error('Error during forward:', error)
}



================================================
FILE: src/examples/extract.ts
================================================
import { AxAI, AxAIGoogleGeminiModel, AxGen } from '@ax-llm/ax'

const chatMessage = `Hello Mike, How are you set for a call tomorrow or Friday? I have a few things to discuss with you. Also the ticket number is 300. Let me know what time works best for you. Thanks!`

const currentDate = new Date()

// Example with OpenAI using custom labels in place of model names
// const ai = new AxAI({
//   name: 'openai',
//   apiKey: process.env.OPENAI_APIKEY as string,
//   config: { model: 'model-a' },
//   models: [
//     {
//       key: 'model-a',
//       model: AxAIOpenAIModel.GPT4OMini,
//       description: 'A model that is good for general purpose',
//     },
//   ],
// })

const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string,
  config: { model: AxAIGoogleGeminiModel.Gemini15Flash8B },
  options: { timeout: 5000 },
  models: [
    {
      key: 'model-a',
      model: AxAIGoogleGeminiModel.Gemini15Flash8B,
      description: 'A model that is good for general purpose',
    },
  ],
})
// ai.setOptions({ debug: true })

const gen = new AxGen<{ chatMessage: string; currentDate: Date }>(
  `chatMessage, currentDate:datetime -> subject, thinking, reasoning, foundMeeting:boolean, ticketNumber?:number, customerNumber?:number, datesMentioned:datetime[], shortSummary, messageType:class "reminder, follow-up, meeting, other"`
)

const stream = await gen.streamingForward(ai, { chatMessage, currentDate })

console.log('# Streaming')

for await (const chunk of stream) {
  console.log('>', chunk)
}

// console.log('\n\n# Not Streaming')

// const res = await gen.forward(ai, { chatMessage, currentDate })
// console.log('>', res)



================================================
FILE: src/examples/fibonacci.ts
================================================
import { AxAI, AxGen, AxJSInterpreter } from '@ax-llm/ax'

const gen = new AxGen<{ numberSeriesTask: string }>(
  {
    inputs: [{ name: 'numberSeriesTask', type: { name: 'string' } }],
    outputs: [{ name: 'fibonacciSeries', type: { name: 'number' } }],
  },
  {
    functions: [new AxJSInterpreter()],
    debug: true,
  }
)

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
  config: { stream: true },
})

const res = await gen.forward(ai, {
  numberSeriesTask: 'Use code to calculate the fibonacci series of 10',
})

console.log('>', res)



================================================
FILE: src/examples/food-search.ts
================================================
import { AxAgent, AxAI, type AxFunction, AxSignature } from '@ax-llm/ax'

const choice = Math.round(Math.random())

const goodDay = {
  temperature: '27C',
  description: 'Clear Sky',
  wind_speed: 5.1,
  humidity: 56,
}

const badDay = {
  temperature: '10C',
  description: 'Cloudy',
  wind_speed: 10.6,
  humidity: 70,
}

const weatherAPI = ({ location }: Readonly<{ location: string }>) => {
  const data = [
    {
      city: 'san francisco',
      weather: choice === 1 ? goodDay : badDay,
    },
    {
      city: 'tokyo',
      weather: choice === 1 ? goodDay : badDay,
    },
  ]

  return data
    .filter((v) => v.city === location.toLowerCase())
    .map((v) => v.weather)
}

const opentableAPI = ({
  location,
}: Readonly<{
  location: string
  outdoor: string
  cuisine: string
  priceRange: string
}>) => {
  const data = [
    {
      name: "Gordon Ramsay's",
      city: 'san francisco',
      cuisine: 'indian',
      rating: 4.8,
      price_range: '$$$$$$',
      outdoor_seating: true,
    },
    {
      name: 'Sukiyabashi Jiro',
      city: 'san francisco',
      cuisine: 'sushi',
      rating: 4.7,
      price_range: '$$',
      outdoor_seating: false,
    },
    {
      name: 'Oyster Bar',
      city: 'san francisco',
      cuisine: 'seafood',
      rating: 4.5,
      price_range: '$$',
      outdoor_seating: true,
    },
    {
      name: 'China Express',
      city: 'san francisco',
      cuisine: 'chinese',
      rating: 4.6,
      price_range: '$$$$',
      outdoor_seating: true,
    },
    {
      name: 'White Rabbit',
      city: 'san francisco',
      cuisine: 'indian',
      rating: 4.7,
      price_range: '$$$',
      outdoor_seating: true,
    },
  ]

  return data
    .filter((v) => v.city === location?.toLowerCase())
    .sort((a, b) => {
      return a.price_range.length - b.price_range.length
    })
}

// List of functions available to the AI
const functions: AxFunction[] = [
  {
    name: 'getCurrentWeather',
    description: 'get the current weather for a location',
    func: weatherAPI,
    parameters: {
      type: 'object',
      properties: {
        location: {
          description: 'location to get weather for',
          type: 'string',
        },
        units: {
          type: 'string',
          enum: ['imperial', 'metric'],
          description: 'units to use',
        },
      },
      required: ['location'],
    },
  },
  {
    name: 'findRestaurants',
    description: 'find restaurants in a location',
    func: opentableAPI,
    parameters: {
      type: 'object',
      properties: {
        location: {
          description: 'location to find restaurants in',
          type: 'string',
        },
        outdoor: {
          type: 'boolean',
          description: 'outdoor seating',
        },
        cuisine: { type: 'string', description: 'cuisine type' },
        priceRange: {
          type: 'string',
          enum: ['$', '$$', '$$$', '$$$$'],
          description: 'price range',
        },
      },
      required: ['location', 'outdoor', 'cuisine', 'priceRange'],
    },
  },
]

// const ai = new AxAI({
//   name: 'openai',
//   apiKey: process.env.OPENAI_APIKEY as string,
//   config: { stream: true },
// })

// const ai = new AxAI({
//   name: 'google-gemini',
//   apiKey: process.env.GOOGLE_APIKEY as string,
//   config: { stream: true },
// })

const ai = new AxAI({
  name: 'openai-responses',
  apiKey: process.env.OPENAI_APIKEY as string,
  config: { stream: true },
})

// const ai = new AxAI({
//   name: 'groq',
//   apiKey: process.env.GROQ_APIKEY as string,
//   config: { stream: false },
// })

// const ai = new AxAI({
//   name: 'cohere',
//   apiKey: process.env.COHERE_APIKEY as string,
//   config: { stream: false },
// })

// const ai = new AxAI({
//   name: 'anthropic',
//   apiKey: process.env.ANTHROPIC_APIKEY as string,
//   config: { stream: true },
// })

ai.setOptions({ debug: true })

const customerQuery =
  "Give me an ideas for lunch today in San Francisco. I like sushi, chinese, indian. Also if its a nice day I'd rather sit outside. Find me something."

const signature = new AxSignature(
  `customerQuery:string  -> plan: string "detailed plan to find a place to eat", restaurant:string, priceRange:string "use $ signs to indicate price range"`
)

const gen = new AxAgent<
  { customerQuery: string },
  { restaurant: string; priceRange: string }
>({
  name: 'food-search',
  description:
    'Use this agent to find restaurants based on what the customer wants. Use the provided functions to get the weather and find restaurants and finally return the best match',
  signature,
  functions,
})

const res = await gen.forward(ai, { customerQuery })

console.log('\n>', res)



================================================
FILE: src/examples/function.ts
================================================
import {
  AxAgent,
  AxAI,
  AxAIAnthropicModel,
  type AxFunction,
  AxFunctionError,
  AxSignature,
} from '@ax-llm/ax'

// Restaurant booking function with validation
const bookRestaurantAPI = ({
  date,
  time,
  partySize,
}: Readonly<{
  date: string
  time: string
  partySize: string
}>) => {
  const errors: { field: string; message: string }[] = []

  // Validate date format (YYYY-MM-DD)
  const dateRegex = /^\d{4}-\d{2}-\d{2}$/
  if (!dateRegex.test(date)) {
    errors.push({
      field: 'date',
      message: 'Date must be in YYYY-MM-DD format',
    })
  }

  // Validate time format (HH:MM)
  const timeRegex = /^([01]\d|2[0-3]):([0-5]\d)$/
  if (!timeRegex.test(time)) {
    errors.push({
      field: 'time',
      message: 'Time must be in 24-hour HH:MM format',
    })
  }

  if (!['small', 'medium', 'large'].includes(partySize)) {
    errors.push({
      field: 'partySize',
      message: 'Party size must be small, medium, or large',
    })
  }

  // If any validation errors, throw AxFunctionError
  if (errors.length > 0) {
    throw new AxFunctionError(errors)
  }

  // If validation passes, proceed with booking
  return {
    success: true,
    confirmation: `Booking confirmed for ${partySize} people on ${date} at ${time}`,
    details: {
      reservationId: Math.random().toString(36).substring(7),
      restaurant: 'Sample Restaurant',
    },
  }
}

// List of functions available to the AI
const functions: AxFunction[] = [
  {
    name: 'bookRestaurant',
    description:
      'Book a restaurant reservation. Date must be YYYY-MM-DD, time must be HH:MM in 24-hour format',
    func: bookRestaurantAPI,
    parameters: {
      type: 'object',
      properties: {
        date: {
          type: 'string',
          description: 'Reservation date in YYYY-MM-DD format',
        },
        time: {
          type: 'string',
          description: 'Reservation time in HH:MM 24-hour format',
        },
        partySize: {
          type: 'string',
          description: 'Number of people',
        },
      },
      required: ['date', 'time', 'partySize'],
    },
  },
]

// Define the signature for the booking agent
const signature = new AxSignature(
  `customerQuery:string -> plan:string "detailed plan to book the restaurant", 
   confirmationNumber:string "reservation confirmation number", 
   details:string "booking details including date, time, and party size"`
)

// Create the booking agent
const gen = new AxAgent<
  { customerQuery: string },
  { confirmationNumber: string; details: string }
>({
  name: 'restaurant-booking',
  description:
    'Use this agent to book restaurant reservations. Must use the provided functions to book a table',
  signature,
  functions,
})

// const ai = new AxAI({
//   name: 'openai',
//   apiKey: process.env.OPENAI_APIKEY as string,
//   config: { stream: true },
// })

const ai = new AxAI({
  name: 'anthropic',
  apiKey: process.env.ANTHROPIC_APIKEY as string,
  config: { stream: true, model: AxAIAnthropicModel.Claude35Haiku },
})

// const ai = new AxAI({
//   name: 'google-gemini',
//   apiKey: process.env.GOOGLE_APIKEY as string,
//   config: { stream: true, model: AxAIGoogleGeminiModel.Gemini15Flash },
// })

// const ai = new AxAI({
//   name: 'cohere',
//   apiKey: process.env.COHERE_APIKEY as string,
//   config: { stream: false },
// })

ai.setOptions({ debug: true })

// Example error case
const invalidQuery = 'Book me a table for 25 people at 8:30 PM on 2025/02/01'

const res = await gen.forward(ai, { customerQuery: invalidQuery })
console.log(res)



================================================
FILE: src/examples/marketing.ts
================================================
import { AxAI, AxGen } from '@ax-llm/ax'

const product = {
  name: 'Acme Toilet Cleaning',
  description: '24/7 Commercial and residential restroom cleaning services',
}

const to = {
  name: 'Jerry Doe',
  title: 'Head of facilities and operations',
  company: 'Blue Yonder Inc.',
}

const messageGuidelines = [
  'Under 160 characters',
  'Prompts recipients to book an call',
  'Employs emojis and friendly language',
]

const gen = new AxGen<{
  productName: string
  productDescription: string
  toName: string
  toDescription: string
  messageGuidelines: string
}>(
  `productName, productDescription, toName, toDescription, messageGuidelines -> message`
)

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

const res = await gen.forward(ai, {
  productName: product.name,
  productDescription: product.description,
  toName: to.name,
  toDescription: to.title,
  messageGuidelines: messageGuidelines.join(', '),
})

console.log('>', res)



================================================
FILE: src/examples/mcp-client-blender.ts
================================================
import {
  AxAgent,
  AxAI,
  AxAIOpenAIModel,
  AxMCPClient,
  AxMCPStdioTransport,
} from '@ax-llm/ax'

// Initialize the MCP client with Blender integration
const blenderTransport = new AxMCPStdioTransport({
  command: 'uvx',
  args: ['blender-mcp'],
})
const client = new AxMCPClient(blenderTransport, { debug: true })
await client.init()

// Create an artistic agent that transforms text prompts into digital art using Blender MCP integration
const drawingAgent = new AxAgent<{ prompt: string }, { imageUrl: string }>({
  name: 'ArtisticBlender',
  description:
    'An AI agent that transforms textual prompts into digital art using Blender MCP integration. Provide a prompt to generate awe-inspiring imagery.',
  signature: 'prompt -> imageUrl',
  functions: [client],
})

// Initialize the AI model with OpenAI GPT-4 Mini
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
  config: { model: AxAIOpenAIModel.GPT4OMini },
})
ai.setOptions({ debug: false })

// Run a series of art sessions to generate interesting visuals
async function runArtSession() {
  console.log('\n--- Art Session: Futuristic Cyberpunk Cityscape ---')
  const response1 = await drawingAgent.forward(ai, {
    prompt:
      'Draw a futuristic cyberpunk cityscape with neon lights and rain-soaked streets.',
  })
  console.log(
    'Prompt: Draw a futuristic cyberpunk cityscape with neon lights and rain-soaked streets.'
  )
  console.log(`Generated Art: ${response1.imageUrl}`)

  console.log('\n--- Art Session: Surreal Floating Islands ---')
  const response2 = await drawingAgent.forward(ai, {
    prompt:
      'Imagine and draw a surreal landscape featuring floating islands in a dreamy, colorful sky.',
  })
  console.log(
    'Prompt: Imagine and draw a surreal landscape featuring floating islands in a dreamy, colorful sky.'
  )
  console.log(`Generated Art: ${response2.imageUrl}`)

  console.log('\n--- Art Session: Abstract Cosmic Patterns ---')
  const response3 = await drawingAgent.forward(ai, {
    prompt:
      'Create an abstract illustration of cosmic patterns and vibrant galaxies merging into chaos and order.',
  })
  console.log(
    'Prompt: Create an abstract illustration of cosmic patterns and vibrant galaxies merging into chaos and order.'
  )
  console.log(`Generated Art: ${response3.imageUrl}`)
}

await runArtSession()



================================================
FILE: src/examples/mcp-client-memory.ts
================================================
import {
  AxAgent,
  AxAI,
  AxAIOpenAIModel,
  AxMCPClient,
  AxMCPStdioTransport,
} from '@ax-llm/ax'

// Initialize the MCP client with server-memory
const stdioTransport = new AxMCPStdioTransport({
  command: 'npx',
  args: ['-y', '@modelcontextprotocol/server-memory'],
})
const client = new AxMCPClient(stdioTransport, { debug: false })
await client.init()

// Create a memory-augmented agent that can remember past conversations
const memoryAgent = new AxAgent<
  { userMessage: string; userId: string },
  { assistantResponse: string }
>({
  name: 'MemoryAssistant',
  description:
    'You are an assistant that remembers past conversations with users. You break down the information to be remembered by entity identifiers and the content to remeber. Use the provided database functions to manage memories, search for memories, and add memories. Use multiple searches with different entity identifiers to get a holistic view of the user.',
  signature: 'userMessage, userId -> assistantResponse',
  functions: [client],
})

// Initialize the AI model
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
  config: { model: AxAIOpenAIModel.GPT4OMini },
})
ai.setOptions({ debug: true })

// Example conversation flow
async function runConversation() {
  const userId = 'user123'

  // First interaction - the agent will store this in memory
  console.log('\n--- First interaction ---')
  const firstResponse = await memoryAgent.forward(ai, {
    userMessage: 'My name is Alice and my favorite color is blue.',
    userId,
  })
  console.log('User: My name is Alice and my favorite color is blue.')
  console.log(`Assistant: ${firstResponse.assistantResponse}`)

  // Second interaction - the agent should remember information from before
  console.log('\n--- Second interaction (later) ---')
  const secondResponse = await memoryAgent.forward(ai, {
    userMessage: "What's my favorite color?",
    userId,
  })
  console.log('User: What is my favorite color?')
  console.log(`Assistant: ${secondResponse.assistantResponse}`)

  // Third interaction - the agent should remember information from before
  console.log('\n--- Third interaction (later) ---')
  const thirdResponse = await memoryAgent.forward(ai, {
    userMessage: 'What do you know about me?',
    userId,
  })
  console.log('User: What do you know about me?')
  console.log(`Assistant: ${thirdResponse.assistantResponse}`)
}

// Run the example
await runConversation()



================================================
FILE: src/examples/mcp-client-pipedream.ts
================================================
import { AxAgent, AxAI, AxAIOpenAIModel, AxMCPClient } from '@ax-llm/ax'
import { AxMCPStreambleHTTPTransport } from '@ax-llm/ax/mcp/httpTransport.js'
import { createBackendClient } from '@pipedream/sdk/server'

/*
# Pipedream configuration
export PIPEDREAM_ENVIRONMENT="your_environment"
export PIPEDREAM_CLIENT_ID="your_client_id"
export PIPEDREAM_CLIENT_SECRET="your_client_secret"  
export PIPEDREAM_PROJECT_ID="your_project_id"

# OpenAI API key for the AI model
export OPENAI_APIKEY="your_openai_api_key"
*/

// Environment variables for Pipedream configuration
const pipedreamEnvironment = 'development'
const pipedreamClientId = process.env.PIPEDREAM_CLIENT_ID as string
const pipedreamClientSecret = process.env.PIPEDREAM_CLIENT_SECRET as string
const pipedreamProjectId = process.env.PIPEDREAM_PROJECT_ID as string

// Initialize the Pipedream SDK client
const pd = createBackendClient({
  environment: pipedreamEnvironment,
  credentials: {
    clientId: pipedreamClientId,
    clientSecret: pipedreamClientSecret,
  },
  projectId: pipedreamProjectId,
})

// Get app information and access token
async function setupPipedreamMCP() {
  // Find the app to use for the MCP server (Notion in this case)
  const apps = await pd.getApps({ q: 'notion' })
  if (!apps.data[0]) {
    throw new Error('No Notion app found')
  }
  const appSlug = apps.data[0].name_slug // e.g., "notion"
  const appLabel = apps.data[0].name // e.g., "Notion"

  // Get access token for MCP server auth
  const accessToken = await pd.rawAccessToken()

  // Send the unique ID that you use to identify this user in your system
  const externalUserId = 'abc-123' // Used in MCP URL to identify the user

  return { appSlug, appLabel, accessToken, externalUserId }
}

async function createNotionAgent() {
  const { appSlug, appLabel, accessToken, externalUserId } =
    await setupPipedreamMCP()

  // Initialize the MCP client with Pipedream's streamable HTTP transport
  const httpTransport = new AxMCPStreambleHTTPTransport(
    'https://remote.mcp.pipedream.net',
    {
      headers: {
        'x-pd-project-id': pipedreamProjectId,
        'x-pd-environment': pipedreamEnvironment,
        'x-pd-external-user-id': externalUserId,
        'x-pd-app-slug': appSlug,
      },
      authorization: `Bearer ${accessToken}`,
    }
  )

  console.log(`
Configuration for Pipedream MCP:
- App: ${appLabel} (${appSlug})
- User ID: ${externalUserId}
- Environment: ${pipedreamEnvironment}
- Project ID: ${pipedreamProjectId}
- Access Token: ${accessToken.substring(0, 10)}...

Using streamable HTTP transport for real-time communication with Pipedream MCP server.
`)

  const client = new AxMCPClient(httpTransport, { debug: false })
  await client.init()

  // Create a Notion-augmented agent that can interact with Notion docs
  const notionAgent = new AxAgent<
    { userRequest: string },
    { assistantResponse: string }
  >({
    name: 'NotionAssistant',
    description: `You are an assistant that can interact with ${appLabel} documents and data. You can read, search, and analyze Notion content to help users with their requests. Use the provided Notion functions to access and work with the user's documents.`,
    signature: 'userRequest -> assistantResponse',
    functions: [client],
  })

  return notionAgent
}

// Initialize the AI model
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
  config: { model: AxAIOpenAIModel.GPT4OMini },
})
ai.setOptions({ debug: true })

// Example usage
async function runNotionExample() {
  console.log('Initializing Notion MCP client...')
  const notionAgent = await createNotionAgent()

  console.log('\n--- Requesting Notion document summary and email draft ---')
  const response = await notionAgent.forward(ai, {
    userRequest:
      'Summarize my most recently created Notion doc for me and help draft an email to our customers',
  })

  console.log(
    'User: Summarize my most recently created Notion doc for me and help draft an email to our customers'
  )
  console.log(`Assistant: ${response.assistantResponse}`)
}

// Run the example
await runNotionExample()



================================================
FILE: src/examples/meetings.ts
================================================
// import * as chrono from 'chrono-node';
// import superagent from 'superagent';

// const trelloApiKey = process.env.TRELLO_APIKEY;
// const trelloApiToken = process.env.TRELLO_APITOKEN;

// const trelloBoardID = process.env.TRELLO_BOARD_ID; // test
// const trelloNewTasksListID = process.env.TRELLO_LIST_ID; // todo

// const findWorker = async ({ query }) => {
//   const res = await superagent
//     .get(`https://api.trello.com/1/search/members`)
//     .query({
//       key: trelloApiKey,
//       token: trelloApiToken,
//     })
//     .query({
//       query,
//       idBoard: trelloBoardID,
//       modelTypes: 'members',
//       memberFields: 'id,fullName,bio,',
//       limit: 1,
//     })
//     .set('Accept', 'application/json')
//     .catch(({ message }) => {
//       throw new Error(message);
//     });

//   const members = res.body?.map(({ id, fullName, bio }) => {
//     id, fullName, bio;
//   });
//   return members;
// };

// const createTask = async ({ name, desc, dueDate, idMembers }) => {
//   const chronoResults = chrono.parseDate(dueDate);
//   const due = chronoResults?.toISOString();

//   const res = await superagent
//     .post(`https://api.trello.com/1/cards`)
//     .query({
//       key: trelloApiKey,
//       token: trelloApiToken,
//     })
//     .query({
//       idList: trelloNewTasksListID,
//       idBoard: trelloBoardID,
//       name,
//       desc,
//       due,
//       idMembers,
//     })
//     .set('Accept', 'application/json')
//     .catch(({ message }) => {
//       throw new Error(message);
//     });

//   const { id, name: cardName } = res.body;
//   return { id, cardName };
// };

// // List of functions available to the AI
// const functions = [
//   {
//     name: 'findWorker',
//     description: 'Find worker by name or skill',
//     parameters: {
//       type: 'object',
//       properties: {
//         query: {
//           type: 'string',
//           description: 'Name or skill of worker',
//           maxLength: 16384,
//         },
//       },
//       required: ['query'],
//     },
//     func: findWorker,
//   },
//   {
//     name: 'createTask',
//     description: 'Create task',
//     parameters: {
//       type: 'object',
//       properties: {
//         name: {
//           type: 'string',
//           description: 'Task name',
//         },
//         desc: {
//           type: 'string',
//           description: 'Task description',
//         },
//         dueDate: {
//           type: 'string',
//           description: 'Task due date',
//         },
//         idMembers: {
//           type: 'string',
//           description:
//             'Comma-separated list of worker IDs to assign this task to',
//         },
//       },
//       required: ['name', 'desc'],
//     },
//     func: createTask,
//   },
// ];

// const responseSchema = {
//   type: 'object',
//   properties: {
//     data: {
//       type: 'array',
//       items: {
//         type: 'object',
//         properties: {
//           id: { type: 'string' },
//           name: { type: 'string' },
//           desc: { type: 'string' },
//           workerName: { type: 'string' },
//         },
//       },
//     },
//     error: {
//       type: 'string',
//     },
//   },
// };

// const prompt = new SPrompt(responseSchema, functions);
// prompt.setDebug(true);

// const meetingNotes = `
// Manager: Alright, team. As we discussed in the last standup, we're working on building a todo list app. Let's finalize who's taking care of what and when we expect it done. I want to start by asking, do we all understand the basics of the project?

// SW1, SW2, SW3, Designer: (in unison) Yes.

// Manager: Great! Let's start with the frontend. SW1, since you are our UI engineer, you will be working on the frontend. We need to ensure it is user-friendly, responsive, and aesthetically pleasing. The Designer will provide you with the design mockups. Designer, when can we have the design finalized?

// Designer: I can have the first drafts of the designs ready by end of day tomorrow, and based on feedback, we can finalize it by Wednesday.

// Manager: Sounds good. SW1, once the designs are ready, you can start implementing them. Let's have the frontend ready by next Friday.

// SW1: Understood. I'll start working on setting up the base frontend code and incorporate the designs as soon as they're finalized.

// Manager: Excellent. Now, for the backend. SW2 and SW3, you will be working together to develop the API endpoints and set up the database. SW2, you will focus on creating the business logic for our API.

// SW2: Alright, I can start with basic CRUD operations for the todo items. I should be able to have them ready for initial testing by mid next week.

// Manager: Good, we want those ready for SW1 to integrate with the frontend. Now, SW3, you'll be responsible for the database schema and managing the cloud services.

// SW3: Okay, I'll design the schema keeping scalability in mind, and set up our servers on the cloud. I think by Tuesday next week, we should have a basic version up and running.

// Manager: That's excellent. SW2 and SW3, I expect the backend to be functional by end of next week so that SW1 has ample time for integration. Let's keep the communication lines open to ensure we are all on the same page. Is everyone clear on their responsibilities and deadlines?

// SW1, SW2, SW3, Designer: (in unison) Yes.

// Manager: Perfect! Let's create a great todo list app, folks. Thank you.
// `;

// const promptText = `
// Use the below meeting notes to first find workers by name or if not provided then skill and then create tasks for these workers.

// Meeting Notes:
// ${meetingNotes}
// `;

// const conf = OpenAIDefaultOptions();
// // conf.model = OpenAGenerateIModel.GPT4;
// const ai = new OpenAI(process.env.OPENAI_APIKEY, conf);

// async function run() {
//   const res = await prompt.generate(ai, promptText);
//   console.log(chalk.green(JSON.stringify(res.value(), null, 2)));
// }
//



================================================
FILE: src/examples/mipro-chained-optimize.ts
================================================
import fs from 'fs/promises'

import {
  ax,
  AxAI,
  AxAIOpenAIModel,
  type AxCheckpointLoadFn,
  type AxCheckpointSaveFn,
  type AxMetricFn,
  AxMiPRO,
  f,
} from '@ax-llm/ax'
import { AxDefaultCostTracker } from '@ax-llm/ax/dsp/optimizer.js'

// First generator: Summarize text
export const summarizerGen = ax`
  documentText:${f.string('Long text to summarize')} -> 
  summary:${f.string('Concise summary of key points')}
`

// Second generator: Analyze sentiment of summaries
export const sentimentGen = ax`
  summary:${f.string('Text summary to analyze')} -> 
  sentiment:${f.class(['positive', 'negative', 'neutral'], 'Overall sentiment')},
  confidence:${f.number('Confidence score 0-1')}
`

// Examples for summarization
const summaryExamples = [
  {
    documentText:
      'The quarterly earnings report shows strong revenue growth of 15% year-over-year, driven primarily by increased customer acquisition in the enterprise segment. However, operating costs have risen by 12% due to expanded marketing spend and new office leases. The company remains optimistic about future growth prospects despite some market headwinds.',
    summary:
      'Company achieved 15% revenue growth but operating costs increased 12%. Strong enterprise customer growth offset by higher marketing and office expenses.',
  },
  {
    documentText:
      'Climate scientists have published new research indicating that ocean temperatures have risen faster than previously predicted. The study, based on 20 years of satellite data, suggests that marine ecosystems are under greater stress than earlier models indicated. This could accelerate ice sheet melting and affect global weather patterns more rapidly than anticipated.',
    summary:
      'New study shows ocean temperatures rising faster than predicted, threatening marine ecosystems and potentially accelerating climate change effects.',
  },
]

// Examples for sentiment analysis
const sentimentExamples = [
  {
    summary:
      'Company achieved 15% revenue growth but operating costs increased 12%. Strong enterprise customer growth offset by higher marketing expenses.',
    sentiment: 'neutral',
    confidence: 0.7,
  },
  {
    summary:
      'New study shows ocean temperatures rising faster than predicted, threatening marine ecosystems and accelerating climate change.',
    sentiment: 'negative',
    confidence: 0.9,
  },
]

// LLM Judge for summary evaluation
const summaryJudgeGen = ax`
  originalText:${f.string('Original text that was summarized')},
  candidateSummary:${f.string('Summary to evaluate')},
  expectedSummary:${f.string('Expected/reference summary')} ->
  score:${f.number('Quality score from 0.0 to 1.0')},
  reasoning:${f.string('Brief explanation of the score')}
`

// Create a function that returns an LLM judge-based metric function
const createSummaryMetric = (judgeAI: Readonly<AxAI>): AxMetricFn => {
  return async ({ prediction, example }) => {
    const candidateSummary = prediction.summary as string
    const expectedSummary = example.summary as string
    const originalText = example.documentText as string

    if (!candidateSummary || !expectedSummary || !originalText) return 0

    const judgeResult = await summaryJudgeGen.forward(judgeAI, {
      originalText,
      candidateSummary,
      expectedSummary,
    })

    return judgeResult.score as number
  }
}

const sentimentMetric: AxMetricFn = ({ prediction, example }) => {
  const predSentiment = prediction.sentiment as string
  const expectedSentiment = example.sentiment as string
  const predConfidence = prediction.confidence as number

  // Exact match for sentiment + confidence bonus
  const sentimentMatch = predSentiment === expectedSentiment ? 0.8 : 0
  const confidenceBonus = predConfidence > 0.5 ? 0.2 : 0

  return sentimentMatch + confidenceBonus
}

// Cost-optimized AI instances
const costTracker = new AxDefaultCostTracker({
  maxTokens: 100000,
})

// Teacher AI: Use more capable model for generating high-quality instructions
const teacherAI = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: {
    model: AxAIOpenAIModel.GPT4O, // More capable model for instruction generation
    maxTokens: 500,
    temperature: 0.3, // Some creativity for diverse instructions
  },
})

// Student AI: Use cheaper model for optimization and inference
const studentAI = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: {
    model: AxAIOpenAIModel.GPT4OMini, // Much cheaper than GPT-4
    maxTokens: 300, // Limit output tokens
    temperature: 0.1, // More consistent, less creative (cheaper)
  },
})

// Even cheaper model for production inference
const inferenceAI = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: {
    model: AxAIOpenAIModel.GPT35Turbo, // Cheapest option
    maxTokens: 200,
    temperature: 0,
  },
})

console.log(
  '=== Teacher-Student Model Optimization with Checkpointing Demo ==='
)

// Set up simple checkpoint functions
const checkpoints = new Map()

const checkpointSave: AxCheckpointSaveFn = async (checkpoint) => {
  const id = `checkpoint_${checkpoint.timestamp}_${checkpoint.optimizerType}`
  checkpoints.set(id, checkpoint)
  console.log(`💾 Saved checkpoint: ${id}`)
  return id
}

const checkpointLoad: AxCheckpointLoadFn = async (id) => {
  return checkpoints.get(id) || null
}

// Step 1: Optimize the summarizer with teacher-student setup and checkpointing
console.log(
  '1. Optimizing summarizer with teacher-student AI setup and checkpointing...'
)
console.log('   Teacher AI: GPT-4O (for instruction generation)')
console.log('   Student AI: GPT-4O-Mini (for optimization)')
console.log('   Checkpoints will be saved in memory (for demo purposes)')

// Create the LLM judge-based metric function
const summaryMetric = createSummaryMetric(studentAI)

const summaryOptimizer = new AxMiPRO({
  studentAI, // Cheaper model for optimization
  teacherAI, // More capable model for instruction generation
  examples: summaryExamples,
  costTracker,
  checkpointSave, // Enable checkpointing
  checkpointLoad, // Enable checkpoint loading
  checkpointInterval: 5, // Save checkpoint every 5 rounds
  options: {
    numCandidates: 3, // Teacher will generate diverse instructions
    numTrials: 5,
    verbose: true, // Show progress
    earlyStoppingTrials: 2, // Stop early if no improvement
  },
})

const optimizedSummarizer = await summaryOptimizer.compile(
  summarizerGen,
  summaryMetric
)

// Step 2: Use optimized summarizer to generate examples (with cost control)
console.log('\n2. Generating examples with optimized summarizer...')
if (optimizedSummarizer.demos) {
  summarizerGen.setDemos(optimizedSummarizer.demos)
}

// Use fewer new texts to control costs
const newTexts = [
  'The product launch exceeded all expectations with pre-orders surpassing targets by 300%. Customer feedback has been overwhelmingly positive, praising the innovative design and competitive pricing.',
]

const generatedExamples = []
for (const documentText of newTexts) {
  const result = await summarizerGen.forward(inferenceAI, { documentText }) // Use cheaper model
  const sentiment =
    documentText.includes('exceeded') || documentText.includes('positive')
      ? 'positive'
      : 'negative'
  const confidence = 0.8

  generatedExamples.push({
    summary: result.summary,
    sentiment,
    confidence,
  })
}

// Combine with original examples
const allSentimentExamples = [...sentimentExamples, ...generatedExamples]

// Step 3: Optimize sentiment analyzer with teacher-student setup
console.log('\n3. Optimizing sentiment analyzer with teacher-student setup...')

// Create a more restrictive cost tracker for the second optimization
const restrictiveCostTracker = new AxDefaultCostTracker({
  maxTokens: 50000, // Lower budget for second optimization
})

const sentimentOptimizer = new AxMiPRO({
  studentAI, // Same cheaper model for optimization
  teacherAI, // Same capable model for instruction generation
  examples: allSentimentExamples,
  costTracker: restrictiveCostTracker,
  checkpointSave, // Enable checkpointing for second optimization too
  checkpointLoad, // Enable checkpoint loading
  checkpointInterval: 3, // More frequent checkpoints for shorter run
  options: {
    numCandidates: 3,
    numTrials: 4,
    verbose: true,
    earlyStoppingTrials: 2,
    minImprovementThreshold: 0.01, // Stop if improvement is minimal
  },
})

const optimizedSentiment = await sentimentOptimizer.compile(
  sentimentGen,
  sentimentMetric
)

// Step 4: Demonstrate runtime teacher override
console.log('\n4. Testing with runtime teacher AI override...')

// Create an even more capable teacher for final optimization
const premiumTeacherAI = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: {
    model: AxAIOpenAIModel.GPT4O, // Premium model
    maxTokens: 800,
    temperature: 0.2,
  },
})

// Re-optimize with premium teacher override
console.log(
  '   Using premium teacher AI override for enhanced instruction generation...'
)
const enhancedOptimizer = new AxMiPRO({
  studentAI,
  teacherAI, // Original teacher
  examples: summaryExamples.slice(0, 1), // Use fewer examples for demo
  options: {
    numCandidates: 2,
    numTrials: 2,
    verbose: true,
  },
})

const enhancedResult = await enhancedOptimizer.compile(
  summarizerGen,
  summaryMetric,
  {
    overrideTeacherAI: premiumTeacherAI, // Override with premium teacher
    verbose: true,
  }
)

// Step 5: Test the optimized pipeline
console.log('\n5. Testing optimized pipeline with inference model...')
if (optimizedSentiment.demos) {
  sentimentGen.setDemos(optimizedSentiment.demos)
}

const testDocumentText =
  'The merger talks have stalled due to regulatory concerns, but both companies remain committed to finding a path forward. Industry analysts are cautiously optimistic about the potential benefits.'

// Run through the pipeline using cheaper inference model
const summary = await summarizerGen.forward(inferenceAI, {
  documentText: testDocumentText,
})
const sentiment = await sentimentGen.forward(inferenceAI, {
  summary: summary.summary,
})

console.log('\n📈 Pipeline Results:')
console.log('Original:', testDocumentText)
console.log('Summary:', summary.summary)
console.log(
  'Sentiment:',
  sentiment.sentiment,
  `(confidence: ${sentiment.confidence})`
)

// Save all optimizations
await fs.writeFile(
  'summary-demos.json',
  JSON.stringify(optimizedSummarizer.demos, null, 2)
)
await fs.writeFile(
  'sentiment-demos.json',
  JSON.stringify(optimizedSentiment.demos, null, 2)
)
await fs.writeFile(
  'enhanced-demos.json',
  JSON.stringify(enhancedResult.demos, null, 2)
)

// List available checkpoints
const checkpointList = Array.from(checkpoints.keys())
console.log('\n📁 Available Checkpoints:')
if (checkpointList.length > 0) {
  checkpointList.forEach((checkpoint) => {
    console.log(`   - ${checkpoint}`)
  })
} else {
  console.log('   No checkpoints found')
}

console.log('\n💰 Cost Optimization Summary:')
console.log('   Teacher AI (GPT-4O): High-quality instruction generation')
console.log('   Student AI (GPT-4O-Mini): Cost-effective optimization')
console.log('   Inference AI (GPT-3.5-Turbo): Production deployment')
console.log('   Runtime override: Premium teacher for critical optimizations')
console.log('   Checkpointing: Automatic state saving for fault tolerance')

console.log(
  '✅ Saved optimizations to summary-demos.json, sentiment-demos.json, and enhanced-demos.json'
)
console.log(`✅ Checkpoints saved in memory (${checkpointList.length} total)`)



================================================
FILE: src/examples/mipro-optimize.ts
================================================
import fs from 'fs/promises'

import {
  ax,
  AxAI,
  AxAIOpenAIModel,
  type AxMetricFn,
  AxMiPRO,
  type AxMiPROCompileOptions,
  f,
} from '@ax-llm/ax'

/**
 * Complex reasoning examples that benefit from teacher model optimization
 * These require nuanced understanding that small models struggle with
 */
const complexReasoningExamples = [
  {
    scenario:
      "A company's revenue increased 25% but profit decreased 10%. The CEO says business is great.",
    analysis:
      "This is concerning. While revenue growth appears positive, the decrease in profit suggests rising costs, operational inefficiencies, or margin compression. The CEO's optimism may be misplaced or misleading to stakeholders.",
  },
  {
    scenario:
      'A politician promises to cut taxes and increase government spending simultaneously during a recession.',
    analysis:
      'This is economically contradictory and likely unsustainable. Cutting taxes reduces government revenue while increasing spending raises expenditures, leading to larger deficits. During a recession, this could worsen long-term fiscal health despite short-term stimulus effects.',
  },
  {
    scenario:
      'A startup claims 1000% user growth but admits 95% of users never return after first visit.',
    analysis:
      'The growth metric is misleading. High acquisition with 95% churn indicates severe product-market fit issues, unsustainable unit economics, and inflated vanity metrics. The real focus should be on retention and engagement, not raw user counts.',
  },
  {
    scenario:
      'A study shows correlation between ice cream sales and drowning deaths, leading to calls to ban ice cream.',
    analysis:
      'This confuses correlation with causation. Both ice cream sales and drowning deaths increase in summer due to hot weather and more swimming activity. The correlation is coincidental - temperature is the common cause. Banning ice cream would not reduce drowning deaths.',
  },
]

// Export the reasoning generator for reuse
export const reasoningGen = ax`
  scenario:${f.string('Business or logical scenario to analyze')} -> 
  analysis:${f.string('Critical analysis explaining what is wrong or misleading about the scenario')}
`

// Sophisticated evaluation metric for reasoning quality
const reasoningMetric: AxMetricFn = ({ prediction, example }) => {
  const predicted = (prediction.analysis as string)?.toLowerCase() || ''
  const expected = (example.analysis as string)?.toLowerCase() || ''

  // Check for key reasoning concepts
  const reasoningIndicators = [
    'concerning',
    'misleading',
    'contradictory',
    'unsustainable',
    'correlation',
    'causation',
    'confuses',
    'however',
    'suggests',
    'indicates',
    'because',
    'therefore',
    'due to',
  ]

  let score = 0

  // Basic content overlap
  if (predicted.includes(expected.slice(0, 50))) score += 0.3

  // Check for reasoning indicators
  const predictedIndicators = reasoningIndicators.filter((word) =>
    predicted.includes(word)
  )
  const expectedIndicators = reasoningIndicators.filter((word) =>
    expected.includes(word)
  )

  if (predictedIndicators.length >= expectedIndicators.length * 0.5)
    score += 0.4

  // Length and detail check (good reasoning should be detailed)
  if (predicted.length >= expected.length * 0.6) score += 0.3

  return score
}

console.log('=== Complex Reasoning Optimization Demo ===\n')

// Teacher model (GPT-4) for optimization
const teacherAI = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: { model: AxAIOpenAIModel.GPT4OMini }, // Use a capable model as teacher
})

console.log('Task: Analyze scenarios for logical flaws and misleading claims')
console.log('Teacher Model: GPT-4o-mini (high reasoning capability)')
console.log('Examples:', complexReasoningExamples.length)

const optimizer = new AxMiPRO({
  studentAI: teacherAI,
  examples: complexReasoningExamples,
  options: {
    numCandidates: 3,
    numTrials: 8,
    verbose: true,
  },
})

console.log('\n=== Running Optimization ===')

const result = await optimizer.compile(reasoningGen, reasoningMetric, {
  auto: 'medium', // More thorough optimization for complex task
} as AxMiPROCompileOptions) // Use proper type instead of any

console.log('\n✅ Optimization Complete!')

// Save just the demos
await fs.writeFile(
  'reasoning-demos.json',
  JSON.stringify(result.demos, null, 2)
)

console.log('💾 Saved demos to: reasoning-demos.json')
console.log(
  `📊 Successful demos: ${optimizer.getStats()?.successfulDemos ?? 0}`
)

// Quick test with teacher model
console.log('\n=== Testing Optimized Generator ===')
const testScenario =
  'A social media company boasts record user engagement while quietly reducing content moderation staff by 60%.'

// Set demos and test
if (result.demos) {
  reasoningGen.setDemos(result.demos)
}
const testResult = await reasoningGen.forward(teacherAI, {
  scenario: testScenario,
})

console.log('Test Scenario:', testScenario)
console.log('Analysis:', testResult.analysis)



================================================
FILE: src/examples/mipro-use-optimized.ts
================================================
import fs from 'fs/promises'

import { ax, AxAI, AxAIOpenAIModel, f } from '@ax-llm/ax'

// Create the reasoning generator inline since the original was removed
const reasoningGen = ax`
  scenario:${f.string('Business or logical scenario to analyze')} -> 
  analysis:${f.string('Critical analysis explaining what is wrong or misleading about the scenario')}
`

/**
 * Demonstrates loading and using previously optimized demos
 * This shows how to use the teacher model's knowledge with a smaller, cheaper model
 */

console.log('=== Loading Optimized Complex Reasoning ===\n')

// Load the saved demos
const demosData = await fs.readFile('reasoning-demos.json', 'utf-8')
const demos = JSON.parse(demosData)

console.log('✅ Loaded optimization demos')
console.log('Demo groups:', demos.length)

// Set demos on the imported generator
reasoningGen.setDemos(demos)

console.log('\n=== Using Cheaper Model with Teacher Knowledge ===')

// Use a much cheaper model that benefits from the teacher's optimization
const cheapAI = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: { model: AxAIOpenAIModel.GPT35Turbo }, // Much cheaper than GPT-4
})

console.log('Inference model: GPT-3.5 Turbo (cheap & fast)')

// Test scenarios that require sophisticated reasoning
const testScenarios = [
  "A crypto influencer promotes a 'revolutionary' new coin while quietly selling their holdings.",
  'A fitness app claims 99% user satisfaction but has 90% uninstall rate within a week.',
  "A news article states 'studies show coffee causes cancer' but cites only one retracted paper.",
  'A politician promises to eliminate unemployment while also promising to reduce immigration.',
]

console.log('\n=== Analyzing Complex Scenarios ===')

for (let i = 0; i < testScenarios.length; i++) {
  const scenario = testScenarios[i]
  console.log(`\n${i + 1}. Scenario: ${scenario}`)

  const result = await reasoningGen.forward(cheapAI, { scenario })
  console.log(`   Analysis: ${result.analysis}`)
}

// Compare with non-optimized baseline
console.log('\n=== Baseline Comparison (No Optimization) ===')

const baselineGen = ax`
  scenario:${f.string('Business or logical scenario to analyze')} -> 
  analysis:${f.string('Critical analysis explaining what is wrong or misleading about the scenario')}
`

const testScenario = testScenarios[0]
console.log(`\nTesting: ${testScenario}`)

const baselineResult = await baselineGen.forward(cheapAI, {
  scenario: testScenario,
})
console.log(`Baseline (no demos): ${baselineResult.analysis}`)

const optimizedResult = await reasoningGen.forward(cheapAI, {
  scenario: testScenario,
})
console.log(`Optimized (with demos): ${optimizedResult.analysis}`)

console.log('\n📊 Notice how the optimized version likely provides:')
console.log('• More structured reasoning')
console.log('• Specific identification of logical flaws')
console.log('• Better use of reasoning vocabulary')
console.log('• More comprehensive analysis')

// Production example
console.log('\n' + '='.repeat(50))
console.log('=== Production Usage Pattern ===\n')

const demosData2 = await fs.readFile('reasoning-demos.json', 'utf-8')
const demos2 = JSON.parse(demosData2)

// Set demos on the reasoning generator
reasoningGen.setDemos(demos2)

// Production AI instance (cost-optimized)
const productionAI = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY!,
  config: {
    model: AxAIOpenAIModel.GPT35Turbo,
    maxTokens: 500, // Control costs
    temperature: 0.1, // More consistent outputs
  },
})

console.log('✅ Production setup:')
console.log('• Optimized with teacher model (GPT-4o-mini)')
console.log('• Running on cost-effective model (GPT-3.5)')
console.log('• Ready for high-volume usage')

// Simulate production usage
const businessScenarios = [
  'Our new marketing campaign has 10x higher CTR but 5x lower conversion rate.',
  "The startup claims 'profitable growth' but is burning $1M monthly with $100K revenue.",
  'Survey shows 95% customer satisfaction but customer retention is only 30%.',
]

console.log('\n=== Batch Processing Demo ===')

for (const scenario of businessScenarios) {
  const analysis = await reasoningGen.forward(productionAI, { scenario })
  console.log(`\n📊 ${scenario}`)
  console.log(`🔍 ${analysis.analysis}`)
}

console.log('\n' + '='.repeat(50))
console.log('=== Key Benefits Demonstrated ===')
console.log('• Teacher model knowledge preserved in demos')
console.log('• Cheap inference model performs better')
console.log('• Clean separation: optimize once, use anywhere')
console.log('• Ready for production deployment')
console.log('• Significant cost savings vs teacher model')



================================================
FILE: src/examples/multi-modal.ts
================================================
import fs from 'node:fs'

import { AxAI, AxAIOpenAIModel, AxChainOfThought } from '@ax-llm/ax'

const gen = new AxChainOfThought(`question, animalImage:image -> answer`)

const image = fs
  .readFileSync('./src/examples/assets/kitten.jpeg')
  .toString('base64')

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
  config: { model: AxAIOpenAIModel.GPT4O },
  options: { debug: true },
})

const res = await gen.forward(ai, {
  question: 'What family does this animal belong to?',
  animalImage: { mimeType: 'image/jpeg', data: image },
})

console.log('>', res)



================================================
FILE: src/examples/openai-responses.ts
================================================
import { AxAI, AxGen, AxSignature } from '@ax-llm/ax'

// Create a simple text generator with a signature
const textGenSignature = new AxSignature(
  `userPrompt:string -> generatedText:string`
)

const textGenerator = new AxGen<
  { userPrompt: string },
  { generatedText: string }
>(textGenSignature)

// Initialize the AxAIOpenAIResponses client
// Note: In production, use environment variables for API keys
const ai = new AxAI({
  name: 'openai-responses',
  apiKey: process.env.OPENAI_APIKEY as string,
})

// Use the responses API directly instead of through AxAI wrapper
// This avoids the name validation issue in AxAI

// If images are provided as command line arguments, analyze them
async function main() {
  //   Simple text generation example
  console.log('=== Text Generation Example ===')
  const prompt = 'Write a haiku about artificial intelligence'
  console.log(`Prompt: ${prompt}`)

  const textResult = await textGenerator.forward(
    ai,
    { userPrompt: prompt },
    { debug: false }
  )
  console.log(`Response: ${JSON.stringify(textResult, null, 2)}`)
  console.log()

  // Demonstrate streaming capability
  console.log('\n=== Streaming Example ===')
  const streamingPrompt =
    'Explain quantum computing in short like 5 short points'
  console.log(`Prompt: ${streamingPrompt}`)

  // Use streaming with direct access to the responses API
  const generator = textGenerator.streamingForward(ai, {
    userPrompt: streamingPrompt,
  })

  console.log('Streaming response:')
  try {
    for await (const res of generator) {
      console.log(JSON.stringify(res, null, 2))
    }
    console.log('\n')
  } catch (error) {
    console.error('Error during streaming:', error)
  }
}

// Run the examples
main().catch(console.error)



================================================
FILE: src/examples/package.json
================================================
{
  "name": "@ax-llm/ax-examples",
  "version": "11.0.61",
  "private": true,
  "type": "module",
  "description": "Examples for the Ax LLM Framework",
  "repository": {
    "type": "git",
    "url": "https://github.com/ax-llm/ax.git"
  },
  "license": "Apache-2.0",
  "keywords": [],
  "scripts": {
    "test": "run-s test:*",
    "test:type-check": "tsc --noEmit",
    "test:lint": "eslint .",
    "test:format": "prettier --check \"**/*.{ts,json,md}\"",
    "fix": "run-s fix:*",
    "fix:lint": "eslint --fix",
    "fix:format": "prettier --write \"**/*.{ts,json,md}\"",
    "tsx": "node --env-file=.env --import=tsx"
  },
  "dependencies": {
    "@ax-llm/ax": "12.0.8",
    "@opentelemetry/exporter-trace-otlp-http": "^0.201.1",
    "@opentelemetry/resources": "^2.0.1",
    "@opentelemetry/sdk-trace-base": "^2.0.1",
    "@pipedream/sdk": "^1.6.4"
  },
  "bugs": {
    "url": "https://github.com/@ax-llm/ax/issues"
  },
  "homepage": "https://github.com/@ax-llm/ax#readme",
  "author": "Vikram <https://twitter.com/dosco>"
}



================================================
FILE: src/examples/prime.ts
================================================
import { AxAI, AxAIGoogleGeminiModel, AxGen, AxSignature } from '@ax-llm/ax'
import type { AxFieldProcessor } from '@ax-llm/ax/dsp/fieldProcessor.js'

// Field processor that executes the code in a sandboxed environment.
async function executeCodeProcessor(code: string) {
  if (!code) {
    return
  }

  try {
    console.log('\n<running_code>\n', code, '\n</running_code>')
    let fn = new Function(code)
    let result = fn()
    console.log('\n\n<result>\n', result, '\n</result>')
    return result
  } catch (e) {
    return `Error executing code: ${(e as Error).message}`
  }
}

// Define a signature.  Crucially, the *result* is a string.
const sig = new AxSignature(`
    "This is a two-step process:
    1. First, provide code to solve the task. The user will execute this code and return the result.
    2. Then, using the execution result, provide a friendly, conversational explanation of what was discovered.
  
    Example:
    Task: What's the sum of numbers 1-100?
    Step 1 - Return Code: 
      print(sum(range(1, 101)))
    Step 2 (after receiving result 5050): 
      The numbers add up to 5,050! That's about the same as saving a dollar a day for 14 years."
  
    primeTask:string -> code!:code "Code that will be executed by the user to solve the task", 
    answerMessage?:string "A friendly message explaining the findings, created after receiving the code's execution result"
  `)

// Create the AxGen instance.
const gen = new AxGen<{ primeTask: string }>(sig, {})

// Register the field processor.
gen.addFieldProcessor(
  'code',
  executeCodeProcessor as AxFieldProcessor['process']
)

// Initialize the AI service.
const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string, // Ensure this is set!
  config: { model: AxAIGoogleGeminiModel.Gemini20Flash }, //Not stream.
})

ai.setOptions({ debug: true })

// Run generation with a task to check if a large number is prime.
const res = await gen.forward(ai, {
  primeTask:
    'Generate a JavaScript function `isPrime` that efficiently checks if a given number is prime.  Then, call that function with the number 170141183460469 and return the result. The last line of the result must be a return statement.',
})

console.log('Final result:', res)



================================================
FILE: src/examples/rag-docs.ts
================================================
import { AxAI, AxApacheTika, AxDBManager, AxDBMemory } from '@ax-llm/ax'

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

const db = new AxDBMemory()

const tika = new AxApacheTika()

const text = await tika.convert(['./README.md'])

const manager = new AxDBManager({ ai, db })
await manager.insert(text, {
  minWordsPerChunk: 50,
  maxWordsPerChunk: 100,
})

const matches = await manager.query('Explain semantic routing')
const topMatch = matches.at(0)

console.log(topMatch)



================================================
FILE: src/examples/rag.ts
================================================
import { AxAI, AxChainOfThought, AxRAG } from '@ax-llm/ax'

// simulated vector db call using an llm
const fetchFromVectorDB = async (query: string) => {
  const cot = new AxChainOfThought<{ query: string }, { answer: string }>(
    'query -> answer'
  )
  const { answer } = await cot.forward(ai, { query })
  return answer
}

const rag = new AxRAG(fetchFromVectorDB, { maxHops: 3 })

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

const res = await rag.forward(ai, {
  context: [],
  question:
    'List 3 of the top most important work done by Michael Stonebraker?',
})

console.log(res)



================================================
FILE: src/examples/react.ts
================================================
import { AxAI, AxChainOfThought } from '@ax-llm/ax'

const values = {
  question: 'What is the weather like in tokyo?',
}

const functions = [
  {
    name: 'getCurrentWeather',
    description: 'get the current weather for a location',
    parameters: {
      type: 'object' as const,
      properties: {
        location: {
          type: 'string',
          description: 'location to get weather for',
        },
        units: {
          type: 'string',
          enum: ['imperial', 'metric'],
          default: 'imperial',
          description: 'units to use',
        },
      },
      required: ['location'],
    },

    func: async (args: Readonly<{ location: string; units: string }>) => {
      return `The weather in ${args.location} is 72 degrees`
    },
  },
]

const cot = new AxChainOfThought(`question:string -> answer:string`, {
  functions,
})

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

const res = await cot.forward(ai, values)
console.log(res)



================================================
FILE: src/examples/reasoning-o3-example.ts
================================================
#!/usr/bin/env node

import { AxAI, AxAIOpenAIResponsesModel, AxGen, AxSignature } from '@ax-llm/ax'

// Mathematical reasoning example with o3
async function runMathExample() {
  console.log('📝 Example 1: Mathematical reasoning with o3')
  console.log('----------------------------------------')

  try {
    const ai = new AxAI({
      name: 'openai-responses',
      apiKey: process.env.OPENAI_APIKEY || '',
      config: {
        model: AxAIOpenAIResponsesModel.O3,
        reasoningEffort: 'medium',
        temperature: 0.7,
        stream: false,
      },
    })

    console.log(`🤖 Using model: ${AxAIOpenAIResponsesModel.O3}`)
    console.log('🔧 Reasoning effort: medium')

    const signature = new AxSignature(
      `question:string -> answer:string "step-by-step solution", thought:string "reasoning process", usage:string "model usage stats"`
    )

    const gen = new AxGen<
      { question: string },
      { answer: string; thought?: string; usage?: string }
    >(signature)

    const result = await gen.forward(ai, {
      question:
        'Solve this step by step: If a train travels 120 km in 1.5 hours, and then increases its speed by 20 km/h for the next 2 hours, what is the total distance traveled?',
    })

    console.log('✅ Response:')
    console.log(result.answer)

    if (result.thought) {
      console.log('\n🧠 Reasoning process:')
      console.log(result.thought)
    }

    console.log('\n📊 Usage:')
    if (result.usage) {
      console.log(result.usage)
    } else {
      console.log('  Usage stats not available')
    }
  } catch (error: Error | unknown) {
    const errorMessage = error instanceof Error ? error.message : String(error)
    if (errorMessage.includes('400') || errorMessage.includes('Bad Request')) {
      console.log('⚠️  o3 model not yet available on this API key')
      console.log('   This is expected - o3 is in limited preview')
    } else {
      console.error('❌ Error:', errorMessage)
    }
  }
}

// Code generation example with o4-mini
async function runCodeExample() {
  console.log('\n📝 Example 2: Code generation with o4-mini')
  console.log('-------------------------------------------')

  try {
    const ai = new AxAI({
      name: 'openai-responses',
      apiKey: process.env.OPENAI_APIKEY || '',
      config: {
        model: AxAIOpenAIResponsesModel.O4Mini,
        reasoningEffort: 'low',
        temperature: 0.3,
        stream: false,
      },
    })

    console.log(`🤖 Using model: ${AxAIOpenAIResponsesModel.O4Mini}`)
    console.log('🔧 Reasoning effort: low')

    const signature = new AxSignature(
      `task:string -> code:string "typescript function", explanation:string "how it works", thought:string "reasoning process"`
    )

    const gen = new AxGen<
      { task: string },
      { code: string; explanation: string; thought?: string }
    >(signature)

    const result = await gen.forward(ai, {
      task: 'Create a TypeScript function that calculates the factorial of a number using recursion',
    })

    console.log('✅ Code generated:')
    console.log(result.code)
    console.log('\n📖 Explanation:')
    console.log(result.explanation)

    if (result.thought) {
      console.log('\n🧠 Reasoning process:')
      console.log(result.thought)
    }
  } catch (error: Error | unknown) {
    const errorMessage = error instanceof Error ? error.message : String(error)
    if (errorMessage.includes('400') || errorMessage.includes('Bad Request')) {
      console.log('⚠️  o4-mini model not yet available on this API key')
      console.log('   This is expected - o4 models are in limited preview')
    } else {
      console.error('❌ Error:', errorMessage)
    }
  }
}

// Logic reasoning example with o3-mini
async function runLogicExample() {
  console.log('\n📝 Example 3: Logic reasoning with o3-mini')
  console.log('------------------------------------------')

  try {
    const ai = new AxAI({
      name: 'openai-responses',
      apiKey: process.env.OPENAI_APIKEY || '',
      config: {
        model: AxAIOpenAIResponsesModel.O3Mini,
        reasoningEffort: 'high',
        temperature: 0.1,
        stream: false,
      },
    })

    console.log(`🤖 Using model: ${AxAIOpenAIResponsesModel.O3Mini}`)
    console.log('🔧 Reasoning effort: high')

    const signature = new AxSignature(
      `premise:string -> conclusion:string "logical deduction", confidence:string "high, medium, low", thought:string "reasoning process"`
    )

    const gen = new AxGen<
      { premise: string },
      { conclusion: string; confidence: string; thought?: string }
    >(signature)

    const result = await gen.forward(ai, {
      premise:
        'All birds can fly. Penguins are birds. However, penguins cannot fly. What logical conclusion can we draw?',
    })

    console.log('✅ Logical conclusion:')
    console.log(result.conclusion)
    console.log('\n🎯 Confidence:', result.confidence)

    if (result.thought) {
      console.log('\n🧠 Reasoning process:')
      console.log(result.thought)
    }
  } catch (error: Error | unknown) {
    const errorMessage = error instanceof Error ? error.message : String(error)
    if (errorMessage.includes('400') || errorMessage.includes('Bad Request')) {
      console.log('⚠️  o3-mini model not yet available on this API key')
      console.log('   This is expected - o3 models are in limited preview')
    } else {
      console.error('❌ Error:', errorMessage)
    }
  }
}

async function main() {
  console.log('🧠 OpenAI Responses API with o3/o4 Models Example')
  console.log('==================================================')

  if (!process.env.OPENAI_APIKEY) {
    console.error('❌ Please set OPENAI_APIKEY environment variable')
    process.exit(1)
  }

  // Run all examples
  await runMathExample()
  await runCodeExample()
  await runLogicExample()

  console.log('\n🎉 Examples complete!')
  console.log('\nℹ️  Available reasoning models:')
  console.log(`  • ${AxAIOpenAIResponsesModel.O3} - Advanced reasoning model`)
  console.log(
    `  • ${AxAIOpenAIResponsesModel.O3Mini} - Efficient reasoning model`
  )
  console.log(
    `  • ${AxAIOpenAIResponsesModel.O4Mini} - Latest mini reasoning model`
  )
  console.log('\n📚 These models are currently in limited preview.')
  console.log('   Contact OpenAI for access to o3/o4 models.')
}

main().catch(console.error)



================================================
FILE: src/examples/show-thoughts.ts
================================================
import {
  AxAI,
  AxAIGoogleGeminiModel,
  AxAIOpenAIResponsesModel,
  AxGen,
} from '@ax-llm/ax'

// Example demonstrating the showThoughts feature
// This allows you to see the model's reasoning process

const main = async () => {
  // For Gemini: includeThoughts config controls reasoning visibility
  const gemini = new AxAI({
    name: 'google-gemini',
    apiKey: process.env.GOOGLE_APIKEY || '',
    config: {
      model: AxAIGoogleGeminiModel.Gemini25Flash,
      thinking: {
        // Can be set at the AI level as default
        includeThoughts: false, // Default to false, will be overridden per request
      },
    },
  })

  // For OpenAI Responses API: encrypted_content provides reasoning when requested
  // Note: Regular OpenAI chat API doesn't support showThoughts, only the Responses API does
  const openaiResponses = new AxAI({
    name: 'openai-responses',
    apiKey: process.env.OPENAI_APIKEY || '',
    config: {
      model: AxAIOpenAIResponsesModel.O1,
    },
  })

  const signature = `question:string -> answer:string "thoughtful response"`

  const gen = new AxGen(signature, {
    // Custom field name for thoughts (optional, defaults to "thought")
    thoughtFieldName: 'reasoning',
  })

  const question = {
    question:
      'How would you solve the traveling salesman problem for 5 cities?',
  }

  console.log('=== Example: Gemini with showThoughts enabled ===')
  try {
    const resultWithThoughts = await gen.forward(gemini, question, {
      showThoughts: true, // Enable reasoning visibility
    })

    console.log('Answer:', resultWithThoughts.answer)
    console.log(
      'Reasoning:',
      resultWithThoughts.reasoning || 'No reasoning provided'
    )
  } catch (error) {
    console.log('Gemini error:', error instanceof Error ? error.message : error)
  }

  console.log('\n=== Example: Gemini with showThoughts disabled ===')
  try {
    const resultWithoutThoughts = await gen.forward(gemini, question, {
      showThoughts: false, // Disable reasoning visibility
    })

    console.log('Answer:', resultWithoutThoughts.answer)
    console.log(
      'Reasoning:',
      resultWithoutThoughts.reasoning || 'No reasoning provided'
    )
  } catch (error) {
    console.log('Gemini error:', error instanceof Error ? error.message : error)
  }

  // Check if OpenAI API key is available and if the API supports showThoughts
  if (process.env.OPENAI_APIKEY) {
    console.log(
      '\n=== Example: OpenAI Responses API with showThoughts enabled ==='
    )
    try {
      const openaiResultWithThoughts = await gen.forward(
        openaiResponses,
        question,
        {
          showThoughts: true, // Request encrypted_content in the response
        }
      )

      console.log('Answer:', openaiResultWithThoughts.answer)
      console.log(
        'Reasoning:',
        openaiResultWithThoughts.reasoning || 'No reasoning provided'
      )
    } catch (error) {
      console.log(
        'OpenAI Responses API error:',
        error instanceof Error ? error.message : error
      )
    }

    console.log(
      '\n=== Example: OpenAI Responses API with showThoughts disabled ==='
    )
    try {
      const openaiResultWithoutThoughts = await gen.forward(
        openaiResponses,
        question,
        {
          showThoughts: false, // Don't request encrypted_content
        }
      )

      console.log('Answer:', openaiResultWithoutThoughts.answer)
      console.log(
        'Reasoning:',
        openaiResultWithoutThoughts.reasoning || 'No reasoning provided'
      )
    } catch (error) {
      console.log(
        'OpenAI Responses API error:',
        error instanceof Error ? error.message : error
      )
    }
  } else {
    console.log('\n=== OpenAI Examples Skipped ===')
    console.log(
      'OPENAI_APIKEY not provided. Set it to see OpenAI Responses API examples.'
    )
  }

  console.log('\n=== Example: Streaming with showThoughts ===')
  try {
    const stream = gen.streamingForward(gemini, question, {
      showThoughts: true,
    })

    console.log('Streaming response:')
    for await (const chunk of stream) {
      if (chunk.delta.reasoning) {
        console.log('💭 Reasoning chunk:', chunk.delta.reasoning)
      }
      if (chunk.delta.answer) {
        console.log('💬 Answer chunk:', chunk.delta.answer)
      }
    }
  } catch (error) {
    console.log(
      'Streaming error:',
      error instanceof Error ? error.message : error
    )
  }

  console.log('\n=== Example: thinkingTokenBudget="none" constraint ===')
  try {
    const resultWithNoneThinking = await gen.forward(gemini, question, {
      thinkingTokenBudget: 'none', // This automatically sets showThoughts to false
      showThoughts: true, // This will be overridden to false due to thinkingTokenBudget="none"
    })

    console.log('Answer:', resultWithNoneThinking.answer)
    console.log(
      'Reasoning:',
      resultWithNoneThinking.reasoning ||
        'No reasoning provided (expected when thinkingTokenBudget="none")'
    )
    console.log(
      'ℹ️ Note: showThoughts=true was overridden to false because thinkingTokenBudget="none"'
    )
  } catch (error) {
    console.log('Gemini error:', error instanceof Error ? error.message : error)
  }

  console.log('\n=== Feature Support Information ===')
  console.log('📋 APIs that support showThoughts:')
  console.log('  ✅ google-gemini (Gemini models with thinking capabilities)')
  console.log('  ✅ openai-responses (OpenAI Responses API with o1 models)')
  console.log(
    '  ❌ openai (Regular OpenAI Chat API - use openai-responses instead)'
  )
  console.log('  ❌ Most other providers (feature not yet implemented)')
  console.log('\n📋 thinkingTokenBudget constraint:')
  console.log(
    '  When thinkingTokenBudget="none", showThoughts is automatically set to false'
  )
  console.log(
    '  This ensures no thinking/reasoning content is returned when budget is disabled'
  )
}

// Error handling for missing API keys
if (!process.env.GOOGLE_APIKEY && !process.env.OPENAI_APIKEY) {
  console.log(
    'Please set GOOGLE_APIKEY and/or OPENAI_APIKEY environment variables'
  )
  console.log('Example usage:')
  console.log(
    'GOOGLE_APIKEY=your_key npm run tsx src/examples/show-thoughts.ts'
  )
  console.log(
    'GOOGLE_APIKEY=your_key OPENAI_APIKEY=your_key npm run tsx src/examples/show-thoughts.ts'
  )
  process.exit(1)
}

main().catch(console.error)



================================================
FILE: src/examples/simple-classify.ts
================================================
import { AxAI, AxSimpleClassifier, AxSimpleClassifierClass } from '@ax-llm/ax'

const customerSupport = new AxSimpleClassifierClass('customerSupport', [
  'how can I return a product?',
  'where is my order?',
  'can you help me with a refund?',
  'I need to update my shipping address',
  'my product arrived damaged, what should I do?',
])

const employeeHR = new AxSimpleClassifierClass('employeeHR', [
  'how do I request time off?',
  'where can I find the employee handbook?',
  'who do I contact for IT support?',
  'I have a question about my benefits',
  'how do I log my work hours?',
])

const salesInquiries = new AxSimpleClassifierClass('salesInquiries', [
  'I want to buy your products',
  'can you provide a quote?',
  'what are the payment options?',
  'how do I get a discount?',
  'who can I speak with for a bulk order?',
])

const technicalSupport = new AxSimpleClassifierClass('technicalSupport', [
  'how do I install your software?',
  'I’m having trouble logging in',
  'can you help me configure my settings?',
  'my application keeps crashing',
  'how do I update to the latest version?',
])

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

const classifier = new AxSimpleClassifier(ai)

await classifier.setClasses([
  customerSupport,
  employeeHR,
  salesInquiries,
  technicalSupport,
])

const r1 = await classifier.forward('I need help with my order')
const r2 = await classifier.forward('I want to know more about the company')
const r3 = await classifier.forward('I need help installing your software')
const r4 = await classifier.forward('I did not receive my order on time')
const r5 = await classifier.forward('Where can I find info about our 401k')

console.log(r1 === 'salesInquiries' ? 'PASS' : 'FAIL: ' + r1)
console.log(r2 === 'salesInquiries' ? 'PASS' : 'FAIL: ' + r2)
console.log(r3 === 'technicalSupport' ? 'PASS' : 'FAIL: ' + r3)
console.log(r4 === 'customerSupport' ? 'PASS' : 'FAIL: ' + r4)
console.log(r5 === 'employeeHR' ? 'PASS' : 'FAIL: ' + r5)



================================================
FILE: src/examples/smart-home.ts
================================================
/**
 *
 * This implementation showcases how to reimplement Lares using llmclient to demonstrate the ease of building such agents.
 * Lares is a simulation of a smart home assistant, powered by a simple AI agent.
 * It exhibits problem-solving abilities, despite its simplicity.
 *
 * For more details on emergent behavior in AI agents, see this reference:
 * https://interconnected.org/more/2024/lares/
 */

import { AxAgent, AxAI, type AxFunctionJSONSchema } from '@ax-llm/ax'

interface RoomState {
  light: boolean
}

interface HomeState {
  rooms: { [key: string]: RoomState }
  robotLocation: string
  dogLocation: string
}

const state: HomeState = {
  rooms: {
    kitchen: { light: false },
    livingRoom: { light: false },
    bedroom: { light: false },
  },
  robotLocation: 'kitchen',
  dogLocation: 'livingRoom',
}

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

const agent = new AxAgent({
  name: 'lares',
  description: 'Lares smart home assistant',
  signature: `instruction -> room:string "the room where the dog is found"`,
  functions: [
    {
      name: 'toggleLight',
      description: 'Toggle the light in a room',
      parameters: {
        type: 'object',
        properties: {
          room: { type: 'string', description: 'Room to toggle light' },
        },
        required: ['room'],
      } as AxFunctionJSONSchema,
      func: async (args) => {
        if (!args?.room) {
          throw new Error('Missing required parameter: room')
        }
        const roomState = state.rooms[args.room]
        if (roomState) {
          roomState.light = !roomState.light
          console.log(
            `Toggled light in ${args.room}: ${roomState.light ? 'on' : 'off'}`
          )
          return {
            success: true,
            light: roomState.light ? 'on' : 'off',
          }
        } else {
          return { success: false, message: 'Invalid room' }
        }
      },
    },
    {
      name: 'moveRobot',
      description: 'Move the robot to an adjacent room',
      parameters: {
        type: 'object',
        properties: {
          destination: { type: 'string', description: 'Destination room' },
        },
        required: ['destination'],
      } as AxFunctionJSONSchema,
      func: async (args: Readonly<{ destination: string }>) => {
        if (state.rooms[args.destination]) {
          state.robotLocation = args.destination
          console.log(`Moved robot to ${args.destination}`)
          return { success: true, location: args.destination }
        } else {
          return { success: false, message: 'Invalid destination' }
        }
      },
    },
    {
      name: 'lookWithRobot',
      description: 'Look with the robot in its current room',
      parameters: {
        type: 'object',
        properties: {},
      } as AxFunctionJSONSchema,
      func: async () => {
        const location = state.robotLocation
        const room = state.rooms[location]

        if (room && room.light) {
          const items = location === state.dogLocation ? ['dog'] : []
          console.log(
            `Looking in ${location}: ${items.length ? 'dog found' : 'no dog'}`
          )
          return { success: true, items }
        } else {
          console.log(`Too dark to see anything in ${location}`)
          return { success: false, message: "It's too dark to see anything" }
        }
      },
    },
  ],
})

// Initial state prompt for the LLM
const instruction = `
    You are controlling a smart home with the following rooms: kitchen, livingRoom, bedroom.
    Each room has a light that can be toggled on or off. There is a robot that can move between rooms.
    Your task is to find the dog. You can turn on lights in rooms to see inside them, and move the robot to different rooms.
    The initial state is: ${JSON.stringify({ ...state, dogLocation: 'unknown' })}.
  `

const res = await agent.forward(ai, { instruction })
console.log('Response:', res)



================================================
FILE: src/examples/streaming1.ts
================================================
import { AxAI, AxAIGoogleGeminiModel, AxChainOfThought } from '@ax-llm/ax'

// setup the prompt program
const gen = new AxChainOfThought<{ startNumber: number }>(
  `startNumber:number -> next10Numbers:number[]`
)

// add a assertion to ensure that the number 5 is not in an output field
gen.addAssert(({ next10Numbers }: Readonly<{ next10Numbers: number[] }>) => {
  return next10Numbers ? !next10Numbers.includes(5) : undefined
}, 'Numbers 5 is not allowed')

gen.addAssert(({ next10Numbers }: Readonly<{ next10Numbers: number[] }>) => {
  return next10Numbers ? !next10Numbers.includes(2) : undefined
}, 'Numbers 2 is not allowed')

// const ai = new AxAI({
//   name: 'openai',
//   apiKey: process.env.OPENAI_APIKEY as string,
// })

const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string,
  config: { model: AxAIGoogleGeminiModel.Gemini20FlashLite },
})
ai.setOptions({ debug: true })

// run the program with streaming enabled
const res = await gen.forward(ai, { startNumber: 1 })

console.log('>', res)



================================================
FILE: src/examples/streaming2.ts
================================================
import { AxAI, AxAIOpenAIModel, AxChainOfThought } from '@ax-llm/ax'

// const ai = new AxAI({
//     name: 'anthropic'
//     apiKey: process.env.ANTHROPIC_APIKEY as string
// });

// setup the prompt program
const gen = new AxChainOfThought<{ question: string }>(
  `question:string -> answerInPoints:string`
)

// add a assertion to ensure all lines start with a number and a dot.
gen.addStreamingAssert(
  'answerInPoints',
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  (value: string, _done?: boolean) => {
    const re = /^\d+\./

    // split the value by lines, trim each line,
    // filter out very short lines and check if all lines match the regex
    return value
      .split('\n')
      .map((x) => x.trim())
      .filter((x) => x.length > 4)
      .every((x) => re.test(x))
  },
  'Lines must start with a number and a dot. Eg: 1. This is a line.'
)

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
  config: { model: AxAIOpenAIModel.GPT4OMini },
})
ai.setOptions({ debug: true })

// run the program with streaming enabled
const res = await gen.forward(ai, {
  question:
    'Provide a list of 3 optimizations to speedup LLM inference. Keep it short a few words each',
})

console.log('>', res)



================================================
FILE: src/examples/streaming3.ts
================================================
import { AxAI, AxAIGoogleGeminiModel, AxChainOfThought } from '@ax-llm/ax'

// Setup the prompt program for movie reviews
const gen = new AxChainOfThought<{ movieTitle: string }>(
  `movieTitle:string -> 
   rating:number,
   genres:string[], 
   strengths:string[], 
   weaknesses:string[], 
   recommendedAudience:string,
   verdict:string`
)

// Assert rating is between 1 and 10
gen.addAssert(({ rating }: Readonly<{ rating: number }>) => {
  if (!rating) return undefined
  return rating >= 1 && rating <= 10
}, 'Rating must be between 1 and 10')

// Assert there are between 1-3 genres
gen.addAssert(({ genres }: Readonly<{ genres: string[] }>) => {
  if (!genres) return undefined
  return genres.length >= 1 && genres.length <= 3
}, 'Must specify between 1-3 genres')

// Assert strengths and weaknesses are balanced (similar length arrays)
gen.addAssert(
  ({
    strengths,
    weaknesses,
  }: Readonly<{ strengths: string[]; weaknesses: string[] }>) => {
    if (!strengths || !weaknesses) return undefined
    const diff = Math.abs(strengths.length - weaknesses.length)
    return diff <= 1
  },
  'Review should be balanced with similar number of strengths and weaknesses'
)

// Assert verdict is not too short
gen.addAssert(({ verdict }: Readonly<{ verdict: string }>) => {
  if (!verdict) return undefined
  return verdict.length >= 50
}, 'Verdict must be at least 50 characters')

// Assert recommended audience doesn't mention specific age numbers
gen.addAssert(
  ({ recommendedAudience }: Readonly<{ recommendedAudience: string }>) => {
    if (!recommendedAudience) return undefined
    return !/\d+/.test(recommendedAudience)
  },
  'Use age groups (e.g. "teens", "adults") instead of specific ages'
)

const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string,
  config: { model: AxAIGoogleGeminiModel.Gemini20FlashLite },
})

// const ai = new AxAI({
//   name: 'openai',
//   apiKey: process.env.OPENAI_APIKEY as string,
//   config: { model: AxAIOpenAIModel.GPT4OMini },
// })
// ai.setOptions({ debug: true })

// Run the program
const generator = await gen.streamingForward(ai, {
  movieTitle: 'The Grand Budapest Hotel',
})

for await (const res of generator) {
  console.log(res)
}



================================================
FILE: src/examples/summarize.ts
================================================
import { AxAI, AxAIGoogleGeminiModel, AxGen, AxSignature } from '@ax-llm/ax'

// const ai = new AxAI({ name: 'ollama', model: 'nous-hermes2' });

const signature = new AxSignature(`\
    updates:string[] \
    -> \
    summary:string, summaryTitle:string, shortSummary:string`)

const gen = new AxGen<
  { updates: string[] },
  { summary: string; summaryTitle: string; shortSummary: string }
>(signature)
gen.setExamples([
  {
    updates: [
      'title: PPG Santa Monica Class Schedule Update summary: Ping Pong For Good modified their class schedule in Santa Monica due to the Santa Monica YMCA community center room being used as a resource center. Mondays are postponed until further notice, and Fridays are now 1 pm-2:15 pm at the Santa Monica YMCA indoor basketball court. Members unable to attend Fridays can temporarily suspend their membership by emailing info@pingpongforgood.org. Sponsorship opportunities are available for additional tables at alternate locations.',
      'title: Major League Table Tennis Matches in Pomona – Jan 17-19, 2025 | 20% Off Tickets! summary: Major League Table Tennis (MLTT) is having matches in Pomona, CA from January 17-19, 2025 at the Pomona Fairplex. Tickets can be purchased at https://mltt.com/tickets/pomona2025/ with a 20% discount using code PPFG.',
      'title: Open Play Session at Santa Monica College  summary: Open play session at Santa Monica College on Sunday, January 26, 2025 from 12:00-1:30pm. The cost is $6 (cash preferred).',
    ],
    summaryTitle:
      'Ping Pong For Good Updates: Schedule Changes, MLTT Pomona Matches, & Open Play',
    summary:
      'Ping Pong For Good (PPG) announces updates affecting their Santa Monica classes (Mondays postponed, Fridays relocated & times adjusted), a 20% discount on Major League Table Tennis (MLTT) matches in Pomona (Jan 17-19, 2025), and an open play session at Santa Monica College on January 26, 2025. PPG members affected by the schedule changes can temporarily suspend their memberships. Sponsorship opportunities are also available for PPG.',
    shortSummary:
      'Ping Pong For Good (PPG) announces updates affecting their Santa Monica Class, MLTT Pomona Matches, & Open Play Session',
  },
])

// gen.addAssert(({ reason }: Readonly<{ reason: string }>) => {
//   if (!reason) return true
//   return !reason.includes('goat')
// }, 'Reason should not contain "the"')

// Example with OpenAI using custom labels in place of model names
// const ai = new AxAI({
//   name: 'openai',
//   apiKey: process.env.OPENAI_APIKEY as string,
//   config: { model: 'model-a' },
//   models: [
//     {
//       key: 'model-a',
//       model: AxAIOpenAIModel.GPT4OMini,
//       description: 'A model that is good for general purpose',
//     },
//   ],
// })

const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string,
  config: { maxTokens: 1000, model: AxAIGoogleGeminiModel.Gemini20FlashLite },
})
// ai.setOptions({ debug: true })

// const generator = gen.streamingForward(ai, { noteText })

// console.log('## Streaming')

// for await (const res of generator) {
//   console.log(res)
// }

const updates = [
  `Title: Purrfect Playtime Schedule Change at Cat Cafe
Summary: The Purrfect Paws Cat Cafe has adjusted its daily playtime schedule due to renovations in the main lounge. Monday cuddle sessions are temporarily paused, and Friday afternoon play sessions are now from 3:00 PM to 4:15 PM in the newly renovated sunroom. Customers unable to attend the Friday slot can request a temporary pause on their reservation package by emailing purr@purrfectpaws.com. Sponsorships for additional cat trees and toys at alternative locations are available.`,

  `Title: National Feline Agility Competition in Pasadena – Feb 22-24, 2025 | 15% Off Tickets!
Summary: The National Feline Agility Competition (NFAC) is hosting its championship event in Pasadena, CA from February 22-24, 2025 at the Pasadena Convention Center. Tickets can be purchased at https://nationalfelineagility.com/tickets/pasadena2025/ with a 15% discount using the code MEOW15.`,

  `Title: Open Cat Social Hour at Westwood Animal Shelter
Summary: Open cat social hour at the Westwood Animal Shelter on Sunday, February 2, 2025 from 2:00 PM to 3:30 PM. A $5 donation is requested (cash donations preferred).`,
]

console.log('## Streaming')

const generator = gen.streamingForward(ai, { updates })

for await (const res of generator) {
  console.log(res)
}

console.log('\n\n## Not Streaming')

const res = await gen.forward(ai, { updates })
console.log(res)



================================================
FILE: src/examples/telemetry.ts
================================================
import { AxAI, AxAIGoogleGeminiModel, AxGen } from '@ax-llm/ax'
import { trace } from '@opentelemetry/api'
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http'
import {
  defaultResource,
  resourceFromAttributes,
} from '@opentelemetry/resources'
import {
  BasicTracerProvider,
  BatchSpanProcessor,
} from '@opentelemetry/sdk-trace-base'
import {
  ATTR_SERVICE_NAME,
  ATTR_SERVICE_VERSION,
} from '@opentelemetry/semantic-conventions'

/*
Start Jaeger on http://localhost:16686 (Web UI)

docker run --rm --name jaeger \
  -p 16686:16686 \
  -p 4317:4317 \
  -p 4318:4318 \
  -p 5778:5778 \
  -p 9411:9411 \
  jaegertracing/jaeger:2.6.0

*/

// Configure OTLP exporter
const otlpExporter = new OTLPTraceExporter({
  url: 'http://localhost:4318/v1/traces', // OTLP HTTP endpoint
})

// Configure BatchSpanProcessor
const spanProcessor = new BatchSpanProcessor(otlpExporter)

const resource = defaultResource().merge(
  resourceFromAttributes({
    [ATTR_SERVICE_NAME]: 'ax-examples',
    [ATTR_SERVICE_VERSION]: '0.0.0',
  })
)

// Set up OpenTelemetry with OTLP
const provider = new BasicTracerProvider({
  spanProcessors: [spanProcessor],
  resource,
})

// Register the provider globally
trace.setGlobalTracerProvider(provider)

const tracer = trace.getTracer('text-classification-example')

// Initialize AI with tracer
const ai = new AxAI({
  name: 'google-gemini',
  apiKey: process.env.GOOGLE_APIKEY as string,
  config: {
    model: 'gemini-2.5-flash-preview-04-17' as AxAIGoogleGeminiModel,
    thinking: { includeThoughts: true },
  },
  options: { debug: false, tracer },
  modelInfo: [
    {
      name: 'gemini-2.5-flash-preview-04-17',
      hasThinkingBudget: true,
    },
  ],
})

// Create a text classifier using Ax
const classifier = new AxGen<
  { textToClassify: string },
  { category: string; confidence: number }
>(
  `textToClassify:string "The text to classify" -> 
   category:string "The category of the text (business, technology, sports, entertainment, or politics)",
   confidence:number "Confidence score between 0 and 1"`
)

classifier.setExamples([
  { textToClassify: 'Apple', category: 'business', confidence: 0.95 },
  {
    textToClassify: 'The latest AI breakthrough enables robots to learn',
    category: 'technology',
    confidence: 0.9,
  },
  { textToClassify: 'Politics', category: 'politics', confidence: 0.8 },
  {
    textToClassify: 'Entertainment',
    category: 'entertainment',
    confidence: 0.75,
  },
])

// Example texts to classify
const texts = [
  "Apple's stock price surged 5% after announcing record iPhone sales",
  'The latest AI breakthrough enables robots to learn from human demonstrations',
  'Manchester United wins dramatic match against Liverpool in injury time',
]

async function main() {
  console.log('Starting text classification with OpenTelemetry tracing...\n')

  try {
    for (const textToClassify of texts) {
      const result = await classifier.forward(
        ai,
        { textToClassify },
        { traceLabel: 'Classifier', thinkingTokenBudget: 'low' }
      )

      console.log('Result:', result)
      console.log('---\n')
    }
  } finally {
    await provider.forceFlush()

    // wait for 3 seconds to ensure all traces are flushed
    console.log('Waiting for 3 seconds to ensure all traces are flushed...')
    await new Promise((resolve) => setTimeout(resolve, 1000))

    await provider.shutdown()
    console.log('OpenTelemetry provider shut down.')
  }
}

main().catch(console.error)



================================================
FILE: src/examples/template-signatures.ts
================================================
import { AxAI, AxChainOfThought, f, s } from '@ax-llm/ax'

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

console.log('=== Tagged Template Literals for AxSignatures ===\n')

// Example 1: Basic tagged template signature
console.log('1. Basic tagged template signature:')
const basicSig = s`userQuestion:string -> responseText:string`
console.log('Signature:', basicSig.toString())
console.log(
  'Input fields:',
  basicSig.getInputFields().map((f) => f.name)
)
console.log(
  'Output fields:',
  basicSig.getOutputFields().map((f) => f.name)
)
console.log()

// Example 2: Using field builders for type-safe field creation
console.log('2. Using field builders:')
const sentimentSig = s`
  inputText:${f.string('Text to analyze')} -> 
  sentimentCategory:${f.class(['positive', 'negative', 'neutral'], 'Sentiment classification')},
  confidenceScore:${f.number('Confidence score 0-1')}
`
console.log('Signature:', sentimentSig.toString())
console.log(
  'Sentiment field options:',
  sentimentSig.getOutputFields()[0]?.type?.options
)
console.log()

// Example 3: Complex multi-field signature with arrays and modifiers
console.log('3. Complex signature with arrays and modifiers:')
const complexSig = s`
  "Extract structured information from customer feedback"
  customerFeedback:${f.string('Customer feedback text')} ->
  extractedTopics:${f.array(f.string())},
  urgencyLevel:${f.class(['low', 'medium', 'high'])},
  actionItems:${f.array(f.string())},
  internalReasoning:${f.internal(f.string('Internal reasoning process'))},
  followUpRequired:${f.optional(f.boolean('Whether follow-up is needed'))}
`
console.log('Signature:', complexSig.toString())
console.log('Description:', complexSig.getDescription())
console.log(
  'Extracted topics field is array:',
  complexSig.getOutputFields()[0]?.type?.isArray
)
console.log(
  'Internal reasoning field is internal:',
  complexSig.getOutputFields()[3]?.isInternal
)
console.log(
  'Follow-up field is optional:',
  complexSig.getOutputFields()[4]?.isOptional
)
console.log()

// Example 4: Using with AxChainOfThought
console.log('4. Using tagged template with AxChainOfThought:')
const cot = new AxChainOfThought(s`
  contextInfo:${f.array(f.string('Context information'))},
  userQuestion:${f.string('Question to answer')} ->
  detailedAnswer:${f.string('Detailed answer')},
  sourceReferences:${f.array(f.string('Source references'))}
`)

const cotResult = await cot.forward(ai, {
  contextInfo: [
    'Paris is the capital of France and its largest city.',
    'France is located in Western Europe.',
    'The Seine River flows through Paris.',
  ],
  userQuestion:
    'What is the capital of France and what river flows through it?',
})

console.log('Chain of Thought Result:')
console.log('Answer:', cotResult.detailedAnswer)
console.log('Sources:', cotResult.sourceReferences)
console.log()

// Example 5: Code generation signature
console.log('5. Code generation signature:')
const codeSig = s`
  problemDescription:${f.string('Programming problem description')} ->
  pythonSolution:${f.code('python', 'Python code solution')},
  solutionExplanation:${f.string('Explanation of the solution')},
  timeComplexity:${f.class(['O(1)', 'O(log n)', 'O(n)', 'O(n log n)', 'O(n²)'], 'Time complexity')}
`
console.log('Signature:', codeSig.toString())
console.log(
  'Python solution field type:',
  codeSig.getOutputFields()[0]?.type?.name
)
console.log(
  'Python solution field language:',
  codeSig.getOutputFields()[0]?.type?.options?.[0]
)
console.log()

// Example 6: Date and datetime fields
console.log('6. Date and datetime fields:')
const eventSig = s`
  eventDescription:${f.string('Event description')} ->
  scheduledDate:${f.date('Event date')},
  createdTimestamp:${f.datetime('Creation timestamp')},
  isRecurringEvent:${f.boolean('Whether event repeats')}
`
console.log('Signature:', eventSig.toString())
console.log()

// Example 7: JSON field for structured data
console.log('7. JSON field for structured data:')
const jsonSig = s`
  rawInputData:${f.string('Raw input data')} ->
  structuredOutput:${f.json('Structured JSON output')},
  isValidData:${f.boolean('Whether data is valid')}
`
console.log('Signature:', jsonSig.toString())
console.log()

// Example 8: Chaining field modifiers
console.log('8. Chaining field modifiers:')
const chainedSig = s`
  inputText:${f.string('Input text')} ->
  primaryResults:${f.array(f.string('Main results'))},
  secondaryResults:${f.optional(f.array(f.string('Optional secondary results')))},
  debugInformation:${f.internal(f.optional(f.json('Internal debug information')))}
`
console.log('Signature:', chainedSig.toString())
console.log(
  'Secondary results - optional array:',
  chainedSig.getOutputFields()[1]?.isOptional &&
    chainedSig.getOutputFields()[1]?.type?.isArray
)
console.log(
  'Debug information - internal optional JSON:',
  chainedSig.getOutputFields()[2]?.isInternal &&
    chainedSig.getOutputFields()[2]?.isOptional &&
    chainedSig.getOutputFields()[2]?.type?.name === 'json'
)
console.log()

// Example 9: Comparison with string-based signature
console.log('9. Comparison with traditional string signature:')
const stringSig =
  'userQuestion:string -> responseText:string, confidenceScore:number'
const templateSig = s`userQuestion:string -> responseText:string, confidenceScore:number`

console.log('String signature:', stringSig)
console.log('Template signature:', templateSig.toString())
console.log('Are equivalent:', stringSig === templateSig.toString())
console.log()

console.log('=== Tagged Template Literals Demo Complete ===')



================================================
FILE: src/examples/thinking-token-budget.ts
================================================
import { ax, f } from '@ax-llm/ax'
import { AxAIGoogleGemini } from '@ax-llm/ax/ai/google-gemini/api.js'

console.log('=== Configurable Thinking Token Budget Levels Demo ===\n')

// Example 1: Default thinking token budget levels
console.log('1. Default thinking token budget levels:')
const defaultAI = new AxAIGoogleGemini({
  apiKey: process.env.GOOGLE_APIKEY!,
})

const reasoningGenerator = ax`
  question:${f.string('Complex reasoning question')} -> 
  answer:${f.string('Detailed answer with reasoning')}
`

try {
  const defaultResult = await reasoningGenerator.forward(
    defaultAI,
    {
      question:
        'Explain the concept of recursion in programming with examples.',
    },
    { thinkingTokenBudget: 'medium' }
  )
  console.log(
    'Default medium level result length:',
    (defaultResult.answer as string)?.length || 0
  )
} catch {
  console.log('Default levels example skipped (no API key)')
}
console.log()

// Example 2: Custom thinking token budget levels
console.log('2. Custom thinking token budget levels:')
const customAI = new AxAIGoogleGemini({
  apiKey: process.env.GOOGLE_APIKEY!,
  config: {
    thinkingTokenBudgetLevels: {
      minimal: 50, // Very minimal reasoning
      low: 200, // Light reasoning
      medium: 1000, // Moderate reasoning
      high: 5000, // Extensive reasoning
      highest: 15000, // Maximum reasoning (within limits)
    },
  },
})

try {
  const customResult = await reasoningGenerator.forward(
    customAI,
    {
      question:
        'Explain the concept of recursion in programming with examples.',
    },
    { thinkingTokenBudget: 'medium' }
  )
  console.log(
    'Custom medium level result length:',
    (customResult.answer as string)?.length || 0
  )
} catch {
  console.log('Custom levels example skipped (no API key)')
}
console.log()

// Example 3: Comparing different levels
console.log('3. Comparing different thinking levels:')
const comparisonAI = new AxAIGoogleGemini({
  apiKey: process.env.GOOGLE_APIKEY!,
  config: {
    thinkingTokenBudgetLevels: {
      minimal: 100,
      low: 500,
      medium: 2000,
      high: 8000,
      highest: 20000,
    },
  },
})

const simpleQuestion = 'What is 2 + 2?'

try {
  console.log('Testing different thinking levels for the same question...')

  const minimalResult = await reasoningGenerator.forward(
    comparisonAI,
    { question: simpleQuestion },
    { thinkingTokenBudget: 'minimal' }
  )
  console.log(
    '- Minimal level answer length:',
    (minimalResult.answer as string)?.length || 0
  )

  const highResult = await reasoningGenerator.forward(
    comparisonAI,
    { question: simpleQuestion },
    { thinkingTokenBudget: 'high' }
  )
  console.log(
    '- High level answer length:',
    (highResult.answer as string)?.length || 0
  )
} catch {
  console.log('Level comparison example skipped (no API key)')
}
console.log()

// Example 4: Using with showThoughts
console.log('4. Using with showThoughts:')
const thoughtsAI = new AxAIGoogleGemini({
  apiKey: process.env.GOOGLE_APIKEY!,
  config: {
    thinkingTokenBudgetLevels: {
      minimal: 150,
      low: 600,
      medium: 2500,
      high: 10000,
      highest: 24000,
    },
  },
})

try {
  const thoughtsResult = await reasoningGenerator.forward(
    thoughtsAI,
    { question: 'Why is the sky blue?' },
    {
      thinkingTokenBudget: 'high',
      showThoughts: true,
    }
  )
  console.log('High level with thoughts enabled')
  console.log(
    '- Answer length:',
    (thoughtsResult.answer as string)?.length || 0
  )
  console.log('- Has reasoning thoughts:', !!thoughtsResult.thought)
} catch {
  console.log('ShowThoughts example skipped (no API key)')
}
console.log()

// Example 5: Disabling thinking with 'none'
console.log('5. Disabling thinking with "none":')
try {
  const noThinkingResult = await reasoningGenerator.forward(
    thoughtsAI,
    { question: 'What is the capital of France?' },
    {
      thinkingTokenBudget: 'none',
      showThoughts: true, // This will be overridden to false
    }
  )
  console.log('No thinking level result')
  console.log(
    '- Answer length:',
    (noThinkingResult.answer as string)?.length || 0
  )
  console.log('- Has reasoning thoughts:', !!noThinkingResult.thought)
  console.log('- Note: showThoughts was automatically disabled')
} catch {
  console.log('No thinking example skipped (no API key)')
}
console.log()

console.log('=== Configurable Thinking Token Budget Levels Demo Complete ===')
console.log('')
console.log('Usage examples:')
console.log('- const ai = new AxAIGoogleGemini({')
console.log('    config: {')
console.log('      thinkingTokenBudgetLevels: {')
console.log('        minimal: 100,')
console.log('        low: 500,')
console.log('        medium: 2000,')
console.log('        high: 8000,')
console.log('        highest: 20000,')
console.log('      }')
console.log('    }')
console.log('  })')
console.log(
  '- await generator.forward(ai, input, { thinkingTokenBudget: "medium" })'
)



================================================
FILE: src/examples/tsconfig.json
================================================
{
  "extends": ["../../tsconfig.json"],
  "compilerOptions": {
    "target": "ES2022",
    "module": "NodeNext"
  }
}



================================================
FILE: src/examples/use-examples.ts
================================================
import { AxAI, AxGen } from '@ax-llm/ax'

// Create a text classifier with multiple output fields
const classifier = new AxGen<
  { contentToClassify: string },
  { category: string; confidence: number; reasoning?: string }
>(
  `contentToClassify:string "The text content that needs to be classified" -> 
   category:class "news, tech, sports, entertainment" "The category of the text",
   confidence:number "Confidence score between 0 and 1",
   reasoning?:string "Optional reasoning for the classification"`
)

console.log(
  JSON.stringify(classifier.getSignature().getOutputFields(), null, 2)
)

// Examples can have missing fields - all fields are now optional in examples
classifier.setExamples([
  {
    contentToClassify:
      'Apple announces new iPhone with revolutionary AI features',
    category: 'tech',
    confidence: 0.95,
    reasoning: 'Clear technology product announcement',
  },
  {
    contentToClassify: 'Lakers win championship in dramatic overtime victory',
    category: 'sports',
    confidence: 0.9,
    // Missing reasoning - this is now allowed!
  },
  {
    contentToClassify: 'Breaking: Major policy changes announced in Congress',
    category: 'news',
    confidence: 0.92,
    // Missing reasoning - this is now allowed!
  },
  {
    contentToClassify: 'New blockbuster movie breaks box office records',
    category: 'entertainment',
    confidence: 0.96,
    reasoning: 'Entertainment industry news about movie performance',
  },
])

// Initialize AI
const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
  options: { debug: true },
})

// Test the classification
const result = await classifier.forward(ai, {
  contentToClassify: 'Scientists discover quantum computing breakthrough',
})

console.log('Classification result:', result)



================================================
FILE: src/examples/vectordb.ts
================================================
import { AxAI, AxDBManager, AxDBMemory } from '@ax-llm/ax'

/* cSpell:disable */
const text = `The technological singularity—or simply the singularity[1]—is a hypothetical future point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable consequences for human civilization.[2][3] According to the most popular version of the singularity hypothesis, I. J. Good's intelligence explosion model, an upgradable intelligent agent will eventually enter a positive feedback loop of self-improvement cycles, each new and more intelligent generation appearing more and more rapidly, causing a rapid increase ("explosion") in intelligence which ultimately results in a powerful superintelligence that qualitatively far surpasses all human intelligence.[4]

One of the most successful early gastromancers was Eurykles, a prophet at Athens; gastromancers came to be referred to as Euryklides in his honour.[3] Other parts of the world also have a tradition of ventriloquism for ritual or religious purposes; historically there have been adepts of this practice among the Zulu, Inuit, and Māori peoples.[3]
`

const ai = new AxAI({
  name: 'openai',
  apiKey: process.env.OPENAI_APIKEY as string,
})

const db = new AxDBMemory()

const manager = new AxDBManager({ ai, db })

await manager.insert(text)

const res = await manager.query(
  'John von Neumann on human intelligence and singularity.'
)
console.log(res)



================================================
FILE: .circleci/config.yml
================================================
# https://circleci.com/docs/2.0/language-javascript/
version: 2
jobs:
  'node-10':
    docker:
      - image: circleci/node:10
    steps:
      - checkout
      # Download and cache dependencies
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "package.json" }}
            # fallback to using the latest cache if no exact match is found
            - v1-dependencies-
      - run: npm install
      - save_cache:
          paths:
            - node_modules
          key: v1-dependencies-{{ checksum "package.json" }}
      - run: npm test
      - run: npm run cov:send
      - run: npm run cov:check
  'node-12':
    docker:
      - image: circleci/node:12
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "package.json" }}
            - v1-dependencies-
      - run: npm install
      - save_cache:
          paths:
            - node_modules
          key: v1-dependencies-{{ checksum "package.json" }}
      - run: npm test
      - run: npm run cov:send
      - run: npm run cov:check
  'node-latest':
    docker:
      - image: circleci/node:latest
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "package.json" }}
            - v1-dependencies-
      - run: npm install
      - save_cache:
          paths:
            - node_modules
          key: v1-dependencies-{{ checksum "package.json" }}
      - run: npm test
      - run: npm run cov:send
      - run: npm run cov:check

workflows:
  version: 2
  build:
    jobs:
      - 'node-10'
      - 'node-12'
      - 'node-latest'



================================================
FILE: .cspell/project-words.txt
================================================
# New Words
agentic
apicall
APIKEY
APITOKEN
APIURL
asig
astro
astrojs
bootstrapper
Buena
chrono
chunker
codellama
Codellama
codestral
Codestral
commandline
companys
countrys
datetime
davinci
Davinci
dedup
deepseek
distractor
dosco
fewshot
fres
frontmatter
fstate
googleauth
groq
Groq
Hono
huggingface
Jiro
jwtx
Kita
llmclient
logit
Logit
Logprob
logprobs
Logprobs
Macbook
MCPHTTP
minibatch
minilm
mipro
Mixtral
modelcontextprotocol
modelinfo
multiservice
nanos
nemo
Nemo
neumann
ollama
onopentag
ontext
openai
OPENAI
Opentable
opentelemetry
parisienne
pegjs
postbuild
qsig
région
reka
rerank
reranker
retryable
retval
sandboxed
sdata
shadcn
Signture
sstate
Stonebraker
stopwords
Streamable
strutil
subjobs
Sukiyabashi
superintelligence
textembedding
tika
trainset
tsimp
tsup
upsert
upserted
usecase
uuidv
valset
vectordb
vectorize
Vikram
weaviate
Weaviate
xlarge
xstate
minibatching
minibatches
appendable
MCPHTTPSSE
Streamble
deepwiki
chatbots
Evals
hypervolume
axgen
checkpointing


================================================
FILE: .cursor/rules/default.mdc
================================================
---
description: 
globs: 
alwaysApply: true
---
# Ax LLM Framework - Cursor Rules

## Project Overview
Ax is a TypeScript framework for building LLM-powered agents with end-to-end streaming, multi-modal DSPy capabilities, and typed signatures. It provides a standard interface across all top LLMs with features like prompt compilation, native streaming, agent orchestration, RAG, vector databases, and automatic prompt tuning.

## Repository Structure
This is a **multi-repository monorepo** with the following structure:
- `src/ax/` - Main Ax library (`@ax-llm/ax`)
- `src/ai-sdk-provider/` - Vercel AI SDK provider (`@ax-llm/ax-ai-sdk-provider`)
- `src/examples/` - Example implementations (`@ax-llm/ax-examples`)
- `src/docs/` - Documentation site (`@ax-llm/ax-docs`)

Each sub-repository under `src/` has its own `package.json` and can be developed independently.

## Package Management
**IMPORTANT**: Use workspace-specific package installation commands:

```bash
# Install packages in specific workspaces
npm i <package-name> --workspace=@ax-llm/ax
npm i <package-name> --workspace=@ax-llm/ax-ai-sdk-provider
npm i <package-name> --workspace=@ax-llm/ax-examples
npm i <package-name> --workspace=@ax-llm/ax-docs

# Examples:
npm i typescript --workspace=@ax-llm/ax
npm i react --workspace=@ax-llm/ax-docs
npm i lodash --workspace=@ax-llm/ax-examples
```

**DO NOT** run `npm install` in individual sub-directories. Always use workspace commands from the root.

## Testing
- **Test Framework**: Vitest (configured in root)
- **Run Tests**: `npx vitest` or `npm run test`
- **Run Tests for Specific Workspace**: `npm run test --workspace=@ax-llm/ax`
- **Watch Mode**: `npx vitest --watch`
- **Coverage**: `npx vitest --coverage`

## Development Commands
```bash
# Build all workspaces
npm run build

# Run tests across all workspaces
npm run test

# Fix formatting and linting
npm run fix

# Run examples with tsx
npm run tsx ./src/examples/<example-file>.ts

# Development mode for specific workspace
npm run dev --workspace=@ax-llm/ax
```

## Demo Creation Guidelines
**KEEP DEMOS SIMPLE AND DIRECT** - No unnecessary abstractions or complexity:

### Structure
- **Top-level code**: Put all code at the top level, no function wrappers
- **Direct execution**: Code should run immediately when file is executed
- **No try-catch blocks**: It's just a demo, don't add error handling clutter
- **No IIFE wrappers**: Top-level await works fine with modern Node.js/tsx
- **Minimal console logs**: Only essential output, avoid verbose logging
- **No fallback logic**: Keep examples clean and focused on the main functionality

### Code Style
- **Export reusable components**: Export generators, signatures, or functions that other examples might use
- **Save minimal data**: Only save essential data (like demos), not complex config objects
- **Import and reuse**: Import exported components in other examples rather than recreating them
- **Clean separation**: Optimize once, save demos, use anywhere

### LLM Judge Pattern
When using LLM judges in metric functions, use factory functions with closure:
```typescript
// Create judge generator
const judgeGen = ax`
  original:${f.string('Original text')} ->
  candidate:${f.string('Candidate to evaluate')} ->
  expected:${f.string('Expected result')} ->
  score:${f.number('Quality score 0-1')}
`

// Create metric function factory
const createMetric = (judgeAI: AxAI): AxMetricFn => {
  return async ({ prediction, example }) => {
    const result = await judgeGen.forward(judgeAI, {
      original: example.original,
      candidate: prediction.output,
      expected: example.expected
    })
    return result.score as number
  }
}

// Use the metric
const metric = createMetric(ai)
```

### Example Pattern
```typescript
// Export reusable generator
export const myGen = ax`input:${f.string('User input')} -> output:${f.string('AI response')}`

// Top-level execution - no function wrappers
console.log('=== Demo ===')

const ai = new AxAI({ name: 'openai', apiKey: process.env.OPENAI_APIKEY! })
const result = await myGen.forward(ai, { input: 'test' })

// Save only essential data
await fs.writeFile('demos.json', JSON.stringify(demos, null, 2))
```

### Key Principles
- **It just works**: Don't overthink it, modern Node.js handles top-level await fine
- **No abstractions**: Avoid function wrappers, IIFEs, or unnecessary error handling
- **Focus on functionality**: Show the core feature, not error handling patterns
- **Reusable components**: Export what others might want to import and use
- **Minimal persistence**: Save only what's needed, not metadata or complex configs
- **Clean and direct**: No try-catch blocks, minimal logging, no fallback complexity

## Code Standards & Architecture

### TypeScript Configuration
- Uses `@total-typescript/tsconfig` as base
- ES Modules (`"type": "module"`)
- NodeNext module resolution
- Path mapping: `@ax-llm/*` → `src/*`
- React JSX support

### Key Architectural Patterns

#### 1. Prompt Signatures & Template Literals
Ax uses a unique prompt signature system with **modern template literal support**:

**PREFERRED: Template Literals with Field Builders**
```typescript
import { ax, s, f } from '@ax-llm/ax'

// Using the `s` template literal for signatures
const signature = s`
  userQuestion:${f.string('User input')} -> 
  responseText:${f.string('AI response')},
  confidenceScore:${f.number('Confidence 0-1')}
`

// Using the `ax` template literal for AxGen instances
const generator = ax`
  emailText:${f.string('Email content')} -> 
  categoryType:${f.class(['urgent', 'normal', 'low'], 'Priority level')},
  actionItems:${f.array(f.string('Required actions'))}
`
```

**Legacy: String-based signatures (discouraged for new code)**
```typescript
// Format: "task description" inputField:type "field description" -> outputField:type
const signature = `userQuestion -> responseText:string "detailed response"`
const signature = `emailText -> categoryType:class "urgent, normal, low", actionItems:string[]`
```

**Field Types & Builders**:
- **Basic types**: `f.string()`, `f.number()`, `f.boolean()`, `f.date()`, `f.datetime()`, `f.json()`
- **Media types**: `f.image()`, `f.audio()`
- **Classifications**: `f.class(['option1', 'option2'], 'description')`
- **Code blocks**: `f.code('python', 'description')`
- **Arrays**: `f.array(f.string())`, `f.array(f.number())`, etc.
- **Modifiers**: `f.optional(f.string())`, `f.internal(f.string())`, chaining: `f.optional(f.array(f.string()))`
- **Field names should be descriptive**: `emailText` not `text`, `userQuestion` not `question`

**Template Literal Advantages**:
- Type-safe field creation with IntelliSense
- Cleaner, more readable syntax
- Supports field interpolation and complex structures
- Better error messages and validation
- Consistent with modern JavaScript/TypeScript patterns

#### 2. Core Components
- **AxAI**: Main AI interface supporting 15+ LLM providers
- **AxChainOfThought**: Chain-of-thought reasoning
- **AxAgent**: Agent framework with inter-agent communication
- **AxDB**: Vector database abstraction (Memory, Weaviate, Pinecone, Cloudflare)
- **AxDBManager**: Smart chunking, embedding, and querying

#### 3. Streaming & Multi-modal
- Native end-to-end streaming
- Multi-modal support (text, images, audio)
- Thinking models support with token budget control
- Real-time validation during streaming

### Code Conventions

#### Import/Export Patterns
```typescript
// Prefer named exports
export { AxAI, AxChainOfThought, AxAgent }

// Use barrel exports in sub-module index.ts files (not the main index.ts which is auto-generated)
export * from './ai/index.js'
export * from './prompts/index.js'
```

#### Async Patterns
- All LLM operations are async and support streaming
- Use async generators for streaming responses
- Implement proper cleanup for streaming connections

## File Organization

### Main Library (`src/ax/`)
- `ai/` - LLM provider implementations
- `prompts/` - Prompt signature and DSPy logic
- `agents/` - Agent framework
- `db/` - Vector database implementations
- `trace/` - OpenTelemetry integration
- `funcs/` - Function calling utilities
- `mcp/` - Model Context Protocol support

### Provider Package (`src/ai-sdk-provider/`)
- Integration with Vercel AI SDK
- Provider utilities and transformations

### Examples (`src/examples/`)
- Comprehensive examples for all features
- Each example should be runnable with `npm run tsx`
- Include proper environment variable setup
- **ALWAYS use template literals** (`ax` and `s`) in examples, not string-based signatures
- Use descriptive field names following the `emailText` not `text` pattern

## Dependencies & Constraints
- **Node.js**: >= 20
- **Runtime**: ES Modules only
- **Core Dependencies**: Minimal, zero-dependencies philosophy
- **Peer Dependencies**: Handle LLM SDKs as peer deps where possible
- **Browser Compatibility**: **CRITICAL** - Do not add filesystem calls (`fs`, `path`, `os`) or other Node.js-specific APIs to the main library (`src/ax/`). The library must run in browser environments. Use only web-standard APIs and platform-agnostic code. Node.js-specific functionality should be in examples or separate utility packages.

## Testing Guidelines
- Write tests in `.test.ts` files
- Use Vitest for unit testing
- Test streaming scenarios
- Mock LLM providers for deterministic tests
- Include type-level tests in `.test-d.ts` files

## Documentation
- TypeDoc for API documentation
- Markdown documentation in `src/docs/`
- Examples serve as living documentation
- Include prompt signature examples in code comments

## Security & Best Practices
- Never commit API keys
- Use environment variables for configuration
- Validate all inputs, especially in streaming contexts
- Implement proper rate limiting and error recovery
- Follow principle of least privilege for LLM permissions

## Performance Considerations
- Optimize for streaming performance
- Minimize token usage through smart prompting
- Cache embeddings and model responses where appropriate
- Use connection pooling for database operations
- Profile memory usage in long-running streams

## OpenTelemetry Integration
- Built-in `gen_ai` semantic conventions support
- Trace all LLM operations
- Include custom spans for agent interactions
- Export traces in production environments

## Environment Setup
```bash
# Required environment variables (examples)
OPENAI_APIKEY=your_key_here
GOOGLE_APIKEY=your_key_here
ANTHROPIC_APIKEY=your_key_here

# Optional for specific features
WEAVIATE_URL=http://localhost:8080
PINECONE_API_KEY=your_key_here
```

## Common Patterns
1. **Creating AI Instance**: Always start with `new AxAI({ name: 'provider', apiKey: '...' })`
2. **Template Literals**: **PREFER** using `ax` and `s` template literals over string-based signatures
3. **Field Creation**: Use `f.string()`, `f.class()`, etc. instead of raw type strings
4. **Signature Design**: Keep signatures simple and descriptive with meaningful field names
5. **Agent Composition**: Agents can call other agents for complex workflows
6. **Streaming Handling**: Always handle both success and error states in streams
7. **Type Safety**: Leverage TypeScript's type system for prompt validation

## Build & Release
- Uses `tsup` for building
- Automated versioning with `standard-version`
- Multi-workspace publishing with `release-it`
- GitHub Actions for CI/CD
- **Auto-generated Files**: `index.ts` in the main library is auto-generated by running `npm run build:index --workspace=@ax-llm/ax`

## Template Literal Best Practices
- **Always prefer** `ax` template literals over `new AxGen()` for creating generators
- **Always prefer** `s` template literals over `new AxSignature()` for creating signatures
- **Import pattern**: `import { ax, s, f } from '@ax-llm/ax'`
- **Field naming**: Use descriptive names like `userQuestion`, `emailText`, `responseText`
- **Type safety**: Leverage `f.string()`, `f.class()`, etc. for better IntelliSense and validation
- **Complex fields**: Chain modifiers like `f.optional(f.array(f.string('descriptions')))`

## Documentation Guidelines
- When implementing big new features, **ask to update the README.md** with examples and documentation
- Include the new feature in the feature list and provide clear usage examples
- Update TypeDoc comments for new APIs
- Add corresponding examples in `src/examples/` for new functionality
- **When creating new examples, always add them to the examples table in README.md** with a clear description
- **ALL examples must use template literals** (`ax`, `s`, `f`) instead of string-based signatures

Remember: This is a production-ready library used by startups in production. Maintain high code quality, comprehensive testing, and backward compatibility. 


================================================
FILE: .github/CONTRIBUTING.md
================================================
# Example Contributing Guidelines

This is an example of GitHub's contributing guidelines file. Check out GitHub's [CONTRIBUTING.md help center article](https://help.github.com/articles/setting-guidelines-for-repository-contributors/) for more information.



================================================
FILE: .github/dependabot.yml
================================================
# .github/dependabot.yml
version: 2
updates:
  # Root package.json
  - package-ecosystem: 'npm'
    directory: '/'
    schedule:
      interval: 'weekly'
      day: 'monday'
    open-pull-requests-limit: 10
    versioning-strategy: increase
    groups:
      typescript-eslint:
        patterns:
          - '@typescript-eslint/*'
      dev-dependencies:
        dependency-type: 'development'

  # Your ax-llm/ax package in src directory
  - package-ecosystem: 'npm'
    directory: '/src/ax' # Adjusted to match your src/* workspace pattern
    schedule:
      interval: 'weekly'
      day: 'monday'
    groups:
      typescript-eslint:
        patterns:
          - '@typescript-eslint/*'
      dev-dependencies:
        dependency-type: 'development'

  # GitHub Actions
  - package-ecosystem: 'github-actions'
    directory: '/'
    schedule:
      interval: 'weekly'
      day: 'monday'
    commit-message:
      prefix: 'ci'
      include: 'scope'



================================================
FILE: .github/ISSUE_TEMPLATE.md
================================================
- **I'm submitting a ...**
  [ ] bug report
  [ ] feature request
  [ ] question about the decisions made in the repository
  [ ] question about how to use this project

- **Summary**

- **Other information** (e.g. detailed explanation, stack traces, related issues, suggestions how to fix, links for us to have context, eg. StackOverflow, personal fork, etc.)



================================================
FILE: .github/PULL_REQUEST_TEMPLATE.md
================================================
- **What kind of change does this PR introduce?** (Bug fix, feature, docs update, ...)

- **What is the current behavior?** (You can also link to an open issue here)

- **What is the new behavior (if this is a feature change)?**

- **Other information**:



================================================
FILE: .github/workflows/npm-publish.yml
================================================
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://docs.github.com/en/actions/publishing-packages/publishing-nodejs-packages

name: Publish Package to npmjs
on:
  release:
    types: [published]
jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4
      # Setup .npmrc file to publish to npm
      - uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          registry-url: 'https://registry.npmjs.org'
      - run: npm ci
      - run: npm run publish
        env:
          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}



================================================
FILE: .github/workflows/pull-request-ci.yml
================================================
name: Pull Request CI

on:
  pull_request:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x' # You can specify your desired Node.js version
      - name: Install dependencies
        run: npm ci



================================================
FILE: .github/workflows/static.yml
================================================
# Simple workflow for deploying static content to GitHub Pages
name: Deploy static content to Pages

on:
  # Runs on pushes targeting the default branch
  push:
    branches: ['main']

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: 'pages'
  cancel-in-progress: false

jobs:
  # Single deploy job since we're just deploying
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          registry-url: 'https://registry.npmjs.org'
      - run: npm ci
      - run: npm run doc:build
      - name: Setup Pages
        uses: actions/configure-pages@v5
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          # Upload entire repository
          path: './src/docs/dist'
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4


